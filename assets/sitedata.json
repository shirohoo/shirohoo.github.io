


{
  "pages": [
    {
      
      
      
      "content": "\n",
      "url": "/404.html"
    },{
      
      "title": "<u>About Me</u>",
      "description": "A brief introduction to my development experience and projects.\n\n",
      "content": "\n\nExperience\n\n\n  \n    2012.04 ~ 2020.07 : 산업기능요원 + 프로그래밍과 무관한 타 업종 근무\n  \n  \n    2020.08 ~ 2021.01 : 컴퓨터과학 독학\n  \n  \n    2021.02 ~ : 소프트웨어 엔지니어로 근무 중\n  \n\n\n\n",
      "url": "/about/"
    },{
      
      "title": "<u>자료구조와 알고리즘</u>",
      "description": "컴퓨터 과학 이론 - 자료구조와 알고리즘에 대해 정리합니다\n",
      "content": "\n  컴퓨터 과학\n\n\n",
      "url": "/cs/data-structure-algorithm/"
    },{
      
      "title": "<u>데이터베이스 구축</u>",
      "description": "컴퓨터 과학 이론 - 데이터베이스에 대해 정리합니다\n",
      "content": "\n  컴퓨터 과학\n\n\n",
      "url": "/cs/database-construct/"
    },{
      
      "title": "<u>Database</u>",
      "description": "데이터베이스에 대해 정리합니다\n",
      "content": "\n  BackEnd\n\n\n",
      "url": "/backend/database/"
    },{
      
      "title": "<u>Gradle</u>",
      "description": "Gradle은 Maven을 잇는 현존 최고의 빌드 도구입니다.\n",
      "content": "\n  BackEnd\n\n\n",
      "url": "/backend/gradle/"
    },{
      
      "title": "<u>Groovy</u>",
      "description": "Gradle에 활발하게 사용되고 있는 Groovy에 대해 정리합니다\n",
      "content": "\n  BackEnd\n\n\n",
      "url": "/backend/groovy/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/"
    },{
      
      "title": "<u>정보시스템 구축</u>",
      "description": "컴퓨터 과학 이론 - 정보시스템 구축에 대해 정리합니다\n",
      "content": "\n  컴퓨터 과학\n\n\n",
      "url": "/cs/information-system/"
    },{
      
      "title": "<u>IntelliJ</u>",
      "description": "Summarize the IDE(Integrated Development Environment) - JetBrain’s IntelliJ\n",
      "content": "\n  IDE\n\n\n",
      "url": "/ide/intellij/"
    },{
      
      "title": "<u>Java</u>",
      "description": "Java에 대해 정리합니다\n",
      "content": "\n  BackEnd\n\n\n",
      "url": "/backend/java/"
    },{
      
      "title": "<u>Javascript</u>",
      "description": "Summarize the Javascript\n",
      "content": "\n  FrontEnd\n\n\n",
      "url": "/frontend/javascript/"
    },{
      
      "title": "<u>프로그래밍 활용</u>",
      "description": "컴퓨터 과학 이론 - 프로그래밍에 대해 정리합니다\n",
      "content": "\n  컴퓨터 과학\n\n\n",
      "url": "/cs/leverage-programming/"
    },{
      
      "title": "<u>운영체제</u>",
      "description": "컴퓨터 과학 이론 - 운영체제에 대해 정리합니다\n",
      "content": "\n  컴퓨터 과학\n\n\n",
      "url": "/cs/operating-system/"
    },{
      
      "title": "<u>Python</u>",
      "description": "Python에 대해 정리합니다\n",
      "content": "\n  BackEnd\n\n\n",
      "url": "/backend/python/"
    },{
      
      "title": "<u>Server Side</u>",
      "description": "서버에서 일어나는 일들에 대해 정리합니다\n",
      "content": "\n  BackEnd\n\n\n",
      "url": "/backend/server-side/"
    },{
      
      "title": "<u>소프트웨어 설계</u>",
      "description": "컴퓨터 과학 이론 - 소프트웨어 설계에 대해 정리합니다\n",
      "content": "\n  컴퓨터 과학\n\n\n",
      "url": "/cs/software-design/"
    },{
      
      "title": "<u>Spring Batch</u>",
      "description": "Spring Batch에 대해 정리합니다\n",
      "content": "\n  Spring\n\n\n",
      "url": "/spring/spring-batch/"
    },{
      
      "title": "<u>Spring Boot</u>",
      "description": "Spring Boot에 대해 정리합니다\n",
      "content": "\n  Spring\n\n\n",
      "url": "/spring/spring-boot/"
    },{
      
      "title": "<u>Spring Cloud</u>",
      "description": "Spring Cloud에 대해 정리합니다\n",
      "content": "\n  Spring\n\n\n",
      "url": "/spring/spring-cloud/"
    },{
      
      "title": "<u>Spring Data Jpa</u>",
      "description": "Spring Data Jpa에 대해 정리합니다\n",
      "content": "\n  Spring\n\n\n",
      "url": "/spring/spring-data-jpa/"
    },{
      
      "title": "<u>Spring MVC</u>",
      "description": "Spring MVC에 대해 정리합니다\n",
      "content": "\n  Spring\n\n\n",
      "url": "/spring/spring-mvc/"
    },{
      
      "title": "<u>Spring Security</u>",
      "description": "Spring Security에 대해 정리합니다\n",
      "content": "\n  Spring\n\n\n",
      "url": "/spring/spring-security/"
    },{
      
      "title": "<u>Spring WebFlux</u>",
      "description": "Spring WebFlux에 대해 정리합니다\n",
      "content": "\n  Spring\n\n\n",
      "url": "/spring/spring-webflux/"
    },{
      
      "title": "<u>Test</u>",
      "description": "Test와 관련된 내용들에 대해 정리합니다\n",
      "content": "\n  BackEnd\n\n\n",
      "url": "/backend/test/"
    },{
      
      "title": "<u>Vue.js</u>",
      "description": "Summarize the Vue.js\n",
      "content": "\n  FrontEnd\n\n\n",
      "url": "/frontend/vue/"
    },{
      
      
      
      "content": "GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\nCopyright (C) 2007 Free Software Foundation, Inc. https://fsf.org/\nEveryone is permitted to copy and distribute verbatim copies\nof this license document, but changing it is not allowed.\n\n                        Preamble\n\n\nThe GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\nThe licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program–to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\nWhen we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\nTo protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\nFor example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\nDevelopers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\nFor the developers’ and authors’ protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users’ and\nauthors’ sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\nSome devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users’ freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\nFinally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\nThe precise terms and conditions for copying, distribution and\nmodification follow.\n\n                   TERMS AND CONDITIONS\n\n\n\n  Definitions.\n\n\n“This License” refers to version 3 of the GNU General Public License.\n\n“Copyright” also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n“The Program” refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as “you”.  “Licensees” and\n“recipients” may be individuals or organizations.\n\nTo “modify” a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a “modified version” of the\nearlier work or a work “based on” the earlier work.\n\nA “covered work” means either the unmodified Program or a work based\non the Program.\n\nTo “propagate” a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\nTo “convey” a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\nAn interactive user interface displays “Appropriate Legal Notices”\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n\n  Source Code.\n\n\nThe “source code” for a work means the preferred form of the work\nfor making modifications to it.  “Object code” means any non-source\nform of a work.\n\nA “Standard Interface” means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\nThe “System Libraries” of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n“Major Component”, in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\nThe “Corresponding Source” for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work’s\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\nThe Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\nThe Corresponding Source for a work in source code form is that\nsame work.\n\n\n  Basic Permissions.\n\n\nAll rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\nYou may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\nConveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n\n  Protecting Users’ Legal Rights From Anti-Circumvention Law.\n\n\nNo covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\nWhen you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work’s\nusers, your or third parties’ legal rights to forbid circumvention of\ntechnological measures.\n\n\n  Conveying Verbatim Copies.\n\n\nYou may convey verbatim copies of the Program’s source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\nYou may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n\n  Conveying Modified Source Versions.\n\n\nYou may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\na) The work must carry prominent notices stating that you modified\nit, and giving a relevant date.\n\nb) The work must carry prominent notices stating that it is\nreleased under this License and any conditions added under section\n7.  This requirement modifies the requirement in section 4 to\n\"keep intact all notices\".\n\nc) You must license the entire work, as a whole, under this\nLicense to anyone who comes into possession of a copy.  This\nLicense will therefore apply, along with any applicable section 7\nadditional terms, to the whole of the work, and all its parts,\nregardless of how they are packaged.  This License gives no\npermission to license the work in any other way, but it does not\ninvalidate such permission if you have separately received it.\n\nd) If the work has interactive user interfaces, each must display\nAppropriate Legal Notices; however, if the Program has interactive\ninterfaces that do not display Appropriate Legal Notices, your\nwork need not make them do so.\n\n\nA compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n“aggregate” if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation’s users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n\n  Conveying Non-Source Forms.\n\n\nYou may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\na) Convey the object code in, or embodied in, a physical product\n(including a physical distribution medium), accompanied by the\nCorresponding Source fixed on a durable physical medium\ncustomarily used for software interchange.\n\nb) Convey the object code in, or embodied in, a physical product\n(including a physical distribution medium), accompanied by a\nwritten offer, valid for at least three years and valid for as\nlong as you offer spare parts or customer support for that product\nmodel, to give anyone who possesses the object code either (1) a\ncopy of the Corresponding Source for all the software in the\nproduct that is covered by this License, on a durable physical\nmedium customarily used for software interchange, for a price no\nmore than your reasonable cost of physically performing this\nconveying of source, or (2) access to copy the\nCorresponding Source from a network server at no charge.\n\nc) Convey individual copies of the object code with a copy of the\nwritten offer to provide the Corresponding Source.  This\nalternative is allowed only occasionally and noncommercially, and\nonly if you received the object code with such an offer, in accord\nwith subsection 6b.\n\nd) Convey the object code by offering access from a designated\nplace (gratis or for a charge), and offer equivalent access to the\nCorresponding Source in the same way through the same place at no\nfurther charge.  You need not require recipients to copy the\nCorresponding Source along with the object code.  If the place to\ncopy the object code is a network server, the Corresponding Source\nmay be on a different server (operated by you or a third party)\nthat supports equivalent copying facilities, provided you maintain\nclear directions next to the object code saying where to find the\nCorresponding Source.  Regardless of what server hosts the\nCorresponding Source, you remain obligated to ensure that it is\navailable for as long as needed to satisfy these requirements.\n\ne) Convey the object code using peer-to-peer transmission, provided\nyou inform other peers where the object code and Corresponding\nSource of the work are being offered to the general public at no\ncharge under subsection 6d.\n\n\nA separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\nA “User Product” is either (1) a “consumer product”, which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, “normally used” refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n“Installation Information” for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\nIf you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\nThe requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\nCorresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n\n  Additional Terms.\n\n\n“Additional permissions” are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\nWhen you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\nNotwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\na) Disclaiming warranty or limiting liability differently from the\nterms of sections 15 and 16 of this License; or\n\nb) Requiring preservation of specified reasonable legal notices or\nauthor attributions in that material or in the Appropriate Legal\nNotices displayed by works containing it; or\n\nc) Prohibiting misrepresentation of the origin of that material, or\nrequiring that modified versions of such material be marked in\nreasonable ways as different from the original version; or\n\nd) Limiting the use for publicity purposes of names of licensors or\nauthors of the material; or\n\ne) Declining to grant rights under trademark law for use of some\ntrade names, trademarks, or service marks; or\n\nf) Requiring indemnification of licensors and authors of that\nmaterial by anyone who conveys the material (or modified versions of\nit) with contractual assumptions of liability to the recipient, for\nany liability that these contractual assumptions directly impose on\nthose licensors and authors.\n\n\nAll other non-permissive additional terms are considered “further\nrestrictions” within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\nIf you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\nAdditional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n\n  Termination.\n\n\nYou may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\nHowever, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\nMoreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\nTermination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n\n  Acceptance Not Required for Having Copies.\n\n\nYou are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n\n  Automatic Licensing of Downstream Recipients.\n\n\nEach time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\nAn “entity transaction” is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party’s predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\nYou may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n\n  Patents.\n\n\nA “contributor” is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor’s “contributor version”.\n\nA contributor’s “essential patent claims” are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, “control” includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\nEach contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor’s essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\nIn the following three paragraphs, a “patent license” is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To “grant” such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\nIf you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  “Knowingly relying” means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient’s use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\nIf, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\nA patent license is “discriminatory” if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\nNothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n\n  No Surrender of Others’ Freedom.\n\n\nIf conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n\n  Use with the GNU Affero General Public License.\n\n\nNotwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n\n  Revised Versions of this License.\n\n\nThe Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\nEach version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License “or any later version” applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\nIf the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy’s\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\nLater license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n\n  Disclaimer of Warranty.\n\n\nTHERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM “AS IS” WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n\n  Limitation of Liability.\n\n\nIN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n\n  Interpretation of Sections 15 and 16.\n\n\nIf the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                 END OF TERMS AND CONDITIONS\n\n        How to Apply These Terms to Your New Programs\n\n\nIf you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\nTo do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe “copyright” line and a pointer to where the full notice is found.\n\nshirohoo`s Blog Copyright (C) 2022  Changhun Han\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License or any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program. If not, see &lt;https://www.gnu.org/licenses/&gt;.\n\n\nAlso add information on how to contact you by electronic and paper mail.\n\nIf the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\nshirohoo`s Blog  Copyright (C) 2022  Changhun Han\nThis program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\nThis is free software, and you are welcome to redistribute it\nunder certain conditions; type `show c' for details.\n\n\nThe hypothetical commands show w' and show c’ should show the appropriate\nparts of the General Public License.  Of course, your program’s commands\nmight be different; for a GUI interface, you would use an “about box”.\n\nYou should also get your employer (if you work as a programmer) or school,\nif any, to sign a “copyright disclaimer” for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\nhttps://www.gnu.org/licenses/.\n\nThe GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\nhttps://www.gnu.org/licenses/why-not-lgpl.html.\n",
      "url": "/LICENSE/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/2/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/3/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/4/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/5/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/6/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/7/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/8/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/9/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/10/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/11/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/12/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/13/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/14/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/15/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/16/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/17/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/18/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/19/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/20/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/21/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/22/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/23/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/24/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/25/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/26/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/27/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/28/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/29/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/30/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/31/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/32/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/33/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/34/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/35/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/36/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/37/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/38/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/39/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/40/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/41/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/42/"
    },{
      
      "title": "돈 받고 일하면 프로",
      "description": "우리는 직장에서 훈련을 하기 때문에 매번 실수를 반복한다\n",
      "content": "\n",
      "url": "/43/"
    }
  ], 
  "documents": [
    {
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "럼바우 분석 기법(Rumbaugh's Object Modeling Technique)",
      "date": "2020-09-22 20:16:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  럼바우 분석 기법(Rumbaugh’s Object Modeling Technique)    \n      객체 모델링(Object Modeling)\n      동적 모델링(Dynamic Modeling)\n      기능 모델링(Functional Modeling)\n    \n  \n\n\n \n\n럼바우 분석 기법(Rumbaugh’s Object Modeling Technique)\n\n소프트웨어 구성 요소를 그래픽 표기법을 이용하여 모델링하는 객체지향 분석(Object-Oriented Analysis) 기법\n\n\n  객체 모델링(Object Modeling) → 동적 모델링(Dynamic Modeling) → 기능 모델링(Functional Modeling)\n\n\n\n\n객체 모델링(Object Modeling)\n\n\n  객체 다이어그램을 이용\n  정보 모델링이라고도 함\n  시스템에서 요구되는 객체를 찾아내어 속성과 연산 식별 및 객체들 간의 관계를 규정\n  가장 중요하며 가장 선행되는 단계\n\n\n\n\n동적 모델링(Dynamic Modeling)\n\n\n  상태도를 이용\n  시간의 흐름에 따른 객체들 사이의 제어 흐름, 상호 작용, 동작 순서 등의 동적인 행위를 표현\n\n\n\n\n기능 모델링(Functional Modeling)\n\n\n  자료 흐름도(DFD, Data Flow Diagram)를 이용\n  다수의 프로세스들 간의 자료 흐름을 중심으로 처리 과정을 표현\n  어떤 데이터를 입력하면 어떤 결과를 구할 것인지 표현\n\n",
      "categories": ["cs","software-design"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/software-design/2020-09-22-rumbaugh/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "자료 흐름도(DFD, Data Flow Diagram)",
      "date": "2020-09-22 22:06:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  자료 흐름도(DFD, Data Flow Diagram)    \n      프로세스(Process)\n      자료 흐름(Flow)\n      자료 저장소(Data Store)\n      단말(Terminator)\n    \n  \n\n\n \n\n자료 흐름도(DFD, Data Flow Diagram)\n\n럼바우 분석 기법 중 기능 모델링에 해당한다\n\n버블차트(Bubble Chart)라고도 한다\n\n\n\n프로세스(Process)\n\n\n  동그라미\n  자료를 변환시키는 처리 과정 하나를 나타냄\n  처리/기능/변환 버블이라고도 함\n\n\n\n\n자료 흐름(Flow)\n\n\n  화살표\n  자료의 이동을 나타냄\n\n\n\n\n자료 저장소(Data Store)\n\n\n  평행선(아래위만 선이 그어진 사각형)\n  파일, 데이터베이스 등 자료가 저장되는 곳을 나타냄\n\n\n\n\n단말(Terminator)\n\n\n  사각형\n  시스템과 교신하는 외부 개체\n  데이터의 입출력 주체(사용자 등)\n\n\n \n\n\n",
      "categories": ["cs","software-design"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/software-design/2020-09-22-dfd/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "S/W 생명주기 (SDLC, Software Development Life Cycle)",
      "date": "2020-09-22 22:53:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  SDLC, Software Development Life Cycle    \n      폭포수형 모델(Waterfall Model)\n      프로토타입 모델(Prototyping Model)\n      나선형 모델(Spiral Model)\n      애자일 모델(Agile Model)        \n          애자일 기반 S/W 개발 모형            \n              애자일 모델 - 스크럼(Scrum)\n              XP(eXtream Programming) 기법\n            \n          \n        \n      \n    \n  \n\n\n \n\nSDLC, Software Development Life Cycle\n\n소프트웨어 개발부터 폐기까지 전 과정을 하나의 생명주기로 정의하고 단계 별 공정을 체계화 한 모델\n\n\n\n폭포수형 모델(Waterfall Model)\n\n\n  소프트웨어 개발의 전 과정을 나누어 체계적이고 순차적으로 접근하는 방식\n  각 단계의 결과가 확인되어야지만 다음 단계로 넘어간다\n  Bohea가 제시한 고전적 생명주기 모델로 선형 순차적 모델이라고도 함\n  가장 오래된 모델로 많은 적용 사례가 있지만 요구사항의 변경이 어렵다\n\n\n\n  타당성 검토 → 계획 → 요구사항 분석 → 설계 → 구현 → 테스트 → 유지보수\n\n\n\n\n프로토타입 모델(Prototyping Model)\n\n\n  점진적으로 시스템을 개발해 나가는 접근 방식\n  프로토타입을 만들어 고객과 사용자가 함께 평가한 후 개발될 소프트웨어의 요구사항을 정제하여 보다 완전한 요구 명세서를 완성하는 방식\n  장점\n    \n      개발과정에서 사용자의 요구를 충분히 반영한다\n      최종결과물이 만들어지기 전에 의뢰자가 최종 결과물의 일부 혹은 모형을 볼 수 있다\n      의뢰자나 개발자 모두에게 공동의 참조 모델을 제공한다\n    \n  \n\n\n\n\n나선형 모델(Spiral Model)\n\n\n  폭포수 모형과 원형모형의 장점을 수용하고 위험분석을 추가한 점증적 개발모델\n  프로젝트 수행시 발생하는 위험을 관리하고 최소화하기 위한 방식\n  대규모 시스템 개발에 적합\n\n\n\n  반복 { 계획 수립 → 위험 분석 → 개발 및 검증 → 고객 평가 }\n\n\n\n\n애자일 모델(Agile Model)\n\n\n  고객의 요구사항 변화에 민첩하게 대응할 수 있도록 일정한 주기를 반복하면서 개발 진행\n  개발절차나 도구보다는 고객과의 소통에 초점을 맞춘 방법론을 의미\n  개발 주기마다 고객의 요구사항이 가장 우선시되어 개발 작업을 진행\n  소규모 프로젝트, 숙련된 개발자, 요구사항의 변화가 많은 프로젝트에 적합\n\n\n애자일 기반 S/W 개발 모형\n\n\n  스크럼 / 칸반 / Lean / 크리스탈\n  XP(eXtream Programming)\n  ASD(Adaptive S/W Development)\n  FDD(Feature Driven Development)\n  DSDM(Dynamic System Development Method)\n  DAD(Disciplined Agile Delivery)\n\n\n\n\n애자일 모델 - 스크럼(Scrum)\n\n\n  팀 중심으로 개발의 효율성을 높이는 형태\n    \n      스크럼마스터(Scrum Master) - 스크럼 회의를 주관하고 진행 사항을 점검\n      제품책임자(Product Owner) - 요구 사항을 작성하는 주체로 백로그를 작성. 프로젝트에 대한 이해도가 높아야 하며 제품 테스트를 수행하고 요구사항의 우선순위를 갱신하는 역할을 맡음\n      개발팀(Development Team) - 개발자, 디자이너, 테스터 등의 구성원\n    \n  \n\n\n \n\n\n\n \n\n\n  백로그(Backlog)\n    \n      제품 개발에 필요한 모든 요구사항을 우선순위에 따라 나열한 목록\n      백로그에 작성된 내용을 토대로 전체 일정계획을 수립\n    \n  \n  스프린트 계획 회의\n    \n      백로그 중 수행할 작업을 대상으로 단기 일정 수립\n      스토리를 개발자들이 나눠서 작업할 수 있도록 태스크 작업 단위로 분할\n      개발자별로 수행할 작업 목록인 스프린트 백로그 작성\n    \n  \n  스프린트(Sprint)\n    \n      스프린트 백로그를 토대로 2~4주 내에서 개발을 진행\n    \n  \n  일일 스크럼 회의\n    \n      팀원들이 약속된 시간 동안 진행한 태스크 상황을 점검\n    \n  \n  스크럼 검토 회의\n    \n      전체 완성 제품이 요구사항에 잘 부합되는지 검증\n      사용자가 포함된 인원 구성으로 테스트\n    \n  \n  스프린트 회고\n    \n      스프린트 주기를 훑어보며 정해놓은 규칙 준수 여부와 개선사항을 확인하고 기록\n    \n  \n\n\n\n\nXP(eXtream Programming) 기법\n\n\n  의사소통 / 단순 / 용기 / 존중 / 피드백\n  사용자의 요구사항에 유연하게 대응하기 위해 고객의 참여와 개발과정의 반복을 극대화\n  단순한 설계와 코딩, 짧고 반복적인 개발 주기, 고객의 참여를 통해 S/W를 신속히 개발하는 것이 목표\n  반복적으로 프로토타입을 고객에게 제공함으로써 고객 요구사항 변화에 신속하게 대응\n\n",
      "categories": ["cs","software-design"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/software-design/2020-09-22-sdlc/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "순수 관계 연산자(Relational Operation)",
      "date": "2020-09-23 09:46:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  순수 관계 연산자(Relational Operation)    \n      Select\n      Project(≒Product)\n      Join\n      Division\n    \n  \n\n\n \n\n순수 관계 연산자(Relational Operation)\n\n관계형 데이터베이스(RDB)에 적용 할 수 있도록 특별히 개발한 연산자를 말한다.\n\n\n  \n    \n      연산자\n      표기\n      키워드\n    \n  \n  \n    \n      Select\n      시그마(σ)\n      선택 / 수평 연산 / 시그마(σ)\n    \n    \n      Project(≒Product)\n      파이(π)\n      추출 / 수직 연산 / 파이(δ)\n    \n    \n      Join\n      보타이(⋈)\n      공통 / 합치다 / 자연 / 보타이(⋈)\n    \n    \n      Division\n      나누기(÷)\n      제외 / 나누기(÷)\n    \n  \n\n\n\n\nSelect\n\n\n  릴레이션에 존재하는 튜플 중에서 선택 조건을 만족하는 튜플의 부분집합을 구하여 새로운 릴레이션으로 만든다\n  릴레이션의 가로(행)에 해당하는 튜플을 구하는 것이므로 수평 연산자라고도 한다\n  연산자의 기호는 그리스 문자 시그마(σ)\n\n\n\n  σ 점수 &gt; 70 (학생) : 학생 릴레이션에서 점수가 70 초과인 튜플을 선택\n\n\n\n\nProject(≒Product)\n\n\n  주어진 릴레이션에서 속성 리스트(Attribute List)에 제시된 속성만을 추출하는 연산이다\n  릴레이션의 세로(열)에 해당하는 속성을 추출하는 것이므로 수직 연산자라고도 한다\n  연산자의 기호는 그리스 문자 파이(π)\n\n\n\n  π 학번, 이름 (학생) : 학생 릴레이션에서 해당하는 학번과 이름 속성을 추출\n\n\n\n\nJoin\n\n\n  공통 속성을 중심으로 2개의 릴레이션을 하나로 합쳐 새로운 릴레이션을 만드는 연산\n  조인 조건이 ‘=’ 일 때 동일한 속성이 두 번 나타나게 되는데 이 때 중복된 속성을 제거하여 같은 속성을 한 번만 표기하는 방법을 자연(Natural) 조인이라고 한다\n  연산자의 기호는 그리스 문자 보타이(⋈)\n\n\n\n  학생 ⋈ 학번 = 학번 대여 : 학생 릴레이션과 대여 릴레이션을 학번 기준으로 합체\n\n\n\n\nDivision\n\n\n  X⊃Y인 2개의 릴레이션에서 R(X)와 S(Y)가 있을 때, R의 속성이 S의 속성값을 모두 가진 튜플에서 S가 가진 속성을 제외한 속성만을 구하는 연산\n  연산자의 기호는 수학 수식 나누기(÷)\n\n\n\n  학생 학번 ÷ 학번 출석체크 : 학생 릴레이션에서 출석체크 릴레이션에 있는 학번을 구한다\n\n",
      "categories": ["cs","database-construct"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/database-construct/2020-09-23-relational-operation/"
    },{
      "image": "/assets/img/backend/db-logo.png",
      "title": "SQL 용어, 용도에 따른 분류",
      "date": "2020-09-23 10:28:00 +0000",
      "description": "이랬다 저랬다 헷갈리는 DB용어! 용어에 대해 정리합니다\n",
      "content": "\n  용어와 기초 개념    \n      릴레이션의 특징\n    \n  \n\n\n \n\n정보처리기사 2020년 4회 차 필기시험을 준비 중이다.\n\n데이터베이스 과목에서 혼용되는 용어가 있는 것 같다.\n\n찾아보니 과연 실제로는 같은 의미이지만 과정에 따라 부르는 이름이 달랐다.\n\n이에 대해 정리해본다.\n\n \n\n용어와 기초 개념\n\n\n\n\n  \n    \n      개념 데이터 모델링\n      논리 데이터 모델링\n      물리 데이터 모델링\n    \n  \n  \n    \n      레코드(Recode)\n      튜플(Tuple)\n      행(Row)\n    \n    \n      필드(Field)\n      속성(Attribute)\n      열(Column)\n    \n    \n      키(Key)\n      주 식별자(Primary Identifier)\n      기본 키(Primary Key, Unique)\n    \n    \n      키(Key)\n      외부 식별자(Foreign Identifier)\n      기본 키(Foreign Key, Unique)\n    \n    \n      파일(File)\n      릴레이션(Relation), 엔티티(Entity)\n      테이블(Table)\n    \n  \n\n\n릴레이션의 특징\n\n\n\n\n  릴레이션의 튜플들은 모두 다르며, 유일한 존재이다\n  릴레이션의 각 속성과 각 튜플 간에는 순서가 없다\n  튜플들의 삽입, 갱신, 삭제 작업이 실시간으로 일어나므로 수시로 변한다\n  속성은 원자 값만 가진다\n\n\n \n\n데이터베이스 교과서에서 릴레이션의 특징은 상기와 같은데,\n\n실제로 데이터베이스에 데이터를 입력하다 보면 종종 중복된 값이 들어가야 하는 경우가 있다.\n\n혹은 정규화가 되지 않은 경우 원자 값이 아닐 수도 있다\n\n\n  ex) 동명이인\n\n",
      "categories": ["backend","database"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/database/2020-09-23-sql-terms/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "스키마(Schema)",
      "date": "2020-09-23 10:42:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  스키마(Schema)\n  종류    \n      개념 스키마(Conceptual Schema)\n      내부 스키마(Internal Schema)\n      외부 스키마(External Schema)\n    \n  \n  설계 과정\n\n\n \n\n스키마(Schema)\n\n데이터베이스의 전체적인 구조와 제약조건에 대한 명세\n\n\n\n종류\n\n\n\n개념 스키마(Conceptual Schema)\n\n\n  논리적 관점에서 본 전체적인 데이터 구조\n  사용자들이 필요로 하는 통합 조직의 데이터베이스 구조\n  뷰(View)라고도 한다\n\n\n내부 스키마(Internal Schema)\n\n\n  물리적 저장 장치 관점에서 본 DB의 물리적인 구조\n\n\n외부 스키마(External Schema)\n\n\n  사용자 관점에서의 논리적 구조\n  서브 스키마, 사용자 뷰라고도 한다\n\n\n\n\n설계 과정\n\n\n\n\n  요구 조건 분석(Requirement Formulation)\n  개념적 설계(Conceptual Schema)\n    \n      DBMS에 독립적인 개념 스키마 모델링\n      트랜잭션 모델링\n      E-R 다이어그램 산출\n    \n  \n  논리적 설계(Logical Schema)\n    \n      논리 스키마의 설계\n      DBMS의 구현 데이터 모델로 표현된 데이터베이스 스키마 도출\n      컴퓨터가 이해하고 처리할 수 있는 특정 DBMS가 지원 가능한 논리적 데이터 구조로 변환\n    \n  \n  물리적 설계(Physical Schema)\n    \n      DB 파일에 대한 저장 구조와 접근 경로를 결정\n      응답시간, 저장공간의 효율, 트랜잭션 처리도를 고려\n    \n  \n  \n    데이터베이스 구현\n\n    \n      해당 DBMS의 DDL을 통해 구축\n    \n  \n\n",
      "categories": ["cs","database-construct"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/database-construct/2020-09-23-schema/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "네트워크(Network)",
      "date": "2020-09-23 12:14:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  네트워크(Network)\n  네트워크 구조    \n      트리형(Tree)\n      링형(루프형, Ring)\n      성형(Star)\n      망형(Mesh)\n      버스형(Bus)\n    \n  \n  네트워크 종류    \n      근거리 통신망(LAN, Local Area Network)\n      도시권 통신망(MAN, Metropolitan Area Network)\n      광대역 통신망(WAN, Wide Area Network)\n    \n  \n\n\n \n\n네트워크(Network)\n\n\n\n둘 이상의 시스템을 전화선이나 케이블 등으로 연결하여 자원을 공유하는 것\n\n네트워크는 다른 컴퓨터의 데이터, 프로그램, 주변장치, 인터넷 등을 공유하기 위해 사용\n\n네트워크 구조\n\n트리형(Tree)\n\n\n\n\n\n\n  분산 처리 시스템을 구성하며 통신선로가 가장 짧음\n\n\n \n\n링형(루프형, Ring)\n\n\n\n\n\n\n  양쪽 방향으로 접근이 가능하여 통신회선 장애에 대해 유연하며, 근거리 통신망(LAN)에서 가장 많이 채택\n\n\n \n\n성형(Star)\n\n\n\n\n\n\n  중앙에 호스트 컴퓨터를 중심으로 터미널들이 연결되어 있는 중앙 집중형 구조\n  중앙 컴퓨터에 오류 발생 시 전체 시스템이 마비되는 구조\n  각 노드의 전송 기능을 간단히 할 수 있음 = 교환 노드수가 가장 적음\n\n\n \n\n망형(Mesh)\n\n\n\n\n\n\n  모든 노드를 통신회선으로 연결시킨 구조로 공중 데이터 통신망에서 주로 사용\n\n\n\n  회선 수 = ( 노드 수 ( 노드수 - 1) ) / 2\n\n  각 장치당 포트 수 = 노드 수 - 1\n\n\n \n\n버스형(Bus)\n\n\n\n\n\n\n  하나의 통신회선(Bus)에 여러 개의 노드를 접속하여 연결한 구조로 물리적 구조가 단순하고 노드의 추가와 삭제가 용이\n  노드의 고장은 통신에 영향을 주지 않지만, 통신회선(Bus)에 이상이 생기면 전체 시스템이 마비됨\n\n\n \n\n네트워크 종류\n\n\n\n근거리 통신망(LAN, Local Area Network)\n\n\n\n\n  한 건물 또는 공장, 학교 구내, 연구소 등의 일정 지역 내에 설치된 통신망\n  각종 기기 사이의 통신을 실행\n  특징\n    \n      근거리에서 고속 통신이 가능\n      자원 공유를 목적으로 사용\n      경로 설정이 불필요하고 확장성과 재배치가 용이\n      오류 발생율이 낮음\n      링형(Ring), 버스형(Bus) 구조를 많이 사용\n    \n  \n\n\n \n\n도시권 통신망(MAN, Metropolitan Area Network)\n\n\n\n\n\n\n  큰 도시 또는 캠퍼스에 퍼져 있는 컴퓨터 네트워크\n  DQDB 국제 표준을 가짐\n  FIFO 기반의 공유 슬롯 방식을 사용\n  두 버스를 이용하여 두개의 단방향 선로를 갖고, 이 선로로 모든 호스트가 연결된다\n  특징\n    \n      사이트 간의 거리가 멀기 때문에 통신 속도가 느림\n      오류 발생율이 높음\n      일정 지역에 있는 사이트들을 LAN으로 연결한 후 각 LAN을 묶는 방식으로 사용\n    \n  \n\n\n\n  DQDB(Distributed Queue Bual Bus)\n\n  도시권통신망(MAN)에 사용되는 IEEE 802.6 규격인 QPSX (queued packet synchronous exchange)의 제어 접속에 사용되는 프로토콜이다. 이 구조는 회선교환과 패킷 교환이 모두 가능하며, 데이터, 음성 및 비디오 등의 전송을 지원한다. DQDB는 일정한 길이의 셀 중계 기술을 사용하므로, 네트워크 전송량이 불안정한 곳에 적합하다.\n\n\n \n\n광대역 통신망(WAN, Wide Area Network)\n\n\n\n\n  국가와 국가 혹은 대륙과 대륙의 사이트들을 연결하여 통신을 실행하는 통신망\n  특징\n    \n      사이트 간의 거리가 멀기 때문에 통신 속도가 느림\n      오류 발생율이 높음\n      일정 지역에 있는 사이트들을 LAN으로 연결한 후 각 LAN을 묶는 방식으로 사용\n    \n  \n\n\n \n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2020-09-23-network/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "라우팅과 트래픽 제어",
      "date": "2020-09-23 14:07:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  라우팅(Routing, 경로제어)\n  라우팅 테이블 (Routing Table)\n  라우팅 프로토콜(Routing Protocol)\n  RIP(Round Information Protocol)\n  OSPF(Open Shortest Path First Protocol)\n  BGP(Border Gateway Protocol)\n  트래픽 제어(Traffic Control)    \n      흐름 제어(Flow Control)\n      혼잡 제어(Congestion Control)\n      LAN 표준\n    \n  \n\n\n \n\n라우팅(Routing, 경로제어)\n\n\n\n\n  데이터 패킷을 목적지까지 전송하기 위해 경로를 설정해주는 방법\n  IP 주소의 목적지 주소를 확인하여 해당 목적지까지의 최적의 경로를 지정\n  라우팅 정보를 가진 라우터는 다른 라우터들과 주기적으로 교환함으로써 목적지까지 데이터 패킷을 전송\n  라우터는 모든 경로에 대한 정보를 라우팅 테이블(Routing Table, 경로 제어 표)에 저장 및 관리\n\n\n\n  경로 제어 요소\n\n  성능 기준 / 경로의 결정 시간과 장소 / 정보 발생지 / 경로 정보의 갱신시간\n\n\n \n\n라우팅 테이블 (Routing Table)\n\n\n\n\n  라우터가 목적지 네트워크에 도달하기 위한 경로를 저장해 놓은 공간\n  데이터 전송 위한 게이트웨이에 대한 정보 보관\n  운영체제나 장비에 관계없이 테이블 형식은 같고, 표현방법에 차이는 존재\n\n\n \n\n라우팅 프로토콜(Routing Protocol)\n\n\n\n\n  패킷을 목적지까지 전송하기 위해 라우터 경로 설정하고 제어\n  내부 게이트웨이 프로토콜(IGP) - 하나의 자율 시스템(AS)에서 라우팅 프로토콜이 이뤄짐\n\n\n\n  IGP의 종류\n\n  RIP / OSPF\n\n\n\n  외부 게이트웨이 프로토콜(EGP) - 자율 시스템 간의 라우팅\n\n\n \n\nRIP(Round Information Protocol)\n\n\n\n\n  라우터 홉 수에 따라 최단거리를 결정하는 프로토콜\n  구조가 간단하여 라우터 프로세서에 부담 없음\n  홉 수가 최대 15이므로 대규모 네트워크에는 부적합\n  라우팅 정보 수명이 짧아서 외부 라우터와 일정 시간 이상 교신이 끊기면 라우팅 정보를 삭제\n  전체 라우팅 테이블을 가장 가까운 호스트에 매 30초마다 전송\n  내부용 프로토콜\n  회선 속도 고려하지 않고 홉 수로만 경로를 설정하여 때에 따라 비효율적인 경로 설정이 이뤄질 수 있음\n\n\n \n\nOSPF(Open Shortest Path First Protocol)\n\n\n\n\n  네트워크에 변화가 있을 때만 정보교환이 일어나며, 멀티캐스트(Multicast) 기법으로 작동\n  라우터 사이의 연결 속도를 중심으로 라우팅\n  자율시스템(AS)에서 사용하기 위해 설계되어 라우터끼리 그룹을 가져 그 그룹끼리만 라우팅\n  사용자에 의한 경로 지정과 복수 경로에 지정이 가능\n  라우팅 알고리즘이 복잡하여 라우터에 부담\n\n\n \n\nBGP(Border Gateway Protocol)\n\n\n\n\n  TCP 포트를 이용하므로 신뢰할 수 있는 연결 지향적인 특징 가짐\n  거리 벡터 라우팅(Path Vector)을 수행하며, 루프가 발생하지 않음\n  AS가 다른 여러 AS와 연결이 되어 있는 경우에 사용\n\n\n\n  자율 시스템(AS, Autonomous System)\n\n  \n    동일한 내부 라우팅과 보안 정책을 사용하고 있는 망들의 집합을 의미\n    AS의 관리자는 자신의 AS에 대해 독자적으로 필요한 변경 및 유지보수 작업을 수행\n  \n\n\n \n\n트래픽 제어(Traffic Control)\n\n\n\n흐름 제어(Flow Control)\n\n\n  송신 측과 수신 측의 데이터 처리 속도 차이를 해결하기 위한 기법\n  종류\n    \n      정지-대기(Stop-and-Wait) - 수신 측의 확인 신호(ACK)를 받은 후에 다음 패킷을 전송하는 것으로 한 번에 하나의 패킷만 전송할 수 있다.\n      슬라이딩 윈도우 기법 - 수신 측에서 설정한 윈도우 크기만큼 송신 측에서 확인 응답 없이 세그먼트를 전송할 수 있게하여 데이터 흐름을 동적으로 제어하는 기법\n    \n  \n\n\n\n  📜 윈도우 크기\n\n  TCP 송신 윈도우 크기는 수신측에서 이전에 송신한 패킷에 대한\n긍정응답(ACK)이 전달되면 크기는 커지고, 그 반대인 경우는 윈도우 크기가 감소한다\n\n\n \n\n혼잡 제어(Congestion Control)\n\n\n\n\n  네트워크 내에 패킷의 수가 과도하게 증가하는 현상을 혼잡(Congestion)이라고 하며 혼잡 현상을 방지하거나 제거하는 기능을 의미\n  기법\n    \n      Slow Start - 처음에는 패킷을 1개씩 전송하고, 패킷이 문제없이 도착하면 각각의 ACK 패킷마다 창 크기를 1씩 늘린다. 즉, 한 주기가 지나면 창 크기가 2배로 된다. 따라서 전송 1,2,4,8,16과 같이 창의 크기가 증가함. 대신 혼잡 현상이 발생하면 창 크기를 1로 떨어뜨린다.\n      혼잡 회피(Congestion Avoidance) - Slow Start의 지수적 증가가 임계 값에 도달하게 되면 혼잡으로 간주하고 회피를 위해 윈도우 크기를 1씩 선형적으로 증가시켜 혼잡을 예방하는 기법\n    \n  \n\n\n \n\nLAN 표준\n\n\n\n\n  \n    \n      표준\n      설명\n    \n  \n  \n    \n      IEEE 802.1\n      상위 계층과의 인터페이스 규정\n    \n    \n      IEEE 802.2\n      LLC(Logical Link Control) 계층\n    \n    \n      IEEE 802.3\n      CSMA/CD 방식\n    \n    \n      IEEE 802.4\n      Token 버스 방식\n    \n    \n      IEEE 802.5\n      Token 링 방식\n    \n    \n      IEEE 802.6\n      DQDB(Distribute Queue Dual Bus) MAN\n    \n    \n      IEEE 802.7\n      브로드밴드(BroadBand)\n    \n    \n      IEEE 802.8\n      광통신 자문그룹\n    \n    \n      IEEE 802.9\n      IVD(Intergrated Voice &amp; Data) LAN\n    \n    \n      IEEE 802.10\n      LAN 보안\n    \n    \n      IEEE 802.11b\n      무선 랜\n    \n  \n\n\n \n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2020-09-23-routing/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "병행 제어(Concurrency Control)",
      "date": "2020-09-23 14:50:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  병행 제어(Concurrency Control)    \n      병행 제어 기법\n      병행 제어의 문제점\n      잠금(Locking)\n    \n  \n  트랜잭션(Transaction)    \n      트랜잭션의 성질 (ACID)        \n          원자성(Atomicity)\n          일관성(Consistency)\n          격리성(Isolation, 독립성)\n          지속성(Durability, 영속성)\n        \n      \n      회복(Recovery)\n      보안 생명주기(Secure SDLC, Secure Software Development Life Cycle)\n    \n  \n\n\n \n\n병행 제어(Concurrency Control)\n\n\n\n\n  동시에 여러 개의 트랜잭션(Transaction)을 병행 수행할 때 이들 명령이 데이터베이스의 일관성을 파괴하지 않도록 트랜잭션 상호 작용을 제어하는 기술\n  목적\n    \n      데이터베이스 공유도 최대화\n      시스템 활용도 최대화\n      데이터베이스 일관성 유지\n      사용자 응답 최소화\n    \n  \n\n\n \n\n병행 제어 기법\n\n\n\n\n  타임스탬프 기법 - 시스템이 각 트랜잭션을 실행할 때 부여하는 값으로 읽거나 변경할 데이터에 대해 트랜잭션을 실행하기 전에 타임스탬프를 부여하고 타임스탬프 순서에 따라 트랜잭션 작업을 수행하도록 하는 기법\n  2PL(Two-Phase Locking) 기법 - 트랜잭션들이 잠금, 잠금해제를 확장,축소단계로 수행하도록 한다\n    \n      확장(Growing) 단계 - 트랜잭션이 잠금만 수행 할 수 있고, 잠금해제는 수행 불가능한 상태\n      축소(Shrinking) 단계 - 트랜잭션이 잠금 해제만 수행할 수 있고, 잠금은 수행할 수 없는 상태\n    \n  \n\n\n \n\n병행 제어의 문제점\n\n\n\n\n  갱신 분실(Lost Update) - 2개 이상의 트랜잭션이 같은 데이터를 공유하여 갱신할 때 갱신 결과의 일부가 소실\n  비완료 의존성(Uncommitted Dependency) - 하나의 트랜잭션 수행이 실패한 후 회복되기 전에 다른 트랜잭션이 실패한 갱신 결과를 참조하는 현상\n  모순성(Inconsistency, 불일치 분석) - 복수의 사용자가 동시에 같은 데이터를 갱신할 때 데이터베이스 내의 데이터들이 상호 일치하지 않아 모순된 결과가 발생하는 현상\n  연쇄 복귀(Cascading Rollback) - 병행 수행되던 트랜잭션들 중 어느 하나에 문제가 생겨 롤백되는 경우 다른 트랜잭션들도 연쇄적으로 롤백되는 현상\n\n\n \n\n잠금(Locking)\n\n\n\n\n  데이터베이스 관리에서 하나의 트랜잭션에 사용되는 데이터를 다른 트랜잭션이 접근하지 못하게 하는 것을 의미\n  데이터를 갱신할 때는 반드시 잠금(Lock), 실행(Execute), 해제(Unlock)의 규칙을 따라야 한다\n  한번에 잠금 할 수 있는 단위(로킹 단위, Locking Unit)로 DB, Table, Record, Field 등을 사용 가능\n  로킹(Locking) 단위와 공유도, 오버헤드는 반비례한다\n\n\n\n  📜 오버헤드\n\n  트랜잭션을 처리하기 위해 들어가는 간접적인 처리 시간 · 메모리 등을 말한다\n\n\n \n\n트랜잭션(Transaction)\n\n\n\n\n  데이터베이스의 상태를 변환시키는 하나의 논리적 기능을 수행하기 위한 작업의 단위\n  또는 한꺼번에 모두 수행되어야 할 일련의 논리적인 연산\n\n\n \n\n트랜잭션의 성질 (ACID)\n\n원자성(Atomicity)\n\n\n\n\n  트랜잭션의 연산은 데이터베이스에 모두 반영되든지 전혀 반영되지 않아야 한다\n  트랜잭션 내의 모든 명령은 반드시 완벽히 수행되어야 하며, 모두가 완벽히 수행되지 않고 어느 하나라도 오류가 발생하면 트랜잭션 전부가 취소되어야 한다\n  즉, 트랜잭션의 최종 결과는 항상 Commit 이거나 Rollback 이다\n\n\n \n\n일관성(Consistency)\n\n\n\n\n  트랜잭션이 그 실행을 성공적으로 완료하면 언제나 일관성 있는 데이터베이스 상태로 변환한다\n  시스템이 가지고 있는 고정 요소는 트랜잭션 수행 전과 트랜잭션 수행 후의 상태가 같아야 한다\n\n\n \n\n격리성(Isolation, 독립성)\n\n\n\n\n  둘 이상의 트랜잭션이 동시에 병행 실행되는 경우 어느 하나의 트랜잭션 실행 중에 다른 트랜잭션의 연산이 끼어들 수 없다\n  수행 중인 트랜잭션은 완전히 완료될 때 까지 다른 트랜잭션에서 수행 결과를 참조할 수 없다\n\n\n \n\n지속성(Durability, 영속성)\n\n\n\n\n  성공적으로 완료 된 트랜잭션의 결과는 시스템이 고장 나더라도 영구적으로 반영되어야 한다\n\n\n \n\n회복(Recovery)\n\n\n\n\n  장애 종류 - 트랜잭션 장애, 시스템 장애, 미디어 장애\n  회복 - 손상 된 데이터베이스를 손상되기 이전의 상태로 복구시키는 작업\n  회복 관리기(Recovery Management) - DBMS의 구성요소로써 트랜잭션 실행이 성공적으로 완료되지 못하면 트랜잭션이 데이터베이스에 생성했던 모든 변화를 취소(Rollback) 시킨 다음 트랜잭션 수행 이전의 상태로 복구하는 역할\n  회복 수행 - 메모리 덤프(데이터베이스 복사), 로그(갱신 전 후 내용을 별도의 파일로 기록)\n\n\n \n\n보안 생명주기(Secure SDLC, Secure Software Development Life Cycle)\n\n\n\n\n  보안상 안전한 소프트웨어를 개발하기 위해 SDLC에 보안 강화를 위한 프로세스를 포함한 것\n  소프트웨어의 유지보수 단계에서 보안 이슈를 해결하기 위해 소모되는 많은 비용을 최소화 하기 위해 등장\n  Secure SDLC의 대표적 방법론 - Secure S/W社 CLASP, MS社 SDL\n\n\n\n  \n    \n      속성\n      설명\n    \n  \n  \n    \n      기밀성(Confidentiality)\n      정보를 인가된 시간, 사용자, 기관에게만 공개 또는 처리\n    \n    \n      무결성(Integrity)\n      데이터를 정확하고 완전한 상태로 보존하는 것. 외부로부터의 정보 변조를 차단\n    \n    \n      인증성(Authentication)\n      정보를 보내는 사람의 신원을 확인\n    \n    \n      가용성(Availability)\n      권한이 부여된 사용자는 언제든 시스템을 사용 할 수 있음\n    \n    \n      접근 제어(Access Control)\n      인가된 사용자만 정보에 접근하도록 제어, 시스템의 자원 이용에 대한 불법적인 접근을 차단\n    \n    \n      부인 방지(Non-Repudiation)\n      송신자의 송신 여부와 수신자의 수신 여부를 확인\n    \n  \n\n\n \n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2020-09-23-concurrency-control/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "암호 알고리즘(Ciphering Algorithm)",
      "date": "2020-09-23 16:10:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  암호 알고리즘(Ciphering Algorithm)    \n      개인 키 암호화 기법(PKE, Private Key Encryption)\n      공개 키 암호화 기법(PKI, Public Key Encryption)\n      해쉬(Hash)\n    \n  \n\n\n \n\n암호 알고리즘(Ciphering Algorithm)\n\n허가받지 않은 사용자가 정보(Data)를 쉽게 이해할 수 없도록 암호화하는 기법들을 총칭\n\n \n\n개인 키 암호화 기법(PKE, Private Key Encryption)\n\n\n\n\n  대칭 암호화 기법, 단일키 암호화 기법이라고도 함\n  한번에 하나의 데이터 블록을 암호화하는 블록 암호화 방식\n  평문과 동일한 길이의 스트림을 생성하여 비트 단위로 암호화하는 스트림 암호화 방식\n  암호화/복호화의 속도가 빠르며, 알고리즘이 단순하고 파일 크기가 작음\n  사용자의 증가에 따라 관리해야 할 키의 수가 상대적으로 많아지는 것이 단점\n\n\n\n  블록 암호화 방식 : DES / SEED / AES / ARIA / RC5 / RC6\n\n  스트림 암호화 방식 : LFSR / RC4\n\n\n \n\n공개 키 암호화 기법(PKI, Public Key Encryption)\n\n\n\n\n  비대칭 암호화 기법\n  데이터를 암호화 할 때 사용되는 키(Public Key, PKI)는 공개하고, 복호화할 때의 키(비밀 키)는 비밀로 함\n  대표적으로 RSA(Rivest Shamir Adleman) 알고리즘 사용\n  서로 다른 키로 데이터를 암호화하고 복호화 수행\n  키의 분배가 용이하고 관리해야 할 키의 개수가 적다\n  암호화/복호화의 속도가 느리며, 알고리즘이 복잡하고 파일 크기가 큼\n\n\n\n  📜 RSA(Rivest Shamir Adleman)\n\n  1978년 MIT의 라이베스트, 샤미르, 애들먼에 의해 제안된 공개키 암호화 알고리즘\n큰 수를 소인수분해 하기 어렵다는 점에 기반하여 만들어짐\n\n\n \n\n\n  📜 PKI 개요\n\n  공개키 인증서의 무결성(인증성)을 제공하기 위한 신뢰 구조\n안전한 PKI는 인터넷 전자상거래 시스템뿐만 아니라 범국가적 정보통신망에서도 중요한 역할 수행\n사용자 공개키와 사용자 ID를 안전하게 전달하는 방법과 공개키를 신뢰성 있게 관리하기 위한 수단 제공\n인증서 발급, 인증서 사용/취소 관련 서비스를 통해 기밀성, 무결성, 접근제어, 인증, 부인방지의 서비스 제공\nX.509 방식 - 인증기관에서 발생하는 인증서를 기반으로 상호 인증을 제공\n비 X.509방식 - 국가별, 지역별로 맞게 보안 및 개발\n\n\n \n\n해쉬(Hash)\n\n\n\n\n  임의의 길이의 입력 데이터나 메시지를 고정된 길이의 값이나 키로 변환하는 것을 의미\n  해쉬를 이용해 평문을 암호문으로 암호화하는 것은 가능하지만, 암호문을 평문으로 복호화하는 것은 불가\n  대칭·비대칭 키 암호화 방식은 양방향 암호화 방식이라 하며, 해쉬 암호화 방식은 단방향 암호화 방식이라 한다\n  데이터의 암호화 및 무결성 검증을 위해 사용될 뿐만 아니라 정보보호의 다양한 분야에서 활용\n\n\n\n  해쉬 함수 종류 : SHA / MD5 / N-NASH / SNEFRU\n\n\n \n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2020-09-23-ciphering-algorithm/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "네트워크 공격 용어",
      "date": "2020-09-23 16:45:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  네트워크 침해 공격 관련 용어\n  정보보안 침해 공격 관련 용어\n\n\n \n\n네트워크 침해 공격 관련 용어\n\n\n\n\n  \n    \n      용어\n      의미\n    \n  \n  \n    \n      스미싱(Smishing)\n      문자 메시지를 이용해 사용자의 개인 정보를 탈취하는 수법. 초기에는 문자 메시지를 이용해 개인의 비밀정보나 소액 결제를 유도하는 형태로 시작\n    \n    \n      스피어 피싱(Spear Phishing)\n      특정 대상을 선정한 후 그 대상에게 일반적인 이메일로 위장한 메일을 지속적으로 발송하여 발송 메일의 본문 링크나 첨부된 파일을 클릭하도록 유도해 사용자의 개인 정보를 탈취하는 수법\n    \n    \n      지능형 지속 위협(APT, Advanced Persistent Threats)\n      특정 조직의 네트워크에 침투하여 활동 거점을 마련 한 뒤 적절한 때를 기다리면서 보안을 무력화 시키고 정보를 수집하여 외부로 탈취하는 수법. 스턱스넷(Stuxnet)과 같이 악성코드가 담긴 이동식 디스크등으로 전파\n    \n    \n      무작위 대입 공격(BFA, Brute Force Attack)\n      암호화된 문서의 암호키를 찾아내기 위해 적용 가능한 모든 값을 대입하여 공격하는 방법\n    \n    \n      큐싱(Qshing)\n      QR코드를 통해 악성 앱의 다운로드를 유도하는 금융사기기법\n    \n    \n      SQL 삽입 공격(SQL Injection)\n      전문 스캐너 프로그램 혹은 봇넷 등을 이용해 웹 사이트를 무차별적으로 공격하는 과정에서 취약한 사이트가 발견되면 데이터베이스의 데이터를 조작하는 수법\n    \n    \n      크로스 사이트 스크립팅(XSS, Cross Site Scripting)\n      네트워크를 통한 컴퓨터 보안 공격의 하나로 웹 페이지의 내용을 사용자 브라우저에 표현하기 위해 사용되는 스크립트 취약점을 악용한 해킹 수법\n    \n  \n\n\n \n\n정보보안 침해 공격 관련 용어\n\n\n\n\n  \n    \n      용어\n      의미\n    \n  \n  \n    \n      C&amp;C서버\n      해커가 원격지에서 감염된 좀비PC에 명령을 내리고 악성코드를 제어하기 위한 용도로 사용하는 서버\n    \n    \n      봇넷(Botnet)\n      악성 프로그램에 감염되어 악의적인 의도로 사용 될 수 있는 다수의 컴퓨터들이 네트워크로 연결 된 형태\n    \n    \n      웜(Worm)\n      네트워크를 통해 연속적으로 자신을 복제하여 시스템의 부하를 높임으로써 결국 시스템을 다운시키는 바이러스. 분산 서비스 거부 공격, 오버플로우 공격, 슬래머 등이 웜 공격의 대표적인 형태\n    \n    \n      트랩 도어(Trap Door)\n      응용 프로그램이나 운영 체제 개발 시 프로그램 오류를 쉽게 발견하기 위해 코드 중간에 중단부분을 만들어 놓는 행위(Break Point). 트랩도어를 삭제하지 않고 다른 용도로 악용\n    \n    \n      백도어(Back Door)\n      시스템에 무단 접근하기 위해 사용되는 일종의 비상구로, 컴퓨터의 보안 예방책에 침입하는 행위 혹은, 시스템 장애를 대비하여 제작회사에서 해당 시스템에 직접 점검할 수 있도록 개방한 특정 Port 의미\n    \n    \n      트로이 목마(Trojan horse)\n      평상시에는 정상적인 프로그램으로 유지되다 특정 프로그램이 실행 되면(Trigger) 시스템에 손상을 주는 프로그램\n    \n    \n      제로 데이 공격(Zero Day Attack)\n      보안 취약점이 발견됐을 때 취약점의 존재가 공표되기 전에 해당 취약점을 공격당하는 것으로, 보안공격의 신속성을 의미\n    \n    \n      키 로거 공격(Key Logger Attack)\n      컴퓨터 사용자의 키보드 움직임을 탐지해 개인정보를 탈취하는 수법\n    \n    \n      랜섬웨어(Ransomware)\n      사용자의 내부 문서를 암호화해 사용자가 열지 못하게하여 복호화를 조건으로 금전을 요구하는 수법\n    \n  \n\n\n \n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2020-09-23-network-attack/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "OSI 7 계층",
      "date": "2020-09-23 17:25:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  OSI 7 계층(Open Systems Interconnection Seven Layer)\n  제1 계층 : 물리 계층(Physical Layer)\n  제2 계층 : 데이터 링크 계층(Data link layer)\n  제3 계층 : 네트워크 계층(Network layer)\n  제4 계층 : 전송 계층(Transport layer)\n  제5 계층 : 세션 계층(Session layer)\n  제6 계층 : 표현 계층(Presentation layer)\n  제7 계층 : 응용 계층(Application layer)\n\n\n \n\nOSI 7 계층(Open Systems Interconnection Seven Layer)\n\n\n\n이 모델은 각 프로토콜을 기능별로 분리한 것이다.\n\n각 계층은 하위 계층의 기능만을 사용하고, 상위 계층에 자신의 기능을 제공한다. ‘프로토콜 스택’ 혹은 ‘스택’이라 부르기도 하는데 이는 하드웨어나 소프트웨어 혹은 둘의 혼합으로 구현될 수도 있다.  일반적으로 하위 계층은 하드웨어, 상위 계층은 소프트웨어로 구현한다.\n\n\n\n제1 계층 : 물리 계층(Physical Layer)\n\n네트워크의 기본 네트워크 하드웨어 전송 기술을 이룬다.\n\n네트워크의 높은 수준의 기능의 논리 데이터 구조를 기초로 하는 필수 계층이다.\n\n다양한 특징의 하드웨어 기술이 접목되어 있기에 OSI 아키텍처에서 가장 복잡한 계층으로 간주된다.\n\n\n\n제2 계층 : 데이터 링크 계층(Data link layer)\n\n포인트 투 포인트(Point to Point) 간 신뢰성 있는 전송을 보장하기 위한 계층으로 CRC 기반의 오류 제어와 흐름 제어가 필요하다. 네트워크 위의 개체들 간 데이터를 전달하고, 물리 계층에서 발생할 수 있는 오류를 찾아내고, 수정하는 데 필요한 기능적, 절차적 수단을 제공한다.\n\n주소 값은 물리적으로 할당 받는데, 이는 네트워크 카드가 만들어질 때부터 맥 주소(MAC Address)가 정해져 있다는 뜻이다. 주소 체계는 계층이 없는 단일 구조이다. 데이터 링크 계층의 가장 잘 알려진 예는 이더넷이다.\n\n이 외에도 HDLC나 ADCCP 같은 포인트 투 포인트(Point to Point) 프로토콜이나 패킷 스위칭 네트워크나 LLC, ALOHA 같은 근거리 네트워크용 프로토콜이 있다. 네트워크 브릿지나 스위치 등이 이 계층에서 동작하며, 직접 이어진 곳에만 연결할 수 있다.\n\n\n  프레임에 주소부여(MAC - 물리적 주소)\n에러 검출/재전송/흐름 제어\n\n\n\n\n제3 계층 : 네트워크 계층(Network layer)\n\n여러 개의 노드를 거칠 때마다 경로를 찾아주는 역할을 하는 계층으로 다양한 길이의 데이터를 네트워크들을 통해 전달하고, 그 과정에서 전송 계층이 요구하는 서비스 품질(QoS)을 제공하기 위한 기능적, 절차적 수단을 제공한다.\n\n네트워크 계층은 라우팅, 흐름 제어, 세그멘테이션(Segmentation/Desegmentation), 오류 제어, 인터네트워킹(Internetworking) 등을 수행한다.\n\n라우터가 이 계층에서 동작하고 이 계층에서 동작하는 스위치도 있다. 데이터를 연결하는 다른 네트워크를 통해 전달함으로써 인터넷이 가능하게 만드는 계층이다. 논리적인 주소 구조(IP), 곧 네트워크 관리자가 직접 주소를 할당하는 구조를 가지며, 계층적(Hierarchical)이다.\n\n서브넷의 최상위 계층으로 경로를 설정하고, 청구 정보를 관리한다. 개방형 시스템들의 사이에서 네트워크 연결을 설정, 유지, 해제하는 기능을 부여하고, 전송 계층 사이에 네트워크 서비스 데이터 유닛(NSDU : Network Service Data Unit)을 교환하는 기능을 제공한다.\n\n\n  경로 설정(Route)\n\n\n\n\n제4 계층 : 전송 계층(Transport layer)\n\n양 끝단(End to End)의 사용자들이 신뢰성 있는 데이터를 주고받을 수 있도록 해 주어, 상위 계층들이 데이터 전달의 유효성이나 효율성을 생각하지 않도록 해준다.\n\n시퀀스 넘버 기반의 오류 제어 방식을 사용한다. 전송 계층은 특정 연결의 유효성을 제어하고, 일부 프로토콜은 상태 개념이 있고(Stateful), 연결 기반(Connection Oriented)이다.\n\n이는 전송 계층이 패킷들의 전송이 유효한지 확인하고 전송 실패한 패킷들을 다시 전송한다는 것을 뜻한다. 가장 잘 알려진 전송 계층의 예는 TCP이다.\n\n종단 간(end-to-end) 통신을 다루는 최하위 계층으로 종단간 신뢰성 있고 효율적인 데이터를 전송하며, 기능은 오류 검출 및 복구와 흐름 제어, 중복검사 등을 수행한다.\n\n\n  패킷 생성\n\n  Assembly / Sequencing / Deassembly / Error detection / Request repeat / Flow control\n\n\n\n\n제5 계층 : 세션 계층(Session layer)\n\n양 끝단의 응용 프로세스가 통신을 관리하기 위한 방법을 제공한다. 동시 송수신 방식(Duplex), 반이중 방식(Half-Duplex), 전이중 방식(Full Duplex)의 통신과 함께, 체크 포인팅과 유휴, 종료, 다시 시작 과정 등을 수행한다.\n\n이 계층은 TCP/IP 세션을 만들고 없애는 책임을 진다.\n\n\n  통신하는 사용자들을 동기화하고 오류 복구 명령들을 일괄적으로 다룬다\n통신을 하기 위한 세션을 확립 / 유지 / 중단 (운영체제가 해줌)\n\n\n\n\n제6 계층 : 표현 계층(Presentation layer)\n\n코드 간의 번역을 담당하여 사용자 시스템에서 데이터의 형식상 차이를 다루는 부담을 응용 계층으로부터 덜어 준다. MIME 인코딩이나 암호화 등의 동작이 이 계층에서 이루어진다. 예를 들면, EBCDIC로 인코딩 된 문서 파일을 ASCII로 인코딩된 파일로 바꿔 주는 것이 표현 계층의 몫이다.\n\n\n  사용자의 명령어를 완성 및 결과 표현\n포장 / 압축 / 암호화\n\n\n\n\n제7 계층 : 응용 계층(Application layer)\n\n응용 프로세스와 직접 관계하여 일반적인 응용 서비스를 수행한다.\n\n일반적인 응용 서비스는 관련된 응용 프로세스들 사이의 전환을 제공한다.\n\n응용 서비스의 예로, 가상 터미널(예를 들어, 텔넷), “Job transfer and Manipulation protocol” (JTM, 표준 ISO/IEC 8832) 등이 있다.\n\n\n  네트워크 소프트웨어 UI 부분 사용자의 입출력(I/O) 부분\n\n",
      "categories": ["cs","leverage-programming"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/leverage-programming/2020-09-23-osi-7-layer/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "보안 솔루션(Security Solution)",
      "date": "2020-09-24 09:33:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  보안 솔루션(Security Solution)    \n      침입 탐지 시스템(IDS, Intrusion Detection System)\n      침입 방지 시스템(IPS, Intrucsion Prevention System)\n      방화벽(Firewall)\n      데이터 유출 방지(DLP, Data Leakage Preventing)\n      가상사설망(VPN, Virtual Private Network)\n      통합보안관리(Enterprise Security Management)\n      네트워크접근제어(Network Access Controll)\n    \n  \n\n\n \n\n보안 솔루션(Security Solution)\n\n\n\n접근통제, 침입 차단 및 탐지 등을 수행하여 외부로부터의 불법적 침입을 막는 기술 및 시스템\n\n \n\n침입 탐지 시스템(IDS, Intrusion Detection System)\n\n\n\n\n  악의적인 시스템의 강제 조작을 탐지하는 역할\n  방화벽이 탐지할 수 없는 종류의 네트워크 트래픽 및 컴퓨터 사용을 탐지하는 시스템을 의미\n  분류\n    \n      오용 탐지(Misuse Detection) - 특정 공격에 대한 분석 결과를 바탕으로 패턴을 설정하고 패턴과의 비교를 통해 일치하는 경우 불법침입으로 간주\n      이상 탐지(Anomaly Detection) - 평균적인 시스템의 상태를 기준으로 비정상적인 행위나 자원의 사용이 감지되면 이를 알려줌\n    \n  \n  장점\n    \n      해킹 방법을 기반으로 해커의 침입을 탐지하므로 신기술의 적용이 빠름\n      외부로부터의 공격 뿐만 아니라 내부자에 의한 해킹도 차단 가능\n      접속하는 IP에 상관없이 침입을 차단하고 시스템 침입에 즉시 대응\n      해킹사실 발견 시 해킹에 관한 정보를 휴대전화, 무선호출기, E-Mail 등으로 즉시 전송\n    \n  \n\n\n \n\n침입 방지 시스템(IPS, Intrucsion Prevention System)\n\n\n\n\n  여러 보안 기술을 이용하여 공격자가 침입하는 것을 방지\n  일종의 경보 시스템으로 인증, 방화벽, 바이러스 등 유해 트래픽을 차단하기 위한 능동형 보안 솔루션\n  침입 탐지 기능으로 패킷을 하나씩 검사한 후 비정상적인 패킷이 탐지되면 방화벽 기능으로 해당 패킷을 차단\n\n\n \n\n방화벽(Firewall)\n\n\n\n\n  보안이 필요한 네트워크의 통로를 단일화하여 관리함으로써 외부의 불법 침입으로부터 내부의 정보 자산을 보호하기 위한 시스템\n  내부로 들어오는 패킷은 인증된 패킷만 통과시키는 구조\n  역추적 기능이 있어 외부의 침입자를 역추적하여 흔적을 찾을 수 있음\n  내부로부터 이루어지는 불법적인 해킹은 막지 못함\n\n\n \n\n데이터 유출 방지(DLP, Data Leakage Preventing)\n\n\n\n\n  내부 직원이 사용하는 PC와 네트워크 상의 모든 정보를 검색하고 사용자의 행위를 탐지/통제해 외부로의 정보유출을 사전에 차단\n\n\n \n\n가상사설망(VPN, Virtual Private Network)\n\n\n\n\n  기존 사설망의 고비용과 비효율적 관리를 해결하기 위한 방법\n  인터넷을 마치 전용선처럼 사용 할 수 있는 네트워크\n  암호화 된 규격을 통해 인터넷망을 전용선의 사설망을 구축한 것처럼 이용하므로 비용 부담을 줄임\n  원격지의 지사, 영업소, 이동 근무자가 지역적인 제한 없이 업무를 수행 할 수 있다\n\n\n \n\n통합보안관리(Enterprise Security Management)\n\n\n\n\n  단순 통합 보안 시스템 관리는 물론이고, 관제, 운영함으로써 조직의 보안 목적을 효과적으로 실현하는 시스템\n  방화벽, 웹 방화벽, IDS, IPS, VPN 등에서 발생한 로그 및 보안 이벤트를 통합 관리함으로써 비용과 자원을 절약\n  각종 네트워크 보안제품의 인터페이스를 표준화하여 중앙 통합 관리, 침입 종합 대응, 통합 모니터링이 가능한 지능형 보안 관리 시스템\n\n\n \n\n네트워크접근제어(Network Access Controll)\n\n\n\n\n  네트워크에 접속하는 내부 PC의 MAC주소를 IP관리 시스템에 등록하여 일관된 보안 관리 기능을 제공\n  사용하는 단말기가 내부 네트워크에 접근하기 전에 보안 정책을 준수했는지 여부를 검사하여 네트워크 접속을 통제\n  일괄적인 배포 관리 기능을 이용하여 백신이나 보안 패치 등의 설치 및 업그레이드를 수행\n\n\n \n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2020-09-24-security-solution/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "정보 통신·기술 용어",
      "date": "2020-09-24 10:17:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  정보 통신·기술 용어    \n      빅 데이터(Big Data)\n      브로드 데이터(Broad Data)\n      디지털 아카이빙(Digital Archiving)\n      하둡(Hadoop)\n      타조(Tajo)\n      데이터 다이어트(Data Diet)\n      디지털 생비자(Digital Prosumer)\n      O2O(Online to Offline)\n      PET(Privacy Enhancing Technology)\n      디지털 포렌식(Digital Forensics)\n      클라우드 컴퓨팅(Cloud Computing)\n      그리드 컴퓨팅(Grid Computing)\n      OGSA(Open Grid Service Architecture)\n      분산 시스템(Distributed System)\n      네트워크 결합 저장소(NAS, Network Attached Storage)\n      인공지능(Artificial Intelligence)\n      머신러닝(Machine Learning)\n      딥 러닝(Deep Learning)\n      전문가 시스템(Expert System)\n      증강현실(Augmented Reality)\n      블록체인(Blockchain)\n      분산 원장기술(Distributed Ledger Technology)\n      양자컴퓨터(Quantum Computer)\n      양자 암호키 분배(Quantum Key Distribution)\n      디지털 저작권 관리(DRM, Digital Rights Management)\n      디지털 트윈(Digital Twin)\n      개인정보 영향평가 제도(Privacy Impact Assessment)\n      그레이웨어(Grayware)\n      매쉬업(Mashup)\n      RIA(Rich Internet Application)\n      서비스 지향 아키텍처(Service Oriented Architecture)\n      서비스형 소프트웨어(Software as a Service)\n      소프트웨어 에스크로(Software Escrow)\n      복잡 이벤트 처리(Complex Event Processing)\n    \n  \n\n\n \n\n정보 통신·기술 용어\n\n빅 데이터(Big Data)\n\n\n\n\n  기존의 관리 방법이나 분석 체계로는 처리하기 어려운 막대한 양의 정형화된 또는 비 정형화된 데이터의 집합으로 스마트 단말기의 빠른 확산, SNS의 활성화, 사물 네트워크의 확대로 데이터 폭발 가속화\n  기업, 정부, 포털사이트 등이 빅데이터를 효과적으로 분석하여 미래를 예측해 최적의 대응 방안을 찾고, 이를 수익으로 연결하여 새로운 가치를 창출할 수 있기 때문에 빅 데이터의 비중이 커지고 있다\n\n\n \n\n브로드 데이터(Broad Data)\n\n\n\n\n  다양한 채널에서 소비자와 상호 작용을 통해 생성되고, 기업 마케팅에 있어 효율적이고 다양한 데이터, 이전에 사용하지 않거나 알지 못했던 새로운 데이터, 기존 데이터에 새로운 가치가 더해진 데이터를 의미\n\n\n \n\n디지털 아카이빙(Digital Archiving)\n\n\n\n\n  디지털 정보 자원을 장기적으로 보존하기 위한 작업으로 아날로그 콘텐츠는 디지털로 변환한 후 압축하여 저장하고, 디지털 콘텐츠도 체계적으로 분류하고 메타데이터(Meta Data : 데이터의 속성)를 만들어 데이터베이스화 하는 작업이다\n\n\n \n\n하둡(Hadoop)\n\n\n\n\n  오픈소스를 기반으로 한 분산 컴퓨팅 플랫폼\n  일반 컴퓨터들로 가상화 된 대형 저장공간을 형성하여 그 안에 보관된 거대 데이터셋(Data Set)을 병렬로 처리할 수 있도록 개발된 자바 소프트웨어 프레임워크\n  구글, 야후 등에 적용 중\n\n\n \n\n타조(Tajo)\n\n\n\n\n  하둡(Hadoop) 기반의 분산 데이터 웨어하우스 프로젝트로 한국이 주도하여 개발\n  하둡의 빅 데이터 분석 시 맵 리듀스(Map Reduce)를 사용하지 않고 구조화된 질의어(SQL)를 사용하여 하둡 분산\n  파일 시스템 파일을 바로 읽어올 수 있는 대규모 데이터 처리와 실시간 상호분석에 모두 사용 가능\n\n\n \n\n데이터 다이어트(Data Diet)\n\n\n\n\n  인터넷 이동통신 이용이 늘어나면서 각 기관이나 기업의 데이터베이스에 쌓인 방대한 정보를 효율적으로 관리하기 위해 대두된 방안으로 데이터를 압축하고, 중복된 정보는 중복을 배제하여 새로운 기준에 따라 분산 저장하는 작업\n\n\n \n\n디지털 생비자(Digital Prosumer)\n\n\n\n\n  인터넷 커뮤니티에 참여해 콘텐츠를 즐기고 정보와 자료를 얻는 소비자이면서 동시에 의견을 적극 개진해 생산에도 영향을 미치는 사람을 뜻함\n\n\n\n  📜 생비자(Prosumer)\n\n  앨빈 토플러(A. Toffler)가 만든 용어로, Producer와 Consumer가 합쳐진 용어\n\n  생산과 소비가 혼연 일치된 생활을 하게 될 미래의 인간을 뜻함\n\n\n \n\nO2O(Online to Offline)\n\n\n\n\n  인터넷과 모바일 등의 온라인 매장에서 오프라인 매장으로 고객을 유치하는 마케팅 기법\n  온라인에서 물건을 주문하고 오프라인 매장에서 수령하는 것\n\n\n \n\nPET(Privacy Enhancing Technology)\n\n\n\n\n  개인정보 침해 위험을 관리하기 위한 핵심기술로 암호화, 익명화 등 개인정보를 보호하는 기술\n\n\n \n\n디지털 포렌식(Digital Forensics)\n\n\n\n\n  컴퓨터, 휴대전화, 인터넷 등의 디지털 저장매체에 존재하는 디지털 정보를 수집하는 디지털 수사과정\n\n\n \n\n클라우드 컴퓨팅(Cloud Computing)\n\n\n\n\n  인터넷 상의 공유 서버를 통해 필요한 소프트웨어를 제공받을 수 있으며, 동시에 각종 IT기기로 데이터를 손쉽게 공유할 수 있는 시스템 사용 환경을 의미\n  Google Drive 등\n\n\n \n\n그리드 컴퓨팅(Grid Computing)\n\n\n\n\n  지리적으로 분산된 고성능 컴퓨터, 대용량 저장장치, 첨단 장비 등의 자원을 고속 네트워크로 연결하고, 연결된 컴퓨터들의 자원을 활용함으로써 많은 양의 데이터를 처리\n  정보기술, 나노기술, 생명공학, 환경공학 같은 첨단분야 연구를 획기적으로 진전시키는 기본 기술\n\n\n \n\nOGSA(Open Grid Service Architecture)\n\n\n\n\n  애플리케이션 공유를 위한 웹 서비스를 그리드 상에서 제공하기 위해 만든 개방형 표준\n  웹 서비스 표준을 적극적으로 따르고 기존의 웹 개발 툴들을 그대로 사용할 수 있는 장점을 가짐\n\n\n \n\n분산 시스템(Distributed System)\n\n\n\n\n  지리적으로 멀리 떨어진 장소에 위치한 컴퓨터 시스템에 기능과 자원을 분산시켜 놓고 통신망을 연결하여 상호 협력이 가능하도록 한 시스템을 의미\n\n\n \n\n네트워크 결합 저장소(NAS, Network Attached Storage)\n\n\n\n\n  네트워크에 연결하여 사용할 수 있는 대용량 저장장치로 여러 개의 하드디스크로 구성\n  작업 처리를 관리할 수 있는 NAS용 OS가 설치되어 있음\n  고유의 IP를 설정 할 수 있어서 독립적으로 네트워크에 연결할 수 있다\n\n\n \n\n인공지능(Artificial Intelligence)\n\n\n\n\n  인간 상호 간의 지능적 인식을 기반으로 행동하도록 컴퓨터가 만들어질 수 있는 가능성을 추구하는 분야\n  기존의 프로그래밍 순서에 따라 작업하는 컴퓨터 시스템과 차별화\n  기존의 컴퓨터 시스템과 달리 유연한 문제 해결을 지원\n  인공지능 개발언어로는 LISP, PROLOG 등이 있다\n\n\n \n\n머신러닝(Machine Learning)\n\n\n\n\n  방대한 데이터를 분석해 미래를 예측하는 기술\n  컴퓨터가 스스로 학습 과정을 거쳐 입력되지 않은 정보를 습득하고 문제를 해결\n\n\n \n\n딥 러닝(Deep Learning)\n\n\n\n\n  많은 데이터를 이용한 컴퓨터 시스템이 마치 사람처럼 스스로 학습할 수 있어 특정 업무 수행 시 정형화된 데이터를 입력받지 않고 스스로 필요한 데이터를 수집하고 분석하여 고속으로 처리하는 인공 신경망(ANN)을 기반으로 하는 머신러닝 기술\n\n\n \n\n전문가 시스템(Expert System)\n\n\n\n\n  인간의 지적 활동과 경험을 통해서 축적된 전문가의 지식과 전문가에 의해 정의된 추론 규칙을 활용하여 특정 분야 전문가가 수행하는 고도의 업무를 지원하기 위한 문제 해결 프로그램\n\n\n \n\n증강현실(Augmented Reality)\n\n\n\n\n  실제 촬영한 화면에 가상의 정보를 부가하여 보여주는 기술\n  방송, 게임, 교육, 오락, 패션 등 산업전반에 걸쳐 대부분의 분야에서 응용이 가능\n\n\n \n\n블록체인(Blockchain)\n\n\n\n\n  P2P 네트워크를 이용하여 온라인 금융 거래 정보를 온라인 네트워크 참여자의 디지털 장비에 분산 저장하는 기술\n  P2P 네트워크 환경을 기반으로 일정 시간동안 과반수 이상의 디지털 장비에 저장된 거래 내역을 서로 교환, 확인, 승인하는 과정을 거쳐 디지털 서명으로 동의한 금융 거래 내역만 하나의 블록으로 만들고, 이러한 블록은 기존의 블록체인에 연결 후 다시 복사되어 각 사용자의 디지털 장비에 분산 저장됨\n\n\n \n\n분산 원장기술(Distributed Ledger Technology)\n\n\n\n\n  중앙 관리자나 중앙 데이터 저장소가 존재하지 않고 P2P 네트워크 내의 참여자들에게 모든 거래 목록이 분산 저장되어 거래가 발생할 때마다 지속적으로 갱신되는 디지털 원장을 의미\n\n\n \n\n양자컴퓨터(Quantum Computer)\n\n\n\n\n  슈퍼컴퓨터의 한계를 뛰어넘고자 추진 중인 첨단 미래형 컴퓨터\n  양자역학에 기반한 논리 연산 방식을 컴퓨터 분야에 적용\n  2진법을 쓰는 현재의 컴퓨터와 달리 양자컴퓨터는 데이터가 ‘0’이면서 동시에 ‘1’이 될 수 있음\n  양자컴퓨터의 기본단위는 큐비트(Qbit)\n  기존의 슈퍼컴퓨터를 뛰어넘는 초고속 연산이 가능\n\n\n \n\n양자 암호키 분배(Quantum Key Distribution)\n\n\n\n\n  양자 통신을 위해 비밀 키를 분배하여 관리하는 기술\n  두 시스템이 암호 알고리즘 동작을 위한 비밀 키를 안전하게 공유하기 위해 양자 암호 키 분배 시스템을 설치하여 운용하는 방식으로 활용\n\n\n \n\n디지털 저작권 관리(DRM, Digital Rights Management)\n\n\n\n\n  인터넷이나 기타 디지털 매체를 통해 유통되는 데이터의 저작권 보호를 위해 데이터의 안전한 배포를 활성화하거나 불법 배포를 방지하기 위한 시스템\n  데이터를 암호화하여 인증된 사용자만 접속할 수 있게 하거나, 디지털 워터마크의 사용 또는 이와 유사한 방식의 콘텐츠를 제작하여 데이터 콘텐츠를 보호하는 기술\n\n\n \n\n디지털 트윈(Digital Twin)\n\n\n\n\n  현실세계의 객체와 같은 객체를 가상공간에 만들어 다양한 시뮬레이션을 통해 검증하는 기술\n  2000년대에 제조업에 도입되었으며 항공, 건설, 헬스케어, 에너지, 국방 도시설계 등 산업 전반에 걸쳐 활용되고 있음\n  3차원 설계 프로그램을 사용하고 사물인터넷(IoT)을 통해 방대한 양의 정보를 수집할 수 있게 되면서 정확도가 높아짐\n\n\n \n\n개인정보 영향평가 제도(Privacy Impact Assessment)\n\n\n\n\n  개인정보를 활용하는 새로운 정보시스템의 도입 및 기존 정보시스템의 중요한 변경 시 시스템의 구축, 운영이 기업의 고객은 물론 국민의 사생활에 미칠 영향에 대해 미리 조사, 분석, 평가하는 제도\n\n\n \n\n그레이웨어(Grayware)\n\n\n\n\n  소프트웨어를 제공하는 입장에서는 악의적이지 않은 유용한 소프트웨어라고 주장할 수 있지만, 사용자 입장에서는 유용할 수도 있고 악의적일 수도 있는 애드웨어(Adware), 트랙웨어(Trackware, 스파이웨어), 기타 악성코드를 의미\n\n\n \n\n매쉬업(Mashup)\n\n\n\n\n  웹에서 제공하는 정보 및 서비스를 이용하여 새로운 소프트웨어나 서비스, 데이터베이스 등을 만드는 기술\n  다수의 정보원이 제공하는 콘텐츠를 조합하여 하나의 서비스로 제공하는 웹 사이트 또는 애플리케이션\n\n\n \n\nRIA(Rich Internet Application)\n\n\n\n\n  플래시 애니메이션 기술과 웹 서버 애플리케이션 기술을 통합\n  기존 HTML보다 역동적이고 Interactive(상호적인) 웹 페이지를 제공하는 신개념 플래시 웹페이지 제작 기술\n\n\n \n\n서비스 지향 아키텍처(Service Oriented Architecture)\n\n\n\n\n  기업의 소프트웨어 정보시스템을 공유와 재사용이 가능한 서비스 단위나 컴포넌트 중심으로 구축\n  정보를 누구나 이용 가능한 서비스로 간주하고 연동과 통합을 전제로 아키텍처를 구축해 나감\n\n\n \n\n서비스형 소프트웨어(Software as a Service)\n\n\n\n\n  소프트웨어의 여러 기능 중에서 사용자가 필요로 하는 서비스만 이용할 수 있도록 한 소프트웨어\n  공급업체가 하나의 플랫폼을 이용해 다수의 고객에게 소프트웨어 서비스를 제공하고 사용자는 대가를 지급\n\n\n \n\n소프트웨어 에스크로(Software Escrow)\n\n\n\n\n  소프트웨어 개발자의 지식재산권을 보호하고 사용자는 저렴한 비용으로 소프트웨어를 사용 및 A/S를 받을 수 있도록 소스 프로그램과 기술 정보 등을 제 3의 기관에 보관하는 것을 의미\n  소프트웨어 저작 재산권자의 지식재산권을 보호하고 저작재산권자의 폐업, 파산, 소프트웨어 개발 관련 정보 멸실 등의 사건이 발생할 경우 소프트웨어 사용 권한이 있는 사용자에게 보관된 자료를 제공하는 등 정당한 사용자의 권리를 보장하는데 목적을 둠\n\n\n \n\n복잡 이벤트 처리(Complex Event Processing)\n\n\n\n\n  실시간으로 발생하는 많은 사건들 중 의미가 있는 것만을 추출할 수 있도록 사건 발생 조건을 정의하는 데이터 처리 방법\n  금융, 통신, 전력, 물류, 국방 등에서 대용량 데이터 스트림에 대한 요구에 실시간으로 대응하기 위해 개발된 기술\n  미들웨어(Middleware)에 접목시키면 기업이 독자적인 실시간 응용 애플리케이션을 개발할 수 있도록 도와줌\n\n\n \n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2020-09-24-it-terms/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "하드웨어 용어",
      "date": "2020-09-24 11:18:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  하드웨어 용어    \n      4D Printing\n      N-Screen\n      Thin Client\n      MEMS(Micro Electro Mechanical Systems)\n      M-Disk\n      멤리스터(Memory + Register)\n    \n  \n\n\n \n\n하드웨어 용어\n\n4D Printing\n\n\n\n\n  특정 시간이나 환경 조건이 갖춰지면 스스로 형태를 변화시키거나 제조되는 자가 조립기술이 적용된 제품을 3D 프린팅 하는 기술을 의미\n  4D 프린팅을 위해서는 인간의 개입없이 열, 진동, 습도, 중력 등 다양한 환경이나 에너지원에 자극받아 변화하는 스마트 소재가 필요하며, 이는 형상기억 합금이나 나노 기술을 통해 전기회로를 내장하는 방법 등으로 제조된다\n\n\n \n\nN-Screen\n\n\n\n\n  다수의 서로 다른 단말기에서 동일한 콘텐츠를 자유롭게 이용할 수 있는 서비스\n  PC, TV, 스마트폰 등에서 동일한 콘텐츠를 끊김없이 이용할 수 있고 사용자가 갖고 있는 여러 개의 단말기에서도 동일한 콘텐츠를 끊김 없이 이용할 수 있다\n\n\n \n\nThin Client\n\n\n\n\n  PC, HDD, 주변장치 없이 기본적인 메모리만 갖추고 서버와 네트워크로 운용되는 개인용 PC를 의미\n  기억장치를 따로 두지 않기 때문에 PC를 분실하더라도 정보가 유출 될 우려가 없다\n\n\n \n\nMEMS(Micro Electro Mechanical Systems)\n\n\n\n\n  초정밀 반도체 제조 기술을 바탕으로 센서, 액추에이터 등 기계 구조를 다양한 기술로 미세 가공하여 전기기계적 동작을 할 수 있도록 한 초미세 장치\n  작은 실리콘 칩 위에 마이크로 단위의 작은 부품과 이들을 입체적으로 연결하는 마이크로 회로들로 구성\n  정보기기의 센서나 프린터 헤드, HDD 자기 헤드, 기타 환경, 의료, 군사 용도로 이용됨\n\n\n \n\nM-Disk\n\n\n\n\n  한 번의 기록만으로 자료를 영구 보관할 수 있는 광 저장장치\n  디스크 표면의 무기물층에 레이저를 이용하여 자료를 조각하고 이를 기록\n  기존의 염료층에 표시하는 방식과 달리 물리적으로 조각하는 방식\n  시간이 흘러도 변하지 않는 금속활자처럼 빛, 열, 습기 등의 외부 환경요인에 영향을 받지 않음\n\n\n \n\n멤리스터(Memory + Register)\n\n\n\n\n  전류량과 방향 등 기존의 경험을 모두 기억하는 특별한 기억소자\n  전원 공급이 중단돼도 직전에 통과한 전류량과 방향을 기억\n  전원 중단 후 재 공급하여도 기존의 상태로 복원\n\n\n \n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2020-09-24-hardware-terms/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "소프트웨어 개발 방법론(Software Development Engineering)",
      "date": "2020-09-24 16:20:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  소프트웨어 개발 방법론    \n      구조적 방법론(Structured Development Engineering)\n      정보공학 방법론(Information Engineering)\n      객체지향 방법론(Object-Oriented Engineering)\n      CBD(Component Based Development) 방법론\n      애자일(Agile) 방법론\n      제품 계열 방법론\n    \n  \n\n\n \n\n소프트웨어 개발 방법론\n\n\n\n\n  소프트웨어 개발부터 유지보수 등에 필요한 수행 방법과 이러한 일들을 효율적으로 수행하는 과정에서 필요한 각종 기법 및 도구를 체계적으로 정리하여 표준화한 것\n  목적 - 소프트웨어의 생산성 향상, 품질 향상\n\n\n \n\n구조적 방법론(Structured Development Engineering)\n\n\n\n\n  정형화된 분석 절차에 따라 사용자 요구사항을 파악하여 문서화하는 처리(Process) 중심의 방법론\n  복잡한 문제를 다루기 위해 분할과 정복(Divide and Conquer) 원리를 적용\n  쉬운 이해 및 검증이 가능한 프로그램 코드를 생성하는 것이 목적\n\n\n\n  타당성 검토 → 계획 → 요구사항 정리 → 설계 → 구현 → 시험 → 운용/유지보수\n\n\n \n\n정보공학 방법론(Information Engineering)\n\n\n\n\n  정보 시스템 개발을 위해 계획, 분석, 설계, 구축에 정형화된 기법들을 상호 연관성 있게 통합 및 적용하는 자료 중심의 방법론\n  대규모 정보 시스템을 구축하는데 적합\n\n\n\n  정보전략 계획 수립 → 업무영역 분석 → 업무시스템 설계 → 업무시스템 구축\n\n\n \n\n객체지향 방법론(Object-Oriented Engineering)\n\n\n\n\n  현실세계의 개체(Entity)를 하나의 객체(Object)로 만든 다음 이들을 조립하여 필요한 소프트웨어를 구현하는 방법론\n  구성요소 - 객체(Object), 클래스(Class), 메시지(Message)\n\n\n\n  요구분석 → 설계 → 구현 → 테스트 및 검증 → 인도\n\n\n \n\nCBD(Component Based Development) 방법론\n\n\n\n\n  기존의 시스템이나 소프트웨어를 구성하는 컴포넌트를 조합하여 하나의 새로운 애플리케이션을 만드는 방법론\n  컴포넌트의 재사용이 가능하여 시간과 노력을 절감할 수 있다\n  유지보수 비용을 최소화하고 생산성 및 품질을 향상 시킬 수 있다\n\n\n\n  준비 → 분석 → 설계 → 구현 → 테스트 → 전개 → 인도\n\n\n \n\n애자일(Agile) 방법론\n\n\n\n\n  고객의 요구사항 변화에 유연하게 대응할 수 있도록 일정한 주기를 반복하면서 개발 과정을 진행하는 방법론\n  급격한 요구사항의 변경, 소규모 프로젝트, 숙련된 개발자 집단에 적합\n\n\n\n  요구사항 → { 계획 → 개발 → 승인 테스트 }\n\n\n \n\n제품 계열 방법론\n\n\n\n\n  특정 제품에 적용하고 싶은 공통된 기능을 정의하여 개발하는 방법론\n  임베디드 소프트웨어(Embedded Software)를 만드는데 적합\n  영역 공학과 응용공학으로 분류되며 이들을 연계하기 위해 제품의 요구사항, 아키텍처, 조립 생산이 필요\n\n\n \n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2020-09-24-development-engineering/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "소프트웨어 비용산정 기법",
      "date": "2020-09-25 13:06:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  소프트웨어 비용산정 기법    \n      하향식 비용산정 기법        \n          전문가 감정 기법\n          델파이 기법\n        \n      \n      상향식 비용산정 기법        \n          LOC(Line of code)\n          수학적 산정 기법 - COCOMO(COnstructive COst  MOdel)            \n              조직형(Organic)\n              반 분리형(Semi-Detached)\n              내장형(Embedded)\n            \n          \n          수학적 산정 기법 - Putnam 모형\n          수학적 산정 기법 - 기능 점수(FP, Function Point) 모형\n        \n      \n    \n  \n\n\n \n\n소프트웨어 비용산정 기법\n\n\n\n\n\n\n  소프트웨어 개발에 소요되는 자원으로 규모를 확인하여 실행 가능한 계획을 수립하기 위해 필요한 비용을 산정\n  비용산정이 높게 책정될 경우 - 업무의 효율성 저하 및 예산의 낭비\n  비용산정이 낮게 책정될 경우 - 개발자의 부담 가중, 품질 이슈 증가\n  종류 - 상향식 비용산정 / 하향식 비용산정\n\n\n\n\n하향식 비용산정 기법\n\n\n\n\n  경험과 전문 지식이 많은 개발자들이 인력, 시스템 크기, 필요 예산 등을 합의하여 결정\n\n\n전문가 감정 기법\n\n\n\n\n  조직 내 경험이 많은 두 명 이상의 전문가에게 비용산정을 의뢰\n  가장 편리하고 신속함\n  새로운 프로젝트에는 과거의 프로젝트와 다른 요소들이 있다는 점을 간과할 수 있다는 단점\n\n\n \n\n델파이 기법\n\n\n\n\n  전문가 감정 기법의 단점을 보완하기 위해 더욱 많은 전문가의 의견을 종합하여 산정\n  전문가들의 편견이나 분위기에 지배되지 않도록 한 명의 의장과 다수의 전문가로 결정\n\n\n \n\n상향식 비용산정 기법\n\n\n\n\n  업무 분류 구조로 정의\n  각 구성요소에 대한 산정을 독립적으로 실시한 후 이를 집계하여 산정\n\n\nLOC(Line of code)\n\n\n\n\n  소프트웨어 각 기능의 소스 코드(원시 코드) 라인수의 비관치, 낙관치, 기대치를 측정하여 예측치를 얻음\n  예측치 = ( a + 4m + b ) / 6\n\n\n\n  a = 낙관치 / b = 비관치 / m = 기대치(중간치)\n\n\n\n  산정 공식\n    \n      노력( 인 / 월 ) = 개발 X 인원 = 전체 코드 라인 수 / 인당 월평균 코드 라인 수\n      개발 비용 = 노력( 인 / 월 ) X 단위 비용 (인당 월평균 인건비)(\n      개발 기간 = 노력( 인 / 월 ) / 인원\n      생산성 = 전체 코드 라인 수 / 노력( 인 / 월 )\n    \n  \n\n\n\n  LOC기법에 의하여 예측된 총 라인 수가 50,000라인, 개발에 참여할 프로그래머가 5명, 프로그래머들의 평균 생산성이 월 500라인 일 때 개발에 소요되는 총기간은 20개월이다\n\n  노력( 인 / 월 ) = 개발 X 인원 = 전체 코드 라인 수 / 인당 월평균 코드 라인 수 = 50,000 / 500 = 100\n개발 기간 = 노력( 인 / 월 ) / 인원 = 100 / 5 = 20\n\n\n \n\n수학적 산정 기법 - COCOMO(COnstructive COst  MOdel)\n\n\n\n\n  보헴(Boehm)이 제안한 것으로 원시 프로그램의 규모인 LOC에 의한 비용산정 기법\n  개발할 소프트웨어의 규모를 예측한 후 이를 소프트웨어 종류에 따라 다르게 책정되는 비용산정공식에 대입\n  같은 규모의 프로그램이라도 성격에 따라 비용이 다르게 산정\n  비용산정 결과는 프로젝트를 완성하는데 필요한 노력(Man-Month)으로 나타남\n\n\n조직형(Organic)\n\n\n\n\n  엄격한 요구사항보다는 덜한 요구사항에 훌륭한 현장 경험을 갖고 있는 소규모 팀이 수행할 수 있는 프로젝트\n  사무처리용, 과학용 응용 소프트웨어 등의 소프트웨어 개발에 적합\n  50,000라인(50 KDSI) 이하의 소프트웨어를 개발하는 유형\n\n\n\n  프로그램 규모(KDSI, Kilo Delivered Source Instruction)\n\n\n반 분리형(Semi-Detached)\n\n\n\n\n  요구사항이 중간급에 종합적인 경험을 갖고 있는 팀이 수행하는 프로젝트\n  DBMS, 컴파일러, 인터프리터 등의 소프트웨어 개발에 적합\n  300,000라인(300 KDSI) 이하의 소프트웨어를 개발하는 유형\n\n\n내장형(Embedded)\n\n\n\n\n  H/W &amp; S/W &amp; 운영 제약들이 하나의 집합으로 개발되도록 만들어 놓은 소프트웨어\n  최대 규모의 트랜잭션 처리 시스템이나 OS 등의 소프트웨어 개발에 적합\n  300,000라인(300 KDSI) 이상의 소프트웨어를 개발하는 유형\n\n\n \n\n수학적 산정 기법 - Putnam 모형\n\n\n\n\n  소프트웨어 생명 주기의 전 과정 동안 사용될 노력 분포를 가정해주는 모형\n  생명주기 예측 모형이라고도 한다\n  대형 프로젝트의 노력 분포 산정에 이용\n  개발기간이 늘어날수록 프로젝트 적용 인원의 노력이 감소\n  Putnam 모형과 Rayleigh-Norden 곡선을 기초로 개발된 자동화 추정 도구 - SLIM\n\n\n\n\n \n\n수학적 산정 기법 - 기능 점수(FP, Function Point) 모형\n\n\n\n\n  소프트웨어의 기능을 증대시키는 요인별로 가중치를 부여\n  요인별 가중치를 합산하여 기능 점수를 산출\n  총 기능 점수와 영향도를 이용하여 기능 점수를 계산하여 이를 기초로 비용산정\n  다양한 프로젝트와 개인별 요소를 수행하도록 FP모형을 기초로 개발된 자동화 추정 도구 - ESTIMACS\n\n\n \n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2020-09-25-software-cost/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "보안 프로그램(Security Program)",
      "date": "2020-09-25 13:29:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  보안 프로그램\n  Cron\n\n\n \n\n보안 프로그램\n\n\n\n\n  \n    \n      프로그램명\n      설명\n    \n  \n  \n    \n      Tripwire\n      크래커가 침입하여 백도어를 만들어 놓거나 설정 파일을 변경했을 때 분석하는 도구\n    \n    \n      Cron\n      유닉스 기반 OS의 작업 예약 스케줄러\n    \n    \n      Aide\n      Tripwire를 대신할 수 있는 도구로 파일의 무결성을 검사\n    \n    \n      sXid\n      MD5 Checksum을 사용하여 SUID, SGID파일을 추적하여 루트키트가 설치되어 있는지 검사 및 경고. Cron 작업 형태로 수행 됨\n    \n    \n      Claymore\n      침입탐지 및 무결성 모니터링 도구. Crontable을 이용하여 주기적으로 파일 시스템의 변조 유무를 확인하고 변조를 탐지할 경우 관리자에게 메일로 통보\n    \n    \n      Samhain\n      시스템의 무결성을 점검하는 도구. 여러 시스템을 관리할 수 있는 수단을 제공하며 모니터링 에이전트와 중앙 로그서버로 구성 됨\n    \n    \n      Slipwire\n      파일 시스템의 무결성을 검사하는 도구로 파일의 SHA-1 해쉬값을 비교하여 변경될 경우 사용자에게 경고\n    \n    \n      Fcheck\n      파일 시스템의 변조유무를 점검하기 위한 PERL Script 도구로 SYSLOG, Console 등으로 관리자에게 파일 시스템 변화를 알림. Tripwire와 비슷한 도구로 보다 설치와 운영이 쉽다\n    \n  \n\n\n \n\nCron\n\n\n\n\n  유닉스/리눅스 계열에서 사용하는 스케쥴링 문법이다\n  어떠한 특정한 시점을 가르킨다\n\n\n\n\n분(Min) 시간(Hour) 일(Day) 월(Month) 요일(Day) 명령어(Command)\n\n\n혹은\n\n[초(sec)] 분(Min) 시간(Hour) 일(Day) 월(Month) 요일(Day) 명령어(Command) [연도(Year)]\n\n\n \n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2020-09-25-security-program/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "통합 모델링 언어(UML, Unified Modeling Language)",
      "date": "2020-09-25 17:30:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  통합 모델링 언어(UML, Unified Modeling Language)    \n      UML 관계(Relationship) 개요 및 종류\n      UML Diagram        \n          구조 다이어그램(정적 모델링)\n          행위 다이어그램(동적 모델링)\n        \n      \n    \n  \n\n\n \n\n통합 모델링 언어(UML, Unified Modeling Language)\n\n\n  시스템 분석, 설계, 구현 등의 개발 작업 과정에서 각 이해관계자들의 의사소통을 보다 원활하게 이뤄지도록 한 시각적 모델링 언어\n  객체지향 언어와 밀접한 관련이 있어 객체지향 모델링 언어라고도 함\n  소프트웨어 시스템, 업무 모델링, 시스템의 산출물을 규정하고 시각화하며 문서화하는 모델링 언어\n\n\n\n\nUML 관계(Relationship) 개요 및 종류\n\n\n  사물(things, 객체) - 다이어그램에서 관계가 형성될 수 있는 대상으로 다이어그램의 가장 중요한 기본 요소\n  관계(Relation) - 사물과 사물 사이의 연관성을 표현\n  연관 관계(Association) - is-member-of\n  사물과 사물 사이를 실선으로 연결하여 표기, 방향성이 있으면 화살표로 표시\n  서로에게 영향을 주는 양방향 관계는 그냥 실선으로 표시\n  다중성은 숫자로 표현\n\n\n \n\n\n\n \n\n\n  집합 관계(Aggregation) - 하나의 사물이 다른 사물에 포함되어 있는 관계 part-whole, is-a-part-of\n\n\n \n\n\n\n \n\n\n  포함 관계(Composition) - 전체 사물의 변화가 포함되는 사물에 영향을 주는 관계\n\n\n \n\n\n\n \n\n\n  일반화 관계(Generalization) - 하나의 사물이 다른 사물에 비해 더 일반적인지 혹은 더 세부적인지 표현 is-a\n\n\n \n\n\n\n \n\n\n  의존 관계(Dependency) - 연관성은 있으나 필요에 의해 일정 시점에만 연관을 유지하는 관계\n\n\n \n\n\n\n \n\n\n  실체화 관계(Realization) - 행위 또는 인터페이스 중심으로 서로를 그룹화할 수 있는 관계\n\n\n \n\n\n\n \n\n\n\nUML Diagram\n\n\n  사물과 관계를 도식화하여 표현\n  다양한 관점에서 시스템을 가시화한 뷰(View)를 제공함으로써 이해자들 간의 의사소통에 도움\n\n\n구조 다이어그램(정적 모델링)\n\n\n  \n    \n      다이어그램명\n      설명\n    \n  \n  \n    \n      클래스 다이어그램(Class Diagram)\n      클래스와 클래스가 갖는 속성, 클래스 사이의 관계\n    \n    \n      객체 다이어그램(Object Diagram)\n      클래스에 속한 사물, 인스턴스를 특정 시점의 객체와 객체사이의 관계로 표현\n    \n    \n      컴포넌트 다이어그램(Component Diagram)\n      컴포넌트간의 관계, 인터페이스를 표현\n    \n    \n      배치 다이어그램(Deployment Diagram)\n      산출물, 프로세스, 컴포넌트 등의 물리적 요소의 위치를 표현\n    \n    \n      복합체 구조 다이어그램(Composite Structure Diagram)\n      클래스, 컴포넌트가 복합적 구조를 갖는 경우 해당 내부구조를 표현\n    \n    \n      패키지 다이어그램(Pakage Diagram)\n      클래스 모델 요소들을 그룹화한 패키지들의 관계를 표현\n    \n  \n\n\n \n\n행위 다이어그램(동적 모델링)\n\n\n  \n    \n      다이어그램명\n      설명\n    \n  \n  \n    \n      유스케이스 다이어그램(Usecase Diagram)\n      사용자의 요구사항을 분석/사용자와 사용사례로 구성\n    \n    \n      시퀀스 다이어그램(Sequence Diagram)\n      상호작용하는 시스템이나 객체들이 주고받는 메시지를 표현\n    \n    \n      커뮤니케이션 다이어그램(Communication Diagram)\n      동작에 참여하는 객체들이 주고받는 메시지, 객체간의 연관까지 표현\n    \n    \n      상태 다이어그램(State Diagram)\n      하나의 객체가 자신이 속한 클래스의 상태 변화 혹은 다른 객체와의 상호작용에 따라 변하는 상태를 표현\n    \n    \n      활동 다이어그램(Activity Diagram)\n      시스템이 어떤 기능을 수행하는지 객체의 처리 알고리즘이나 조건에 따른 처리 흐름을 순서에따라 표현\n    \n    \n      상호작용 개요 다이어그램(Interaction Diagram)\n      상호작용 다이어그램 간의 제어흐름 표현\n    \n    \n      타이밍 다이어그램(Timing Diagram)\n      객체상태변화에 시간제약을 표현\n    \n  \n\n",
      "categories": ["cs","software-design"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/software-design/2020-09-25-uml/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "사용자 인터페이스(UI, User Interface)",
      "date": "2020-09-25 17:46:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  사용자 인터페이스(UI, User Interface)    \n      UI 구문\n      UI 기본 원칙\n      UI 설계 시 고려사항\n      UI 설계 도구\n    \n  \n\n\n \n\n사용자 인터페이스(UI, User Interface)\n\n\n  사용자와 시스템 간의 상호작용이 원활하게 이뤄지도록 도와주는 장치나 소프트웨어를 의미\n  사용자의 만족도에 가장 큰 영향을 미치는 중요한 요소로 소프트웨어 영역 중 변경이 가장 많음\n  사용자의 편리성과 가독성을 높임으로써 작업 시간을 단축시키고 업무에 대한 이해도를 높여준다\n  최소한의 노력으로 원하는 결과를 얻을 수 있게 한다\n  수행 결과의 오류를 줄인다\n  사용자의 막연한 작업 기능에 대해 구체적인 방법을 제시한다\n\n\n\n\nUI 구문\n\n\n  CLI(Command Line Interface) - 명령과 줄이 텍스트 형태로 이뤄지는 인터페이스\n  GUI(Graphic User Interface) - 아이콘이나 메뉴를 마우스로 조작하는 그래픽 환경의 인터페이스\n  NUI(Natural User Interface) - 사용자의 말이나 행동으로 조작하는 인터페이스\n\n\n\n\nUI 기본 원칙\n\n\n  직관성 - 누구나 쉽게 이해하고 사용할 수 있어야 함\n  유효성 - 사용자의 목적을 정확하고 완벽하게 달성해야 함\n  학습성 - 누구나 쉽게 배우고 익힐 수 있어야 함\n  유연성 - 사용자의 요구사항을 최대한 수용하고 실수를 최소화해야 함\n\n\n\n\nUI 설계 시 고려사항\n\n\n  사용자 중심 - 사용자가 쉽게 이해하고 편리하게 사용할 수 있는 환경을 제공\n  일관성 - 버튼이나 조작 방법 등을 일관성 있게 제공하므로 사용자가 쉽게 기억하고 습득할 수 있게 설계\n  단순성 - 조작 방법을 단순화시켜 인지적 부담을 감소시켜야 함\n  결과 예측 가능 - 작동시킬 기능만 보고도 결과를 예측할 수 있도록 설계해야 함\n  가시성 - 메인화면에 주요 기능을 노출시켜 최대한 조작이 쉽도록 설계해야 함\n  표준화 - 기능 구조와 디자인을 표준화하여 한 번 학습한 이후에는 쉽게 사용할 수 있도록 설계\n  접근성 - 사용자의 연령, 성별, 인종 등 다양한 계층이 사용할 수 있도록 설계해야 함\n  명확성 - 사용자가 개념적으로 쉽게 인지할 수 있도록 설계해야 함\n  오류 발생 해결 - 오류가 발생하면 사용자가 쉽게 인지할 수 있도록 설계해야 함\n\n\n\n\nUI 설계 도구\n\n\n  와이어프레임(Wireframe)\n    \n      기획 단계 초기에 자작하는 것으로 페이지에 대한 개략적인 레이아웃이나 UI 요소에 대한 뼈대를 설계\n      와이어프레임 제작 시 각 페이지의 영역 구분, 콘텐츠, 텍스트 배치 등을 화면 단위로 설계\n    \n  \n  목업(Mockup)\n    \n      디자인, 사용방법, 평가 등을 위해 와이어프레임보다 좀 더 실제 화면과 유사하게 만든 정적 형태의 모형\n    \n  \n  스토리보드(Storyborad)\n    \n      와이어프레임에 콘텐츠에 대한 설명, 페이지 간 이동 흐름 등을 추가한 문서\n      디자이너와 개발자가 최종적으로 참고하는 작업 지침서\n      정책, 프로세스, 콘텐츠 구성, 와이어프레임, 기능 정의 등 서비스 구축을 위한 모든 정보가 담김\n    \n  \n  프로토타입(Prototype)\n    \n      와이어프레임이나 스토리보드 등에 인터랙션을 적용함으로써 실제 구현된 것처럼 테스트가 가능한 동적 형태의 모형\n      사용성 테스트나 작업자 간 서비스 이해를 위해 작성하는 샘플\n    \n  \n  유스케이스(Usecase)\n    \n      사용자 측면에서의 요구사항으로 사용자가 원하는 목표를 달성하기 위해 수행할 내용을 기술\n      요구사항을 빠르게 파악함으로써 프로젝트 초기에 시스템의 기능적인 요구를 결정하고 그 결과를 문서화\n      자연어로 작성된 사용자의 요구사항을 구조적으로 표현한 것으로 일반적으로 다이어그램 형식으로 묘사된다\n    \n  \n\n",
      "categories": ["cs","software-design"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/software-design/2020-09-25-ui/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "객체지향 프로그래밍(Object-Oriented Programming)?",
      "date": "2020-09-28 19:31:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n이번에 정보처리기사 필기 공부를 하면서 지긋지긋하도록 많이 접한 용어이다.\n\n자매품으로 CBD(Component Based Development)라는 친구가 있다.\n\n솔직히 무슨 차이인지 모르겠다. 똑같은 말 같아서… 🤣\n\n이해하기를 OOP란 컴퓨터라는 객체가 있다면\n\n컴퓨터의 부품들인 키보드, 마우스, 모니터, 본체 등을 더 작은 단위의 객체로 쪼개고\n\n더 쪼개자면 본체는 CPU, GPU, RAM 등의 부품단위로도 쪼갤 수 있을 것이다.\n\n아무튼 그렇게 쪼개고 쪼개서 작은 단위의 객체를 Class로 구현하여 조립한다는 취지인 것 같다.\n\nCBD는 소프트웨어를 컴포넌트 단위로 구성하여 재사용성, 유지보수성의 증가를 꾀한다는 논지의 개념이었는데,\n\n이건 OOP에 속하면서 보다 더 큰 단위의 개념처럼 느껴진다.\n\n아무튼 아직은 이거다 싶게 와 닿는 개념은 아니다. 아리송하다.\n\n \n\n \n\n\n\n \n\n자바를 책으로 공부한 지 한 달이 다 되어가는 시점에 만든 두더지 잡기 게임인데,\n\n지금에 와서 뜯어보니 소스코드가 절차 지향적이라는 생각이 든다.\n\n이렇게 프로그램을 만들 경우 프로그램이 단순하다는 가정하에 원하는 그림을 그리기 쉬울 것 같긴 하다.\n\n다만 이렇게 프로그래밍을 해서 유지보수조차 힘들어질 정도의 대형 프로젝트라는 걸 도통해본 적도 없고,\n\n하는 방법도 알지 못하니 그것이 문제다.\n\n \n\nOOP라는 것이 결국 목표를 구상하고 어떻게 구현할지 설계한 후\n\n객체를 Class 단위로 쪼개어 만든 후 조립하는 상향식 기법 같은데\n\n이렇게 하려면 우선 펜대를 잡고 설계라는 걸 좀 해봐야 하지 않을까 싶다.\n\n오픈소스를 꾸준히 리뷰해봐야겠다. 꾸준히 하면 언젠가는 잘하겠지.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2020-09-28-diary-1/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "SQL 문법(Syntax)",
      "date": "2020-09-30 19:51:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  구분\n  속성\n  데이터 정의어(DDL, Data Definition Language)    \n      CREATE(생성)\n      DROP(삭제)\n      ALTER(변경)\n      데이터 조작어(DML, Data Manipulation Language)\n      SELECT(조회)\n      UPDATE(변경)\n      DELETE(삭제)\n      INSERT(추가)\n      데이터 제어어(DCL, Data Control Language)\n      GRANT(권한 부여)\n      REVOKE(권한 박탈)\n    \n  \n\n\n \n\n구분\n\n\n  \n    \n      데이터 정의어 (DDL, Data Definition Language)\n      CREATE / DROP / ALTER\n    \n  \n  \n    \n      데이터 조작어 (DML, Data Manipulation Language)\n      SELECT /  UPDATE / DELETE / INSERT\n    \n    \n      데이터 제어어 (DCL, Data Control Language)\n      GRANT / REVOKE\n    \n  \n\n\n속성\n\n  NO ACTION - 참조 릴레이션의 참조 속성 값이 변경되었을 때 기본 릴레이션에는 아무런 조치를 취하지 않음\n  CASCADE - 참조 릴레이션의 튜플 조작 시 그와 관련된 기본 릴레이션의 튜플들도 연쇄적으로 조작\n  SET NULL - 참조 릴레이션에 변화가 있으면 기본 릴레이션의 관련 튜플의 값을 NULL로 변경\n  SET DEFAULT - 참조 릴레이션에 변화가 있으면 기본 릴레이션의 관련 튜플의 값을 기본값으로 변경\n  RESTRICTED - 변경할 요소를 다른 개체에서 참조하고 있으면 변경하지 못함\n  WITH GRANT OPTION - 부여된 권한을 다른 사용자에게 다시 부여할 수 있는 권리\n  GRANT OPTION FOR - 다른 사용자에게 권한을 부여할 수 있는 권한을 박탈\n  DISTINCT - 중복되는 레코드는 한 개로 표현\n  WHERE - SQL에 조건을 걸 때 사용\n  AS - 테이블에 별명(줄임말)을 부여할 때 사용\n  ORDER BY 필드명 ASC(오름차순) | DESC(내림차순) - 정렬하여 표시\n  GROUP BY 필드명 - 특정 필드를 기준으로 그룹화하여 표시\n  HAVING 그룹조건 - 그룹에 대한 조건을 기술. GROUP BY문에 종속되어 사용됨\n  AVG(필드명) - 평균으로 표시\n  SUM(필드명) - 합계로 표시\n  COUNT(*) - 개수를 계산하여 표시\n  MAX(필드명) - 최댓값 표시\n  MIN(필드명) - 최솟값 표시\n\n\n\n\n데이터 정의어(DDL, Data Definition Language)\n\n스키마, 릴레이션, 뷰, 인덱스 등을 정의하거나 변경/제거할 때 사용되는 명령\n\n\n\nCREATE(생성)\n\n\n  CREATE [데이터베이스 | 테이블 | 인덱스 | 뷰] [속성]\n\n\n\n\nDROP(삭제)\n\n\n  DROP [데이터베이스 | 테이블 | 인덱스 | 뷰] [속성]\n\n\n\n\nALTER(변경)\n\n\n  ALTER [테이블] [ADD | ALTER | DROP] [속성]\n\n\n\n\n데이터 조작어(DML, Data Manipulation Language)\n\n테이블 내의 Row를 추가, 제거, 변경, 검색할 때 사용되는 명령\n\n\n\nSELECT(조회)\n\n\n  SELECT 필드명 FROM 테이블 [WHERE] [필드 명=필드 값]\n\n\n\n\nUPDATE(변경)\n\nUPDATE 테이블명 SET 필드명=필드 값 [WHERE] [필드 명=필드 값]\n\n\n  UPDATE student SET address=’서울’;\n\n  UPDATE student SET name=’홍길동’ WHERE id=1;\n\n  UPDATE student SET name=’홍길동’, birthday=’2000-1-1’ WHERE id=1;\n\n\n\n\nDELETE(삭제)\n\nDELETE FROM [테이블]\n\nDELETE FROM [테이블] [WHERE] [필드 명=필드 값]\n\n\n  DELETE FROM student WHERE id = 1;\n\n\n\n\nINSERT(추가)\n\nINSERT INTO 테이블명 VALUES (필드 값, 필드 값, 필드 값)\n\nINSERT INTO 테이블명(필드명, 필드명, 필드명) VALUES (필드 값, 필드값, 필드 값)\n\n\n  INSERT INTO student VALUES (‘1’, ‘홍길숙’, ‘여자’, ‘서울’, ‘2000-1-1’);\n\n  INSERT INTO student (id, name, sex, address, birthday) VALUES (‘1’, ‘홍길동’, ‘남자’, ‘서울’, ‘2000-1-1’);\n\n\n\n\n데이터 제어어(DCL, Data Control Language)\n\n데이터베이스의 보안, 무결성을 유지하기 위한 명령\n\n\n\nGRANT(권한 부여)\n\nGRANT 사용자등급 TO ID@IP [IDENTFIED BY PASSWORD]\n\n\n\nREVOKE(권한 박탈)\n\nREVOKE 사용자등급 FROM ID@IP\n",
      "categories": ["cs","database-construct"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/database-construct/2020-09-30-sql-syntax/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "DB 유의사항",
      "date": "2020-09-30 20:04:00 +0000",
      "description": "개발일기\n",
      "content": "\n  1. DROP, DELETE를 하기 전에 손을 떼고 잠시 심호흡을 하자. 커피 한잔도 괜찮다.\n  2. CHAR와 VARCHAR의 차이가 무엇인지 고민했다.\n  3. DELETE는 Row단위로, TRUNCATE는 한 번에\n  4. INSERT문 사용 시\n\n\n \n\n오늘은 데이터베이스 기초 공부를 마쳤다. 공부를 하면서 이것은 중요하다고 생각했던 부분들을 정리해본다\n\n1. DROP, DELETE를 하기 전에 손을 떼고 잠시 심호흡을 하자. 커피 한잔도 괜찮다.\n\n\n\n개인 프로젝트 등의 소규모 작업에서는 실수로 데이터를 날렸을 시 잠깐 귀찮고 말 수 있다는 생각이 들었지만,\n\n기업은 대규모의 데이터를 핸들링하는데 담당자가 실수로 그런 대규모의 데이터를 한순간에\n\n날려버릴 수도 있다는 생각이 드니 그 상황이 얼마나 끔찍할지 상상이 된다.\n\n회사에서 임금을 받는다면 나는 돈을 받고 일을 하는 프로이다. 프로의 마음가짐은 인생 모든 부분에서 중요하다.\n\n \n\n2. CHAR와 VARCHAR의 차이가 무엇인지 고민했다.\n\n\n\n설명만 들어보면 “그냥 VARCHAR로 다 해버리면 공간 복잡도가 줄어드는 거 아닌가?” 라고 생각하였는데,\n\n구글링을 해보니 CHAR의 경우 고정된 공간을 할당하므로 검색에서 VARCHAR보다 유리하다고 한다.\n\n즉, 시간 복잡도에서 이득을 볼 수 있다는 뜻 같다.\n\n일장 일단이 있는 것 같으므로 타입을 잘 생각해서 결정해야 할 것 같다.\n\n \n\n3. DELETE는 Row단위로, TRUNCATE는 한 번에\n\n\n\n시간 복잡도의 차이가 크다.\n\n \n\n4. INSERT문 사용 시\n\n\n\n\n  INSERT INTO 테이블명(필드명) VALUES(필드 값)\n\n  INSERT INTO 테이블명 VALUES(필드 값)\n\n\n \n\n두가지 문법이 존재한다.\n\n처음에는 후자가 더 짧으니까 편해 보인다고 생각하였는데,\n\n생각해보니 데이터베이스는 수시로 변동이 되기 때문에\n\n후자의 문법으로 추가를 한다면 오류가 날 확률이 있다고 생각했다.\n\n추가로 INSERT문 실행 시 특정 필드에 NULL값이 들어가길 원하는 경우도 있을 수 있는데,\n\n후자의 문법을 사용하면 일괄적으로 데이터가 삽입되어야 하므로 원치 않는 값을 넣어야 하는 상황이 생길 수 있기 때문에 이때도 전자의 문법을 사용한다더라.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2020-09-30-diary-2/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "성적 관리 프로그램",
      "date": "2020-09-30 20:20:00 +0000",
      "description": "자바로 만드는 성적 관리 프로그램\n",
      "content": "\n \n\n요즘 OOP에 엄청나게 관심이 많은데 Java를 배우고 약 보름 후에 만들었던,\n\n지금에서 보면 약 한 달전쯤에 작성한 코드를 다시 보니 정말 비루하다는 생각이 든다.\n\n다음에는 이렇게 만들지 말아야지\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n// file: 'ManagemnetScore.java'\npublic class ManagementScore implements Serializable {\n    String names;\n    int score;\n\n    public ManagementScore(String names) {\n        this.names = names;\n    }\n\n    public ManagementScore(int score) {\n        this.score = score;\n    }\n}\n\n\n \n\n// file: 'Management.java'\npublic class Management {\n    // 변수 선언 &amp; 생성자 호출\n    public Scanner sc = new Scanner(System.in);\n    public String strM = \"0\";\n\n    private ArrayList&lt;ManagementScore&gt; nameslist = new ArrayList&lt;ManagementScore&gt;();\n    private ArrayList&lt;ManagementScore&gt; guklist = new ArrayList&lt;ManagementScore&gt;();\n    private ArrayList&lt;ManagementScore&gt; englist = new ArrayList&lt;ManagementScore&gt;();\n    private ArrayList&lt;ManagementScore&gt; sulist = new ArrayList&lt;ManagementScore&gt;();\n\n    private String names;\n    private int guk = 0, eng = 0, su = 0;\n\n    public void managementProgram() {\n        // 메뉴 선택\n        strM = sc.nextLine();\n\n        // 메뉴 실행\n        switch(strM) {\n            // 입력\n            case \"1\":\n                System.out.println(\"※등록하실 이름을 입력하세요.\");\n                System.out.print(\"※이름 : \");\n                ManagementScore nl = new ManagementScore(sc.nextLine());\n                nameslist.add(nl);\n\n                System.out.println(\"※국어 점수를 입력하세요.\");\n                System.out.print(\"※국어 : \");\n                ManagementScore gl = new ManagementScore(sc.nextInt());\n                guklist.add(gl);\n\n                System.out.println(\"※영어 점수를 입력하세요.\");\n                System.out.print(\"※영어 : \");\n                ManagementScore el = new ManagementScore(sc.nextInt());\n                englist.add(el);\n\n                System.out.println(\"※수학 점수를 입력하세요.\");\n                System.out.print(\"※수학 : \");\n                ManagementScore sl = new ManagementScore(sc.nextInt());\n                sulist.add(sl);\n                break;\n\n            // 저장\n            case \"2\":\n                // 파일 내보내기\n                try {\n                    FileOutputStream fosnames = new FileOutputStream(\"D:\\\\Java\\\\WorkSpace\\\\java_project\\\\src\\\\java_proj_src\\\\namelist.ser\");\n                    BufferedOutputStream bosnames = new BufferedOutputStream(fosnames);\n                    ObjectOutputStream outnames = new ObjectOutputStream(bosnames);\n                    outnames.writeObject(nameslist);\n\n                    FileOutputStream fosguk = new FileOutputStream(\"D:\\\\Java\\\\WorkSpace\\\\java_project\\\\src\\\\java_proj_src\\\\guklist.ser\");\n                    BufferedOutputStream bosguk = new BufferedOutputStream(fosguk);\n                    ObjectOutputStream outguk = new ObjectOutputStream(bosguk);\n                    outguk.writeObject(guklist);\n\n                    FileOutputStream foseng = new FileOutputStream(\"D:\\\\Java\\\\WorkSpace\\\\java_project\\\\src\\\\java_proj_src\\\\englist.ser\");\n                    BufferedOutputStream boseng = new BufferedOutputStream(foseng);\n                    ObjectOutputStream outeng = new ObjectOutputStream(boseng);\n                    outeng.writeObject(englist);\n\n                    FileOutputStream fossu = new FileOutputStream(\"D:\\\\Java\\\\WorkSpace\\\\java_project\\\\src\\\\java_proj_src\\\\sulist.ser\");\n                    BufferedOutputStream bossu = new BufferedOutputStream(fossu);\n                    ObjectOutputStream outsu = new ObjectOutputStream(bossu);\n                    outsu.writeObject(sulist);\n\n                    // Stream Close\n                    outnames.close();\n                    outguk.close();\n                    outeng.close();\n                    outsu.close();\n                }\n\n                // 에러 검출\n                catch(Exception e) {\n                    System.out.printf(\"파일 저장 오류 : %s\", e.getMessage());\n                }\n                System.out.println(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\");\n                System.out.println(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\");\n                System.out.println(\"!!!!!!!!                     !!!!!!!!\");\n                System.out.println(\"!!!!!!!!   저장 되었습니다   !!!!!!!!\");\n                System.out.println(\"!!!!!!!!                     !!!!!!!!\");\n                System.out.println(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\");\n                System.out.println(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\");\n                break;\n\n            // 조회\n            case \"3\":\n                // 파일 불러오기\n                try {\n                    FileInputStream fisnames = new FileInputStream(\"D:\\\\Java\\\\WorkSpace\\\\java_project\\\\src\\\\java_proj_src\\\\namelist.ser\");\n                    BufferedInputStream bisnames = new BufferedInputStream(fisnames);\n                    ObjectInputStream innames = new ObjectInputStream(bisnames);\n\n                    FileInputStream fisguk = new FileInputStream(\"D:\\\\Java\\\\WorkSpace\\\\java_project\\\\src\\\\java_proj_src\\\\guklist.ser\");\n                    BufferedInputStream bisguk = new BufferedInputStream(fisguk);\n                    ObjectInputStream inguk = new ObjectInputStream(bisguk);\n\n                    FileInputStream fiseng = new FileInputStream(\"D:\\\\Java\\\\WorkSpace\\\\java_project\\\\src\\\\java_proj_src\\\\englist.ser\");\n                    BufferedInputStream biseng = new BufferedInputStream(fiseng);\n                    ObjectInputStream ineng = new ObjectInputStream(biseng);\n\n                    FileInputStream fissu = new FileInputStream(\"D:\\\\Java\\\\WorkSpace\\\\java_project\\\\src\\\\java_proj_src\\\\sulist.ser\");\n                    BufferedInputStream bissu = new BufferedInputStream(fissu);\n                    ObjectInputStream insu = new ObjectInputStream(bissu);\n\n                    // 읽어온 Byte파일을 배열로 강제 형 변환\n                    Object objnames = innames.readObject();\n                    ArrayList&lt;ManagementScore&gt; readnames = (ArrayList&lt;ManagementScore&gt;) objnames;\n\n                    Object objguk = inguk.readObject();\n                    ArrayList&lt;ManagementScore&gt; readguk = (ArrayList&lt;ManagementScore&gt;) objguk;\n\n                    Object objeng = ineng.readObject();\n                    ArrayList&lt;ManagementScore&gt; readeng = (ArrayList&lt;ManagementScore&gt;) objeng;\n\n                    Object objsu = insu.readObject();\n                    ArrayList&lt;ManagementScore&gt; readsu = (ArrayList&lt;ManagementScore&gt;) objsu;\n\n                    System.out.println(\"+------------+---------+---------+---------+\");\n                    System.out.println(\"|   이  름   |  국  어 |  영  어 |  수  학 |\");\n                    System.out.println(\"+------------+---------+---------+---------+\");\n\n                    // 강제 형 변환 한 파일 출력을 위한 for문\t\n                    for(int i = 0; i &lt; readnames.size(); i++) {\n                        if(Objects.isNull(readnames.get(i))) {\n                        }\n                        else {\n                            System.out.printf(\"|   %-3s   |   %3s   |   %3s   |   %3s   |\\n\", readnames.get(i).names, readguk.get(i).score, readeng.get(i).score, readsu.get(i).score);\n                        }\n                    }\n\n                    // Stream Close\n                    innames.close();\n                    inguk.close();\n                    ineng.close();\n                    insu.close();\n                }\n\n                //에러 검출\n                catch(Exception e) {\n                    System.out.printf(\"파일 불러오기 오류 : %s\", e.getMessage());\n                }\n\n                System.out.println(\"+------------+---------+---------+---------+\");\n                break;\n\n            // 화면 청소 메서드 호출\n            case \"4\":\n                clearScreen();\n                break;\n\n            // default \n            default:\n                break;\n        }\n    }\n\n    // 화면 청소 메서드 정의\n    void clearScreen() {\n        try {\n            if(System.getProperty(\"os.name\").contains(\"Windows\")) {\n                new ProcessBuilder(\"cmd\", \"/c\", \"cls\").inheritIO().start().waitFor();\n            }\n            else {\n                Runtime.getRuntime().exec(\"clear\");\n            }\n\n        }\n        catch(IOException | InterruptedException ex) {\n        }\n    }\n}\n\n\n \n\n// file: 'ScoreManagementProgram.java'\npublic class ScoreManagementProgram {\n    public static void main(String[] args) {\n        // 생성자\n        Management mg = new Management();\n\n        // 프로그램 실행\n        do {\n            // 메뉴 출력    \t  \n            System.out.println(\"                            \");\n            System.out.println(\"        +------------------+\");\n            System.out.println(\"        | 성적관리프로그램 |\");\n            System.out.println(\"        +------------------+\");\n            System.out.println(\"        |    1. 입력       |\");\n            System.out.println(\"        +------------------+\");\n            System.out.println(\"        |    2. 저장       |\");\n            System.out.println(\"        +------------------+\");\n            System.out.println(\"        |    3. 조회       |\");\n            System.out.println(\"        +------------------+\");\n            System.out.println(\"        |    4. 화면청소   |\");\n            System.out.println(\"        +------------------+\");\n            System.out.println(\"        |    5. 종료       |\");\n            System.out.println(\"        +------------------+\");\n            System.out.print(\"          ※선택 : \");\n\n            // 메뉴 기능 메서드 호출\n            mg.managementProgram();\n\n            // 프로그램 종료\n        } while(!mg.strM.equals(\"5\"));\n        System.out.println(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\");\n        System.out.println(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\");\n        System.out.println(\"!!!!!!!!!             !!!!!!!!!\");\n        System.out.println(\"!!!!!!!!! PROGRAM END !!!!!!!!!\");\n        System.out.println(\"!!!!!!!!!             !!!!!!!!!\");\n        System.out.println(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\");\n        System.out.println(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\");\n\n        // 스캐너 Close\n        mg.sc.close();\n        System.exit(0);\n    }\n}\n\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2020-09-30-game-1/"
    },{
      "image": "/assets/img/backend/db-logo.png",
      "title": "정규화(Normalization)",
      "date": "2020-10-01 02:22:00 +0000",
      "description": "테이블을 쪼갠다?\n",
      "content": "\n  정규화(Normalization)    \n      제1 정규형        \n          학생\n        \n      \n      제2 정규형        \n          학생\n          성적\n        \n      \n      제3 정규형        \n          학생\n          학과\n          성적\n        \n      \n    \n  \n\n\n \n\n정보처리기사 필기를 공부하는데 정규화에 대한 내용이 나왔다.\n\n나름 이해한 바를 간단하게 요약하면 테이블을 특정 도메인별로 쪼개는 과정인 것 같다.\n\n \n\n정규화(Normalization)\n\n제1 정규형\n\n\n\n학생\n\n\n  \n    \n      학번\n      학과\n      과목코드\n      지도교수\n      성적\n    \n    \n      1000\n      컴퓨터공학\n      MSC1000\n      홍길동\n      A\n    \n  \n\n\n \n\n모든 튜플의 값이 원자성을 가진다.\n\n제1 정규형을 만족한다.\n\n하지만 함수적 종속관계가 존재한다.\n\n학번은 학과와 지도교수를 결정할 수 있고,\n\n학번과 과목코드는 성적을 결정할 수 있다.\n\n \n\n정리하자면\n\n\n  {학번, 과목코드} → 성적\n\n  학번 → 학과\n\n  학과 → 지도교수\n\n  학번 → 지도교수\n\n\n \n\n성적은 학번과 과목코드에 완전 함수적 종속성을 갖고,\n\n학과와 지도교수는 학번에 부분 함수적 종속성을 갖는다.\n\n그러므로 학번은 결정자, 학과와 지도교수는 종속자가 된다.\n\n \n\n제2 정규형\n\n\n\n학생\n\n\n  \n    \n      학번\n      학과\n      지도교수\n    \n    \n      1000\n      컴퓨터공학\n      홍길동\n    \n  \n\n\n \n\n성적\n\n\n  \n    \n      학번\n      과목코드\n      성적\n    \n    \n      1000\n      MSC1000\n      A\n    \n  \n\n\n \n\n\n  학번 → 학과\n\n  학과 → 지도교수\n\n  학번 → 지도교수\n\n\n이행 함수적 종속성을 갖는다. 제 3정규형 대상이다.\n\n학과를 기준으로 릴레이션을 나눈다.\n\n \n\n제3 정규형\n\n\n\n학생\n\n\n  \n    \n      학번\n      학과\n    \n    \n      1000\n      컴퓨터공학\n    \n  \n\n\n \n\n학과\n\n\n  \n    \n      학과\n      지도교수\n    \n    \n      컴퓨터공학\n      홍길동\n    \n  \n\n\n \n\n성적\n\n\n  \n    \n      학번\n      과목코드\n      성적\n    \n    \n      1000\n      MSC1000\n      A\n    \n  \n\n\n \n",
      "categories": ["backend","database"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/database/2020-10-01-normalization/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "함수(Function)와 메서드(Method)의 차이",
      "date": "2020-10-02 09:48:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n공부를 하면서 둘이 같은 의미로 사용된다는 점은 바로 깨달았다.\n\n근데 “왜 헷갈리게시리 굳이 용어를 나눠 혼용하고 있을까?”라는 의문이 생겼다.\n\n \n\n구글링을 해보니 결론적으로,\n\n함수(Function)란 무언가에 종속적이지 않은 독립적인 기능을 뜻하는 것이고\n\n메서드(Method)란 Class에 종속된 기능을 뜻하는 것이었다.\n\n고로 메서드는 함수의 부분집합이다. 클래스 함수라고도 부른다고 한다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2020-10-02-diary-3/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Java를 공부할 때 중요한 것?",
      "date": "2020-10-02 10:05:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n나는 질문하는 것에 거리낌이 없지만, 내 가치관에 입각하여 최소한의 기준이 있다.\n\n나는 무언가를 공부할 때 기초, 기본기를 매우 중요하게 생각한다.\n\n내가 하고자 하는 것의 기본에 숙달되고 그것의 프로세스를 명확하게 이해하면 대부분의 예외상황은 혼자서 헤쳐나갈 수 있다.\n\n비록 시간 혹은 체력적인 비용이 들지라도.\n\n \n\n이것은 내가 짧다면 짧고 길다면 긴 인생을 살면서 겪은 천고의 진리 중 하나다.\n\n \n\n내가 타인에게 무언가를 질문해야 하는 필요성을 느낄 때는\n\n나의 사고나 견문이 좁아 어떠한 당연한 사실을 깨닫지 못할 때,\n\n그것을 제삼자의 시선에서 보아준다면 나의 사고가 한순간에 확장될 수 있기 때문이다.\n\n그리고 나의 사고는 다시 가지를 뻗어나갈 것이다.\n\n \n\nJava를 공부하면서 코딩을 하다 보면 수도 없이 많은 에러를 마주친다.\n\n그때마다 디버깅을 해야 하는데 초보라 왜 이러한 에러가 나는지 나는 잘 알지 못한다.\n\n아마 대부분의 초보들이 그렇지 않을까?\n\n하지만 우리의 인생과 같이 항상 문제의 힌트는 문제 주변에 존재한다.\n\n \n\n비록 영어를 잘하지는 못하지만 새빨간 글씨로 무어라 뿌려주는데\n\n그것을 잘 읽어보면 어떤 에러의 메시지임을 알 수 있다.\n\n비록 그것이 정확히 어떤 것을 말하고자 하는지는 잘 모르더라도\n\n에러에서 얻어낸 에러 메시지로 구글링을 시도하면 어찌하여 그런 문제가 생겼는지 대부분은 알 수 있다.\n\n그리고 그러한 문제에 대해 더 구체적으로 분석하기 위해서는 Java 소스코드의 구조를 더 명확하게 알아야 할 필요성이 있다.\n\n \n\n이러한 구조를 제대로 알기 위해서 어떻게 해야 할까?\n\n정답은 API 문서를 보는 것이다.\n\nAPI를 뜯어보면 내가 무심코 사용하고 있는 Class들의 명세를 정확하게 알 수 있다.\n\n매개변수로 무엇을 받아 어떻게 처리하여 무엇을 리턴해주는지에 대한 모든 정보가 들어있다.\n\n오류가 생길 때마다 이렇게 혼자 API를 뒤져가며 한 땀 한 땀 디버깅을 하다 보면 나도 언젠가 Java와 친해질 수 있지 않을까?\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2020-10-02-diary-4/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "두더지 잡기 게임",
      "date": "2020-10-23 16:31:00 +0000",
      "description": "자바로 만드는 두더지 잡기 게임\n",
      "content": "\n \n\n \n\n\n\n \n\n자바공부 한달차에 만든건데 지금보니 개판이다.\n\n그래도 미래의 나를 위해서 업로드는 해둬야지..\n\nDB가 뭔지 모를때 만든거라 기록은 IOStream을 이용해 txt파일로 Save&amp;Load 되는 구조다.\n\n맵은 2차원 배열로 구현하였음.\n\n \n\npublic class MoleMain {\n    public static void main(String[] args) throws InterruptedException {\n        MoleGame mg = new MoleGame();\n        mg.moleGame();\n    }\n}\n\n\n \n\npublic class MoleGame {\n    static private int[][] map = {\n            {3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4},\n            {3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4}};\n\n    static private void callMap() {\n        for(int i = 0; i &lt; 18; i++) {\n            for(int j = 0; j &lt; 20; j++) {\n                if(map[i][j] == 4) {\n                    System.out.print(\"▩\");\n                }\n                else if(map[i][j] == 3) {\n                    System.out.print(\"  \");\n                }\n                else if(map[i][j] == 2) {\n                    System.out.print(\"∩\");\n                }\n                else if(map[i][j] == 1) {\n                    System.out.print(\"＿\");\n                }\n                else if(map[i][j] == 0) {\n                    System.out.print(\"♨\");\n                }\n            }\n            System.out.println(\"\");\n        }\n    }\n\n    //////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n    static private void clearScreen() {\n        try {\n            if(System.getProperty(\"os.name\").contains(\"Windows\")) {\n                new ProcessBuilder(\"cmd\", \"/c\", \"cls\").inheritIO().start().waitFor();\n            }\n            else {\n                Runtime.getRuntime().exec(\"clear\");\n            }\n        }\n        catch(IOException | InterruptedException ex) {\n        }\n    }\n\n    //////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n    public void moleGame() throws InterruptedException {\n\n        DecimalFormat formatter = new DecimalFormat(\"###,###\");\n\n        Scanner sc = new Scanner(System.in);\n\n        String name, sel, selM, show_score;\n\n        Record rc;\n\n        double time;\n\n        long start_time = 0, end_time = 0;\n\n        int input = 0, score = 0, cnt = 1;\n\n        boolean trg0 = false, trg1 = false, trg2 = false, trg3 = false, trg4 = false;\n\n        clearScreen();\n        System.out.println(\"\\n\\n\\n    ♨♨♨ 두더지 잡기 게임 ♨♨♨\\n\");\n        System.out.println(\"           &lt;&lt;&lt;&lt;&lt; 입력 &gt;&gt;&gt;&gt;&gt;\");\n        System.out.println(\"좌상 : 1 / 우상 : 2 / 좌하 : 3 / 우하 : 4\\n\");\n        System.out.println(\"두더지를 잘못 잡을 경우 점수가 감소합니다.\\n\\n\\n\");\n        System.out.println(\"     게임을 시작하려면 y를 입력하세요\\n\\n\");\n\n        callMap();\n        sel = sc.nextLine();\n        switch(sel) {\n            case \"y\":\n                start_time = System.currentTimeMillis();\n                break;\n\n            default:\n                clearScreen();\n                System.out.println(\"\\n\\n\\t++----------------------------++\");\n                System.out.println(\"\\t++----------------------------++\");\n                System.out.println(\"\\t||                            ||\");\n                System.out.println(\"\\t||     게임을 종료 합니다     ||\");\n                System.out.println(\"\\t||                            ||\");\n                System.out.println(\"\\t++----------------------------++\");\n                System.out.println(\"\\t++----------------------------++\");\n                Thread.sleep(4000);\n                clearScreen();\n                System.exit(0);\n        }\n        do {\n            map[4][6] = (int) Math.round(Math.random() + 1);\n            map[4][15] = (int) Math.round(Math.random() + 1);\n            map[13][6] = (int) Math.round(Math.random() + 1);\n            map[13][15] = (int) Math.round(Math.random() + 1);\n\n            if(map[4][6] == 1 &amp;&amp; map[4][15] == 1 &amp;&amp; map[13][6] == 1 &amp;&amp; map[13][15] == 1) {\n                System.out.println(\"\\n\\n\\t++----------------------------++\");\n                System.out.println(\"\\t++----------------------------++\");\n                System.out.println(\"\\t||                            ||\");\n                System.out.println(\"\\t||   Lucky! 추가점수 획득!    ||\");\n                System.out.println(\"\\t||                            ||\");\n                System.out.println(\"\\t++----------------------------++\");\n                System.out.println(\"\\t++----------------------------++\");\n                score += 3;\n                Thread.sleep(500);\n                continue;\n            }\n\n            clearScreen();\n            System.out.println(\"\\n\\n\\n    ♨♨♨ 두더지 잡기 게임 ♨♨♨\\n\");\n            System.out.printf(\"               STAGE %d\\n\\n\", cnt);\n            System.out.println(\"           &lt;&lt;&lt;&lt;&lt; 입력 &gt;&gt;&gt;&gt;&gt;\");\n            System.out.println(\"좌상 : 1 / 우상 : 2 / 좌하 : 3 / 우하 : 4\\n\");\n            callMap();\n\n            trg1 = map[4][6] == 0 || map[4][6] == 1 ? true : false;\n            trg2 = map[4][15] == 0 || map[4][15] == 1 ? true : false;\n            trg3 = map[13][6] == 0 || map[13][6] == 1 ? true : false;\n            trg4 = map[13][15] == 0 || map[13][15] == 1 ? true : false;\n            trg0 = trg1 == true &amp;&amp; trg2 == true &amp;&amp; trg3 == true &amp;&amp; trg4 == true ? true : false;\n\n            while(trg0 == false) {\n                input = sc.nextInt();\n                if(input == 1 &amp;&amp; trg1 == true) {\n                    System.out.println(\"땡! &gt;ㅆ&lt;\");\n                    score -= 5;\n                }\n                if(input == 2 &amp;&amp; trg2 == true) {\n                    System.out.println(\"땡! &gt;ㅆ&lt;\");\n                    score -= 5;\n                }\n                if(input == 3 &amp;&amp; trg3 == true) {\n                    System.out.println(\"땡! &gt;ㅆ&lt;\");\n                    score -= 5;\n                }\n                if(input == 4 &amp;&amp; trg4 == true) {\n                    System.out.println(\"땡! &gt;ㅆ&lt;\");\n                    score -= 5;\n                }\n                if(input &lt; 1 || input &gt; 4) {\n                    System.out.println(\"땡! &gt;ㅆ&lt;\");\n                    score -= 5;\n                }\n                if(map[4][6] == 2 &amp;&amp; input == 1) {\n                    map[4][6] = 0;\n                    clearScreen();\n                    score += 1;\n                    System.out.println(\"\\n\\n\\n    ♨♨♨ 두더지 잡기 게임 ♨♨♨\\n\");\n                    System.out.printf(\"               STAGE %d\\n\\n\", cnt);\n                    System.out.println(\"           &lt;&lt;&lt;&lt;&lt; 입력 &gt;&gt;&gt;&gt;&gt;\");\n                    System.out.println(\"좌상 : 1 / 우상 : 2 / 좌하 : 3 / 우하 : 4\\n\");\n                    callMap();\n                    trg1 = map[4][6] == 0 || map[4][6] == 1 ? true : false;\n\n                }\n                else if(map[4][15] == 2 &amp;&amp; input == 2) {\n                    map[4][15] = 0;\n                    clearScreen();\n                    score += 1;\n                    System.out.println(\"\\n\\n\\n    ♨♨♨ 두더지 잡기 게임 ♨♨♨\\n\");\n                    System.out.printf(\"               STAGE %d\\n\\n\", cnt);\n                    System.out.println(\"           &lt;&lt;&lt;&lt;&lt; 입력 &gt;&gt;&gt;&gt;&gt;\");\n                    System.out.println(\"좌상 : 1 / 우상 : 2 / 좌하 : 3 / 우하 : 4\\n\");\n                    callMap();\n                    trg2 = map[4][15] == 0 || map[4][15] == 1 ? true : false;\n\n                }\n                else if(map[13][6] == 2 &amp;&amp; input == 3) {\n                    map[13][6] = 0;\n                    clearScreen();\n                    score += 1;\n                    System.out.println(\"\\n\\n\\n    ♨♨♨ 두더지 잡기 게임 ♨♨♨\\n\");\n                    System.out.printf(\"               STAGE %d\\n\\n\", cnt);\n                    System.out.println(\"           &lt;&lt;&lt;&lt;&lt; 입력 &gt;&gt;&gt;&gt;&gt;\");\n                    System.out.println(\"좌상 : 1 / 우상 : 2 / 좌하 : 3 / 우하 : 4\\n\");\n                    callMap();\n                    trg3 = map[13][6] == 0 || map[13][6] == 1 ? true : false;\n\n                }\n                else if(map[13][15] == 2 &amp;&amp; input == 4) {\n                    map[13][15] = 0;\n                    clearScreen();\n                    score += 1;\n                    System.out.println(\"\\n\\n\\n    ♨♨♨ 두더지 잡기 게임 ♨♨♨\\n\");\n                    System.out.printf(\"               STAGE %d\\n\\n\", cnt);\n                    System.out.println(\"           &lt;&lt;&lt;&lt;&lt; 입력 &gt;&gt;&gt;&gt;&gt;\");\n                    System.out.println(\"좌상 : 1 / 우상 : 2 / 좌하 : 3 / 우하 : 4\\n\");\n                    callMap();\n                    trg4 = map[13][15] == 0 || map[13][15] == 1 ? true : false;\n\n                }\n                trg0 = trg1 == true &amp;&amp; trg2 == true &amp;&amp; trg3 == true &amp;&amp; trg4 == true ? true : false;\n            }\n\n            cnt++;\n            Thread.sleep(200);\n\n        } while(!(cnt == 20));\n        end_time = System.currentTimeMillis();\n        time = (end_time - start_time) / 1000.0;\n        show_score = formatter.format(score * 123456);\n\n        System.out.print(\"\\n\\n    ■\");\n        for(int i = 0; i &lt; 17; i++) {\n            Thread.sleep(200);\n            System.out.print(\"■\");\n        }\n        Thread.sleep(1000);\n        clearScreen();\n        System.out.println(\"\\n+-----------------------------------------------+\");\n        System.out.println(\"|                  결        과                 |\");\n        System.out.println(\"+-----------------------------------------------+\");\n        System.out.println(\"|                                               |\");\n        System.out.printf(\"|   잡은 두더지    :                   %3d 마리 |\\n\", score);\n        System.out.println(\"|                                               |\");\n        System.out.println(\"+-----------------------------------------------+\");\n        System.out.println(\"|                                               |\");\n        System.out.printf(\"|    경과 시간     :                   %5.2f 초 |\\n\", time);\n        System.out.println(\"|                                               |\");\n        System.out.println(\"+-----------------------------------------------+\");\n        System.out.println(\"|                                               |\");\n        System.out.printf(\"|      점수        :              %10s 점 |\\n\", show_score);\n        System.out.println(\"|                                               |\");\n        System.out.println(\"+-----------------------------------------------+\\n\\n\");\n\n        System.out.println(\"\\n\\n\\t++----------------------------++\");\n        System.out.println(\"\\t++----------------------------++\");\n        System.out.println(\"\\t||                            ||\");\n        System.out.println(\"\\t||  기록을 저장하시겠습니까?  ||\");\n        System.out.println(\"\\t||        y   /   AnyKey      ||\");\n        System.out.println(\"\\t||                            ||\");\n        System.out.println(\"\\t++----------------------------++\");\n        System.out.println(\"\\t++----------------------------++\");\n        sc.nextLine();\n        selM = sc.nextLine();\n\n        switch(selM) {\n            case \"y\":\n                clearScreen();\n                System.out.println(\"\\n\\n\\t++----------------------------++\");\n                System.out.println(\"\\t++----------------------------++\");\n                System.out.println(\"\\t||                            ||\");\n                System.out.println(\"\\t||      이름을 입력하세요     ||\");\n                System.out.println(\"\\t||                            ||\");\n                System.out.println(\"\\t++----------------------------++\");\n                System.out.println(\"\\t++----------------------------++\\n\");\n                System.out.print(\"이름 : \");\n                name = sc.nextLine();\n\n                while(name.matches(\"^[가-힣]*$\") || name.length() &gt; 12) {\n                    clearScreen();\n                    System.out.println(\"\\n\\n\\t++---------------------------------------------------++\");\n                    System.out.println(\"\\t++---------------------------------------------------++\");\n                    System.out.println(\"\\t||                                                   ||\");\n                    System.out.println(\"\\t||       한글이 포함되었거나 이름이 너무 깁니다      ||\");\n                    System.out.println(\"\\t||               이름을 다시 입력하세요              ||\");\n                    System.out.println(\"\\t||                                                   ||\");\n                    System.out.println(\"\\t++---------------------------------------------------++\");\n                    System.out.println(\"\\t++---------------------------------------------------++\\n\");\n                    System.out.print(\"이름 : \");\n                    name = sc.nextLine();\n                }\n\n                rc = new Record(name, show_score, score, time);\n                rc.loadandsaveRecord();\n                clearScreen();\n                rc.showRecord();\n                Thread.sleep(4000);\n                System.out.println(\"\\n\\n\\t++----------------------------++\");\n                System.out.println(\"\\t++----------------------------++\");\n                System.out.println(\"\\t||                            ||\");\n                System.out.println(\"\\t||    게임을 재시작 할까요?   ||\");\n                System.out.println(\"\\t||        y   /   AnyKey      ||\");\n                System.out.println(\"\\t||                            ||\");\n                System.out.println(\"\\t++----------------------------++\");\n                System.out.println(\"\\t++----------------------------++\");\n\n                selM = sc.nextLine();\n\n                switch(selM) {\n                    case \"y\":\n                        clearScreen();\n                        System.out.println(\"\\n\\n\\t++----------------------------++\");\n                        System.out.println(\"\\t++----------------------------++\");\n                        System.out.println(\"\\t||                            ||\");\n                        System.out.println(\"\\t||    게임을 재시작 합니다    ||\");\n                        System.out.println(\"\\t||                            ||\");\n                        System.out.println(\"\\t++----------------------------++\");\n                        System.out.println(\"\\t++----------------------------++\");\n                        Thread.sleep(3000);\n                        clearScreen();\n                        moleGame();\n                        break;\n\n                    default:\n                        clearScreen();\n                        System.out.println(\"\\n\\n\\t++----------------------------++\");\n                        System.out.println(\"\\t++----------------------------++\");\n                        System.out.println(\"\\t||                            ||\");\n                        System.out.println(\"\\t||     게임을 종료 합니다     ||\");\n                        System.out.println(\"\\t||                            ||\");\n                        System.out.println(\"\\t++----------------------------++\");\n                        System.out.println(\"\\t++----------------------------++\");\n                        Thread.sleep(3000);\n                        clearScreen();\n                        System.exit(0);\n                        break;\n                }\n\n            default:\n                clearScreen();\n                System.out.println(\"\\n\\n\\t++----------------------------++\");\n                System.out.println(\"\\t++----------------------------++\");\n                System.out.println(\"\\t||                            ||\");\n                System.out.println(\"\\t||     게임을 종료 합니다     ||\");\n                System.out.println(\"\\t||                            ||\");\n                System.out.println(\"\\t++----------------------------++\");\n                System.out.println(\"\\t++----------------------------++\");\n                Thread.sleep(3000);\n                clearScreen();\n                System.exit(0);\n                break;\n        }\n        sc.close();\n    }\n}\n\n\n \n\npublic class Record {\n    private int score;\n    private double time;\n    private String name, show_score, scoreborad, format, arraybean;\n    private ArrayList&lt;String&gt; forloadscoreboard = new ArrayList&lt;&gt;();\n\n    private String compare_one, compareto_one, compare_two, compareto_two;\n    private String[] copyArray, to_one, to_two;\n\n    public Record(String name, String show_score, int score, double time) {\n        this.name = name;\n        this.show_score = show_score;\n        this.score = score;\n        this.time = time;\n        this.format = String.format(\"| %12s    | %5s    | %8s   |   %10s  |\", this.name, this.score, this.time,\n                                    this.show_score);\n        this.scoreborad = this.format;\n    }\n\n    //////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n    @SuppressWarnings(\"unchecked\")\n    public void loadandsaveRecord() {\n        try {\n            FileInputStream fisrecord = new FileInputStream(\"D:/java/ws/java_proj/src/game_src/molerecord.ser\");\n\n            BufferedInputStream bisrecord = new BufferedInputStream(fisrecord);\n\n            ObjectInputStream inrecord = new ObjectInputStream(bisrecord);\n\n            Object objrecord = inrecord.readObject();\n\n            inrecord.close();\n\n            ArrayList&lt;String&gt; loadrecord = (ArrayList&lt;String&gt;) objrecord;\n\n            for(String read_scoreboard : loadrecord) {\n                forloadscoreboard.add(read_scoreboard);\n            }\n\n        }\n        catch(Exception e) {\n            System.out.printf(\"파일 불러오기 오류 : %s\", e.getMessage());\n        }\n\n        forloadscoreboard.add(this.scoreborad);\n        copyArray = new String[forloadscoreboard.size()];\n        int size = 0;\n\n        for(String temp : forloadscoreboard) {\n            copyArray[size++] = temp;\n        }\n\n        for(int i = 0; i &lt; copyArray.length; i++) {\n            for(int j = i + 1; j &lt; copyArray.length; j++) {\n                compare_one = copyArray[i].replace(\" \", \"\");\n                compareto_one = compare_one.replace(\"|\", \" \");\n                compareto_one = compareto_one.trim();\n                to_one = compareto_one.split(\" \");\n                to_one[3] = to_one[3].replace(\",\", \"\");\n\n                compare_two = copyArray[j].replace(\" \", \"\");\n                compareto_two = compare_two.replace(\"|\", \" \");\n                compareto_two = compareto_two.trim();\n                to_two = compareto_two.split(\" \");\n                to_two[3] = to_two[3].replace(\",\", \"\");\n\n                if(Integer.parseInt(to_one[3]) &lt; Integer.parseInt(to_two[3])) {\n                    arraybean = copyArray[i];\n                    copyArray[i] = copyArray[j];\n                    copyArray[j] = arraybean;\n                }\n            }\n        }\n\n        ArrayList&lt;String&gt; saveList = new ArrayList&lt;&gt;();\n\n        for(String temp : copyArray) {\n            saveList.add(temp);\n        }\n\n        try {\n            FileOutputStream fosrecord = new FileOutputStream(\"D:/java/ws/java_proj/src/game_src/molerecord.ser\");\n\n            BufferedOutputStream bosrecord = new BufferedOutputStream(fosrecord);\n\n            ObjectOutputStream outrecord = new ObjectOutputStream(bosrecord);\n\n            outrecord.writeObject(saveList);\n\n            outrecord.close();\n\n        }\n\n        catch(Exception e) {\n            System.out.printf(\"파일 저장 오류 : %s\", e.getMessage());\n        }\n\n    }\n\n    //////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n    @SuppressWarnings(\"unchecked\")\n    public void showRecord() {\n        try {\n            FileInputStream fisrecord = new FileInputStream(\"D:/java/ws/java_proj/src/game_src/molerecord.ser\");\n\n            BufferedInputStream bisrecord = new BufferedInputStream(fisrecord);\n\n            ObjectInputStream inrecord = new ObjectInputStream(bisrecord);\n\n            Object objrecord = inrecord.readObject();\n\n            inrecord.close();\n\n            ArrayList&lt;String&gt; loadrecord = (ArrayList&lt;String&gt;) objrecord;\n\n            System.out.println(\"+---------------------------------------------------------+\");\n            System.out.println(\"|      이 름      |  두더지  |    시간    |     점수      |\");\n            System.out.println(\"+---------------------------------------------------------+\");\n            for(String show_scoreboard : loadrecord) {\n                System.out.println(show_scoreboard);\n            }\n            System.out.println(\"+---------------------------------------------------------+\");\n\n        }\n        catch(Exception e) {\n            System.out.printf(\"파일 불러오기 오류 : %s\", e.getMessage());\n        }\n    }\n}\n\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2020-10-23-game-2/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "행맨 게임",
      "date": "2020-10-23 16:58:00 +0000",
      "description": "자바로 만드는 행맨 게임\n",
      "content": "\n \n\n이것도 지금와서 보니 코드가 구리다…\n\n일단 네이밍 컨벤션부터 개판이다.\n\n그리고 DB가 뭔지 모르던 때라 words.txt 파일에 영단어 천개정도를 저장하고,\n\nreadLine() 으로 한줄씩 긁어와 문제를 만들었다.\n\n \n\npublic class HangmanMain {\n    public static void main(String[] args) {\n        Hangman hang = new Hangman();\n        try {\n            hang.run();\n        }\n        catch(InterruptedException e) {\n        }\n    }\n}\n\n\n \n\npublic class Hangman {\n    static private void clearScreen() {\n        try {\n            if(System.getProperty(\"os.name\").contains(\"Windows\")) {\n                new ProcessBuilder(\"cmd\", \"/c\", \"cls\").inheritIO().start().waitFor();\n            }\n            else {\n                Runtime.getRuntime().exec(\"clear\");\n            }\n        }\n        catch(IOException | InterruptedException ex) {\n        }\n    }\n\n    public void run() throws InterruptedException {\n        clearScreen();\n        Scanner sc = new Scanner(System.in);\n        Random random = new Random();\n        ArrayList&lt;String&gt; read_words = new ArrayList&lt;&gt;();\n        ArrayList&lt;String&gt; hidden_word = new ArrayList&lt;&gt;();\n        ArrayList&lt;String&gt; answer_word = new ArrayList&lt;&gt;();\n        ArrayList&lt;String&gt; answer_result_word = new ArrayList&lt;&gt;();\n        String[] words;\n        String[] hidden_word_array;\n        String[] answer_word_array;\n        String[] answer_result_word_array;\n\n        int select, cnt;\n        String read_word, input_letter, result;\n\n        try {\n            File file = new File(\"D:\\\\java\\\\ws\\\\studyjava\\\\src\\\\game_src\\\\words.txt\");\n            FileReader file_reader = new FileReader(file);\n            BufferedReader br = new BufferedReader(file_reader);\n            while(true) {\n                read_word = br.readLine();\n                if(read_word.equals(null)) {\n                    break;\n                }\n                else {\n                    read_words.add(read_word);\n                }\n            }\n            br.close();\n        }\n        catch(Exception e) {\n        }\n        words = read_words.toArray(new String[read_words.size()]);\n        select = random.nextInt(words.length);\n\n        System.out.println(\"행맨 게임을 시작합니다!\\n\");\n        for(int i = 0; i &lt; words[select].length(); i++) {\n            hidden_word.add(words[select].substring(i, i + 1));\n            answer_word.add(\"＿\");\n            System.out.print(\"＿\");\n        }\n\n        hidden_word_array = hidden_word.toArray(new String[hidden_word.size()]);\n        answer_word_array = answer_word.toArray(new String[answer_word.size()]);\n        answer_result_word_array = answer_result_word.toArray(new String[answer_result_word.size()]);\n\n        int chance = 15;\n        for(cnt = 1; cnt &lt;= 15; cnt++) {\n            System.out.print(\"\\ninput letter &gt; \");\n            input_letter = sc.nextLine();\n\n            if(input_letter.equals(\"cls\")) {\n                System.out.println(\"프로그램을 종료합니다.\");\n                System.exit(0);\n            }\n\n            while(input_letter.length() &gt; 1) {\n                System.out.println(\"다시 입력하시오\");\n                input_letter = sc.nextLine();\n                if(input_letter.equals(\"cls\")) {\n                    System.out.println(\"프로그램을 종료합니다.\");\n                    System.exit(0);\n                }\n            }\n\n            clearScreen();\n\n            for(int i = 0; i &lt; hidden_word_array.length; i++) {\n                if(hidden_word_array[i].equals(input_letter)) {\n                    answer_word_array[i] = input_letter;\n                }\n\n                System.out.print(answer_word_array[i]);\n            }\n\n            chance -= 1;\n            System.out.print(\"\\n\\n남은 기회 : \" + chance + \"\\n\");\n\n            if(Arrays.equals(hidden_word_array, answer_word_array)) {\n                System.out.println(\"\\n정답입니다!\");\n                Thread.sleep(10000);\n                run();\n            }\n\n        }\n\n        System.out.print(\"\\n단어를 입력하세요 &gt; \");\n        result = sc.nextLine();\n\n        for(int i = 0; i &lt; result.length(); i++) {\n            answer_result_word.add(result.substring(i, i + 1));\n        }\n\n        answer_result_word_array = answer_result_word.toArray(new String[answer_result_word.size()]);\n\n        if(Arrays.equals(hidden_word_array, answer_result_word_array)) {\n            System.out.println(\"\\n정답입니다!\");\n            Thread.sleep(10000);\n            run();\n        }\n        else if(!(Arrays.equals(hidden_word_array, answer_word_array)) || Arrays.equals(hidden_word_array, answer_result_word_array)) {\n            System.out.println(\"\\n틀렸습니다!\");\n            System.out.print(\"정답은 : \");\n            for(String foryou : hidden_word_array) {\n                System.out.print(foryou);\n            }\n            System.out.println(\"10초후 게임이 시작됩니다.\");\n            Thread.sleep(10000);\n            run();\n        }\n    }\n}\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2020-10-23-game-3/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "블랙잭(BLACKJACK) 게임",
      "date": "2020-10-23 17:17:00 +0000",
      "description": "자바로 만드는 블랙잭(BLACKJACK) 게임\n",
      "content": "\n \n\n\n  📕 개발자가 반드시 정복해야 할 객체지향과 디자인 패턴 - 최범균 저\n\n\n \n\n요즘 보고있는 책인데, 이 책을 보면서 정말 많은 것들을 깨닫고있다.\n\n변화에 유연한 구조를 위한 OOP의 이론을 담기위해 연습하고있다.\n\n그래서 블랙잭을 구현해보았다.\n\n아직 미흡하지만 두더지 잡기 만들때에 비하면 많이 나아진 걸 느낀다.\n\n \n\npublic class Main {\n\n    /* --------------------------------------------------------------\n     * 첫 턴 카드 받을 때 딜러와 플레이어는 2장씩 받음\n     * A는 기본적으로 1점으로 계산하되 두장의 합이 21점이 될 수 있을 경우 11점으로 계산함\n     * 받은 2장의 카드합이 21이 될 경우(블랙잭) = A + 10 or J or Q or K : 11 + 10 = 21\n     *\n     * 딜러는 17점 이상이 될 경우 카드를 뽑지 않음\n     * 플레이어는 21점 이상이 될 경우 패배함\n     * 플레이어는 매 턴마다 게임을 멈추고 승패를 가릴지, 카드를 새로 뽑을지 추가할 수 있음\n     * 플레이어의 점수가 딜러보다 높을 경우 승리\n     *\n     * 플레이어는 승리 할 경우 걸은 베팅액 만큼의 돈을 추가로 얻음\n     * 플레이어는 패배 할 경우 걸은 베팅액 만큼의 돈을 잃음\n     -------------------------------------------------------------- */\n     \n    public static void main(String[] args) {\n        Scanner sc = new Scanner(System.in);\n        Player player = new Player();\n        Player dealer = new Player();\n        Blackjack blackjack = new Blackjack();\n\n        System.out.println(\"게임을 시작합니다.\");\n        System.out.println(\"지갑 잔액 : \" + player.getWallet());\n        System.out.println(\"배팅할 금액을 입력하세요.\");\n        int bet = sc.nextInt();\n        player.setWallet(bet);\n        sc.nextLine();\n\n        System.out.println(\"카드를 2장씩 받습니다.\");\n        blackjack.firstGetCard(player, dealer);\n        System.out.println(\"플레이어 카드 : \" + player.playerScore());\n        System.out.println(\"딜러 카드 : \" + dealer.playerScore());\n\n        //2장 받은 시점에서 플레이어의 카드 합이 21점이 넘을 경우 패배\n        if(player.playerScore() &gt; 21) {\n            System.out.println(\"패배\");\n            System.out.println(\"지갑 잔액 : \" + player.getWallet());\n            System.out.println(\"게임 끝\");\n            sc.close();\n            System.exit(0);\n        }\n\n        while(true) {\n            //카드를 추가로 뽑을지 승패비교를 할지 선택\n            System.out.println(\"카드를 받는다. = Y\");\n            System.out.println(\"멈춘다 = N\");\n\n            String select = sc.nextLine();\n\n            //카드를 추가로 뽑을 경우\n            if(select.equals(\"Y\") || select.equals(\"y\")) {\n                blackjack.getCard(player);\n\n                //딜러의 카드합이 17점이 넘을경우 딜러는 카드를 뽑지 않음\n                if(dealer.playerScore() &lt; 17) {\n                    blackjack.getCard(dealer);\n                    System.out.println(\"딜러 카드 : \" + dealer.playerScore());\n                }\n\n                System.out.println(\"플레이어 카드 : \" + player.playerScore());\n                System.out.println(\"딜러 카드 : \" + dealer.playerScore());\n\n                //카드 합이 21점이 넘을 경우 패배\n                if(player.playerScore() &gt; 21) {\n                    System.out.println(\"패배\");\n                    System.out.println(\"지갑 잔액 : \" + player.getWallet());\n                    break;\n                }\n            }\n\n            //게임을 중단할 경우\n            else if(select.equals(\"N\") || select.equals(\"n\")) {\n\n                //딜러의 카드합이 17점이 넘을경우 딜러는 카드를 뽑지 않음\n                if(dealer.playerScore() &lt; 17) {\n                    blackjack.getCard(dealer);\n                    System.out.println(\"딜러 카드 : \" + dealer.playerScore());\n                }\n\n                //플레이어와 딜러의 점수가 같을 경우 무승부, 베팅액은 돌려받음\n                if(player.playerScore() == dealer.playerScore()) {\n                    System.out.println(\"무승부\");\n                    player.resetWallet(bet);\n                    System.out.println(\"지갑 잔액 : \" + player.getWallet());\n                    break;\n                }\n\n                //플레이어의 점수가 딜러의 점수보다 높을 경우 승리\n                if(player.playerScore() &gt; dealer.playerScore()) {\n                    System.out.println(\"승리\");\n                    player.betting(bet);\n                    System.out.println(\"지갑 잔액 : \" + player.getWallet());\n                    break;\n                }\n\n                //플레이어의 점수가 딜러의 점수보다 낮을 경우 패배\n                else {\n                    System.out.println(\"패배\");\n                    System.out.println(\"지갑 잔액 : \" + player.getWallet());\n                    break;\n                }\n            }\n        } // while end\n        System.out.println(\"게임 끝\");\n        sc.close();\n    }\n}\n\n\n \n\npublic class Player {\n    private List&lt;Integer&gt; myCardPack = new ArrayList&lt;&gt;();\n    private int wallet = 300000;\n\n    //카드팩에서 카드를 받아 플레이어의 카드덱에 추가함\n    public void addCard(int card) {\n        myCardPack.add(card);\n    }\n\n    //플레이어의 카드덱의 점수 합계를 구하여 리턴\n    public int playerScore() {\n        int sum = 0;\n\n        for(Integer e : myCardPack) {\n            sum += e;\n        }\n\n        return sum;\n    }\n\n    //지갑 잔액을 리턴\n    public int getWallet() {\n        return wallet;\n    }\n\n    //베팅할 경우 지갑에서 베팅액을 차감\n    public void setWallet(int bet) {\n        this.wallet -= bet;\n    }\n\n    //무승부일 경우 지갑에 베팅액을 돌려줌\n    public void resetWallet(int bet) {\n        this.wallet += bet;\n    }\n\n    //베팅액의 2배를 지갑에 추가함\n    public void betting(int bet) {\n        this.wallet += bet * 2;\n    }\n}\n\n\n \n\npublic class Blackjack {\n    //카드팩에 52장의 카드를 추가함\n    private String[] cardPack = {\n            \"sA\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\", \"s9\", \"s10\", \"sj\", \"sq\", \"sk\",\n            \"dA\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\", \"d8\", \"d9\", \"d10\", \"dj\", \"dq\", \"dk\",\n            \"hA\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"h7\", \"h8\", \"h9\", \"h10\", \"hj\", \"hq\", \"hk\",\n            \"cA\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\", \"c9\", \"c10\", \"cj\", \"cq\", \"ck\"\n    };\n    \n    //카드팩 HashMap\n    private HashMap&lt;String, Integer&gt; cards;\n\n    //카드팩을 shuffle메서드를 이용하여 섞음\n    private String[] shuffleCardPack = shuffle(cardPack);\n\n    //카드를 한장씩 뽑기 위한 카운터\n    private int cnt = 0;\n\n    //카드팩을 섞기 위한 shuffle 메서드\n    public String[] shuffle(String[] cardPack) {\n        for(int i = 0; i &lt; cardPack.length; i++) {\n            int x = (int) (Math.random() * cardPack.length);\n            int y = (int) (Math.random() * cardPack.length);\n\n            String temp = cardPack[x];\n            cardPack[x] = cardPack[y];\n            cardPack[y] = temp;\n\n        }\n\n        //카드팩의 HashMap을 생성\n        cards = new HashMap&lt;&gt;();\n        for(String str : cardPack) {\n            String num = str.substring(1);\n            try {\n                int value = Integer.valueOf(num);\n                cards.put(str, value);\n            }\n            catch(NumberFormatException e) {\n                if(num.equals(\"A\")) {\n                    cards.put(str, 1);\n                }\n                else {\n                    cards.put(str, 10);\n                }\n            }\n        }\n        //무작위로 섞인 카드팩을 리턴\n        return cardPack;\n    }\n\n    //카드 한장 뽑기\n    public void getCard(Player player) {\n        player.addCard(compareCard(shuffleCardPack[cnt++]));\n    }\n\n    //String 타입으로 넘겨받은 카드를 점수로 환산하기 위한 메서드 ex) 스페이드2(s2) = 2점 \n    public int compareCard(String card) {\n        return cards.get(card);\n    }\n\n    //처음 2장받는 카드의 알고리즘, 두 카드의 합이 21이 될 수 있는 경우 A의 점수를 11로 환산하여 계산. 플레이어(player)와 딜러(dealer) 동일\n    public void firstGetCard(Player player, Player dealer) {\n        boolean condiOne = false, condiTwo = false, condiThree = false, condiFour = false, blackJackConditionOne = false;\n\n        Integer firstCard = cards.get(shuffleCardPack[cnt++]);\n        if(firstCard == 1) condiOne = true;\n        if(firstCard == 10) condiTwo = true;\n\n        Integer secondCard = cards.get(shuffleCardPack[cnt++]);\n        if(secondCard == 1) condiThree = true;\n        if(secondCard == 10) condiFour = true;\n\n        if((condiOne == true || condiThree == true) &amp;&amp; (condiTwo == true || condiFour == true)) {\n            blackJackConditionOne = true;\n        }\n\n        if(blackJackConditionOne) {\n            if(condiOne) {\n                player.addCard(11);\n            }\n            else {\n                player.addCard(firstCard);\n            }\n\n            if(condiThree) {\n                player.addCard(11);\n            }\n            else {\n                player.addCard(secondCard);\n            }\n        }\n\n        else {\n            player.addCard(firstCard);\n            player.addCard(secondCard);\n        }\n\n        firstCard = cards.get(shuffleCardPack[cnt++]);\n        if(firstCard == 1) condiOne = true;\n        if(firstCard == 10) condiTwo = true;\n\n        secondCard = cards.get(shuffleCardPack[cnt++]);\n        if(secondCard == 1) condiThree = true;\n        if(secondCard == 10) condiFour = true;\n\n        if((condiOne == true || condiThree == true) &amp;&amp; (condiTwo == true || condiFour == true)) {\n            blackJackConditionOne = true;\n        }\n\n        if(blackJackConditionOne) {\n            if(condiOne) {\n                dealer.addCard(11);\n            }\n            else {\n                dealer.addCard(firstCard);\n            }\n\t\t\t\n            if(condiThree) {\n                dealer.addCard(11);\n            }\n            else {\n                dealer.addCard(secondCard);\n            }\n        }\n\n        else {\n            dealer.addCard(firstCard);\n            dealer.addCard(secondCard);\n        }\n    }\n}\n\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2020-10-23-game-4/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "생성자(Constructor)",
      "date": "2020-10-29 23:22:00 +0000",
      "description": "Java의 생성자(Constructor)에 대한 정리\n",
      "content": "\n \n\n자바 생성자의 문법은 new ClassName(); 이다.\n\n \n\npublic class TestMain {     \n    public static void main(String[] args) { \n        TestClass testA = new TestClass(\"아반떼\", \"검은색\");\n    }\n}\n\n\n \n\n생성자는 클래스의 사용을 위해 객체를 생성할 때 사용한다.\n\n기본적으로 개발자가 따로 생성자를 작성해주지 않는다면 자바 컴파일러는 소스코드를 컴파일링 하며 기본 생성자를 작성하여 준다. 이것이 우리의 눈에는 직접적으로 보이지 않을 뿐이다.\n\n이 기본 생성자를 이용하여 객체를 생성한다면 객체를 만든 클래스의 필드를 모두 자동으로 초기화시켜주는데, 이 말은\n\nint의 경우 값이 0으로 초기화가 될 것이고, String 같은 경우 null로 초기화가 되는 것을 말한다.\n\n생성자를 개발자가 직접 작성하는 경우는 객체가 생성되는 시점에 특정 필드를 이러한 기본값이 아닌 원하는 값으로 지정하여 초기화하고자 함이다.\n\n예를 들어 위 코드 블록과 같이 매개변수를 지정하여 생성자를 호출할 경우 TestClass에는\n\n \n\npublic class TestClass {\n    String model;\n    String color;\n    int a;\n\n    TestClass(String model, String color){\n        this.model = model;\n        this.color = color;\n    }\n}\n\n\n \n\n위와 같이 시그니처가 동일한 생성자가 따로 작성되어 있어야 한다.\n\n그리고 위와같이 작성하여 매개변수를 보낼 경우, 객체가 생성되는 시점에 String model과 String color 필드는\n\n각각 null, null이 아닌 아반떼, 검은색으로 초기화된다.\n\n물론 int a 필드의 경우 따로 생성자에서 지정해준 값이 없으므로 자동적으로 0으로 초기화가 될 것이다.\n\n그리고 이 생성자는 개발자가 원하는 대로 여러 개를 작성할 수 있는데, 이를 생성자 오버로딩이라고 부른다.\n\n \n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2020-10-29-java-constructor/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "객체(Object)",
      "date": "2020-10-29 23:22:00 +0000",
      "description": "객체지향언어인 Java의 객체(Object)에 대한 정리\n",
      "content": "\n \n\n자바의 클래스는 속성(Field)과 기능(Method)을 갖는다.\n\n자바에서 객체라 함은 일반적으로 이 클래스의 인스턴스를 말한다.\n\n우리는 자바로 프로그래밍을 하면서 우리가 만들고자 하는 것의 기능들을 각 책임 별로 나누어 클래스로 서술한다.\n\n다만 착각하지 않아야 할 것은 이것은 단순히 서술하였을 뿐이지 사용하는 단계는 아니다.\n\n이 클래스를 실제적으로 사용하기 위해서는 클래스를 인스턴스화 하여야만 한다.\n\n이때 우리는 클래스의 생성자를 이용하여 인스턴스를 생성하는 것을 객체를 생성한다고 이야기한다.\n\n혹은 클래스를 인스턴스화 한다고 표현한다.\n\n이는 클래스에 메모리를 할당하는 물리적인 현상을 뜻한다.\n\n보통 프로젝트를 실행하면 JVM은 해당 패키지에서 Main 메서드를 찾아 실행하는데 이때 메모리에는 Main메서드가 등록되어 프로세스로서 실행되는 것이다.\n\n이 프로세스에서 타 클래스의 객체를 생성하면 힙 메모리 영역에 해당 객체가 물리적으로 등록되며, 만들어진 객체가 참조되지 않을 경우 Garbage Collector는 해당 객체를 메모리에서 삭제하여 메모리의 누수를 방지한다.\n\npackage test;\n\npublic class TestMain {\n\tpublic static void main(String[] args) {\n\t\tTestClass testA = new TestClass(\"아반떼\", \"검은색\");\n\t\tTestClass testB = new TestClass(\"코나\", \"빨간색\");\n\t\t\n\t\tSystem.out.println(testA);\n\t\tSystem.out.println(testB);\n\t\t\n\t\tSystem.out.println(\"testA의 모델명 : \" + testA.model);\n\t\tSystem.out.println(\"testA의 색상 : \" + testA.color);\n\t\tSystem.out.println(\"testB의 모델명 : \" + testB.model);\n\t\tSystem.out.println(\"testB의 색상 : \" + testB.color);\n\t}\n}\n\n\n\npackage test;\n\npublic class TestClass {\n\tString model;\n\tString color;\n\t\n\tTestClass(String model, String color){\n\t\tthis.model = model;\n\t\tthis.color = color;\n\t}\n}\n\n\n\n \n\n\n\n \n\n정말 간단하게 테스트코드를 작성하였다.\n\n일련의 과정을 간단하게 설명해보자면,\n\n\n  \n    TestClass testA = new TestClass(\"아반떼\", \"검은색\"); 이 실행되는 순간 힙 메모리 영역에 파라미터로 아반떼, 검은색을 전달받은 TestClass의 객체가 생성되고(인스턴스화) 이 객체의 힙 메모리 영역 주소를 TestClass타입의 변수 testA에 할당한다.\n  \n  \n    System.out.println(testA); 로 testA의 값을 출력하면 힙 메모리 영역의 주소 값이 출력된다. 그것이 test.TestClass@5aaa6d82라는 결과값으로 나타나는 것\n  \n  \n    testA는 힙 메모리 영역(생성된 객체)을 참조하고 있으므로, testA와 .(마침표)를 입력하면 해당 클래스의 필드와 메서드를 호출할 수 있게 된다. 그 소스코드와 결과값은 하기와 같다.\n  \n\n\n \n\nSystem.out.println(\"testA의 모델명 : \" + testA.model); // testA의 모델명 : 아반떼\nSystem.out.println(\"testA의 색상 : \" + testA.color); // testA의 색상 : 검은색\n\n\n \n\n결론적으로 쉽게 비유하여 서술하자면, 클래스를 작성하는 것은 붕어빵 틀을 만든 것과 같고, 객체를 실제로 생성하는 것은 붕어빵 틀에서 붕어빵을 구워낸 것과 같은 것이다.\n\n실제로 콘솔 창의 1,2번째 줄을 보면 각 객체는 같은 클래스에서 생성되었지만 서로 다른 주소 값을 갖고 있다. 이는 힙 메모리 영역에 두개의 객체가 생성되었음을 뜻하고, 두 객체는 상호 독립적인 존재임을 확인 할 수 있다.\n\n마지막으로 2번 항목에 대해 추가적으로 이야기해보자면, 주소 값은 16진수의 해쉬 코드로 출력되는데 이는 Object의 toString() 메서드가 실행되기 때문이다. 모든 요소의 조상인 Object 클래스의 Java API를 참조하면\n\n \n\n\n  public String toString()\n\n  Returns a string representation of the object. In general, the toString method returns a string that “textually represents” this object. The result should be a concise but informative representation that is easy for a person to read. It is recommended that all subclasses override this method.\n\n  The toString method for class Object returns a string consisting of the name of the class of which the object is an instance, the at-sign character `@’, and the unsigned hexadecimal representation of the hash code of the object. In other words, this method returns a string equal to the value of:\n\n  getClass(). getName() + ‘@’ + Integer.toHexString(hashCode())\n\n  Returns:a string representation of the object.\n\n\n\n \n\n위와 같은 내용을 확인할 수 있다. 리턴되는 값은 하기와 같다.\n\n \n\ngetClass()  .   getName() + '@' + Integer.toHexString(hashCode())\n\ntest            .    TestClass      @        5aaa6d82   (16진수(Hex) 해쉬 코드)\n\n\n \n\n자바의 모든의 요소는 Object 클래스를 상속받고\n\nSystem.out.println(); 메서드는 해당 요소의 toString() 메서드를 실행하여 출력해주는데,\n\ntoString(); 메서드를 따로 오버라이딩하지 않았기 때문에 Object 클래스의 toString() 메서드가 실행되는 것이다.\n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2020-10-29-java-object/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "스프링은 인터페이스를 어떻게 빈(Bean)으로 만들까?",
      "date": "2020-11-12 08:51:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n스프링 프레임워크는 클래스의 인스턴스를 만들어 빈(Bean)이라는 이름으로\n\n스프링 컨테이너에 등록한다는 부분은 숙지를 하였다.\n\n그리고 이 빈이 등록될 때의 명명 규칙은 카멜 케이스였다.\n\n예를 들어 BoardService라는 파스칼 케이스의 클래스가 있을 경우\n\nboardService라는 카멜 케이스의 빈으로 등록을 한다.\n\n그래서인지 스프링MVC와 마이바티스를 공부하던 중 마이바티스 맵퍼는 인터페이스로 작성하는 부분을 유심히 보았다.\n\n자바를 공부할 때 분명 인터페이스 클래스는 자체적으로 인스턴스를 생성할 수 없다고 공부하였다.\n\n그럼에도 불구하고 왜 인터페이스일까? 인터페이스를 만들면 어떻게 빈으로 등록한다는 걸까?\n\n \n\n\n\n \n\npublic interface BoardMapper {\n\n\tpublic List&lt;BoardDTO&gt; getList();\n\n\tpublic void insert(BoardDTO board);\n\n\tpublic void insertSelectKey(BoardDTO board);\n\n\tpublic BoardDTO read(long bno);\n\n\tpublic int delete(Long bno);\n\n\tpublic int update(BoardDTO board);\n}\n\n\n \n\n\n\n \n\nBoardMapper 인터페이스가 boardMapper 라는 이름의 빈으로 등록이 되었다.\n\n우선 직관적으로 생각했을 때\n\nBoardMapper 인터페이스를 구현하는 어떤 클래스를 만들어\n\n이 클래스의 이름을 boardMapper라는 이름의 빈으로 스프링 컨테이너에 등록하는 걸까?\n\n라고 가정하고 토비의 스프링도 열심히 뒤져보고 코드도 까뒤집어보았다.\n\n운이 좋게도 이 생각이 맞는 것 같다.\n\n \n\n&lt;!-- MyBatis-Scan --&gt;\n&lt;mybatis-spring:scan base-package=\"com.springExample.mapper\"/&gt;\t\n\n\n \n\nroot-context.xml에 마이바티스가 맵퍼를 스캔하는 패키지를 지정해주고\n\n마이바티스가 해당 패키지에서 인터페이스를 스캔할 경우\n\norg.mybatis.spring.mapper 의 MapperFactoryBean 클래스가 해당 인터페이스를 구현한다.\n\n그리고 이 MapperFactoryBean 클래스는\n\n스프링 프레임워크의 org.springframework.beans.factory에 존재하는 FactoryBean 인터페이스를 구현한다.\n\n \n\n\n\n \n\n대충 위와같은 구조를 갖는 것 같다.\n\n스프링 프레임워크의 인터페이스를 어댑터로 활용하여 마이바티스가 스프링 프레임워크에 결합되는 구조였던 것이다 !\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2020-11-12-diary-5/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "스프링은 어떻게 모든 요청을 동시에 처리할까?",
      "date": "2020-11-12 10:28:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n스프링 프레임워크가 DispatcherServlet를 프론트 서블릿으로 사용해\n\n모든 Request들을 처리한다는 부분은 숙지하였다.\n\n여기서 의문이 생기는데 그것이 뭐냐하면 “모든 Request를 처리” 한다는 것이다.\n\n \n\n네이버 같은 대형 포털사이트는 나도 하루에 수십 번씩 접속을 하는데,\n\n인당 하루 최소 수십 번의 Request라면\n\n전 세계 사람이 하루에 네이버에 요청하는 Request는 일견 생각하기에도\n\n수백만수천만 이상의 횟수일 것이다.\n\n \n\n아무리 요즘 개인PC의 CPU 연산속도가 초당 억 단 위이고,\n\n슈퍼컴퓨터는 조 단위라고 하지만 DispatcherServlet하나로\n\n“이 많은 요청들을 어떻게 그렇게 빠르게 처리할까?” 라는 의문이 또 들었다.\n\n그럼 한개의 Request를 처리하는 동안 뒤에 있는 수백 수천만의 Request들은 대기를 해야 하는 걸까?\n\n \n\n이 문제를 해결하려면 결국 멀티스레드가 필요하다는 결론이 나왔는데\n\n나는 자바를 공부하면서 웹 애플리케이션을 만들 때 스레드에 관한 코드를 써본 적이 없었다.\n\n그러면 결국 WAS에 답이 있지 않을까? PC에 설치한 톰캣의 server.xml을 살펴보았다.\n\n \n\n-&lt;Service name=\"Catalina\"&gt;\n&lt;!--The connectors can use a shared executor, you can define one or more named thread pools--&gt;\n&lt;!--&lt;Executor name=\"tomcatThreadPool\" namePrefix=\"catalina-exec-\"maxThreads=\"150\" minSpareThreads=\"4\"/&gt; --&gt;\n\n\n \n\n답은 WAS였다.\n\n역시나 스레드 어쩌고 하는 구문이 보인다.\n\n카탈리나(Catalina)는 톰캣의 서블릿 컨테이너 이름이다.\n\n카탈리나는 4~150개의 스레드를 스레드 풀에 보관할 수 있다는 주석을 찾았다.\n\nRequest가 들어오면 WAS는 스레드를 생성하고\n\n해당 스레드는 DispatcherServlet 객체를 생성하여 Request를 처리하는 구조인 것 같다.\n\n \n\n그리고 모든 Request에 트랜잭션을 적용하면\n\n동시 접속으로 인한 데이터 충돌의 문제도 해결할 수 있다는 결론이 나온다.\n\n또한, 그 많은 트랜잭션은 스프링의 AOP로 일괄 해결한다.\n\n머릿속에 흩어져 있던 퍼즐 조각들이 합쳐지는 느낌이 난다.\n\n해답을 찾은 것 같다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2020-11-12-diary-6/"
    },{
      "image": "/assets/img/ide/Intellij.png",
      "title": "인텔리제이(IntelliJ)에 Git Bash 연동하기",
      "date": "2021-01-08 07:18:00 +0000",
      "description": "Windows10 에서 인텔리제이(IntelliJ) 터미널에 Git Bash를 설정해봅시다\n",
      "content": "\n \n\nCtrl + Alt + S를 입력해 Settings에 진입한 다음\n\nTools - Terminal에 진입한다.\n\n\n\nShell path에 Default 값으로 cmd.exe가 설정되어 있을 것인데 위와같이 바꿔준다.\n\nGit의 경로를 타고 들어가 sh.exe를 선택하고\n\n-login -i를 추가해주고 IntelliJ에서 Terminal탭을 껏다가 킨다.\n\n\n",
      "categories": ["ide","intellij"],
      "tags": [],
      
      "collection": "posts",
      "url": "/ide/intellij/2021-01-08-git-bash/"
    },{
      "image": "/assets/img/ide/Intellij.png",
      "title": "인텔리제이(IntelliJ) Docs 빠르게 확인하기",
      "date": "2021-01-08 07:18:00 +0000",
      "description": "인텔리제이(IntelliJ)에서 공식 문서를 즉시 확인합니다\n",
      "content": "\n \n\n1. Shift + Ctrl + Alt + S 를 눌러 Project Structure 창을 팝업시킨다\n\n2. 연동하고자 하는 외부 도큐먼트 문서의 링크를 입력해준다.\n\n3. 확인하고자 하는 클래스를 더블클릭하여 하이라이팅 한 후 Shift + F1 을 입력한다\n\n\n",
      "categories": ["ide","intellij"],
      "tags": [],
      
      "collection": "posts",
      "url": "/ide/intellij/2021-01-08-intellij-document/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "ORA-01033 ORACLE의 초기화 또는 정지 처리가 진행중입니다",
      "date": "2021-01-10 20:11:00 +0000",
      "description": "Oracle DB 비정상 종료로 인한 이슈\n",
      "content": "\n \n\n처음 제작하는 쇼핑몰 프로젝트가 마무리 단계였다.\n\n여느 날과 다름없이 WAS를 기동하는데,\n\n뜬금없이 ORA-01033라는 SQLException을 뱉어대면서 열리질 않는다.\n\n \n\n\n\n \n\n?? 내심 당황했지만 자세를 가다듬고 문제 해결에 들어갔다.\n\n\n  Git Commit 사항 확인 -&gt; 아무 문제없음 확인\n  구글에 ORA-01033을 검색 -&gt; REDO.LOG 파일이 손상될 때 발생하는 문제란다.\n\n\n?? 왠 뜬금없이 Log파일 손상이냐 하고 곰곰이 생각을 해보니,\n\n어머니가 콘센트를 잘못 건드리셔서 서버가 돌아가던 중 컴퓨터가 강제 종료됐던 게 살짝 걸렸다.\n\n“아니 이런 걸로 DB가 먹통이 된다고?”라는 생각을 했는데\n\n아무리 붙잡고 고민해도 최소한이나마 의심 가는 게 이거밖에 없었다.\n\n아예 DB에서 System 관리자 계정으로 접속이 불가능한 상황이었다.\n\n그래서 우선 sqlplus로 접속하여 DB 복구를 시도해보았다.\n\n  Microsoft Windows [Version 10.0.19041.685]\n  (c) 2020 Microsoft Corporation. All rights reserved.\n\n  C:\\Users\\Han&gt;sqlplus \"/as sysdba\"\n\n  SQL*Plus: Release 12.2.0.1.0 Production on 일 1월 10 19:00:29 2021\n\n  Copyright (c) 1982, 2016, Oracle.  All rights reserved.\n\n\n  다음에 접속됨:\n  Oracle Database 12c Enterprise Edition Release 12.2.0.1.0 - 64bit Production\n\n  SQL&gt; recover database;\n  ORA-00283: 복구 세션이 오류로 인하여 취소되었습니다\n  ORA-00742: 로그 읽기 중 스레드 1 시퀀스 98 블록 110711에서 손실된 쓰기를\n  감지했습니다.\n  ORA-00312: 온라인 로그 2 스레드 1: 'D:\\ORACLE\\ORADATA\\ORCL\\REDO02.LOG'\n\n  SQL&gt; recover database until time '2021-01-09 18:30:00';\n  ORA-01547: 경고: RECOVER은 성공했지만 OPEN RESETLOGS에 아래와 같은 오류가\n  생길수 도 있습니다\n  ORA-01194: 1 파일이 일관성을 갖기 위해서는 더 많은 복구가 필요로 합니다\n  ORA-01110: 1 데이터 파일: 'D:\\ORACLE\\ORADATA\\ORCL\\SYSTEM01.DBF'\n\n\n\n\n어제 오후를 기준으로 복구를 해봤는데 먹히질않는다.\n\n어차피 간단한 쇼핑몰 프로젝트겠다, 더미데이터 DML도 만들어서 백업해둔 것이 있어서 데이터 손실로 인한 리스크는 없는 상태라 봐도 무방하여 데이터 파일을 모두 날려버리고 서버를 재부팅해보자고 생각했다.\n\n당연히 데이터 파일은 모두 백업해두었다.\n\n  SQL&gt; shutdown immediate\n  ORA-01109: 데이터베이스가 개방되지 않습니다\n\n\n  데이터베이스가 마운트 해제되었습니다.\n  ORACLE 인스턴스가 종료되었습니다.\n  SQL&gt; startup\n  ORACLE 인스턴스가 시작되었습니다.\n\n\n\n\n \n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n \n\n  Total System Global Area 1.0301E+10 bytes\n  Fixed Size                 12468536 bytes\n  Variable Size            1912606408 bytes\n  Database Buffers         8355053568 bytes\n  Redo Buffers               21082112 bytes\n  데이터베이스가 마운트되었습니다.\n  ORA-01589: 데이터베이스를 열기 위해서는 RESETLOGS/NORESETLOGS 옵션을 사용해야함\n\n  SQL&gt; alter database open resetlogs;\n  alter database open resetlogs\n  *\n  1행에 오류:\n  ORA-01194: 1 파일이 일관성을 갖기 위해서는 더 많은 복구가 필요로 합니다\n  ORA-01110: 1 데이터 파일: 'D:\\ORACLE\\ORADATA\\ORCL\\SYSTEM01.DBF'\n\n\n\n\n혈안이 돼서 StackOverflow를 뒤져 보니 따로 복구 툴 사용법이 있길래 혹시나 해서 따라 해 보았다\n\n  Microsoft Windows [Version 10.0.19041.685]\n  (c) 2020 Microsoft Corporation. All rights reserved.\n\n  C:\\Users\\Han&gt;rman target/\n\n  복구 관리자: Release 12.2.0.1.0 - Production on 일 1월 10 20:05:39 2021\n\n  Copyright (c) 1982, 2017, Oracle and/or its affiliates.  All rights reserved.\n\n  대상 데이터베이스에 접속됨: ORCL(DBID=1580994622, 열리지 않음)\n\n  RMAN&gt; recover database;\n\n  21/01/10에서 recover을(를) 시작하는 중입니다.\n  복구 카탈로그 대신 대상 데이터베이스 제어 파일을 사용하고 있습니다.\n  채널을 할당했습니다: ORA_DISK_1\n  채널 ORA_DISK_1: SID=251 장치 유형=DISK\n\n  미디어 복구를 시작합니다\n\n  1 스레드, 98 시퀀스에 대한 아카이브된 로그는 이미 디스크에 D:\\ORACLE\\ORADATA\\ORCL\\REDO02.LOG 파일로 존재합니다.\n  아카이브된 로그 파일 이름=D:\\ORACLE\\ORADATA\\ORCL\\REDO02.LOG 스레드=1 시퀀스=98\n  Oracle 오류:\n  ORA-01547: 경고: RECOVER은 성공했지만 OPEN RESETLOGS에 아래와 같은 오류가 생길수 도 있습니다\n  ORA-01245: 오프라인 파일 1 은 RESETLOGS이 끝나면 없어집니다\n  ORA-01110: 1 데이터 파일: 'D:\\ORACLE\\ORADATA\\ORCL\\SYSTEM01.DBF'\n\n  매체 복구 완료, 경과 시간: 00:00:08\n  21/01/10에서 recover을(를) 종료했습니다.\n\n  RMAN&gt; exit\n\n  복구 매니저가 완성되었습니다.\n\n  C:\\Users\\Han&gt;sqlplus \"/as sysdba\"\n\n  SQL*Plus: Release 12.2.0.1.0 Production on 일 1월 10 20:07:34 2021\n\n  Copyright (c) 1982, 2016, Oracle.  All rights reserved.\n\n\n  다음에 접속됨:\n  Oracle Database 12c Enterprise Edition Release 12.2.0.1.0 - 64bit Production\n\n  SQL&gt; alter database open resetlogs;\n\n  데이타베이스가 변경되었습니다.\n\n\n\n\n\n\n \n\n해결된건 좋은데 데이터베이스는 정말 너무 어렵다 😭\n\n \n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-01-10-debugging-1/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "HTTP / GET / POST",
      "date": "2021-01-10 21:05:00 +0000",
      "description": "교과서 기초 개념 정리\n",
      "content": "\n  HTTP\n  GET    \n      GET의 특징        \n          📜 파라미터가 URL을 통해 외부에 노출된다\n          📜 쿼리스트링(Querystring)의 길이는 한계가 있다\n          📜 브라우저에 캐시 될 수 있다\n        \n      \n    \n  \n  POST\n\n\n \n\n공부한걸 틈틈이 포스팅하며 정리와 복습을 해야 하는데,\n\n워낙 학습량이 많다 보니 포스팅하는 게 생각보다 쉽지가 않다.\n\n그래도 미래의 나를 위해서 힘들더라도 조금씩이나마 꾸준히 포스팅해야겠다고 생각했다.\n\nServlet을 처음 공부할 때 DNS &amp; HTTP 프로토콜과 GET/ Post 방식에 대해 공부했었는데,\n\n당시에는 “아~ 이런 것도 있구나” 하고 가볍게 넘어갔었다.\n\n그때는 자바에서 웹 통신을 하기 위한 입출력 장치가 없기 때문에\n\nWAS의 Servlet을 가져와 입출력 장치(HttpRequest, HttpResponse)를 자바로 구현한다는 게 보다 더 핵심적인 기능이라고 생각했기 때문이다.\n\n \n\n물론 이 생각은 아직도 유효하다..!\n\n \n\n사실 이때 처음 안 사실이 하나 있는데,\n\n그게 뭐냐 하면 자바는 javax(자바 extension)라는 확장 패키지를 통해\n\n이기종 시스템의 기능을 자바에서 구현한다는 사실이었다.\n\n대표적인 녀석으로 Swing이라는 자바의 UI 라이브러리가 있겠다.\n\n그 유명하고 우리가 많이 사용하는 인텔리제이(IntelliJ)가 바로 이 Swing으로 만들어진 대표적인 프로그램이다.\n\n \n\n아무튼 각설하고, AJAX(Asynchronous javascript and XML)를 처음 구현하고\n\nSpring Security를 막 사용할 때 이 GET과 Post에 대해 진지하게 찾아보게된 계기가 있는데 그 이유가 뭐냐하면 통신이 되질 않아서였다.\n\nSpring Security는 XSS 공격을 방지하기 위해 Post 방식으로 통신할 경우 매번 CSRF Token을 주고받아야 했고\n\nHTTP 헤더에 Content Type을 명시해야 했는데 당시엔 이를 몰랐기 때문이다.\n\nGET은 설계 자체가 조회를 위해 만들어진 방식이기 때문에 위의 내용과는 상관이 없는 것 같았다.\n\n아무튼 매번 이렇게 통신이 안돼 구글링을 하느니 차라리 이걸 내가 확실하게 이해해놔야 겠다는 생각이 강하게 들었었다.\n\n \n\nHTTP\n\n\n\nHTTP는 웹 통신을 위한 국제적인 약속의 일종이다.\n\n웹 개발자라면 모두 이 HTTP의 요구사항에 맞추어 개발을 해야 한다.\n\n이런 약속을 어겨서 모두가 피해를 보는 경우가 있는데\n\n범주는 약간 다르지만 웹 브라우저 표준을 지키지 않는 대표적인 예가 있다.\n\n바로 MS의 IE(Internet Explorer)이다. (크로스 브라우징 이슈)\n\n \n\n이 HTTP는 Header와 Body로 구성되는데\n\nHTTP Header는 General Header와 Request/Response Header 로 나뉜다.\n\nGeneral Header에는 간략한 요청정보와 통신의 상태 코드등의 정보가 들어있고\n\nRequest/Response Header에는 더 자세한 내용들이 담겨있으며,\n\nHTTP Body에는 요청 정보에 대한 상세한 내용이 담겨있다.\n\n즉 HTML, JSON, XML 등의 메시지가 들어간다.\n\n \n\nGET\n\n\n\n  -General Header\n  Request URL: http://localhost:8090/member/user-ask-list?pageNum=1&amp;pageNumReview=1&amp;amount=10\n  Request Method: GET\n  Status Code: 200 \n  Remote Address: [::1]:8090\n  Referrer Policy: strict-origin-when-cross-origin\n\n  -Request Header\n  Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\n  Accept-Encoding: gzip, deflate, br\n  Accept-Language: ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\n  Connection: keep-alive\n  Cookie: JSESSIONID=B8E6104ABE710304CEDBD46DE2FDB17F\n  Host: localhost:8090\n  Referer: http://localhost:8090/member/my-page\n  sec-ch-ua: \"Google Chrome\";v=\"87\", \" Not;A Brand\";v=\"99\", \"Chromium\";v=\"87\"\n  sec-ch-ua-mobile: ?0\n  Sec-Fetch-Dest: document\n  Sec-Fetch-Mode: navigate\n  Sec-Fetch-Site: same-origin\n  Sec-Fetch-User: ?1\n  Upgrade-Insecure-Requests: 1\n  User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36\n\n  -Query String 파라미터s\n  pageNum: 1\n  pageNumReview: 1\n  amount: 10\n\n\nGET은 서버로부터 데이터를 조회할 때 사용하도록 만들어진 녀석이다.\n\n이 녀석은 멱등(Idempotent) 하게 설계되었다.\n\n\n  📜 멱등(Idempotent)\n\n  수학이나 전산학에서 연산의 한 성질을 나타내는 것으로, 연산을 여러 번 적용하더라도 결과가 달라지지 않는 성질 \n동일한 연산을 여러 번 수행해도 동일한 값이 나와야 함을 의미함\n\n\nGET의 특징\n\n📜 파라미터가 URL을 통해 외부에 노출된다\n\n\n\nhttp://localhost:8090/member/user-ask-list?pageNum=1&amp;pageNumReview=1&amp;amount=10\n\n\n위와 같은 URL이 GET방식의 URL인데 user-ask-list 다음 ?로 시작하는 부분이 있다.\n\n?는 이제부턴 파라미터라는 뜻이고 &amp;는 파라미터를 구분하는 구분자다.\n\n각 파라미터는 키(Key)=값(Value)의 쌍으로 표시된다.\n\n이 파라미터의 표시를 쿼리스트링(Querystring) 이라고 부른다.\n\n \n\n결론적으로 위 URL의 파라미터는\n\npageNum=1, pageNumReview=1, amount=10\n\n이며, 어떤 요청(Request)에 위와 같은 값들을 서버로 함께 보내는 것이다.\n\n서버에서는 이 값들을 전달받아 비즈니스 로직을 처리하여 처리된 데이터를 Client에게 되돌려준다.\n\n실제로 위 코드블럭을 보면 최하단에\n\n -Query String parameters  \n  pageNum: 1  \n  pageNumReview: 1  \n  amount: 10\n\n\n라는 문구를 볼 수 있다.\n\n \n\n📜 쿼리스트링(Querystring)의 길이는 한계가 있다\n\n\n\n웹 브라우저에 입력되는 URL의 길이는 무한할 수 없다\n\n \n\n📜 브라우저에 캐시 될 수 있다\n\n\n\n조회(GET) 시 주로 js, css, image 등의 크기가 크고 변동될 사항이 적은 정적 파일들을 가져오기 때문에\n\n브라우저는 이 파일들을 브라우저가 깔린 하드디스크 경로에 저장해 두고\n\n이를 재사용하기 때문에 통신속도의 향상을 기대할 수 있다.\n\n다만 캐시 된 파일을 사용하기 때문에 수정사항이 생겨 정적 파일에 변동사항이 생겼음에도\n\n변경되기 전의 파일이 웹 브라우저에 캐시 되어있어 변경사항이 반영되지 않는 경우가 있을 수 있는데,\n\n이때는 당황하지 말고 브라우저의 캐시를 초기화시켜주면 반영된 결과를 볼 수 있을 것이다.\n\n(브라우저 강력 새로고침 기능)\n\n \n\nPOST\n\n\n\n  -General Header\n  Request URL: http://localhost:8090/login\n  Request Method: POST\n  Status Code: 200 \n  Remote Address: [::1]:8090\n  Referrer Policy: strict-origin-when-cross-origin\n\n  -Request Header\n  Accept: application/json, text/자바script, */*; q=0.01\n  Accept-Encoding: gzip, deflate, br\n  Accept-Language: ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\n  Connection: keep-alive\n  Content-Length: 37\n  Content-Type: application/x-www-form-urlencoded; charset=UTF-8\n  Cookie: JSESSIONID=0000000038AB0E7D556C6D68F0A\n  Host: localhost:8090\n  Origin: http://localhost:8090\n  Referer: http://localhost:8090/member/login-page\n  sec-ch-ua: \"Google Chrome\";v=\"87\", \" Not;A Brand\";v=\"99\", \"Chromium\";v=\"87\"\n  sec-ch-ua-mobile: ?0\n  Sec-Fetch-Dest: empty\n  Sec-Fetch-Mode: cors\n  Sec-Fetch-Site: same-origin\n  User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36\n  X-CSRF-TOKEN: 61a8cec2-efff-47ce-b644-77cd5425ac3c\n  X-Requested-With: XMLHttpRequest\n\n  -Form Data\n  memberId: tester\n  memberPw: QWERASDF!\n\n\n이 녀석은 주로 데이터의 입력/수정을 위해 사용된다.\n\n그래서 GET과 반대로 Non-Idempotent 하게 설계되었다.\n\n항상 값이 변할 수 있다는 이야기이다.\n\n \n\nPOST는 GET과 다르게 파라미터의 크기에 제한이 없다.\n\nhttp://localhost:8090/login\n\n\n위는 POST방식의 URL인데 보다시피 외부로 노출된 파라미터가 없다.\n\n주의할 점은 명확하게 Content Type을 명시해줘야 타입 추론으로 인한 장애가 발생하지 않는다.\n\n이를 명시하지 않을 경우 통신에 실패하는 경우가 생길 수 있다.\n\n(나는 이걸 명시해주지 않아서 AJAX 구현 할 때 물을 먹었다)\n\n \n\n또한 파라미터가 바디에 숨겨진다고는 하나 개발자 도구나, 피들러같은 툴을 사용하여 작정하고 보려고 하면 쉽게 볼 수 있기 때문에\n\n보안을 생각한다면 추가적인 암호화를 반드시 해줘야 한다.\n\n \n\n위 코드블럭은 웹 브라우저의 개발자 도구로 본 POST방식 Request Header의 상세정보이다.\n\n보다시피 최하단에\n\n\\-Form Data-Form Data  \nmemberId: tester  \nmemberPw: QWERASDF!\n\n\n라 하여 서버에 보내는 정보를 눈으로 바로 확인할 수 있음을 알 수 있다.\n",
      "categories": ["cs","information-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/information-system/2021-01-10-http-get-post/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "첫 프로젝트와 첫 호스팅에 대한 회고",
      "date": "2021-01-13 10:52:00 +0000",
      "description": "개발일기\n",
      "content": "\n  💡 What AWS?\n  💡 Why AWS?\n  💡 What EC2?\n  😎 후기\n\n\n \n\nSpring5를 이용한 첫 프로젝트로 쇼핑몰을 선택했고,\n\n이를 잘 완성하고 호스팅까지 해내며 느낀 점을 정리한다.\n\n \n\n처음엔 Cafe24를 이용하여 호스팅을 할 계획이었다.\n\n호스팅을 하기 전에 내가 가진 네트워크 지식을 전체적으로 한번 정리해야했다.\n\n웹서비스 배포를 위해 알아야 할 지식들이 많았기 때문이다.\n\n막상 호스팅을 하려고 보니 Cafe24는 Oracle RDB를 지원하지 않아 다른 방법을 찾게 되었는데,\n\n최종적으로 결정하게 된 부분은 AWS를 이용한 호스팅이었다.\n\n \n\n💡 What AWS?\n\n\n\nAWS(Amazon Web Services) 는 아마존에서 제공하는 클라우드 컴퓨팅 서비스다.\n\n네트워크를 기반으로 가상 머신과 스토리지를 비롯한 각종 네트워크 인프라를 제공해준다.\n\n쉽게 얘기하면 AWS를 이용한다는 건 대부분의 네트워크 인프라를 아마존의 시스템에 의존해 구축하는 것이다.\n\n더 쉽게 얘기하면 아마존에서 구축해놓은 데이터 센터에서 컴퓨터를 빌려다가 자신의 서비스를 구축&amp;배포하는것이다.\n\n \n\n💡 Why AWS?\n\n\n\n우선 프리티어라 해서 무료로 제공하는 서비스가 매우 괜찮았었고,\n\n취준생 입장에서 많은 회사들이 AWS를 사용하고 있다는 걸 아는데\n\n왜 AWS를 많이 사용하는지 직접 느껴보기에 좋은 기회라고 생각했다.\n\n그래서 AWS의 EC2를 이용한 웹 애플리케이션 배포를 생각하게 됐다.\n\n그리고 애초에 Cafe24가 Oracle을 지원 안 해줬던게 가장 크긴 했다.\n\n \n\n💡 What EC2?\n\n\n\nAmazon EC2(Amazon Elastic Compute Cloud),\n\n번역해보자면 아마존의 탄력적인 클라우드 컴퓨터?라고 볼 수 있으려나??\n\n그냥 단순하게 내 서비스를 아마존의 인프라를 통해 구현하기 위해\n\n아마존에서 가상 머신(컴퓨터)을 한대 빌리는 걸 말한다.\n\n이렇게 빌려서 생성된 가상 머신을 인스턴스라고 부른다.\n\n \n\n이 인스턴스는 처음 구축할 때 다양한 OS를 선택할 수 있고 기본적으로 SSD를 제공해주며,\n\n이는 지불하는 요금에 따라 탄력적(Elastic)으로 변경될 수도 있었다.\n\n \n\n또한 기본적으로 유동 IP가 설정되어있어 웹 애플리케이션 서비스 중 접속 장애가 일어날 수 있는데\n\n이는 아마존에서 제공하는 고정 IP를 연동시켜 안정적인 서비스를 이루어 내 문제를 해결 할 수도 있으며,\n\n그 외 수십 종의 다양한 AWS 서비스를 이용할 수 있다.\n\n \n\n처음 EC2 인스턴스를 생성할 때 별생각 없이 윈도우 OS를 선택했다.\n\n왜냐하면 나는 태어나서 윈도우 외의 다른 OS를 직접 만져본 적이 없었기 때문이다.\n\n하지만 만들자마자 바로 리눅스(우분투)를 선택하게 됐는데 이유가 뭐냐 하면\n\n프리티어(체험판) EC2의 경우 최대 30GB의 하드디스크 용량을 얻을 수 있는데,\n\n윈도우로 인스턴스를 생성할 시 30GB 중 14GB를 OS가 잡아먹는 것이었다.\n\n \n\n대충 용량을 보고 계산해보니 오라클 등의 필수 패키지를 설치하고 웹 애플리케이션을 배포하면 용량이 간당간당할 것 같았다.\n\n쇼핑몰이기 때문에 이미지 파일이 많이 들어가기 때문이었다.\n\n그래, 이참에 나도 리눅스를 한번 써 보자 생각하여 인스턴스를 반납하고 우분투 OS를 선택해 EC2 인스턴스를 새로 생성했다.\n\n일단 정보처리기사를 공부하면서 리눅스가 CLI기반의 OS라는 건 알고는 있었는데 막상 모든 걸 CLI로 조작하려니 생각보다 어렵기도 했고 무엇보다 재미있기도 했다.\n\n정보처리기사를 공부하면서 봤던 리눅스 명령어란 명령어는 다 써봤고 추가적인 명령어도 검색해서 써보게 되더라.\n\n역시 백문이 불여일타(?)라고, 직접 해보는 것만큼 확실하게 숙달되는 게 없다고 다시금 느끼게 되는 좋은 계기였다.\n\n30GB의 용량 중 OS가 이미 깔려있음에도 27GB 이상의 용량을 사용할 수 있음에 “와..? 이래서 리눅스 쓰는 건가?”라고 감탄하게 됐다.\n\n우선 간략하게 순서를 나열해보자면\n\n \n\n\n  \n    푸티(Putty)를 이용하여 서버(인스턴스)에 대한 원격 시스템을 구축\n  \n  \n    JVM환경 구축을 위해 JDK를 설치하고 환경변수 설정\n  \n  \n    Tomcat(WAS)을 설치하고 환경변수 설정\n  \n  \n    파일질라(FileZilla)를 이용하여 로컬에 설치된 Tomcat경로에 war 배포\n  \n  \n    Oracle RDB 구축 및 WAS와 연동(포트 포워딩)\n  \n  \n    WAS를 구동하여 웹 애플리케이션 실행\n  \n  \n    정상 구동 확인 후 DNS 서버 구축\n  \n\n\n \n\n우선 푸티는 간단하게 얘기해서 다른 컴퓨터에 원격으로 접속할 수 있게 도와주는 툴이다.\n\nAWS자체에서 원격 서비스를 지원해주긴 하지만 웹 브라우저 기반이라\n\n사용하는데 불편함을 많이 느껴 직접 SSH프로토콜을 이용하여 원격제어 시스템을 구축했다.\n\n \n\n첨언하자면 여기서 SSH(Secure Shell)프로토콜은 암호화 보안이 적용된 원격지 접속을 위한 프로토콜이다.\n\n이 녀석이 사용되기 전엔 텔넷이라는 프로토콜을 많이 사용했다고 하는데, 이 텔넷은 암호화를 하지 않아 보안에 취약했다고 한다.\n\n텔넷과 다르게 SSH를 이용하기 위해서는 개인정보를 암호화한 Key파일이 필요하고 이는 AWS에서 제공해준다.\n\n푸티를 통해 인스턴스에 접속하고 인스턴스에 JDK를 설치하여 JVM이 돌아갈 환경을 만들어주었고,\n\nWAS로 로컬에서 개발할 때 사용했던 Tomcat9.0.41을 설치해줬다.\n\n \n\n파일질라는 TCP/IP 기반으로 동작하는 FTP(File Transfer Protocol) 파일 업로드 툴인데,\n\n다른 컴퓨터에 접속한다는 건 푸티와 동일하지만 이 파일질라는 그냥 파일 전달에 특화돼있는 친구다.\n\nFTP 자체가 역사가 매우 깊은 프로토콜이지만 간단하고 강력하다는 점에 아직도 널리 사용된다 느꼈다.\n\n파일질라로 파일 전송을 할 때 SFTP를 지원하길래 이를 통해 파일 업로드를 했는데, SFTP는 FTP+SSH를 뜻한다.\n\n이 역시 SSH이므로 Key파일이 필요하고 이 Key파일은 AWS에서 제공한 파일을 사용하였다.\n\n인스턴스에 Tomcat이 설치되어 로컬에서 인텔리제이를 이용해 개발한 프로젝트를 Maven을 통해 war로 Build 했고,\n\n이렇게 만들어진 war파일을 호스팅 서버의 tomcat/webapps 경로에 배포해줬다.\n\n \n\nOracle RDB를 구축하고 이 RDB에 외부에서 접속할 수 있게끔 포트 포워딩을 진행해야 했다.\n\n포트 포워딩이란 개발자가 아닌 일반인들도 많이 하는 경우가 있는데, 일상생활에서 하는 공유기 설정이 대표적인 예이다.\n\n \n\nIP주소는 문이다.\n\n행복아파트 5층에는 10가구가 살고 있다고 한다면,\n\n이 5층에는 10개의 현관문이 있는 셈이다.\n\n이를 네트워크로 비유하자면 10개의 IP주소가 있는 것과 같다.\n\n그리고 아파트의 공동현관문을 게이트웨이(Gateway)라고 볼 수 있겠다.\n\n \n\n포트(Port)는 정확한 주소다.\n\n굳이 비유하자면 각 가구의 문(IP)을 지나 집 안에 들어서면\n\n각 방을 Port라고 비유할 수 있을 것 같다.\n\n최종 도착지(End Point)인 셈이다.\n\n \n\n그래서 웹 애플리케이션을 개발하여 WAS를 통해 가동하였을 때\n\nURL상에서 localhost:8080 이런 식으로 나오게 되는 것인데\n\nlocalhost는 WAS를 돌리는 컴퓨터의 IP주소이고 :8080은 해당 컴퓨터의 WAS Port인 셈이다.\n\n그래서 Port는 한 컴퓨터에 여러개가 있을 수 있다.\n\n \n\n192.168.0.1(localhost)의 8080 포트(=Tomcat)에 접속한다면\n\nTomcat내부 Root폴더(webapps)에 진입하게 되는 것이다.\n\n \n\n아무튼, 외부에서도 Oracle RDB에 접속할 수 있게끔\n\n1521(Oracle Port Number) 포트를 모든 IP에 대해 개방해주고\n\n내 컴퓨터에서 SQLDeveloper.exe를 실행 해 RDB에 접속 테스트를 하였고,\n\n성공적으로 접속이 되어 DB구축을 하게 되었다.\n\n \n\n또한 RDB를 새로 구축한 만큼 웹 애플리케이션의 설정 파일을 바꿔줘야 했는데,\n\n대표적으로 Tomcat의 server.xml을 커스터마이징해 Context Path를 변경해주어야 했고,\n\n웹 애플리케이션의 root-context.xml에 설정된 DataSource 또한 바꿔주어야 했다.\n\nContext Path를 바꾸어주지 않는다면 192.168.0.1(임의의 IP주소):8080/Project명/이라는\n\nContext path가 Default값으로 설정되기에\n\n웹 애플리케이션이 정상적으로 동작하지 않을 위험이 있기 때문이었으며,\n\nroot-context에는 로컬에 구축된 DB의 정보가 들어있기 때문에\n\n이를 서버에 새로 구축한 DB의 정보로 업데이트해줬다.\n\n \n\n결론적으로 정상적으로 호스팅이 되는 걸 확인했고,\n\n가비아에서 도메인을 구매한 후\n\nAWS Route53을 사용해 내가 배포한 웹 애플리케이션의 도메인을 변경해줬다.\n\n \n\nDNS(Domain Name System) 서버란 사람이 기억하기 힘든 IP주소를 사람이 알아보기 쉬운 문자의 나열로 URL을 바꿔주는 서버다.\n\n내가 만든 웹 애플리케이션을 호스팅 하는 컴퓨터의 IP주소를 DNS 서버에 등록하고,\n\nDNS 서버가 해당 IP에 요청을 받으면 도메인을 반환하게끔 작동한다. 반대로도 가능하다.\n\n그래서 192.168.0.1(임의의 IP) 이란 IP가 DNS 서버에 등록되어 있고,\n\nwww.naver.com라는 도메인을 반환하게끔 설정되어 있는 상태에서\n\n이 IP로 접속을 한다면 DNS는 맵핑되어 있는 문자열을 반환해주는 것이다.\n\n \n\n이를 실험해보려면 다른 웹 사이트에 ping을 보내 해당 사이트의 IP를 알아내고\n\n웹 브라우저 URL창에 해당 IP를 입력하면 정상적으로 접속되는 것을 확인할 수 있을 것이다.\n\n결과적으로 EC2 인스턴스의 고정 IP:8080이었던 URL이 www.hklmart.shop으로 바뀐 것이다.\n\n \n\n😎 후기\n\n\n\n적어놓고 나니 굉장히 간략한데. 처음 해보는 것이기도 했고 알고 있는 지식을 실전에 적용해보며 많은 시행착오가 있었다.\n\n아침 9시에 시작해서 새벽 1시에 끝냈고, 하루 종일 몰입하느라 아무것도 먹지 못해 새벽 1시에 야식을 시켜먹었다.\n\n(문제 해결 후 먹는 족발이 그렇게 맛있을 수가 없었다.)\n\n \n\n이번에 많은 시행착오를 겪으면서 많은 걸 배우고 느꼈는데 간략하게 정리해보자면\n\n \n\n첫 번째로 우선 가장 많은 시간을 빼앗긴 타임존 이슈가 있겠다.\n\nDNS 구축 전 최종적으로 웹 애플리케이션을 가동할 때 서블릿 컨테이너 이니셜 라이징중에 빈 생성 에러가 발생했는데, ORA-01882(타임존) 에러였다.\n\n이 에러의 근본적인 원인은 한참의 삽질 끝에 알아냈다.\n\nEC2 인스턴스의 타임존, OS의 타임존, WAS의 타임존, DB의 타임존 4박자가 모두 일치하지 않을 경우 발생하는 에러였는데\n\n가상 머신이 한국에 있지 않다는데서 오는 게 가장 큰 원인이었던 것으로 보인다.\n\n그래서 EC2 인스턴스를 이미지화해 한국으로 리전(Region)을 옮겼으며, 모든 타임존을 KST로 변경하고나서야 해결이 되었다.\n\n타임존이 안 맞으면 접속이 안된다는 것도 처음 알았는데 큰 수확이었던 것 같다.\n\n \n\n두 번째로 war파일을 이용한 배포를 처음 해보았다는 것이다.\n\nwar를 Tomcat/webapps에 배포하고 Tomcat을 Restart 할 경우 war가 자동으로 압축해제가 된다는 것도 처음 알았고,\n\n이 war파일을 삭제할 경우 프로젝트 폴더도 같이 없어진다는 것도 처음 알았다.\n\n평소 압축파일을 풀면 압축파일을 삭제하거나 정리하는 버릇이 있어 war파일이 압축 해제된 걸 확인하고 “얘는 이제 없어도 되겠지~”\n\n라며 war를 지웠는데 갑자기 웹 애플리케이션이 먹통이 돼서 404 에러를 뿜어대는 것이었다.\n\n알고 보니 war 삭제되면 압축 해제한 프로젝트 폴더도 사라지더라. 그래서 404를 뿜어댔던 것이고…\n\n \n\n세 번째로 서버와 로컬의 환경 차이에서 발생하는 이슈였다.\n\n이게 정말 큰 문제였는데 로컬(내 컴퓨터)의 인텔리제이로 돌릴 땐 정상 동작하던 것들이\n\n서버로 마이그레이션(Migration) 하여 구동시키자 온갖 버그가 발생하는데\n\n정말 사람 뒷목 잡게 만드는 상황이었다.\n\n \n\n아마 JVM이 아니었다면 쓰러졌을지도 모르겠다.\n\n나름 OOP니 SOLID니 하며 신경 써서 만들었던 코드들인데 (구리지만…)\n\n이런 버그들이 발생하는 걸 보니 마음이 편치는 않았다.\n\n그래도 배우는 입장이니 좋은 경험 했다고 긍정적으로 생각해본다.\n\n \n\n마지막으로 리눅스를 사용해보았다는 것이다.\n\n인스턴스 생성 중 OS를 선택하기 전에 리눅스에 대해 알아보았는데\n\n데미안, 레드햇, 우분투 세 종류의 리눅스 선택이 가능했었다.\n\nSpring Security를 채택&amp;적용해 개인정보 암호화, XSS 공격 방지, 중복 로그인 방지 등\n\n보안에 나름대로 많은 신경을 썼던 프로젝트였기 때문에\n\n보안 업데이트가 끝나 보안에 취약하다는 레드햇은 보자마자 최우선 배제대상이었다.\n\n \n\n남은 건 데비안과 우분투였는데 우분투가 데비안에서 나온 녀석이기도 하고,\n\n내가 리눅스를 아예 사용해보지 않은 초짜 중의 초짜라\n\n데비안은 너무 진입장벽이 높지 않을까 하는 생각에 우분투로 시작을 해보자고 생각하게 됐다.\n\n이 걱정은 기우였던 걸로 생각이 되는데, 리눅스가 생각보다 어렵지 않았다.\n\n오히려 재미있었다.\n\n영어공부도 많이 되는 것 같고… 리눅스는 앞으로 노트북에 설치해서 두고두고 공부해볼까 하는 생각도 들었다.\n\n \n\n이번의 시행착오(삽질)는 앞으로 더 크게 발전할 수 있는 기반이 됐다고 생각한다.\n\n왜냐하면 공부해서 머릿속으로만 알고 있던 지식의 대부분을\n\n실전에 적용해보았던 첫 경험(역대급 삽질 퍼레이드)이었기 때문이다.\n\n추상적으로 막연하게만 느끼고 있던 부분들도 대부분 이해하게 됐던 게 그야말로 가장 큰 수확이었다고 생각한다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-01-13-diary-7/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "테스트 주도 개발(Test-Driven Development, TDD) - 1",
      "date": "2021-01-14 12:40:00 +0000",
      "description": "테스트 주도 개발(Test-Driven Development, TDD)에 대한 학습\n",
      "content": "\n  테스트 주도 개발\n\n\n \n\n\n\n참고 - 아름다운 코드와 즐거운 개발을 위한 테스트 주도 개발 | 켄트백 저\n\n \n\n테스트 주도 개발\n\n\n\n엔터프라이즈급 개발 환경에선 새로운 기능을 하나 추가하거나 수정하면\n\n온갖 자잘하거나 크리티컬한 에러가 연쇄적으로 발생할 가능성이 매우 높다.\n\n이는 각 코드가 서로 독립적이지 않으면서 단위별로 완벽하게 검증되지 않은 상태이기 때문에 발생한다.\n\n그리고 이런 연쇄적인 에러는 코드를 유지보수 하는 개발자에게 두려움을 심어준다.\n\nTDD는 개발자가 용기를 가질 수 있게 해 준다 그래서 두려움을 관리하는 방법이다.\n\n \n\n물론 단위 테스트(Unit Test)를 진행하여 각 코드를 검증했다고 하더라도 이러한 에러는 분명 발생할 수 밖에 없겠지만,\n\n그나마 에러 발생 빈도를 최저치까지 끌어내릴 수는 있을 것이다.\n\nTDD란 테스트 코드 자체를 하나의 요구사항 명세서로서 쓰는 것과도 같다.\n\n \n\n일반적으로 우리는 프로그램을 개발할 때 아래와 같은 순서로 진행한다.\n\n \n\n\n  \n    코드를 작성한다\n  \n  \n    서버를 올린다\n  \n  \n    코드가 제대로 동작하는지 확인한다\n  \n  \n    에러가 발생하면 서버를 내린다\n  \n  \n    1~4를 반복한다\n  \n\n\n \n\n우선 서버를 올렸다 내렸다 하는 부분에서 시간적인 비용의 손해가 많이 발생한다.\n\n이러한 시간 지연은 개발자를 조급하게 만들고(결과물을 빨리 확인하고 싶기에),\n\n이런 조급함은 완벽한 테스트를 하기 힘들게 만들 가능성이 높다.\n\n그렇다면 TDD를 적용한 경우에는 어떻게 개발을 진행할까?\n\n켄트 백은 이를 레드-그린 사이클(Red-Green Cycle)이라고 말했다.\n\n \n\n\n\n \n\n\n  \n    빨강(Red) - 실패하는 작은 테스트를 작성한다. 처음에는 컴파일조차 되지 않을 수 있다\n  \n  \n    초록(Green) - 빨리 테스트가 통과하게끔 코드를 작성한다. 이를 위해 어떤 죄악을 저질러도 좋다\n  \n  \n    리팩토링(Refactoring) - 일단 테스트를 통과하게만 하는 와중에 생겨난 모든 나쁜 냄새(Bad Smell)를 제거한다.\n  \n\n\n \n\n\n  💡 죄악 : 기존 코드 복사해서 붙이기(Copy &amp; Paste), 테스트만 간신히 통과할 수 있게 함수가 상수를 반환하도록 구현하기 등의 편법들\n\n  💡 나쁜 냄새(Bad Smell) : 리팩토링(Refactoring) - 마틴 파울러를 읽어보자. 명저서이다. 일반적으론 중복되는 코드를 말한다.\n\n\n \n\nTDD의 장점으로 빠른 피드백(Feedback)이 있겠다.\n\n대부분의 과정을 자동화하여 테스트 코드만 실행한다면 결과물을 즉시 확인할 수 있기때문이다.\n\n그리고 이렇게 테스트 코드를 먼저 작성하고 해당 테스트 코드를 통과해낸 코드는 소위 말하는 검증된 코드라고 볼 수 있다.\n\n \n\n여기서 중요한 것은 우리는 개발자로서 코드를 작성할 때\n\n무의식적으로 통과되게끔 코드를 작성할 가능성이 높기 때문에 무조건 실패할 수밖에 없는 테스트 코드를 작성하라는 것이다.\n\n켄트 백은 이 TDD가 보안 소프트웨어와 동시성 프로그램을 제외한 대부분의 코드를\n\n완벽에 가깝게 검증해줄 수 있는 방식이라고 설명하고 있다.\n\n우선 어려운 용어는 다 제쳐두고 위의 일반적인 개발 방식의 1~5의 과정을 직접 반복하지 않아도\n\n모두 자동화하여 결과물을 즉시 볼 수 있다는 점에서 매우 큰 메리트가 느껴진다.\n\n \n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-01-14-tdd-1/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "테스트 주도 개발(Test-Driven Development, TDD) - 2",
      "date": "2021-01-14 13:22:00 +0000",
      "description": "테스트 주도 개발(Test-Driven Development, TDD)에 대한 학습\n",
      "content": "\n  📕 환경\n\n\n \n\n\n  📜 참고문서 : JUnit 5 User Guide\n\n\n📕 환경\n\n\n\nTDD를 공부하기에 앞서 나는 아래와 같은 환경으로 시스템을 구축했다.\n\n \n\n\n  \n    \n      통합개발환경(IDE)\n      IntelliJ Ultimate\n    \n  \n  \n    \n      프로그래밍 언어(Language)\n      Java 11\n    \n    \n      프레임워크(Framework)\n      Spring Boot 2.4.1\n    \n    \n      테스트 프레임워크(Test Framework)\n      JUnit 5\n    \n    \n      빌드 도구(Build Tool)\n      Gradle\n    \n  \n\n\n \n\n우선 컨트롤러(Controller)를 만들기 전 테스트 코드를 작성할 것이다.\n\n테스트 코드를 관리하기 위해 전체적인 구조를 변경하고 테스트 코드 작성에 들어간다.\n\n// file: 'SpringbootApplicationTests.class'\n@SpringBootTest\n// @ExtendWith(SpringExtension.class) \npublic abstract class SpringbootApplicationTests {\n}\n\n\n최상위 테스트 코드 클래스인 SpringbootApplicationTests이다.\n\n이 녀석을 모든 패키지의 최상단에 위치하도록 위치를 변경하고, 추상 클래스로 변경한다.\n\n \n\n\n  💡 추상클래스로 변경하는 이유?\n\n  Spring의 각 계층을 모두 쪼개어 테스트 코드를 작성하기 위함이다.\n최상위 클래스를 추상 클래스로 선언하고, 클래스 계층을 피라미드 형식으로 상속받아 구현 할 것이다.\n그래서 각 테스트를 진행할 때 지나치게 무겁지 않은 테스트 코드를 작성할 수 있는 구조를 만든다.\n\n\n \n\n@SpringBootTest \n\n\n \n\n애플리케이션 콘텍스트에서 모든 설정과 Bean을 가져와 로딩한다.\n\n테스트 프레임워크가 개발환경과 가장 유사하게 동작하게 해 줄 수 있다.\n\n다만 애플리케이션의 모든 설정을 가져오는 것이기 때문에 테스트 코드가 무거워진다는 단점이 있다.\n\n \n\n@ExtendWith(SpringExtension.class)\n\n\n \n\nJUnit5로 업데이트되면서 변한 부분인데,\n\nJUnit4의  @RunWith와 비슷한 역할을 한다.\n\nJUnit4는 @RunWith를 필수적으로 선언해야 했는데\n\nJUnit5는 이를 생략 할 수 있다.\n\n왜냐하면 @SpringBootTest안에 이미 선언되어 있기 때문이다.\n\n \n\n\n\n \n\n설정 파일의 흐름을 간단하게 풀어보자면\n\n애플리케이션 -&gt; 테스트 코드 -&gt; JUnit5(Test Framework)로 가져오는 셈\n\n \n\n// file: 'AbstractMockMvcTests.class'\n@AutoConfigureMockMvc\npublic abstract class AbstractMockMvcTests extends SpringbootApplicationTests {\n    @Autowired\n    protected MockMvc mvc;\n}\n\n\n \n\nMVC 테스트를 위한 AbstractMockMvcTests클래스이다.\n\n역시 추상 클래스로 선언해주고 SpringbootApplicationTests를 상속받도록 한다.\n\n \n\n@AutoConfigureMockMvc\n\n\n \n\nMockMvc를 빌더 없이 주입받을 수 있게 설정해주는 애노테이션이다.\n\n@WebMvcTest와는 다른 방법으로, @AutoConfigureMockMvc는 MVC테스트 외 모든 설정을 같이 올린다.\n\n이 모든 설정이라 함은 AOP도 되고 JPA Repository도 사용 가능하다는 뜻이다.\n\n그래서 실제적으로 동작하는 MVC테스트를 진행하려면 위 애노테이션을 사용한다.\n\n \n\n@Autowired\nprotected MockMvc mvc;\n\n\n \n\nAbstractMockMvcTests 를 상속받는 클래스에서 MockMvc 객체를 확인할 수 있게\n\n접근제한자를 protected로 공개해준다.\n\n// file: 'FirstControllerTest.class'\npublic class FirstControllerTest extends AbstractMockMvcTests {\n    @Test\n    public void init() throws Exception {\n        mvc.perform(get(\"/\"))\n                .andExpect(status().isOk())\n                .andExpect(content().string(\"Hello! World!\"));\n    }\n}\n\n\n \n\n컨트롤러 테스트 코드를 작성한다.\n\nAbstractMockMvcTests를 상속받아 FirstControllerTest를 작성한다.\n\n앞으로 작성될 모든 컨트롤러 테스트 코드는 AbstractMockMvcTests를 상속받아 작성하면 된다.\n\n \n\n@Test\n\n\n \n\n이 애노테이션이 선언된 메서드를 테스트하겠다는 뜻이다.\n\n해당 애노테이션을 쓰기 위해서는 지켜야 할 약속이 두 가지 있다.\n\n@Test가 선언된 메서드는 접근 제한자가 public 이어야 하고 반환 타입이 void 여야 한다.\n\n그리고 @Test를 단위 테스트(Unit Test)에서 말하는 단위(Unit) 로 본다.\n\n그러니까 FirstControllerTest에는 @Test가 한개 뿐 이므로,\n\n테스트 코드를 실행하면 한번의 테스트가 실행 될 것이다.\n\n성공하면 1/1 성공!\n\n실패하면 1/1 실패! 같은 식으로 말이다.\n\n \n\n// file: 'FirstControllerTest.class'\n@Test\npublic void init() throws Exception {\n        mvc.perform(get(\"/\"))\n                .andExpect(status().isOk())\n                .andExpect(content().string(\"Hello! World!\"));\n  }\n\n\n \n\nperform()을 수행한다.\n\nperform()은 Get 방식으로 URL / 에 요청(Request)을 보낸다.\n\nandExpect()는 검증을 위한 코드이다.\n\nstatus().isOk()는 통신상태가 200이면 true를 반환한다.\n\ncontent().string(\"Hello! World!\")는 컨트롤러가 반환하는 내용이 Hello! World! 이면 true를 반환한다.\n\n \n\n그리고 테스트를 실행하면 실패 할 것이다.\n\n아직 이 테스트를 통과할 구현 코드가 없기때문이다.\n\n이제 이 테스트 코드를 따라 실행될 FirstController를 작성한다.\n\n \n\n// file: 'FirstController.class'\n@RestController\npublic class FirstController {\n    @GetMapping(\"/\")\n    public String init() {\n        return \"Hello! World!\";\n    }\n}\n\n\n \n\n@RestController\n\n\n \n\n@Controller + @ResponseBody이다.\n\n컨트롤러가 View Page가 아닌 데이터 리터럴을 반환하게 해준다.\n\n \n\n@GetMapping(\"/\")\n\n\n \n\nURL /에 Get방식의 요청(Request)을 받아 처리하겠다는 의미이다.\n\n \n\npublic String init() {\n        return \"Hello! World!\";\n}\n\n\n \n\nURL /에 Get방식의 요청(Request)을 받을 경우 init()을 실행할 것이고,\n\ninit()은 Hello! World!라는 String 리터럴을 반환해 줄 것이다.\n\n최종적으로 모든 코드를 작성했으면 FirstControllerTest를 실행해본다.\n\n \n\n\n\n \n\n&gt; Task :compileJava UP-TO-DATE\n&gt; Task :processResources UP-TO-DATE\n&gt; Task :classes UP-TO-DATE\n&gt; Task :compileTestJava\n&gt; Task :processTestResources NO-SOURCE\n&gt; Task :testClasses\n&gt; Task :test\n13:18:52.515 [Test worker] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating CacheAwareContextLoaderDelegate from class [org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate]\n13:18:52.526 [Test worker] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating BootstrapContext using constructor [public org.springframework.test.context.support.DefaultBootstrapContext(java.lang.Class,org.springframework.test.context.CacheAwareContextLoaderDelegate)]\n13:18:52.555 [Test worker] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating TestContextBootstrapper for test class [com.study.springboot.controller.FirstControllerTest] from class [org.springframework.boot.test.context.SpringBootTestContextBootstrapper]\n13:18:52.570 [Test worker] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Neither @ContextConfiguration nor @ContextHierarchy found for test class [com.study.springboot.controller.FirstControllerTest], using SpringBootContextLoader\n13:18:52.575 [Test worker] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [com.study.springboot.controller.FirstControllerTest]: class path resource [com/study/springboot/controller/FirstControllerTest-context.xml] does not exist\n13:18:52.576 [Test worker] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [com.study.springboot.controller.FirstControllerTest]: class path resource [com/study/springboot/controller/FirstControllerTestContext.groovy] does not exist\n13:18:52.576 [Test worker] INFO org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [com.study.springboot.controller.FirstControllerTest]: no resource found for suffixes {-context.xml, Context.groovy}.\n13:18:52.577 [Test worker] INFO org.springframework.test.context.support.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [com.study.springboot.controller.FirstControllerTest]: FirstControllerTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.\n13:18:52.633 [Test worker] DEBUG org.springframework.test.context.support.ActiveProfilesUtils - Could not find an 'annotation declaring class' for annotation type [org.springframework.test.context.ActiveProfiles] and class [com.study.springboot.controller.FirstControllerTest]\n13:18:52.687 [Test worker] DEBUG org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider - Identified candidate component class: file [D:\\Project\\springboot\\build\\classes\\java\\main\\com\\study\\springboot\\SpringbootApplication.class]\n13:18:52.688 [Test worker] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration com.study.springboot.SpringbootApplication for test class com.study.springboot.controller.FirstControllerTest\n13:18:52.761 [Test worker] DEBUG org.springframework.boot.test.context.SpringBootTestContextBootstrapper - @TestExecutionListeners is not present for class [com.study.springboot.controller.FirstControllerTest]: using defaults.\n13:18:52.761 [Test worker] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.boot.test.autoconfigure.webservices.client.MockWebServiceServerTestExecutionListener, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.test.context.event.EventPublishingTestExecutionListener]\n13:18:52.772 [Test worker] DEBUG org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Skipping candidate TestExecutionListener [org.springframework.test.context.transaction.TransactionalTestExecutionListener] due to a missing dependency. Specify custom listener classes or make the default listener classes and their required dependencies available. Offending class: [org/springframework/transaction/interceptor/TransactionAttributeSource]\n13:18:52.772 [Test worker] DEBUG org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Skipping candidate TestExecutionListener [org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener] due to a missing dependency. Specify custom listener classes or make the default listener classes and their required dependencies available. Offending class: [org/springframework/transaction/interceptor/TransactionAttribute]\n13:18:52.773 [Test worker] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@1cc79614, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1d454c54, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@33794a82, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@38817d1d, org.springframework.test.context.support.DirtiesContextTestExecutionListener@18d62b2f, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@2f46f38d, org.springframework.test.context.event.EventPublishingTestExecutionListener@561281bd, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@65c877f7, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@4c6eb732, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@54acefa9, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@167183e8, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@30a0391e, org.springframework.boot.test.autoconfigure.webservices.client.MockWebServiceServerTestExecutionListener@9cedf1f, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@3aaca828]\n13:18:52.776 [Test worker] DEBUG org.springframework.test.context.support.AbstractDirtiesContextTestExecutionListener - Before test class: context [DefaultTestContext@78793906 testClass = FirstControllerTest, testInstance = [null], testMethod = [null], testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@565eca81 testClass = FirstControllerTest, locations = '{}', classes = '{class com.study.springboot.SpringbootApplication}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[org.springframework.boot.test.autoconfigure.actuate.metrics.MetricsExportContextCustomizerFactory$DisableMetricExportContextCustomizer@53352bfc, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@4b3fa0b3, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@251d899, [ImportsContextCustomizer@5938f557 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@64fbb213, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@52ff824c, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@56d40319, org.springframework.boot.test.context.SpringBootTestArgs@1, org.springframework.boot.test.context.SpringBootTestWebEnvironment@774ee425], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -&gt; true]], class annotated with @DirtiesContext [false] with mode [null].\n13:18:52.808 [Test worker] DEBUG org.springframework.test.context.support.TestPropertySourceUtils - Adding inlined properties to environment: {spring.jmx.enabled=false, org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}\n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::                (v2.4.1)\n\n2021-01-14 13:18:53.040  INFO 13132 --- [    Test worker] c.s.s.controller.FirstControllerTest     : Starting FirstControllerTest using Java 11.0.8 on Changhoon-Han with PID 13132 (started by Han in D:\\Project\\springboot)\n2021-01-14 13:18:53.045  INFO 13132 --- [    Test worker] c.s.s.controller.FirstControllerTest     : No active profile set, falling back to default profiles: default\n2021-01-14 13:18:54.243  INFO 13132 --- [    Test worker] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\n2021-01-14 13:18:54.648  INFO 13132 --- [    Test worker] o.s.b.t.m.w.SpringBootMockServletContext : Initializing Spring TestDispatcherServlet ''\n2021-01-14 13:18:54.648  INFO 13132 --- [    Test worker] o.s.t.web.servlet.TestDispatcherServlet  : Initializing Servlet ''\n2021-01-14 13:18:54.649  INFO 13132 --- [    Test worker] o.s.t.web.servlet.TestDispatcherServlet  : Completed initialization in 1 ms\n2021-01-14 13:18:54.670  INFO 13132 --- [    Test worker] c.s.s.controller.FirstControllerTest     : Started FirstControllerTest in 1.856 seconds (JVM running for 2.936)\n2021-01-14 13:18:54.983  INFO 13132 --- [extShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'\nBUILD SUCCESSFUL in 4s\n4 actionable tasks: 2 executed, 2 up-to-date\n오후 1:18:55: 작업 실행이 완료되었습니다 ':test --tests \"com.study.springboot.controller.FirstControllerTest\"'.\n\n\n \n\n테스트에 관련된 로그가 작성되며 테스트가 성공으로 완료됨을 확인할 수 있다.\n\nFirstController의 init() 반환 값을 바꾸면 어떻게 될까?\n\n \n\n@RestController\npublic class FirstController {\n    @GetMapping(\"/\")\n    public String init() {\n        return \"Hellow! World!\";\n    }\n}\n\n\n반환 값을 Hello! World! -&gt; Hellow! World!로 변경하고\n\nFirstControllerTest를 실행해보았다.\n\n\n\n \n\n&gt; Task :compileJava\n&gt; Task :processResources UP-TO-DATE\n&gt; Task :classes\n&gt; Task :compileTestJava UP-TO-DATE\n&gt; Task :processTestResources NO-SOURCE\n&gt; Task :testClasses UP-TO-DATE\n&gt; Task :test\n13:39:15.001 [Test worker] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating CacheAwareContextLoaderDelegate from class [org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate]\n13:39:15.010 [Test worker] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating BootstrapContext using constructor [public org.springframework.test.context.support.DefaultBootstrapContext(java.lang.Class,org.springframework.test.context.CacheAwareContextLoaderDelegate)]\n13:39:15.033 [Test worker] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating TestContextBootstrapper for test class [com.study.springboot.controller.FirstControllerTest] from class [org.springframework.boot.test.context.SpringBootTestContextBootstrapper]\n13:39:15.041 [Test worker] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Neither @ContextConfiguration nor @ContextHierarchy found for test class [com.study.springboot.controller.FirstControllerTest], using SpringBootContextLoader\n13:39:15.044 [Test worker] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [com.study.springboot.controller.FirstControllerTest]: class path resource [com/study/springboot/controller/FirstControllerTest-context.xml] does not exist\n13:39:15.044 [Test worker] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [com.study.springboot.controller.FirstControllerTest]: class path resource [com/study/springboot/controller/FirstControllerTestContext.groovy] does not exist\n13:39:15.044 [Test worker] INFO org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [com.study.springboot.controller.FirstControllerTest]: no resource found for suffixes {-context.xml, Context.groovy}.\n13:39:15.045 [Test worker] INFO org.springframework.test.context.support.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [com.study.springboot.controller.FirstControllerTest]: FirstControllerTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.\n13:39:15.081 [Test worker] DEBUG org.springframework.test.context.support.ActiveProfilesUtils - Could not find an 'annotation declaring class' for annotation type [org.springframework.test.context.ActiveProfiles] and class [com.study.springboot.controller.FirstControllerTest]\n13:39:15.130 [Test worker] DEBUG org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider - Identified candidate component class: file [D:\\Project\\springboot\\build\\classes\\java\\main\\com\\study\\springboot\\SpringbootApplication.class]\n13:39:15.131 [Test worker] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration com.study.springboot.SpringbootApplication for test class com.study.springboot.controller.FirstControllerTest\n13:39:15.197 [Test worker] DEBUG org.springframework.boot.test.context.SpringBootTestContextBootstrapper - @TestExecutionListeners is not present for class [com.study.springboot.controller.FirstControllerTest]: using defaults.\n13:39:15.197 [Test worker] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener, org.springframework.security.test.context.support.ReactorContextTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.boot.test.autoconfigure.webservices.client.MockWebServiceServerTestExecutionListener, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.test.context.event.EventPublishingTestExecutionListener]\n13:39:15.205 [Test worker] DEBUG org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Skipping candidate TestExecutionListener [org.springframework.test.context.transaction.TransactionalTestExecutionListener] due to a missing dependency. Specify custom listener classes or make the default listener classes and their required dependencies available. Offending class: [org/springframework/transaction/interceptor/TransactionAttributeSource]\n13:39:15.206 [Test worker] DEBUG org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Skipping candidate TestExecutionListener [org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener] due to a missing dependency. Specify custom listener classes or make the default listener classes and their required dependencies available. Offending class: [org/springframework/transaction/interceptor/TransactionAttribute]\n13:39:15.206 [Test worker] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@1cc79614, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@1d454c54, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@33794a82, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@38817d1d, org.springframework.test.context.support.DirtiesContextTestExecutionListener@18d62b2f, org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@2f46f38d, org.springframework.test.context.event.EventPublishingTestExecutionListener@561281bd, org.springframework.security.test.context.support.ReactorContextTestExecutionListener@65c877f7, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@4c6eb732, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@54acefa9, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@167183e8, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@30a0391e, org.springframework.boot.test.autoconfigure.webservices.client.MockWebServiceServerTestExecutionListener@9cedf1f, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@3aaca828]\n13:39:15.209 [Test worker] DEBUG org.springframework.test.context.support.AbstractDirtiesContextTestExecutionListener - Before test class: context [DefaultTestContext@78793906 testClass = FirstControllerTest, testInstance = [null], testMethod = [null], testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@565eca81 testClass = FirstControllerTest, locations = '{}', classes = '{class com.study.springboot.SpringbootApplication}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[org.springframework.boot.test.autoconfigure.actuate.metrics.MetricsExportContextCustomizerFactory$DisableMetricExportContextCustomizer@53352bfc, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@4b3fa0b3, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@251d899, [ImportsContextCustomizer@5938f557 key = [org.springframework.boot.test.autoconfigure.web.servlet.MockMvcAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebClientAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcWebDriverAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientAutoConfiguration, org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration, org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcSecurityConfiguration]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@64fbb213, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@52ff824c, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@56d40319, org.springframework.boot.test.context.SpringBootTestArgs@1, org.springframework.boot.test.context.SpringBootTestWebEnvironment@774ee425], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -&gt; true]], class annotated with @DirtiesContext [false] with mode [null].\n13:39:15.234 [Test worker] DEBUG org.springframework.test.context.support.TestPropertySourceUtils - Adding inlined properties to environment: {spring.jmx.enabled=false, org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}\n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::                (v2.4.1)\n\n2021-01-14 13:39:15.404  INFO 9684 --- [    Test worker] c.s.s.controller.FirstControllerTest     : Starting FirstControllerTest using Java 11.0.8 on Changhoon-Han with PID 9684 (started by Han in D:\\Project\\springboot)\n2021-01-14 13:39:15.406  INFO 9684 --- [    Test worker] c.s.s.controller.FirstControllerTest     : No active profile set, falling back to default profiles: default\n2021-01-14 13:39:16.247  INFO 9684 --- [    Test worker] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\n2021-01-14 13:39:16.512  INFO 9684 --- [    Test worker] o.s.b.t.m.w.SpringBootMockServletContext : Initializing Spring TestDispatcherServlet ''\n2021-01-14 13:39:16.512  INFO 9684 --- [    Test worker] o.s.t.web.servlet.TestDispatcherServlet  : Initializing Servlet ''\n2021-01-14 13:39:16.513  INFO 9684 --- [    Test worker] o.s.t.web.servlet.TestDispatcherServlet  : Completed initialization in 1 ms\n2021-01-14 13:39:16.535  INFO 9684 --- [    Test worker] c.s.s.controller.FirstControllerTest     : Started FirstControllerTest in 1.295 seconds (JVM running for 2.188)\n\nMockHttpServletRequest:\n      HTTP Method = GET\n      Request URI = /\n       Parameters = {}\n          Headers = []\n             Body = null\n    Session Attrs = {}\n\nHandler:\n             Type = com.study.springboot.controller.FirstController\n           Method = com.study.springboot.controller.FirstController#init()\n\nAsync:\n    Async started = false\n     Async result = null\n\nResolved Exception:\n             Type = null\n\nModelAndView:\n        View name = null\n             View = null\n            Model = null\n\nFlashMap:\n       Attributes = null\n\nMockHttpServletResponse:\n           Status = 200\n    Error message = null\n          Headers = [Content-Type:\"text/plain;charset=UTF-8\", Content-Length:\"14\"]\n     Content type = text/plain;charset=UTF-8\n             Body = Hellow! World!\n    Forwarded URL = null\n   Redirected URL = null\n          Cookies = []\n\nResponse content expected:&lt;Hello! World!&gt; but was:&lt;Hellow! World!&gt;\n필요:Hello! World!\n실제   :Hellow! World!\n&lt;클릭하여 차이점 확인&gt;\n\njava.lang.AssertionError: Response content expected:&lt;Hello! World!&gt; but was:&lt;Hellow! World!&gt;\n\tat org.springframework.test.util.AssertionErrors.fail(AssertionErrors.java:59)\n\tat org.springframework.test.util.AssertionErrors.assertEquals(AssertionErrors.java:122)\n\tat org.springframework.test.web.servlet.result.ContentResultMatchers.lambda$string$4(ContentResultMatchers.java:136)\n\tat org.springframework.test.web.servlet.MockMvc$1.andExpect(MockMvc.java:196)\n\tat com.study.springboot.controller.FirstControllerTest.init(FirstControllerTest.java:14)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688)\n\tat org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)\n\tat org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)\n\tat org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)\n\tat org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)\n\tat org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:210)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:206)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:65)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1541)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1541)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)\n\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:32)\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)\n\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:51)\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)\n\tat org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)\n\tat org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)\n\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:99)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:79)\n\tat org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:75)\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)\n\tat org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)\n\tat com.sun.proxy.$Proxy2.stop(Unknown Source)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:133)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)\n\tat org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182)\n\tat org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164)\n\tat org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:414)\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)\n\tat org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n\n\n2021-01-14 13:39:16.850  INFO 9684 --- [extShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'\nFirstControllerTest &gt; init() FAILED\n    java.lang.AssertionError at FirstControllerTest.java:14\n1 test completed, 1 failed\n&gt; Task :test FAILED\nFAILURE: Build failed with an exception.\n* What went wrong:\nExecution failed for task ':test'.\n&gt; There were failing tests. See the report at: file:///D:/Project/springboot/build/reports/tests/test/index.html\n* Try:\nRun with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.\n* Get more help at https://help.gradle.org\nBUILD FAILED in 3s\n4 actionable tasks: 2 executed, 2 up-to-date\n\n\n \n\nResponse content expected:&lt;Hello! World!&gt; but was:&lt;Hellow! World!&gt;\n필요:Hello! World!\n실제:Hellow! World!\n\n2021-01-14 13:39:16.850  INFO 9684 --- [extShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'\nFirstControllerTest &gt; init() FAILED\n    java.lang.AssertionError at FirstControllerTest.java:14\n\n\n \n\n로그를 자세히 읽어보면\n\nFirstController의 init()이 제대로 수행되지 못했고,\n\n해당 코드가 FirstController 클래스의 14번째 줄에 있다는 것이다.\n\n테스트 실패 원인은 Hello! World!가 나올 거라 예상하였는데\n\n실제로 나온 값이 Hellow! World!라는 것이다.\n\n \n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-01-14-tdd-2/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "테스트 주도 개발(Test-Driven Development, TDD) - 3",
      "date": "2021-01-14 18:19:00 +0000",
      "description": "테스트 주도 개발(Test-Driven Development, TDD)에 대한 학습\n",
      "content": "\n \n\n이전 포스팅에서 컨트롤러를 테스트하기 위한 환경을 구축하고 실제로 동작하는지까지 확인해봤다.\n\n이번에는 신장과 체중을 입력하면 BMI지수를 반환해주는 API를 만들어 볼 것이다.\n\n입력은 숫자만 들어온다고 가정한다. &lt;input type=\"number\"&gt;\n\n이를 테스트하기 위한 코드를 먼저 작성해보자.\n\n \n\n// file: 'FirstControllerTest.class'\npublic class FirstControllerTest extends AbstractMockMvcTests {\n    @Test\n    public void init() throws Exception {\n        mvc.perform(get(\"/\"))\n                .andExpect(status().isOk())\n                .andExpect(content().string(\"Hello! World!\"));\n    }\n\n    @Test\n    public void getBmi() throws Exception {\n        DecimalFormat df = new DecimalFormat(\"#.##\");\n        String height = \"180\";\n        String weight = \"70\";\n        \n        // BMI = 체중(kg) / (신장(m) * 신장(m))\n        double bmi = Double.parseDouble(weight) / Math.pow(Double.parseDouble(height) / 100, 2);\n        String result = df.format(bmi);\n        \n        mvc.perform(get(\"/get/bmi\")\n                .param(\"height\", height)\n                .param(\"weight\", weight))\n                .andExpect(content().string(result));\n    }\n}\n\n\n \n\nDecimalFormat df = new DecimalFormat(\"#.##\");\n\n\n \n\n계산하여 나온 BMI지수는 double이기 때문에 소수점 자리가 길게 늘어질 거라 예상이 된다.\n\n깔끔하게 소수점 2번째 자리까지만 보고 싶기 때문에 DecimalFormat을 생성한다.\n\n \n\nString height = \"180\";\nString weight = \"70\";\n\n\n \n\n클라이언트가 입력할 신장과 체중 값을 미리 입력해보는 곳이다.\n\n이곳의 값들을 조정해 Tase-Case로 이용할 것이다.\n\n \n\n// BMI = 체중(kg) / (신장(m) * 신장(m))\ndouble bmi = Double.parseDouble(weight) / Math.pow(Double.parseDouble(height) / 100, 2);\nString result = df.format(bmi);\n\n\n \n\n테스트 코드를 자동화하기 위해 BMI의 계산식을 코드로 구현한다.\n\nresult 에는 계산되어 나온 BMI지수가 소수점 2번째 자리에서 잘려 String 리터럴로 저장될 것이다.\n\n \n\nmvc.perform(get(\"/get/bmi\")\n         .param(\"height\", height)\n         .param(\"weight\", weight))\n         .andExpect(content().string(result));\n\n\n \n\nURL /get/bmi 에 신장과 체중을 매개변수로 전달하여 예상하는 BMI값과 일치하는지 검증할 것이다.\n\n예를 들어 신장=180cm, 체중=70kg이라는 값을 넣는다면\n\n\n  BMI = 70 / (1.8*1.8) = 21.60493827160494\n\n\n하지만 2번째 자리에서 잘라낼 것이므로 예상되는 BMI지수는 21.60이다.\n\n모든 코드를 작성하였으니 테스트를 돌려보자.\n\n \n\n\n\n \n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::                (v2.4.1)\n\n2021-01-14 17:57:47.932  INFO 1600 --- [    Test worker] c.s.s.controller.FirstControllerTests    : Starting FirstControllerTests using Java 11.0.8 on Changhoon-Han with PID 1600 (started by Han in D:\\Project\\springboot)\n2021-01-14 17:57:47.935  INFO 1600 --- [    Test worker] c.s.s.controller.FirstControllerTests    : No active profile set, falling back to default profiles: default\n2021-01-14 17:57:48.865  INFO 1600 --- [    Test worker] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\n2021-01-14 17:57:49.188  INFO 1600 --- [    Test worker] o.s.b.t.m.w.SpringBootMockServletContext : Initializing Spring TestDispatcherServlet ''\n2021-01-14 17:57:49.188  INFO 1600 --- [    Test worker] o.s.t.web.servlet.TestDispatcherServlet  : Initializing Servlet ''\n2021-01-14 17:57:49.189  INFO 1600 --- [    Test worker] o.s.t.web.servlet.TestDispatcherServlet  : Completed initialization in 1 ms\n2021-01-14 17:57:49.208  INFO 1600 --- [    Test worker] c.s.s.controller.FirstControllerTests    : Started FirstControllerTests in 1.47 seconds (JVM running for 2.493)\n\nMockHttpServletRequest:\n      HTTP Method = GET\n      Request URI = /get/bmi\n       Parameters = {height=[180], weight=[70]}\n          Headers = []\n             Body = null\n    Session Attrs = {}\n\nHandler:\n             Type = org.springframework.web.servlet.resource.ResourceHttpRequestHandler\n\nAsync:\n    Async started = false\n     Async result = null\n\nResolved Exception:\n             Type = null\n\nModelAndView:\n        View name = null\n             View = null\n            Model = null\n\nFlashMap:\n       Attributes = null\n\nMockHttpServletResponse:\n           Status = 404\n    Error message = null\n          Headers = [Vary:\"Origin\", \"Access-Control-Request-Method\", \"Access-Control-Request-Headers\"]\n     Content type = null\n             Body = \n    Forwarded URL = null\n   Redirected URL = null\n          Cookies = []\n\nResponse content expected:&lt;21.6&gt; but was:&lt;&gt;\n필요:21.6\n실제   :\n\n\n\n \n\n당연히 실패한다. 실패하게끔 코드를 작성했기 때문이다.\n\n왜냐하면 테스트 대상인 FirstController에는 처리 로직이 구현되어 있지 않기 때문이다.\n\n그래서 21.6이라는 값이 나올 거라 예상했지만, 실제로 얻은 값은 ““이므로 테스트가 실패했다는 로그가 발생한다.\n\n그럼 이제 실제 로직을 작성해보자.\n\n \n\n// file: 'FirstController.class'\n@RestController\npublic class FirstController {\n    @GetMapping(\"/\")\n    public String init() {\n        return \"Hello! World!\";\n    }\n\n    @GetMapping(\"/get/bmi\")\n    public String calcBmi(@RequestParam(\"height\") double height, @RequestParam(\"weight\") double weight) {\n        \n        DecimalFormat df = new DecimalFormat(\"#.##\");\n        \n        // BMI = 체중(kg) / (신장(m) * 신장(m))\n        double bmi = weight / Math.pow(height / 100, 2);\n        return df.format(bmi);\n    }\n}\n\n\n \n\n테스트를 다시 돌려본다.\n\n \n\n\n\n \n\n컨트롤러가 예상한 대로 잘 동작하고 있다.\n\n다음 포스팅엔 리팩토링을 진행해볼 것이다.\n\n \n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-01-14-tdd-3/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "테스트 주도 개발(Test-Driven Development, TDD) - 4",
      "date": "2021-01-14 19:24:00 +0000",
      "description": "테스트 주도 개발(Test-Driven Development, TDD)에 대한 학습\n",
      "content": "\n \n\n// file: 'FirstControllerTest.class'\npublic class FirstControllerTest extends AbstractMockMvcTests {\n    @Test\n    public void init() throws Exception {\n        mvc.perform(get(\"/\"))\n                .andExpect(status().isOk())\n                .andExpect(content().string(\"Hello! World!\"));\n    }\n\n    @Test\n    public void getBmi() throws Exception {\n        DecimalFormat df = new DecimalFormat(\"#.##\");\n        String height = \"180\";\n        String weight = \"70\";\n        // BMI = 체중(kg) / (신장(m) * 신장(m))\n        double bmi = Double.parseDouble(weight) / Math.pow(Double.parseDouble(height) / 100, 2);\n        String result = df.format(bmi);\n        mvc.perform(get(\"/get/bmi\")\n                .param(\"height\", height)\n                .param(\"weight\", weight))\n                .andExpect(content().string(result));\n    }\n}\n\n\n \n\n// file: 'FirstController.class'\n@RestController\npublic class FirstController {\n    @GetMapping(\"/\")\n    public String init() {\n        return \"Hello! World!\";\n    }\n\n    @GetMapping(\"/get/bmi\")\n    public String calcBmi(@RequestParam(\"height\") double height, @RequestParam(\"weight\") double weight) {\n        DecimalFormat df = new DecimalFormat(\"#.##\");\n\n        // BMI = 체중(kg) / (신장(m) * 신장(m))\n        double bmi = weight / Math.pow(height / 100, 2);\n        return df.format(bmi);\n    }\n}\n\n\n \n\n처음 원했던 기능이 제대로 동작함을 확인했다.\n\n하지만 몇 가지 문제점이 보인다.\n\n \n\n\n  \n    사용자가 아무런 값을 입력하지 않았을 때의 예외상황에 대한 처리 로직\n  \n  \n    제어 계층(Control Layer)에 비즈니스 로직이 노출되어있음 - 책임 분리\n  \n\n\n \n\n모든 문제를 해결해서 최종적으로\n\n/get/bmi로 신장과 체중을 포함한 Get방식의 요청을 받으면\n\nBMI지수 혹은 값을 제대로 입력하세요 라는 문자열을 반환하도록 것이다.\n\n \n\nString height = null;\nString weight = null;\n\n\n \n\n신장과 체중을 null로 설정하고 테스트를 진행해보자.\n\n예상하기에 NullPointerException이 나올 거라 생각된다.\n\n \n\n\n\n \n\n값을 null이 아닌 ““라고 입력하면 NumberFormatException이 발생할 것이다.\n\n왜냐하면 테스트 코드에서 Double.parseDouble(\"\") 코드가 실행 될 텐데\n\n이러면 이곳에서 double 타입의 값을 반환하지 못하게 되기 때문이다.\n\n \n\nString height = \"\";\nString weight = \"\";\n\n\n \n\n\n\n \n\n테스트 코드를 리팩토링한다.\n\n사용자가 아무런 값을 입력하지 않았을 경우 “값을 제대로 입력하세요” 라는 문구가 출력되게끔 할 것이다.\n\n우선 두 가지 경우의 수가 있다.\n\n \n\n\n  \n    값이 null 인 경우\n  \n  \n    값이 ““인 경우\n  \n\n\n \n\n입력값이 어떻게 들어올지 확정할 수 없으므로\n\n두 경우 모두 “값을 제대로 입력하세요”라는 문자열을 리턴해야 한다.\n\n값이 null이라면 비교 연산자(==)를 이용하여 동일 비교를 한다.\n\n \n\nString height = \"\";\n\nif(height == null) // true\n\n\n \n\n\n  이해가 안된다면 Call By Value, Call By Reference 에 대해 공부해보자.\n\n\n \n\n값이 “” 라면 equals()를 이용하여야 한다.\n\n \n\nString height = \"\";\n\nif(\"\".equals(height)) // true\n\n\n \n\n이때 약간 주의해야 할 점이 있다.\n\n \n\nif(height.equals(\"\"))\n\n\n \n\n이와 같이 코드를 작성할 경우\n\nheight가 ““이라면 true가 반환될 것이다.\n\n하지만 height가 null이라면?\n\nnull에는 equals()가 정의되어있지 않기 때문에 NullPointerException이 발생할 것이다.\n\n \n\n// 정리\n\nif(height.equals(\"\")) // NullPointerException 발생위험\n\n\n \n\n따라서 다음과 같이 리팩토링한다.\n\n \n\nif ((height == null || \"\".equals(height)) || (weight == null || \"\".equals(weight)))\n\n\n \n\n신장과 체중 둘중 하나라도 입력이 되지 않으면 해당 조건문에서 필터링될 것이다.\n\n최종 코드를 보자.\n\n \n\n// file: 'FirstControllerTest.class'\npublic class FirstControllerTest extends AbstractMockMvcTests {\n    @Test\n    public void init() throws Exception {\n        mvc.perform(get(\"/\"))\n                .andExpect(status().isOk())\n                .andExpect(content().string(\"Hello! World!\"));\n    }\n\n    @Test\n    public void getBmi() throws Exception {\n        DecimalFormat df = new DecimalFormat(\"#.##\");\n        String result;\n        String height = \"180\";\n        String weight = \"\";\n\n        if ((height == null || \"\".equals(height)) || (weight == null || \"\".equals(weight))) {\n            result = \"값을 제대로 입력하세요\";\n        }\n        else {\n            // bmi = 체중(kg) / (신장(m) * 신장(m))\n            double bmi = Double.parseDouble(weight) / Math.pow(Double.parseDouble(height) / 100, 2);\n            result = df.format(bmi);\n        }\n        mvc.perform(get(\"/get/bmi\")\n                .param(\"height\", height)\n                .param(\"weight\", weight))\n                .andExpect(content().string(result));\n    }\n}\n\n\n \n\n테스트를 돌려본다.\n\n\n\n \n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::                (v2.4.1)\n\n2021-01-14 19:02:28.457  INFO 2040 --- [    Test worker] c.s.s.controller.FirstControllerTests    : Starting FirstControllerTests using Java 11.0.8 on Changhoon-Han with PID 2040 (started by Han in D:\\Project\\springboot)\n2021-01-14 19:02:28.458  INFO 2040 --- [    Test worker] c.s.s.controller.FirstControllerTests    : No active profile set, falling back to default profiles: default\n2021-01-14 19:02:29.290  INFO 2040 --- [    Test worker] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\n2021-01-14 19:02:29.562  INFO 2040 --- [    Test worker] o.s.b.t.m.w.SpringBootMockServletContext : Initializing Spring TestDispatcherServlet ''\n2021-01-14 19:02:29.563  INFO 2040 --- [    Test worker] o.s.t.web.servlet.TestDispatcherServlet  : Initializing Servlet ''\n2021-01-14 19:02:29.564  INFO 2040 --- [    Test worker] o.s.t.web.servlet.TestDispatcherServlet  : Completed initialization in 1 ms\n2021-01-14 19:02:29.586  INFO 2040 --- [    Test worker] c.s.s.controller.FirstControllerTests    : Started FirstControllerTests in 1.293 seconds (JVM running for 2.209)\n2021-01-14 19:02:29.863  WARN 2040 --- [    Test worker] .w.s.m.s.DefaultHandlerExceptionResolver : Resolved [org.springframework.web.method.annotation.MethodArgumentTypeMismatchException: Failed to convert value of type 'java.lang.String' to required type 'double'; nested exception is java.lang.NumberFormatException: empty String]\n\nMockHttpServletRequest:\n      HTTP Method = GET\n      Request URI = /get/bmi\n       Parameters = {height=[180], weight=[]}\n          Headers = []\n             Body = null\n    Session Attrs = {}\n\nHandler:\n             Type = com.study.springboot.controller.FirstController\n           Method = com.study.springboot.controller.FirstController#calcBMI(double, double)\n\nAsync:\n    Async started = false\n     Async result = null\n\nResolved Exception:\n             Type = org.springframework.web.method.annotation.MethodArgumentTypeMismatchException\n\nModelAndView:\n        View name = null\n             View = null\n            Model = null\n\nFlashMap:\n       Attributes = null\n\nMockHttpServletResponse:\n           Status = 400\n    Error message = null\n          Headers = []\n     Content type = null\n             Body = \n    Forwarded URL = null\n   Redirected URL = null\n          Cookies = []\n\nResponse content expected:&lt;값을 제대로 입력하세요&gt; but was:&lt;&gt;\n필요:값을 제대로 입력하세요\n실제   :\n\n\n \n\n체중을 비워놓았기 때문에\n\n“값을 제대로 입력하세요” 라는 String 리터럴이 필요하다는 로그가 발생한다.\n\n \n\n\n  사용자가 아무런 값을 입력하지 않았을 때의 예외상황에 대한 처리 로직 ✔\n  제어 계층(Control Layer)에 비즈니스 로직이 노출되어있음 - 책임 분리\n\n\n \n\n이제 두 번째 문제점을 해결하면서 테스트 코드가 통과되게끔 코드를 리팩토링 해보자.\n\n비즈니스 계층(Business Logic Layer)에 새로운 클래스를 작성할 것이다.\n\n새로운 비즈니스 로직을 작성하기 전에 테스트를 먼저 작성하자\n\n \n\n// file: 'BmiCalculatorServiceTest.class'\npublic class BmiCalculatorServiceTest extends SpringbootApplicationTests {\n    @Autowired\n    private BmiCalculatorService bmiService;\n\n    @Test\n    public void calcBmi() {\n        DecimalFormat df = new DecimalFormat(\"#.##\");\n        String result;\n        String height = \"180\";\n        String weight = \"72\";\n        if((height == null || \"\".equals(height)) || (weight == null || \"\".equals(weight))) {\n            result = \"값을 제대로 입력하세요\";\n        }\n        else {\n            double bmi = Double.parseDouble(weight) / Math.pow(Double.parseDouble(height) / 100, 2);\n            result = df.format(bmi);\n        }\n        assertEquals(result, bmiService.calcBmi(height, weight));\n    }\n}\n\n\n \n\nAbstractMockMvcTests를 상속받으면 테스트 코드가 지나치게 무거워 질 수 있다.\n\nMockMvc 테스트를 할 것이 아니기 때문이다.\n\nSpringbootApplicationTests를 상속받아 Bean만 호출할 수 있게끔 설정을 해준다.\n\n \n\n신장과 체중을 입력받아 BMI지수를 반환하되,\n\n신장과 체중 둘중 하나라도 입력되지 않을 경우\n\n“값을 제대로 입력하세요” 라는 String 리터럴을 반환하게 할 것이다.\n\n이대로 실행하면 컴파일 에러가 발생할 것이다.\n\n아직 처리로직이 없기 때문이다.\n\n우선 Stub을 작성해서 컴파일이 되게끔 만든다\n\n \n\n// file: 'BmiCalculatorService.class'\n@Service\npublic class BmiCalculatorService {\n    public String calcBmi(String height, String weight) {\n        return \"\";\n    }\n}\n\n\n \n\n이제 컴파일이 되며 테스트가 실행되고 실패할 것이다.\n\n \n\n// file: 'BmiCalculatorService.class'\n@Service\npublic class BmiCalculatorService {\n    public String calcBmi(String height, String weight) {\n        DecimalFormat df = new DecimalFormat(\"#.##\");\n        if ((height == null || \"\".equals(height)) || (weight == null || \"\".equals(weight))) {\n            return \"값을 제대로 입력하세요\";\n        }\n        else {\n            double bmi = Double.parseDouble(weight) / Math.pow(Double.parseDouble(height) / 100, 2);\n            return df.format(bmi);\n        }\n    }\n}\n\n\n \n\n테스트 코드의 명세대로 본격적인 비즈니스 로직을 작성하고\n\n(사실상 이전 컨트롤러에 작성했던 테스트 코드와 거의 동일하다)\n\n테스트를 실행해본다.\n\n\n\n \n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::                (v2.4.1)\n\n2021-01-15 12:21:53.081  INFO 15240 --- [    Test worker] c.s.s.service.BmiCalculatorServiceTest   : Starting BmiCalculatorServiceTest using Java 11.0.8 on Changhoon-Han with PID 15240 (started by Han in D:\\Project\\springboot)\n2021-01-15 12:21:53.083  INFO 15240 --- [    Test worker] c.s.s.service.BmiCalculatorServiceTest   : No active profile set, falling back to default profiles: default\n2021-01-15 12:21:54.145  INFO 15240 --- [    Test worker] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\n2021-01-15 12:21:54.467  INFO 15240 --- [    Test worker] c.s.s.service.BmiCalculatorServiceTest   : Started BmiCalculatorServiceTest in 1.569 seconds (JVM running for 3.229)\n대상 VM에서 연결 해제되었습니다, 주소: 'localhost:13529', 전송: '소켓'\n2021-01-15 12:21:54.738  INFO 15240 --- [extShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'\nBUILD SUCCESSFUL in 4s\n4 actionable tasks: 2 executed, 2 up-to-date\n오후 12:21:54: 작업 실행이 완료되었습니다 ':test --tests \"com.study.springboot.service.BmiCalculatorServiceTest\"'.\n\n\n \n\n모든 문제를 해결하였으니 FirstController를 수정한다.\n\n \n\n// file: 'FirstController.class'\n@RestController\npublic class FirstController {\n    private BmiCalculatorService calc;\n\n    public FirstController(BmiCalculator calc) {\n        this.calc = calc;\n    }\n\n    @GetMapping(\"/\")\n    public String init() {\n        return \"Hello! World!\";\n    }\n\n    @GetMapping(\"/get/bmi\")\n    public String calcBmi(@RequestParam(\"height\") String height, @RequestParam(\"weight\") String weight) {\n        return calc.calcBmi(height, weight);\n    }\n}\n\n\n \n\n수정된 FirstController의 코드\n\n \n\n// FirstControllerTests.class\npublic class FirstControllerTests extends AbstractMockMvcTests {\n    @Test\n    public void init() throws Exception {\n        mvc.perform(get(\"/\"))\n                .andExpect(status().isOk())\n                .andExpect(content().string(\"Hello! World!\"));\n    }\n\n    @Test\n    public void getBmi() throws Exception {\n        DecimalFormat df = new DecimalFormat(\"#.##\");\n        String result;\n        \n        //Test-Case\n        String height = \"180\";\n        String weight = \"\";\n        \n        if ((height == null || \"\".equals(height)) || (weight == null || \"\".equals(weight))) {\n            result = \"값을 제대로 입력하세요\";\n        }\n        else {\n            double bmi = Double.parseDouble(weight) / Math.pow(Double.parseDouble(height) / 100, 2);\n            result = df.format(bmi);\n        }\n        \n        mvc.perform(get(\"/get/bmi\")\n                .param(\"height\", height)\n                .param(\"weight\", weight))\n                .andExpect(content().string(result));\n    }\n}\n\n\n \n\nFirstControllerTests의 코드에서 위처럼 신장이나 체중값을 비우고\n\ngetBmi()를 실행한다.\n\n\n\n \n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::                (v2.4.1)\n\n2021-01-14 19:16:38.516  INFO 5768 --- [    Test worker] c.s.s.controller.FirstControllerTests    : Starting FirstControllerTests using Java 11.0.8 on Changhoon-Han with PID 5768 (started by Han in D:\\Project\\springboot)\n2021-01-14 19:16:38.519  INFO 5768 --- [    Test worker] c.s.s.controller.FirstControllerTests    : No active profile set, falling back to default profiles: default\n2021-01-14 19:16:39.523  INFO 5768 --- [    Test worker] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\n2021-01-14 19:16:39.808  INFO 5768 --- [    Test worker] o.s.b.t.m.w.SpringBootMockServletContext : Initializing Spring TestDispatcherServlet ''\n2021-01-14 19:16:39.808  INFO 5768 --- [    Test worker] o.s.t.web.servlet.TestDispatcherServlet  : Initializing Servlet ''\n2021-01-14 19:16:39.808  INFO 5768 --- [    Test worker] o.s.t.web.servlet.TestDispatcherServlet  : Completed initialization in 0 ms\n2021-01-14 19:16:39.826  INFO 5768 --- [    Test worker] c.s.s.controller.FirstControllerTests    : Started FirstControllerTests in 1.511 seconds (JVM running for 2.48)\n2021-01-14 19:16:40.167  INFO 5768 --- [extShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'\nBUILD SUCCESSFUL in 4s\n4 actionable tasks: 2 executed, 2 up-to-date\n오후 7:16:40: 작업 실행이 완료되었습니다 ':test --tests \"com.study.springboot.controller.FirstControllerTests.getBMI\"'.\n\n\n \n\nFirstControllerTests의 getBmi()가 실행되며\n\nBmiCalculatorService의 calcBmi(String height, String weight)를 호출했고\n\n이 코드는 이미 검증된 코드이기 때문에 별 문제없이 테스트 통과가 될 것이다.\n\n“값을 제대로 입력하세요” 라는 값이 나올 거라 예상했고,\n\n실제로도 같은 값이 나오고 있음을 확인할 수 있다.\n\n또한 계층을 나눠 책임을 분리시켰다.\n\n \n\n이제 사용자는 UI에 신장과 체중을 입력하면 자신의 BMI를 얻어낼 수 있을 것이고\n\n둘 중 하나라도 값을 입력하지 않으면 “값을 제대로 입력하세요”라는 메시지를 확인할 수 있게 되었다.\n\n그리고 사실, 이런 간단한 로직은 프론트단에서 Javascript로 처리하는 게 훨씬 편했을 것이다.\n\n \n\n아무튼 각설하고 결론을 내보자면,\n\n\n  사용자가 아무런 값을 입력하지 않았을 때의 예외상황에 대한 처리 로직 ✔\n  제어 계층(Control Layer)에 비즈니스 로직이 노출되어있음 - 책임 분리 ✔\n\n\n \n\n이렇게 개발을 할 경우 서버를 계속 재기동하지 않아도 되므로 코드의 결과 또한 빠르게 확인 해 볼 수 있다.\n\n또한 계속해서 테스트 케이스를 변경해가며 코드를 검증하기 때문에 더욱 탄탄한 코드를 만들 수 있다.\n\n또한, 테스트 코드를 만들면서 대부분의 구현또한 작성하기 때문에\n\n테스트 코드를 작동시킬 실제 구현코드를 만드는데 드는 시간은 사실상 거의 없다고 봐도 무방하다.\n\n결론적으로 개발하는데 드는 시간이 단축되면서도 더욱 탄탄한 코드를 작성할 수 있게 되는 것이다.\n\n \n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-01-14-tdd-4/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "JUnit 5 Annotations",
      "date": "2021-01-15 14:50:00 +0000",
      "description": "JUnit 5 어노테이션 정리 !\n",
      "content": "\n  📕 JUnit 5 Annotations\n\n\n \n\n\n  📜 참고 - JUnit 5 User Guide\n\n\n📕 JUnit 5 Annotations\n\n\n\n \n\n\n  \n    \n      어노테이션\n      설명\n    \n  \n  \n    \n      @Test\n      해당 메소드가 테스트 메소드임을 표시. JUnit 4의 @Test와 다르게 JUnit Jupiter를 기반으로 동작하기때문에 따로 속성(Attributes)을 표시하지 않음. 이 메소드는 오버라이딩 하지 않는 한 상속할 수 있다.\n    \n    \n      @ParameterizedTest\n      해당 메소드가 매개변수를 받는 테스트 메소드임을 나타냄. 오버라이딩 하지 않는 한 상속할 수 있음.\n    \n    \n      @RepeatedTest\n      해당 메소드가 반복 테스트를 위한 메소드임을 나타냄. 오버라이딩 하지 않는 한 상속할 수 있음\n    \n    \n      @TestFactory\n      메소드가 동적 테스트를 위한 테스트 팩토리임을 나타냄. 오버라이딩 하지 않는 한 상속할 수 있음\n    \n    \n      @TestTemplate\n      @Test의 묶음임을 표시한다. 이는 반드시 private이나 static이 아니어야 하며 void를 반환해야 한다. 오버라이딩 하지 않는 한 상속할 수 있다.\n    \n    \n      @TestMethodOrder\n      테스트 메소드 실행 순서를 설정한다. JUnit 4의 @FixMethodOrder와 유사하다. @TestMethodOrder는 상속할 수 있다.\n    \n    \n      @TestInstance\n      테스트 메소드의 Life Cycle을 설정하는 데 사용한다. @TestInstance는 상속할 수 있다.\n    \n    \n      @DisplayName\n      테스트 클래스나 테스트 메소드를 사용자가 지정한 이름으로 표시할 수 있다. @DisplayName은 상속할 수 없다.\n    \n    \n      @DisplayNameGeneration\n      @DisplayName 생성기를 선언한다. @DisplayNameGeneration은 상속할 수 있다.\n    \n    \n      @BeforeEach\n      @BeforeEach가 선언된 테스트 메소드는 각 @Test, @RepeatedTest, @ParameterizedTest, @TestFactory 가 선언된 테스트 메소드가 실행되기 전에 먼저 실행된다. JUnit 4의 @Before와 유사하다. 이 메소드는 오버라이딩 하지 않는 한 상속할 수 있다.\n    \n    \n      @AfterEach\n      @AfterEach가 선언된 테스트 메소드는 각 @Test, @RepeatedTest, @ParameterizedTest, @TestFactory 가 선언된 테스트 메소드가 실행되고 난 후에 실행된다. JUnit 4의 @After와 유사하다. 이 메소드는 오버라이딩 하지 않는 한 상속할 수 있다\n    \n    \n      @BeforeAll\n      @BeforeAll이 선언된 테스트 메소드는 모든 @Test, @RepeatedTest, @ParameterizedTest, @TestFactory가 선언된 메소드들이 실행되기 전에 최초에 한번 실행된다. JUnit 4의 @BeforeClass와 유사하며, 이 메소드는 반드시 static으로 선언되어야 한다. 이 메소드는 숨겨지거나 재정의되지 않는 한 반드시 상속된다.\n    \n    \n      @AfterAll\n      @AfterAll이 선언된 테스트 메소드는 모든 @Test, @RepeatedTest, @ParameterizedTest, @TestFactory가 선언된 메소드들이 끝난 후에 한번 실행된다. JUnit 4의 @AfterClass와 유사하며, 이 메소드는 반드시 static으로 선언되어야 한다. 이 메소드는 숨겨지거나 재정의되지 않는 한 반드시 상속된다.\n    \n    \n      @Nested\n      @Nested가 선언된 클래스는 중첩된 비 정적(non-static) 테스트 클래스임을 나타낸다. 테스트 클래스 안에서 내부 클래스를 정의해 테스트를 계층화할 수 있다. 또한 내부 클래스를 사용하기 때문에 부모 클래스의 멤버에 접근할 수 있다. @BeforeAll 또는 @AfterAll과 함께 사용할 수 없으며, 상속할 수 없다.\n    \n    \n      @Tag\n      테스트 필터링을 위한 태그를 선언하는 데 사용한다. JUnit 4의 @Categories와 유사하다. 클래스 수준에서는 상속할 수 있으나, 메소드 수준에서는 상속할 수 없다.\n    \n    \n      @Disabled\n      테스트 클래스나 테스트 메소드를 비활성화하는 데 사용한다. JUnit 4의 @Ignore와 유사하다. @Disabled은 상속할 수 없다.\n    \n    \n      @Timeout\n      @Test, @TestFactory, @TestTemplate의 실행시간이 주어진 시간을 초과하는 경우의 Life Cycle을 관리할 수 있게 설정한다. @Timeout은 상속할 수 있다.\n    \n    \n      @ExtendWith\n      확장을 선언하는데 사용한다. 다른 설정 파일의 설정을 가져올 수 있게 해준다. JUnit 4의 @RunWith와 유사하다.\n    \n    \n      @RegisterExtension\n      Used to register extensions programmatically via fields. Such fields are inherited unless they are shadowed. (뭘 말하고 싶은지 모르겠음)\n    \n    \n      @TempDir\n      Used to supply a temporary directory via field injection or parameter injection in a lifecycle method or test method; located in the org.junit.jupiter.api.io package. (뭘 말하고 싶은지 모르겠음)\n    \n  \n\n\n \n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-01-15-junit5/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "JUnit 5 Life Cycle",
      "date": "2021-01-15 16:14:00 +0000",
      "description": "JUnit 5 생명주기에 대한 이해\n",
      "content": "\n  📕 JUnit 5 Life Cycle\n\n\n \n\n\n  📜 참고 - JUnit 5 User Guide\n\n\n \n\n📕 JUnit 5 Life Cycle\n\nJUnit은 객체의 생명주기(Life Cycle) 관리를 지원한다.\n\n이 기능을 이용하면 각 테스트 케이스마다 새로운 객체를 생성해주므로\n\n각 테스트 케이스의 독립성을 확보 할 수 있다.\n\n \n\n// file: 'WhatJUnit.class'\n@DisplayName(\"JUnit은 어떻게 돌아갈까?\")\npublic class WhatJUnit extends SpringbootApplicationTests {\n    @BeforeAll\n    @DisplayName(\"BeforeAll Method\")\n    public static void beforeAll() {\n        System.out.println(\"BeforeAll.............!\");\n    }\n\n    @BeforeEach\n    @DisplayName(\"BeforeEach Method\")\n    public void init() {\n        System.out.println(\"init...........!\");\n    }\n\n    @Test\n    @DisplayName(\"첫번째_테스트 Method\")\n    public void 첫번째_테스트() {\n        System.out.println(\"test1 run..........!\");\n    }\n\n    @Test\n    @DisplayName(\"두번째_테스트 Method\")\n    public void 두번째_테스트() {\n        System.out.println(\"test2 run..........!\");\n    }\n\n    @AfterEach\n    @DisplayName(\"AfterEach Method\")\n    public void exit() {\n        System.out.println(\"exit...........!\");\n    }\n\n    @AfterAll\n    @DisplayName(\"AfterAll Method\")\n    public static void afterAll() {\n        System.out.println(\"AfterAll.............!\");\n    }\n}\n\n\n \n\n@DisplayName은 각 요소에 일종의 이름표를 붙여주는 기능을 한다.\n\n@BeforeAll은 모든 테스트가 시작하기전에 딱 한 번만 실행되는 메소드다.\n\n이곳에서 초기화 같은 작업을 해주면 좋다.\n\n여기서 주의해야 할 점은 @BeforeAll은 반드시 static을 명시해줘야한다.\n\n왜냐하면 JUnit은 각 테스트 케이스마다 새로운 객체를 생성해서\n\n각 케이스간의 독립성을 얻기 때문에 테스트 케이스간 정보의 공유가 안된다.\n\n실제로 JUnit5 docs에는 이 애노테이션은 반드시 static으로 사용하라고 되어있다.\n\n \n\n@AfterAll은 반대로 모든 테스트가 종료되면 마지막으로 딱 한번 실행되는 메소드다.\n\n마찬가지로 모든 자원의 반납 같은 기능을 작성하면 좋겠다.\n\n이 역시 마찬가지로 static으로 선언해야만 한다.\n\n@BeforeEach는 JUnit4의 @Before와 같은 기능을 한다.\n\n테스트 케이스가 실행되기 전에 실행될 코드를 작성하면 된다.\n\n각 테스트 케이스가 실행되기직전에 한번 실행된다.\n\n \n\n@AfterEach는 JUnit4의 @After와 같은 기능을 한다\n\n테스트 케이스가 끝난 후 실행될 코드를 작성하면 된다.\n\n각 테스트케이스가 실행된 후에 한번 실행된다.\n\n \n\n@Test는 테스트의 단위를 뜻한다.\n\n \n\n우선 실행 순서를 보자면\n\n \n\n\n  @BeforeAll 실행\n  @BeforeEach 실행\n  첫번째 @Test 실행\n  @AfterEach 실행\n  모든 @Test가 완료될 때까지 2~4를 반복\n  @AfterAll 실행\n  테스트 종료\n\n\n \n\n그러면 예상되는 출력값은\n\n \n\n\n  BeforeAll………….!\ninit………..!\ntest1 run……….!\nexit………..!\ninit………..!\ntest2 run……….!\nexit………..!\nAfterAll………….!\n\n\n \n\n이다.\n\n테스트를 진행해보자.\n\n \n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::                (v2.4.1)\nBeforeAll.............!\n2021-01-15 16:05:18.561  INFO 4104 --- [    Test worker] com.springboot.service.WhatJUnit         : Starting WhatJUnit using Java 11.0.8 on Changhoon-Han with PID 4104 (started by Han in D:\\Project\\springboot)\n2021-01-15 16:05:18.563  INFO 4104 --- [    Test worker] com.springboot.service.WhatJUnit         : No active profile set, falling back to default profiles: default\n2021-01-15 16:05:19.527  INFO 4104 --- [    Test worker] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\n2021-01-15 16:05:19.846  INFO 4104 --- [    Test worker] com.springboot.service.WhatJUnit         : Started WhatJUnit in 1.453 seconds (JVM running for 2.333)\ninit...........!\ntest1 run..........!\nexit...........!\ninit...........!\ntest2 run..........!\nexit...........!\nAfterAll.............!\n2021-01-15 16:05:20.169  INFO 4104 --- [extShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'\nBUILD SUCCESSFUL in 3s\n4 actionable tasks: 2 executed, 2 up-to-date\n오후 4:05:20: 작업 실행이 완료되었습니다 ':test --tests \"com.springboot.service.WhatJUnit\"'.\n\n\n \n\n예상과 같은 결과값이 나온다.\n\n이번엔 @DisplayName이 어떻게 동작하는지 확인해보자.\n\n \n\n @Test\n @DisplayName(\"두번째_테스트 Method\")\n public void 두번째_테스트() {\n   assertEquals(1, 0);\n   System.out.println(\"test2 run..........!\");\n }\n\n\n \n\n두번째\\_테스트() 가 실패하게끔 코드를 작성한다.\n\n \n\n2021-01-15 16:11:36.472  INFO 9700 --- [extShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'\nJUnit은 어떻게 돌아갈까? &gt; 두번째_테스트 Method FAILED\n    org.opentest4j.AssertionFailedError at WhatJUnit.java:32\n2 tests completed, 1 failed\n&gt; Task :test FAILED\n\n\n \n\n달아준 이름표대로 콘솔에 로그가 출력된다.\n\n \n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-01-15-junit5-life-cycle/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "진도 정리",
      "date": "2021-01-15 18:34:00 +0000",
      "description": "개발일기\n",
      "content": "\n  📕 보고 있는 도서\n  📕 봐야할 도서\n  📕 한번이상 읽은 도서\n  📕 계획에 없는 도서\n\n\n \n\n개발 독학 중간 정리를 해본다.\n\n \n\n\n\n \n\n📕 보고 있는 도서\n\n\n\n\n  \n    \n      도서명\n      저자\n    \n  \n  \n    \n      스프링 부트와 AWS로 혼자 구현하는 웹 서비스\n      이동욱\n    \n    \n      Refactoring\n      마틴 파울러\n    \n    \n      Spring Security 3/e\n      믹 넛슨, 로버트 윈치, 피터 뮬라리엔\n    \n    \n      스프링5 레시피 4판\n      마틴 데니엄, 다니엘 루비오, 조시 롱\n    \n  \n\n\n \n\n📕 봐야할 도서\n\n\n\n\n  \n    \n      도서명\n      저자\n    \n  \n  \n    \n      자바 ORM 표준 JPA 프로그래밍\n      김영한\n    \n    \n      이것이 SQL Server다\n      우재남\n    \n  \n\n\n \n\n📕 한번이상 읽은 도서\n\n\n\n\n  \n    \n      도서명\n      저자\n    \n  \n  \n    \n      누구나 쉽게 스칼라+플레이\n      고락윤\n    \n    \n      코드로 배우는 스프링 웹 프로젝트\n      구멍가게 코딩단\n    \n    \n      초보 웹 개발자를 위한 스프링5 프로그래밍 입문\n      최범균\n    \n    \n      토비의 스프링 3.1\n      이일민\n    \n    \n      Do it! 자료구조와 함께 배우는 알고리즘 입문 자바 편\n      시바타 보요\n    \n    \n      프로젝트로 배우는 자바 웹 프로그래밍\n      황희정\n    \n    \n      이것이 자바다\n      신용권\n    \n    \n      개발자가 반드시 정복해야 할 객체 지향과 디자인 패턴\n      최범균\n    \n    \n      Do it! HTML5+CSS3 웹 표준의 정석\n      고경희\n    \n    \n      Head First Design Patterns: 스토리가 있는 패턴 학습법\n      GoF\n    \n    \n      최범균의 JSP 2.3 웹 프로그래밍\n      최범균\n    \n    \n      Test-Driven Development:By Example)\n      켄트 백\n    \n  \n\n\n📕 계획에 없는 도서\n\n\n\n\n  \n    \n      도서명\t저자\n       \n    \n  \n  \n    \n      뇌를 자극하는 C++ 프로그래밍\n      이현창\n    \n    \n      뇌를 자극하는 알고리즘\n      박상현\n    \n  \n\n\n \n\n여태까지 뭘 했고, 앞으로 뭘 더 해야 할지 정리하는 시간을 가졌는데\n\n2020년 7월부터 많이도 봤다.\n\n그리고 앞으로도 공부해야 할 게 산더미라는 생각이 더 든다.\n\n가지고 있는 책은 다 볼 계획인데,\n\nC 관련 책 두 개는 아마 몇 년 뒤에나 보게 될 것 같다.\n\n혹은 아예 볼 일이 없던가…\n\n아직은 자바에 집중해야겠다는 생각이 더 확고하게 든다.\n\n \n\n토비의 스프링 / 리팩토링 / TDD / Head First Design Patterns\n\n위 네 가지 책은 두고두고 봐야 할 명저서라는 생각이 든다.\n\n정말 바이블이 아닐까?\n\n \n\n중복되는 책을 여러권 읽으면서 느끼는건데,\n\n예를 들어 Spring에 관한 책을 한권 떼고 다른 Spring 책을 읽고있노라면\n\n각 책의 저자마다 프로그래밍에 대해 가지고있는 시각이 조금씩 다름을 느낀다.\n\n그리고 가볍게 고개를 끄덕이면서 읽게되는 내용 또한 많고 읽는 속도도 점점 빨라짐을 느낀다.\n\n \n\n처음 한권을 읽을때가 가장 힘든 것 같다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-01-15-diary-8/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "Java와 JVM(Java Virtual  Machine)",
      "date": "2021-01-16 20:03:00 +0000",
      "description": "Java와 JVM(Java Virtual  Machine)에 대한 정리\n",
      "content": "\n  📕 Java\n  📕 에디션\n  📕 버전\n  📕 자바의 장점\n  📕 자바의 단점\n  📕 JVM(Java Virtual Machine)\n  📕 Java Virtual Machine Architecture    \n      📜 Class Loader Subsystem        \n          1. 적재(Loading)            \n              Application ClassLoader\n              Extension ClassLoader\n              Bootstrap ClassLoader\n            \n          \n          2. 연결(Link)\n          3. 초기화(Initialize)\n        \n      \n      📜 Runtime Data Area        \n          1. 메서드 영역(Method Area)\n          2. 힙 영역(Heap Area)\n          3. 스택 영역(Stack Area)\n          4. 프로그램 카운터(Program Count Register)\n          5. Native Method Stack\n        \n      \n      📜 실행 엔진(Excution Engine)        \n          1. 인터프리터(Interpreter)\n          2. Just In Time Compiler(JIT)\n        \n      \n    \n  \n\n\n \n\n📕 Java\n\n \n\n최초 고안자는 제임스 아서 고슬링(James Arthur Gosling)이다.\n\n썬 마이크로시스템즈에서 개발되었고,\n\n현재는 개발사가 Oracle에 인수되어 Oracle의 소유가 된 언어이다.\n\n이 언어로 작성된 프로그램은 정말 너무 많다.\n\n \n\n당장 생각나는 것만 해도 우리가 개발할 때 쓰는 인텔리제이가 있고,\n\n마인크래프트도 바로 이 자바로 작성되었다.\n\n그리고 구글이 인텔리제이를 활용해 안드로이드 스튜디오를 만들었다.\n\n자바의 사상은 한번 작성되면, 어디서든 동작한다. (Write once, Run anywhere)이다.\n\n이 사상에 의해 JVM(Java Virtual Machine)이라는 굉장한 아키텍처가 등장했다고 봐도 무방할 것이다.\n\n자바의 가장 큰 특징은 플랫폼에 독립적이라는 것이다.\n\nJVM기반으로 동작하기 때문에 해당 플랫폼에 JVM만 설치되어 있다면\n\n그 어떤 플랫폼에서 작성되었던 언어라도 똑같이 실행시킬 수가 있다.\n\n그리고 또 다른 특징으로는 자바는 객체지향 프로그래밍(Object-oriented programming)에 최적화된 언어이다.\n\n그래서 원활한 협업과 유지보수의 용이성을 위해 엔터프라이즈급 환경에서 많이 사용된다.\n\n \n\n📕 에디션\n\n\n\n\n  Java SE (Java Standard Edition / J2SE)\n    \n      우리가 가장 많이 사용하는 표준 에디션이다.\n    \n  \n  Jakarta EE (Java Enterprise Edition / J2EE)\n    \n      기업용 에디션이다.\n      DBCP, Message System, Load Balancing 등의 화려한 기능을 탑재하고 있다.\n    \n  \n  Java ME (Java Micro / J2ME)\n    \n      임베디드 시스템 환경에 특화된 에디션이다.\n    \n  \n  JavaFX\n    \n      흔히 Swing으로 알려진 Java GUI 라이브러리가 진화한 것이 이 녀석이다.\n    \n  \n\n\n \n\n📕 버전\n\n\n\n자잘한 것 제외하고 굵직하거나 자주 사용되는 버전만 부분만 정리해보자면\n\n\n  JDK 1.0a2\n    \n      1995.05.23 자바가 공식적으로 태어난 날이자 버전\n    \n  \n  J2SE 1.4\n    \n      단정문, 정규표현식, IPv6 지원, Non-Blocking IO, XML 지원, Java Web Start 등이 추가됨\n    \n  \n  Java SE 6 (1.6)\n    \n      이때부터 버전 표기가 J2SE(Java 2 Standard Edition)에서  Java SE로 바뀌었다\n      스크립트 언어 지원, JDBC 4.0, 자바 컴파일러 API 등이 추가되었다\n      스크립트 언어 지원과 함께 Rhino JavaScript Engine이 탑재되기 시작했다\n    \n  \n  Java SE 8 (1.8 LTS)\n    \n      람다 표현식, Rhino -&gt; Nashorn Engine으로 변경, Annotation on java Types, 정수형 타입의 음수 계산 지원\n      새로운 날짜와 시간 API(LocalDate 계열), Stream API 등 추가\n      공식적으로 32비트를 지원하는 마지막 Java 버전이다\n      2021.01 기준 | 우리나라에서 가장 많이 사용하는 버전\n    \n  \n  Java SE 11 (11 LTS)\n    \n      9와 10 버전에서 정말 많은 기능이 추가되었으나 크리티컬 한 이슈가 많았다. 이를 대부분 해결한 버전\n      우리나라는 자바 8에서 11로 넘어오는 추세이다\n      JShell 추가, 선행 컴파일 베타 버전 추가, 구조적 불변 컬렉션 추가, 통합 로깅 지원, HTTP/2 지원\n      private interface method 가능, HTML5 Javadoc 추가, UTF-8 지원\n      Deprecated API 삭제, 64비트 지원, var를 이용한 타입 추론 지원, 병렬 처리 GC, 개별 스레드\n      JDK Repository 통합, JVM Heap memory 공유, JIT 컴파일러 추가\n      2021년 1월부터 Oracle JDK는 유료버전으로 전환, OpenJDK기반의 서드파티는 개인/기업 무료\n      OpenJDK 기반의 서드파티로 Azul Systems에서 개발한 Zulu JDK가 있다\n    \n  \n\n\n \n\n📕 자바의 장점\n\n\n\n\n  레퍼런스, 특히 한글 레퍼런스가 풍부하다\n    \n      API를 참고하되, 막히는 부분이 있을 시 구글링 하면 대부분의 문제와 해결방법들이 나온다.\n      그만큼 많은 개발자들이 자바로 개발을 했고 노하우가 축적되어있는 상태이다\n    \n  \n  생산성 대비 안정성이 좋다\n    \n      타 언어들에 비해 생산성이 좋다고 보기는 힘들겠으나 깐깐한 예외처리 덕분에 안정성이 매우 뛰어나다\n      원초적인 객체지향 프로그래밍 언어 중 한 개이기 때문에 엔터프라이즈급 환경에서 협업하기 매우 좋은 언어\n    \n  \n  플랫폼에 독립적이다\n    \n      이는 자바뿐만 아니라 JVM기반의 모든 언어가 갖는 특징이기도 하다\n      JVM기반으로 작동하기 때문에 플랫폼(OS와 같은)에 완벽하게 독립적인 코드 생산이 가능하다\n      아마 가장 큰 장점이 아닐까 싶음\n    \n  \n  가비지 컬렉션\n    \n      가비지 컬렉션(GC) - 메모리(RAM) 관리를 자동으로 해준다\n    \n  \n\n\n \n\n📕 자바의 단점\n\n\n\n\n  속도가 느리다\n    \n      첫 실행 시 JVM이 완벽하게 로딩되어야 하기 때문에 오버헤드가 발생하는 부분이 있다\n        \n          하드웨어의 엄청난 발달로 현재는 거의 무의미함\n        \n      \n    \n  \n  코드가 장황하다\n    \n      가독성이 나쁜 편은 아닌데 좋다고 보기도 어렵다\n      코드가 정말 장황하다\n        \n          예를 들자면 자바로 30줄 작성해서 만들 코드면 스칼라는 3줄 정도만에 완성할 수도 있다\n        \n      \n    \n  \n  깐깐한 예외 처리\n    \n      더럽고 지저분한 try-catch 지옥\n      예외 처리를 직접 해주지 않으면 컴파일 에러가 떠버린다 (장점일수도 있음)\n    \n  \n\n\n \n\n📕 JVM(Java Virtual Machine)\n\n\n\n직역하자면 자바 가상 머신이다.\n\n자바로 작성된 코드는 .java의 확장자를 가지며 이 소스 파일은 자바 컴파일러에 의해\n\n바이트 코드(byte code)로 컴파일된다.\n\n그리고 이 바이트 코드는 .class 확장자를 갖고 클래스 파일이라고 부른다.\n\n이 클래스 파일과 해당 플랫폼에 종속된 JVM만 설치되어 있다면 자바로 작성한 프로그램은\n\n그 어떤 환경에서라도 동작할 수 있다.\n\nJDK(Java Development Kit)를 설치하면 JDK안에 JRE(Java Runtime Environment)가 포함되어있으며,\n\n이 JRE안에 JVM이 포함되어 설치된다.\n\n이름을 해석하면 JDK는 자바 개발을 위한 킷, JRE는 자바 실행 환경이다.\n\n그래서 자바로 개발을 하려면 JDK를 필수로 설치해야 하며,\n\n자바로 작성된 프로그램만 실행시키고 싶다면 JRE만 따로 설치하면 된다.\n\n\n\n \n\n📕 Java Virtual Machine Architecture\n\n\n\n\n\n \n\n클래스 파일을 가지고 JVM이 동작하는 구조를 알아보자.\n\n먼저 그림을 보자.\n\n중요한 포인트는 JVM은 우리가 사용하는 컴퓨터에서 메모리(RAM)를 사용할 수 있게끔\n\n일정 메모리를 할당받은 프로세스라는 것이다.\n\n여기서 프로세스에 대한 개념이 약간 필요한데, 우리가 사용하는 모든 프로그램은\n\n컴퓨터의 메모리에서 일정한 공간을 할당받아야만 동작할 수 있다.\n\n그리고 클래스 파일에 메모리를 할당시켜주는 것이 JVM이 하는 가장 중요한 일이라고 할 수 있겠다.\n\n한마디로 클래스 파일이 진짜 기계어로 번역되어 실행되기 전에\n\n임시로 적재되고 제어되는 공간이 JVM이다.\n\n그래서 이름이 자바가상머신(Java Virtual Machine)인 것이다.\n\n \n\n📜 Class Loader Subsystem\n\n\n\n자바 컴파일러에 의해 바이트 코드로 변환된 자바 소스파일(클래스 파일)을 실행하려면 JVM에 적재해줘야 한다.\n\n자바 컴파일러에 의해 컴파일 된 클래스 파일이 처음 실행될 때 적재, 연결, 초기화 과정을 거친다.\n\n이 역할을 Class Loader가 담당한다.\n\n \n\n1. 적재(Loading)\n\n\n\n\n\n \n\nApplication ClassLoader\n\n\n\n시스템의 클래스 파일 경로(class path)에 위치한 모든 클래스 파일을 JVM의 메모리에 적재한다.\n\n \n\nExtension ClassLoader\n\n\n\njre/lib/ext 경로에 위치한 확장(Extension) 라이브러리를 이 녀석이 적재한다.\n\nWAS가 구동될 때 위의 디렉터리에서 클래스 파일들을 가져오는 것이다.\n\n대표적으로 HttpServlet.class가 있다.\n\n \n\nBootstrap ClassLoader\n\n\n\n여기서 Bootstrap은 CSS 라이브러리를 말하는 게 아니다.\n\n클래스 로더는 java.lang.ClassLoader에 의해 실행된다.\n\n그렇다면 java.lang.ClassLoader는 대체 누가 실행시킬까?\n\n바로 이 Bootstrap ClassLoader가 실행한다.\n\n \n\n\n\n \n\nBoot-Strap이란 말 그대로 부츠 뒤에 달린 고리를 뜻하는데,\n\n신발 뒤축에 달린 고리를 집어 들어 자신을 공중에 띄워야 하는 상황을 일컫는다.\n\n전산 쪽에선 이를 자기 참조(Selft-Referential)라고 부른다.\n\n \n\n운영체제 과목에서는 이런 내용이 나온다.\n\n컴퓨터 전원버튼을 누르면 컴퓨터에 전원이 들어가면서 ROM(비휘발성)으로 구성된 바이오스가 작동한다.\n\n바이오스는 모든 하드웨어 한번를 점검하고 부트스트랩 로더를 실행시키며 제어권을 넘겨준다.\n\n부트스트랩 로더는 하드웨어를 초기화하고 초기화된 하드웨어에 운영체제 커널을 올려준다.\n\n그리고 운영체제 커널로 제어권을 넘긴다.\n\n \n\n부트스트랩 로더에 의해 실행된 운영체제는 컴퓨터를 제어하며 스케쥴링을 시작한다.\n\n(이 부트스트랩 로더는 C 계열의 Low Level Native Language로 작성되어 있다.)\n\n컴퓨터가 켜져 있는 상태(Runtime)에서 JVM이 실행된다면, 운영체제는 JVM의 부트스트랩 클래스 로더를 실행시켜준다.\n\n그리고 부트스트랩 클래스 로더는 자식 클래스들을 JVM에 적재시키는 것이다.\n\n그래서 부트스트랩이란 대부분의 시스템에서 자기 자신을 최초에 실행해주는 행위를 의미한다.\n\n우선 바로 확인할 수 있는건 WAS 초기화 시 콘솔에 로그가 쭉 뜨는걸 볼 수 있는데\n\n맨 윗줄을 확인해보면 부트스트랩 어쩌고 하는 로그를 확인 해 볼 수 있을것이다.\n\n \n\n\n\n \n\n2. 연결(Link)\n\n\n\n클래스 로더에 의해 JVM 메모리에 적재된 클래스 파일들을 연결시키는 부분이다.\n\n이건 확실히는 모르겠고 추상적으로 생각하기로는 아마 상속관계 등을 따져 연결하고 검증한다는 이야기로 해석된다.\n\n초기화를 하기 전에 클래스 파일들이 각자의 코드에 설정된 의존관계대로 모두 연결되고\n\n사용할 수 있는지 검증하는 과정인 듯하다\n\n \n\n3. 초기화(Initialize)\n\n\n\n모든 클래스 파일의 생성자 같은 초기화 로직이 실행되고 메모리를 할당받는다.\n\n또한 static(정적)으로 선언된 모든 변수들을 초기화하고 메모리를 할당한다.\n\n이 정적멤버들은 힙이아닌 메서드영역에 위치한다.\n\n \n\n📜 Runtime Data Area\n\n\n\nJVM이 실행되면서 운영체제로부터 할당받은 메모리영역이다.\n\nJVM의 클래스 로더가 클래스 파일을 적재 한 영역이 바로 이곳이다.\n\n그러니까 컴퓨터의 메모리에서 일부를 JVM이 점유하고 있고,\n\n이 JVM의 내부에 또 실행 데이터 영역(Runtime Data Area)이라는  메모리 영역이 있는 것이다.\n\n결과론적으로 이야기하자면 결국 모두 다 컴퓨터의 메모리를 사용하는 것이라고 볼 수 있겠다.\n\n \n\n1. 메서드 영역(Method Area)\n\n\n\nJVM내의 모든 스레드가 공유하는 자원이다.\n\n그래서 이 메서드 영역은 JVM마다 하나만 존재하는 자원이다.\n\n컴파일된 코드의 정보를 클래스단위로 저장한다.\n\n그리고 static으로 선언된 정적 멤버들은 미리 Interpret 되어 이 영역에 할당된다.\n\n \n\n2. 힙 영역(Heap Area)\n\n\n\n힙 영역 또한 메서드 영역과 마찬가지로 모든 스레드가 공유하는 자원이다.\n\n이 역시 각 JVM당 하나만 존재한다.\n\n이곳엔 메서드 영역에 위치하는 인스턴스 파일의 모든 구성 코드에\n\n실제로 메모리를 할당하여 실제로 실행되고 있는 인스턴스가 위치하는 공간이다.\n\n여기서 인스턴스란 것은 new(생성자)를 통해\n\n메서드 영역에 올려져 있는 클래스 파일을 Interpret 하여\n\n기계어로 번역된 실제 실행 되는 파일을 말한다.\n\n그래서 이 메서드 영역을 이 힙 영역의 논리적 부분(Logical Part)라고도 부른다.\n\n힙 영역은 물리적인 부분(Physical Part)이라고 볼 수 있겠다.\n\n또한 힙 영역에 위치하게 된 인스턴스는 스택 영역에서 참조가 되지 않을 때에서야\n\n비로소 가비지 컬렉터(Garbage Collector)에 의해 제거된다.\n\n \n\n3. 스택 영역(Stack Area)\n\n\n\n스택 영역은 각 스레드마다 독자적으로 하나씩 존재한다.\n\n그러니까 공유되는 자원이 아니다.\n\n스택과 힙이 다른 점은 힙에는 객체 단위의 인스턴스가 적재되는 것이고,\n\n스택에는 힙에 위치한 이 인스턴스를 참조하는 요소들이 적재된다는 것이다.\n\n이 스택은 이름 그대로 스택 구조로 되어있어 메서드가 실행되면 push\n\n끝나면 pop 되는 식으로 동작한다.\n\n \n\n4. 프로그램 카운터(Program Count Register)\n\n\n\n운영체제 과목에서 나오는 개념인데, 각 스레드에 한 개씩 존재하며 이들은 Runtime 중에 자신이 속한 스레드의\n\n현재 작업을 저장하고 다음에 해야 할 일을 가리키는 역할을 한다.\n\n5. Native Method Stack\n\n\n\n자바 스레드와 네이티브 코드(C 같은)로 작성된 코드를 연결해주는 역할을 한다.\n\n \n\n📜 실행 엔진(Excution Engine)\n\n\n\n자바 컴파일러가 변환한 바이트 코드가 실제로 실행되는 공간이다.\n\nRuntime Data Area에 적재될 기계어들을 이곳에서 Interpret 한다.\n\n1. 인터프리터(Interpreter)\n\n\n\n인터프리터는 다들 아는 대로 한 줄 읽고 해석하기를 반복하는 프로그램이다.\n\n여기서는 바이트 코드를 한 줄 읽어 기계어로 반환하는 식으로 동작할 것이다.\n\n2. Just In Time Compiler(JIT)\n\n\n\n자바는 자바 코드를 바이트코드로 한번 컴파일한 후 이 바이트 코드를 또다시 기계어로 인터프리팅한다.\n\n이를 JIT라고 부르며 이 방식은 정적 번역(C와 같은 컴파일), 동적 번역(Python과 같은 인터프리팅)을 모두 사용하는 방식을 말한다.\n\n그래서 자바는 타 언어에 비해 컴파일을 두 번 하므로 (자바 코드 -&gt; 바이트코드 -&gt; 기계어) 타 언어들보다 속도가 느릴 수밖에 없다.\n\n대신 플랫폼에 독립적이라는 트레이드 오프(trade-off)가 있다.\n\n \n\n자바는 이 느린 속도를 해결하기 위해 CPU의 캐시 메모리를 사용하는데\n\n바이트 코드를 한 줄 읽고 기계어로 해석한 후 이를 캐시메모리에 저장해두는 것이다.\n\n그리고 다음에 캐시된 기계어를 재사용하는 식으로 동작한다.\n\n \n\n다만 캐시는 굉장히 비싼 자원이다.\n\n클래스 파일이 위의 모든 과정을 거쳐 기계어로 번역되고 메모리를 할당받으면\n\nOS가 이를 인식하고 CPU가 연산하여 처리해준다.\n\n그리고 우리는 클래스 파일의 처리 결과를 볼 수 있게 된다.\n\n \n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2021-01-16-java-jvm/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "DTO와 VO의 차이",
      "date": "2021-01-17 14:45:00 +0000",
      "description": "초보자들이 가장 많이 실수하는 DTO(Data Transfer Object)와 VO(Value Object)에 대한 정리\n",
      "content": "\n  DTO (Data Transfer Object)\n  VO(Value Object)\n  📜 equals()\n  📜 hashCode()\n\n\n~DTO, ~VO 라는 클래스들을 꽤 보았을 법 하다. 무슨 차이인지 알아보자.\n\nDTO (Data Transfer Object)\n\n\n\n직역하자면 데이터를 옮기기 위한 객체라는 뜻이다.\n\n이 DTO는 흔히 우리가 자바빈즈(Java Beans)라고 부르는 형태와 똑같다고 볼 수 있다.\n\npublic class Money {\n    private String currency;\n    private int amount;\n    \n    public Money(String currency, int amount){\n        this.currency = currency;\n        this.amount = amount;\n    }\n\n    public String getCurrency() {\n        return currency;\n    }\n\n    public void setCurrency(String currency) {\n        this.currency = currency;\n    }\n\n    public int getAmount() {\n        return amount;\n    }\n\n    public void setAmount(int amount) {\n        this.amount = amount;\n    }\n}\n\n\nMoney라는 데이터를 주고받기 위해 인스턴스 변수 통화(currency)와 값(amount)을 정의했고\n\n인스턴스 변수들을 초기화시켜줄 수 있는 생성자(constructor)와\n\n이에 접근하기 위한 수정자(setter), 접근자(getter)를 정의한다.\n\n그러면 이 객체를 매개로 각 계층 간에 데이터를 주고받을 수 있을 것이다.\n\n정말 단순하게 위의 형태를 갖는 것은 DTO라고 봐도 무방하다.\n\n주로 쿼리의 결과를 바인딩하거나, 계층간 데이터 전달을 위해 사용된다.\n\nVO(Value Object)\n\n\n\n직역하면 값 객체라는 뜻인데 데이터 전달에 목적을 두는 DTO와 다르게 VO는 객체 자체를 어떠한 값(Value)으로서 사용하는데 목적을 두기 때문에 DTO와 차별화되는 점이 몇 가지 있다.\n\n하나는 equals()와 hashCode()를 반드시 재정의(Override)해서 각 객체의 동등성을 판별할 수 있어야 한다는 것이고,\n\n다른 하나는 객체의 인스턴스 변수가 생성자에 의해 한번 초기화되면 이 값이 불변(Immutable)해야 한다는 것이다.\n\n\n  💡 프로그래밍에서의 동등성? 동일성?\n\n  \n    동등성 - 두 개체의 가치가 동일함을 의미. 즉, 두 개체가 참조하는 메모리 주소는 다를 수 있다.\n      \n        10,000원짜리 지폐 두장은 서로 독립적인 별개의 개체이지만, 동일한 가치를 갖는다.\n      \n    \n    동일성 - 두 개체가 참조하는 메모리 주소가 동일함을 의미.\n      \n        이에 대해 궁금하다면 얕은복사, 깊은복사를 공부해보면 도움이 될 것이다.\n      \n    \n  \n\n\n예를 들어 $1000, $2000, $3000 라는 세개의 달러를 VO로 만들 수 있다.\n\n \n\npublic final class Dollar {\n    private final String amount;\n\n    public Dollar(String amount) {\n        this.amount = amount;\n    }\n\n    public BigDecimal amount() {\n        return new BigDecimal(amount);\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) {\n            return true;\n        }\n        if (o == null || getClass() != o.getClass()) {\n            return false;\n        }\n        Dollar that = (Dollar) o;\n        return Objects.equals(this.amount, that.amount);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(this.amount);\n    }\n}\n\n\n이 객체는 생성자에 의해 amount가 초기화되면 절대 바뀌지 않아야 한다.\n\n예를 들자면 식당에서 $70 짜리 식사를 마치고 $100를 건넸는데 주인이 돈이 부족해서 결제가 안된다고 말하면 이는 말이 되지 않는 상황이다.\n\n즉, 이러한 말이 안되는 상황이 VO를 가변으로 설계하면 일어날 수 있는 상황이다.\n\n$100 짜리 지폐는 그 어떤 상황에서도 $100의 가치를 해야만 한다. (불변성, Immutable)\n\n그리고 $100짜리 지폐 두장이 있을 경우 두 지폐의 가치는 동일해야 한다. (동등성)\n\n정말 간단한 테스트를 해보자\n\nclass DollarTests {\n    @Test\n    void test() {\n        Dollar oneDollar1 = new Dollar(\"1\");\n        Dollar oneDollar2 = new Dollar(\"1\");\n        Dollar twoDollar = new Dollar(\"2\");\n        \n        assertTrue(oneDollar1.equals(oneDollar2));\n        assertFalse(oneDollar1, oneDollar2);\n        assertFalse(oneDollar1.equals(twoDollar));\n        assertFalse(oneDollar2.equals(twoDollar));\n    }\n}\n\n\noneDollar1와 oneDollar2는 서로 메모리 주소를 참조하는 별개의 객체임을 알 수 있다. (동일성 비교, 비교 연산자를 이용한 비교 결과 false)\n\n하지만 이 두 객체는 같은 가치를 갖는다. (동등성 비교, equals를 이용한 비교 결과 true)\n\noneDollar1, oneDollar2와 twoDollar의 가치는 서로 같지 않다.\n\n즉, $1와 $1는 같은 가치를 갖지만, $1와 $2의 가치는 다르다. (너무 당연한 이야기이다.)\n\n일견 보기에 끝난 것 같지만 이 상태로 oneDollar1과 oneDollar2를 해시 컬렉션에서 사용한다면 어떤 결과가 나올까?\n\n해시 컬렉션은 해시코드도 활용해 동등성 검사를 하기 때문에 두 객체는 다른 가치를 갖는 객체라는 결과가 나올수도 있다.\n\n즉, Set에 $1가 두개 들어갈수도 있게 된다.\n\n이는 잘못된 결과일수 있으며, 객체가 해시 컬렉션에서 사용되더라도 각 객체간의 가치판단은 항상 정확해야 한다.\n\n그렇기 때문에 Object.equals()와 Object.hashCode()를 반드시 함께 재정의(Override) 해준다.\n\n다행히 인텔리제이 같은 IDE에서는 재정의를 자동으로 해주는 기능을 이용하면 대부분 이 두 메서드가 함께 재정의된다.\n\n또한 이 내용은 모두 📜 자바 레퍼런스에 명시되어 있다.\n\n📜 equals()\n\n\n\n\n  It is reflexive: for any non-null reference value x, x.equals(x) should return true.\n    \n      반사성: null이 아닌 모든 참조 값 x에 대해 x.equals(x) == true를 만족해야한다.\n    \n  \n  It is symmetric: for any non-null reference values x and y, x.equals(y) should return true if and only if y.equals(x) returns true.\n    \n      대칭성: null이 아닌 모든 참조 값 x, y에 대해 x.equals(y) == true면, y.equals(x) == true도 만족해야 한다.\n    \n  \n  It is transitive: for any non-null reference values x, y, and z, if x.equals(y) returns true and y.equals(z) returns true, then x.equals(z) should return true.\n    \n      이행성: null이 아닌 모든 참조 값 x, y, z에 대해 x.equals(y) == true이고, y.equals(z) == true이면 x.equals(z)도 true여야 한다.\n    \n  \n  It is consistent: for any non-null reference values x and y, multiple invocations of x.equals(y) consistently return true or consistently return false, provided no information used in equals comparisons on the objects is modified.\n    \n      일관성: null이 아닌 모든 참조 값 x, y에 대해, x.equals(y)를 반복해서 호출하면 항상 true를 반환하거나 항상 false를 반환한다.\n    \n  \n  For any non-null reference value x, x.equals(null) should return false.\n    \n      null이 아닌 모든 참조 값 x에 대해, x.equals(null)은 false다.\n    \n  \n\n\n📜 hashCode()\n\n\n\n\n  Whenever it is invoked on the same object more than once during an execution of a Java application, the hashCode method must consistently return the same integer, provided no information used in equals comparisons on the object is modified. This integer need not remain consistent from one execution of an application to another execution of the same application.\n    \n      equals 비교에 사용되는 정보가 변경되지 않았다면 객체의 hashCode 메서드는 몇 번을 호출해도 항상 일관된 값을 반환해야 한다. 단, Application을 다시 실행한다면 메모리 주소또한 달라지기 때문에 값이 달라져도 상관없다.\n    \n  \n  If two objects are equal according to the equals(Object) method, then calling the hashCode method on each of the two objects must produce the same integer result.\n    \n      equals를 통해 두 개의 객체가 같다고 판단했다면 두 객체는 똑같은 해시코드를 반환해야 한다.\n    \n  \n  It is not required that if two objects are unequal according to the equals(java.lang.Object) method, then calling the hashCode method on each of the two objects must produce distinct integer results. However, the programmer should be aware that producing distinct integer results for unequal objects may improve the performance of hash tables.\n    \n      equals가 두 개의 객체를 다르다고 판단했다 하더라도 두 객체의 해시코드가 반드시 서로 다른 값을 가질 필요는 없다. 이는 해시 알고리즘에 의한 특성이다. 하지만 가급적이면 서로 다른 객체라면 다른 해시코드를 반환해야 해시 테이블의 성능이 좋아진다.\n    \n  \n\n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2021-01-17-dto-vo/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "REST API 에 대한 고찰",
      "date": "2021-01-18 23:11:00 +0000",
      "description": "개발일기\n",
      "content": "\n  🚀 서문\n  💡 REST\n  📕 REST에는 6가지 제약조건이 있다    \n      📜 일관적인 인터페이스(Uniform interface)\n    \n  \n  😎 결론\n\n\n \n\n\n  📜 참고 - REST 위키백과\n\n  📜 참고 - REST Wikipedia\n\n  📜 참고 - Youtube naverd2 - 그런 REST API로 괜찮은가\n\n  📜 참고 - WWW란 무엇인가?\n\n\n \n\n🚀 서문\n\n\n\n아무리 찾아봐도 업계에서 사용하는 REST의 뜻과 로이 필딩이 말하는 REST는 다르다.\n\n \n\n이게 현재 내가 내린 결론이다.\n\n \n\n문득 “지금 이걸 완벽하게 이해하는 게 지금의 나한테 중요한가?” 라는 생각도 든다.\n\n \n\n맞는 말이다.\n\n끽해야 주니어 개발자인 내가 이런 Deep한 부분까지 신경 쓰면서 개발할 일은 없을 것이다.\n\n업계에서 통용되는 REST API에 대한 의미를 알고 활용할 정도만 돼도 문제없을 것이다.\n\n \n\n그래서 이 포스팅은 감정적인 성격의 포스팅이다.\n\n내가 제대로 이해하고 있지 못하다는데서 오는 찝찝함.\n\n그게 이 글을 작성하는 이유다.\n\n근데 작성하고 보니 더 찝찝해졌다.\n\n \n\n💡 REST\n\n\n\nREST(Representational State Transfer)는\n\n2000년에 로이 필딩(Roy Fielding)이 박사 학위 논문에 정의하며 세계에 퍼진 단어다.\n\n로이 필딩은 웹(Web)을 탄생시킨\n\n티머시 존 버너스 리(Timothy John Berners-Lee)의 제자로\n\n역시 웹의 탄생부터 깊게 관여해온 선구자이다.\n\n웹(Web)은 인터넷에서의 정보 공유를 어떻게 할 것인지에 대해\n\n여러 전문가 집단에 의해 정의됐다.\n\n \n\n\n  \n    표현 방식 : HTML (관리 그룹 : W3C)\n  \n  \n    통신 방식 : HTTP (관리 그룹 : IETF)\n  \n  \n    식별자 : URI\n  \n\n\n \n\n로이 필딩이 REST에 대한 발표를 할 때 웹과 HTTP는 존재했지만\n\n2021년인 현재와는 매우 환경이 다르다는 걸 우선 완벽하게 인지해야 할 것 같다.\n\n로이 필딩은 HTTP의 상위 버전인 HTTP/1.0을 정립할 때 발생하는 호환성 문제를 고심했다고 한다.\n\n우리는 자바 1.6으로 작성된 간단한 애플리케이션을 자바 1.8로 업데이트하는 일 조차 두려워한다.\n\n호환성에 의한 에러가 무수히 뜰 수 있기 때문이다.\n\n로이 필딩은 어땠을까? 무려 세계적인 통신 규약 자체를 업데이트하는데\n\n이때 전 세계적으로 터져 나올 호환성 문제에 대해 어마어마한 부담을 느끼지 않았을까?\n\n \n\n나는 그 부담감을 감히 상상조차 할 수 없다.\n\n \n\n로이 필딩의 REST라는 것은 소프트웨어 아키텍처(Software Architecture)이다.\n\n대저 아키텍처라 함은 제약조건의 묶음을 말한다.\n\n \n\n📕 REST에는 6가지 제약조건이 있다\n\n\n\n\n  \n    클라이언트-서버 구조(Client-server architectur)\n\n    \n      \n        The principle behind the client–server constraints is the separation of concerns. Separating the user interface concerns from the data storage concerns improves the portability of the user interfaces across multiple platforms. It also improves scalability by simplifying the server components. Perhaps most significant to the Web is that the separation allows the components to evolve independently, thus supporting the Internet-scale requirement of multiple organizational domains.\n      \n      \n        클라이언트-서버 구조의 원칙은 관심사(책임)의 분리이다.  유저 인터페이스에 의한 문제와 서버 데이터에 의한 문제를 분리시키면 여러 플랫폼에서 유저 인터페이스의 이식성이 향상된다(낮은 결합도를 말하는 듯하다). 또한 서버가 단순화됨으로써 서버의 확장성 또한 개선될 것이다. 아마도 웹에서 가장 중요한 가치는 각 요소들이 독립적으로 진화할 수 있게끔 관심사를 분리하여 인터넷 환경에서 각 도메인들의 요구사항을 지원해 줄 수 있게 하는 것이다.\n      \n    \n  \n\n\n \n\n\n  \n    비상태성(Statelessness)\n\n    \n      \n        In a client–server interaction, state is made up of intrinsic state and extrinsic state. Intrinsic state, called resource state, is stored on the server and consists of information that is independent of the server’s context, thereby making it sharable to all clients of the server. Extrinsic state, called application state, is stored on each client and consists of information that is dependent on the server’s context and therefore cannot be shared. Clients are responsible for passing application state to the server when it needs it. The constraint of storing application state on the client rather than on the server makes the communication stateless.\n      \n      \n        클라이언트-서버의 상호 작용은 고유한 상태와 외적인 상태로 구성된다. 고유한 상태는 리소스 상태라고도 부르는데 이것은 서버에 저장되며 서버의 콘텍스트와 상호 독립적으로 구성되므로 서버의 모든 클라이언트와 공유할 수 있다(현대의 세션을 말하는 듯하다). 외적인 상태는 애플리케이션 상태라고도 부르며, 이는 각 클라이언트에 저장되고 서버에 종속되어 공유될 수 없는 정보로 구성된다(현대의 쿠키를 말하는 듯하다). 클라이언트는 상태에 대한 정보가 필요할 때 서버에 애플리케이션 상태를 전달하는 역할을 해야 한다. 애플리케이션 상태를 서버가 아닌 클라이언트에 저장함으로서 통신을 비상태성으로 만든다.\n      \n    \n  \n\n\n \n\n\n  \n    캐시 가능(Cacheability)\n\n    \n      \n        As on the World Wide Web, clients and intermediaries can cache responses. Responses must, implicitly or explicitly, define themselves as either cacheable or non-cacheable to prevent clients from providing stale or inappropriate data in response to further requests. Well-managed caching partially or completely eliminates some client–server interactions, further improving scalability and performance.\n      \n      \n        월드 와이드 웹(www)처럼 클라이언트와 이를 중개하는 장치는 응답을 캐시 할 수 있어야 한다. 이 응답은 암시적으로나 명시적으로나 캐시 가능한지 혹은 불가능한지 반드시 정의되어야만 한다. 알맞게 관리되는 캐시는 클라이언트-서버의 결합도를 낮추어 확장성과 성능의 향상을 가져올 것이다.\n      \n    \n  \n\n\n \n\n\n  \n    계층적 시스템(Layerd system)\n\n    \n      \n        A client cannot ordinarily tell whether it is connected directly to the end server or to an intermediary along the way. If a proxy or load balancer is placed between the client and server, it won't affect their communications, and there won't be a need to update the client or server code. Intermediary servers can improve system scalability by enabling load balancing and by providing shared caches. Also, security can be added as a layer on top of the web services, separating business logic from security logic. Adding security as a separate layer enforces security policies. Finally, intermediary servers can call multiple other servers to generate a response to the client.\n      \n      \n        대충 OSI 7 계층에 대한 내용으로 보인다. 혹은 URL의 트리구조를 말하는 것인 것 같기도 하다.\n      \n    \n  \n\n\n \n\n\n  \n    서버에 의한 클라이언트 제어(Code on demand)\n\n    \n      \n        Servers can temporarily extend or customize the functionality of a client by transferring executable code: for example, compiled components such as Java applets, or client-side scripts such as JavaScript.\n      \n      \n        서버는 Java Applets이나 JavaScript와 같은 클라이언트 사이드 스크립트를 클라이언트에 전송하여 클라이언트의 기능을 임시적으로 확장시키거나 커스터마이징 할 수 있어야 한다.\n      \n    \n  \n\n\n \n\n📜 일관적인 인터페이스(Uniform interface)\n\n\n\n\n  \n    The uniform interface constraint is fundamental to the design of any RESTful system. It simplifies and decouples the architecture, which enables each part to evolve independently. The four constraints for this uniform interface are:\n  \n  \n    일관적인 인터페이스 제약조건은 모든 RESTful 한 시스템의 근본적인 설계이다. 일관적인 인터페이스는 아키텍처를 단순화시키고 관심사를 분리하여 각 부분이 독립적으로 진화할 수 있게 해 준다. 이 제약조건은 다음의 네 가지가 있다.\n  \n\n\n \n\n\n  \n    요청의 자원 식별(Resource identification in requests)\n\n    \n      \n        Individual resources are identified in requests, for example using URIs in RESTful Web services. The resources themselves are conceptually separate from the representations that are returned to the client. For example, the server could send data from its database as HTML, XML or as JSON—none of which are the server's internal representation.\n      \n      \n        요청에서 각 자원은 식별된다. 예를 들면 RESTful 웹 서비스에서 URI를 사용하는 것이다. 각 자원들은 클라이언트에게 반환되는 표현과 개념적으로 분리되어 있다. 예를 들자면 서버는 데이터베이스에서 내부 데이터들을 보내는 대신, 그 데이터들을 HTML, XML, JSON 등으로 표현하여 보낼 수 있다.\n      \n    \n  \n\n\n \n\n\n  \n    표현에 의한 자원 조작(Resource manipulation through representations)\n\n    \n      \n        When a client holds a representation of a resource, including any metadata attached, it has enough information to modify or delete the resource's state.\n      \n      \n        클라이언트가 자원을 표현하는 메타데이터를 갖고 있다면, 자원의 상태를 수정하거나 삭제할 수 있는 충분한 정보를 갖고 있는 것이다.\n      \n    \n  \n\n\n \n\n\n  \n    하이퍼미디어는 애플리케이션의 상태를 실행시킨다(Hypermedia as the engine of application state (HATEOAS))\n\n    \n      \n        Having accessed an initial URI for the REST application—analogous to a human Web user accessing the home page of a website—a REST client should then be able to use server-provided links dynamically to discover all the available resources it needs. As access proceeds, the server responds with text that includes hyperlinks to other resources that are currently available.\n      \n      \n        REST 애플리케이션에 처음 접속한 REST 클라이언트는 서버에서 제공하는 링크를 동적으로 사용하여 필요한 모든 가용 자원을 알 수 있어야 한다. 접속이 진행되면 서버는 현재 사용 가능한 다른 자원에 대한 하이퍼링크를 클라이언트에게 알려줄 수 있어야 한다. (HTML 문서를 말하는 듯함. HTML에 처음 접속하면 버튼(링크)을 통해 다른 페이지로 자유롭게 이동할 수 있는 부분들. www에 따르면 하이퍼미디어는 하이퍼텍스트의 집합을 의미한다.)\n      \n    \n  \n\n\n \n\n\n  💡 하이퍼미디어(Hypermedia)\n\n  하이퍼미디어(hypermedia)란 하이퍼텍스트(hypertext)의 커다란 집합체라고 말 할 수 있다. 하이퍼텍스트는 일반적인 텍스트와 별 다른 차이가 없지만 하이퍼텍스트 링크 즉, 하이퍼링크(hyperlink)라는 다른 문서로의 연결고리를 가진다는 큰 특징을 가지고 있다. 다시말해, 하이퍼텍스트란 어떤 문서내의 특정 단어 또는 문장으로써, 그 단어 또는 문장 상에서 사용자가 마우스를 클릭하게 되면 스크린상에 새로운 문서를 나타나게 하는 텍스트를 의미한다.\n하이퍼미디어란 간단히 말하자면 하이퍼텍스트와 멀티미디어를 조합시킨 형태라고 할 수 있다. 이는 다시말해, 다른 문서 또는 텍스트로의 하이퍼링크를 가지는 하이퍼텍스트 문서이면서, 연결되어 있는 문서의 형태가 단순한 텍스트뿐만 아니라 여러 형태 즉, 음성 또는 영상(정지영상, 동영상) 등의 멀티미디어 데이타라는 것이다. 예를 들면, 사용자가 문서상의 한 하이퍼텍스트를 클릭하게 되면, 그와 연결된 문서 즉, 단순한 텍스트 문서 또는 어떤 음성, 이미지내지는 동영상이 나타날 수 있는 것이다. WWW를 하이퍼미디어 정보 검색 시스템이라고 하는 것은 WWW가 하이퍼텍스트를 기반으로 멀티미디어 데이타의 전송이 가능한 시스템이기 때문이다.\n\n\n \n\n\n  \n    메시지는 스스로를 설명해야 한다(Self-descriptive Messages)\n\n    \n      \n        Each message includes enough information to describe how to process the message. For example, which parser to invoke can be specified by a media type.\n      \n      \n        각 메시지는 스스로를 어떻게 처리해줘야 하는지에 대한 충분한 정보가 포함되어 있어야 한다. 예를 들자면, 미디어 타입의 파서를 명시해서 호출해야 한다. (미디어 타입만 가지고도 클라이언트 측에서 어떻게 처리를 해야 할지 알 수 있어야 할 만큼 정보가 명시되어있어야 한다는 뜻 같음. Ajax의 Content Type을 명시하는 부분을 말하는 듯함)\n      \n    \n  \n\n\n \n\n굉장히 많고 복잡하다.\n\n특히 표현(Representational)과 상태(State)라는 단어가 굉장히 많이 나온다.\n\n이 부분이 잘 이해가 가지 않는데 문맥상 추론하기에 HTML을 표현이라고 하고 있는 것 같고,\n\n상태코드를 상태라고 부르고 있는 것 같다.\n\n \n\n우리는 위의 제약조건들이 발표된 시기가 2000년임을 기억해야 한다.\n\n현재 우리가 사용하고 있는 HTTP에 의해 저 위의 대부분의 제약조건들이 실제로 지켜지며 작동되고 있다.\n\n다만 Self-descriptive Messages와 HATEOAS는 개발자가 직접 신경쓰지 않으면 잘 지켜지지 않기 때문에\n\n로이 필딩은 대부분의 시스템이 RESTful하지 않다고 말하고, 굳이 RESTful에 목매지 말라는 이야기도 덧붙이고 있다.\n\n \n\n\n  How do i improve HTTP without breaking the Web?\n\n\n \n\n애당초 로이 필딩이 REST를 발표하게 된 계기이다.\n\n그러니까 로이 필딩의 궁극적인 목표는\n\n클라이언트와 서버의 책임이 완벽하게 분리되고 독립적으로 진화하여\n\n서버의 기능이 변경되더라도 클라이언트는 아무 문제없이 동작할 수 있는 환경이었던 것 같다.\n\n \n\n\n  가장 RESTful 한 것은 웹(Web)이다.\n\n\n \n\n웹 브라우저가 변경되더라도 클라이언트는 같은 결과물을 서버에서 받아볼 수 있다.\n\n웹 브라우저가 크롬(Chrome)이었다가 사파리(Safari)로 바뀐다고 클라이언트가 서버로부터 다른 정보를 받는 경우는 없다.\n\n클라이언트와 서버는 상호 독립적이며 클라이언트가 바뀌더라도 서버는 같은 요청을 받고 같은 결과를 보내 줄 수 있다.\n\n \n\n\n  그래서 웹(Web)은 가장 RESTful 한 시스템이다.\n\n\n \n\n그런 REST API로 괜찮은가에 따르면\n\nSelf-descriptive Messages는 Custom Media Type이나 Profile Link Relation 등으로 충족시킬 수 있고,\n\nHATEOAS는 HTTP 헤더나 바디에 Link를 달아 만족시킬 수 있다고 한다.\n\n이는 개발자가 직접 세팅해줘야 하기 때문에 귀찮고 번거로우며,\n\n이 귀찮음을 감수하고 추가 개발했다고 하더라도 그로 인해 당장 얻어지는 이득이 없다.\n\n이러한 사실로 인해 로이필딩이 말하는 진정한 의미의 Restful은 나오기 힘든 것같다.\n\n \n\n😎 결론\n\n\n\n로이 필딩은 HTTP/1.0 로 업데이트를 진행하며\n\n전 세계 시스템의 하위 호환성에 문제가 생기는 것을 걱정했고,\n\n이를 미연에 방지하고 미래에 계속될 HTTP 업데이트 또한 문제없기를 바라며 REST의 개념을 도출해냈다.\n\n현대에 이르러 전 세계적으로 HTTP/1.1이 사용되고 있고\n\nHTTP/2.0이 도입되고 있는 추세이며, 20년 말에는 HTTP/3.0에 대한 논의가 나왔다고 한다.\n\n이 HTTP/1.0부터의 모든 버전이 로이 필딩이 REST라고 명명한\n\n소프트웨어 아키텍처(Software Architecture)의 영향을 받아 발전했기 때문에\n\n지금에 이르러선 HTTP을 통한 통신을 하는 것만으로 사실상 대부분의 REST 제약조건을 지키는 셈이다.\n\n \n\n하지만 HTTP를 통해 통신을 한다고 하더라도\n\n일관된 인터페이스라는 제약조건은 개발자가 제대로 신경 쓰지 않으면\n\n실제로 잘 지켜지지 않기 때문에 엄격한 의미에서 RESTful 하지 않다고 이야기하는 것이다.\n\n \n\n로이 필딩은 REST라면 반드시 이러한 문법(Syntax)을 지켜야한다고 분명하게 이야기하지 않았다.\n\nREST는 그저 소프트웨어 아키텍처(Software Architecture)일 뿐이고\n\n이것이 포함하는 모든 제약사항을 충족시키는 시스템이 진정 RESTful한 것이라고 말하고 있을 뿐이다.\n\n \n\n처음 REST API에 대해 구글링을 할때 HTTP의 Get, Post, Put, Delete, Patch와 CRUD를 연관시키고,\n\nURL은 동사가 아닌 명사여야 한다는 둥의 글들이 나를 더욱 혼란스럽게 만들었었다.\n\n하지만 위 내용들과 별개로 아직도 대부분의 시스템이 Get과 Post만을 이용해 사용되어지고 있다.\n\nSpring 4.3에도 HTTP의 5가지 Method에 대한 애노테이션이 추가되었지만\n\n현실적으로 @GetMapping과  @PostMapping을 이용한 개발만이 주를 이루고있다.\n\n \n\n그래서 내 생각에 현재 업계에서 통용되는 REST와 학술적 의미의 진정한 REST는 분명한 차이가 있다고 생각한다.\n\n \n\n전 세계적으로 모바일 시장이 커짐에 따라 API서버를 통한 멀티플랫폼 서비스가 시작됐다.\n\n또한 웹 분야에서 현재 우리나라 업계는 SPA(Single Page Application) 방식의 개발이\n\n트렌드로 자리 잡으며 프론트 개발자와 백엔드 개발자로 업무분담이 세부화 되어가는 시점인데,\n\n각 페이지를 교체하며 계속해서 렌더링 하는 기존의 방식보다\n\n모든 페이지를 최초에 한번 렌더링 해놓고\n\nAPI서버를 통한 비동기 통신을 이용해 페이지를 동적으로 교체하는 현재의 방식은 성능이 더 뛰어나다.\n\n \n\n또한, 이러한 방식의 개발은 프론트 개발자와 백엔드 개발자가\n\n서로 이 API에는 어떠한 URI를 보내면 어떠한 응답이 올 것이다 라는걸\n\n미리 약속하고 진행하기 때문에 각자의 업무를 세부적으로 분담할 수 있고, 협업에 용이하다.\n\n \n\n하지만 이 방식으로 일을 진행하기 위해 API기반의 설계와 개발이 필요하기 때문에\n\n대부분의 채용공고에 REST, RESTful에 대한 이해같은 글귀같은 것들이 있는 것으로 사료된다.\n\n \n\n결론적으로 업계에서 말하는 REST API란 학술적 의미의 Rest가 아닌 HTTP Body를 주로 이용하는 @RestController와 같은 통신방식을 의미하는 걸로 이해가 된다.\n\n \n\n마치며 이를 REST API가 아닌 HTTP API라고 불러야 함이 옳지 않을까? 라는 생각을 해본다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-01-18-diary-9/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "필드와 변수의 정의",
      "date": "2021-01-19 16:41:00 +0000",
      "description": "자바 문서 정리\n",
      "content": "\n  📕 서론\n  📕 자바 변수 종류에 대한 정의\n  📕 결론\n\n\n \n\n📕 서론\n\n\n\n욕심 많았던 첫 프로젝트를 끝내고 다음 진도로 나아가기 전 기초 회귀 학습을 진행하고 있다.\n\n이번 포스팅에는 자바의 변수와 필드에 대해 알아볼 것이다.\n\n \n\n📕 자바 변수 종류에 대한 정의\n\n\n\nThe Java programming language defines the following kinds of variables.\n\n자바 프로그래밍 언어의 변수 종류에 대해 다음과 같이 정의한다.\n\n \n\n\n  \n    Instance Variables (NonStatic Fields) Technically speaking, objects store their individual states in \"nonstatic fields\", that is, fields declared without the static keyword. Nonstatic fields are also known as instance variables because their values are unique to each instance of a class (to each object, in other words); the currentSpeed of one bicycle is independent from the currentSpeed of another.\n\n    \n      인스턴스 변수(비정적 필드)는 엄밀히 따지면 오브젝트에 저장된 각각의 상태다. 이는 정적 키워드(static) 없이 선언된 필드인 인스턴스 변수(비정적 필드)에 각각의 상태를 저장한다. 정적 필드가 아닌 필드는 각 클래스의 인스턴스마다(또는 각 객체 마다라고 부를 수 있겠다.) 고유하기 때문에 인스턴스 변수라고 부른다. 한 자전거의 현재 속도는 다른 자전거의 현재 속도와 독립적인 것이다.\n    \n  \n\n\n \n\n\n  \n    Class Variables (Static Fields) A class variable is any field declared with the static modifier; this tells the compiler that there is exactly one copy of this variable in existence, regardless of how many times the class has been instantiated. A field defining the number of gears for a particular kind of bicycle could be marked as static since conceptually the same number of gears will apply to all instances. The code static int numGears = 6; would create such a static field. Additionally, the keyword final could be added to indicate that the number of gears will never change.\n\n    \n      클래스 변수(정적 필드)는 정적 수정자(static)를 사용해 선언된 필드이며, 클래스가 인스턴스화 됐는지에 관계없이 이 변수가 정확히 한 개만 존재함을 컴파일러에게 알려준다. 개념적으로 모든 자전거에는 동일한 수의 기어가 존재하므로 특정 자전거의 기어 수를 정의하는 필드는 정적(static)으로 표시할 수 있다. static int numGears = 6; 코드는 이러한 정적 필드를 생성하는 예시이다. 또한 키워드 final을 추가해 이 값이 절대로 변하지 않는 상수임을 표시할 수도 있다.\n    \n  \n\n\n \n\n\n  \n    Local Variables Similar to how an object stores its state in fields, a method will often store its temporary state in local variables. The syntax for declaring a local variable is similar to declaring a field (for example, int count = 0;). There is no special keyword designating a variable as local; that determination comes entirely from the location in which the variable is declared — which is between the opening and closing braces of a method. As such, local variables are only visible to the methods in which they are declared; they are not accessible from the rest of the class.\n\n    \n      지역 변수는 인스턴스 변수와 유사하지만 메서드가 상태를 저장하는 곳을 의미한다. 지역 변수를 선언하는 문법은 필드를 선언하는 문법과 유사하다(예: int count = 0;). 변수를 지역 변수로 지정하는 키워드는 따로 존재하지 않으며, 이 판단은 전적으로 변수가 선언된 위치에 근거한다. 따라서 지역 변수는 메서드 안에 있는 변수를 의미하며 지역 변수는 해당 메서드에서만 접근할 수 있고 메서드 밖에서는 지역 변수에 접근할 수 없다.\n    \n  \n\n\n \n\n\n  \n    Parameters You've already seen examples of parameters, both in the Bicycle class and in the main method of the \"Hello World!\" application. Recall that the signature for the main method is public static void main(String\\[\\] args). Here, the args variable is the parameter to this method. The important thing to remember is that parameters are always classified as \"variables\" not \"fields\". This applies to other parameteraccepting constructs as well (such as constructors and exception handlers) that you'll learn about later in the tutorial.\n\n    \n      당신은 이미 자전거 클래스에서 매개변수를 보았다. 메인 메서드는 문법상 public static void main(String[] args)로 표기하는데, 여기서 args변수를 매개변수라고 부른다. 반드시 기억해야 할 것은 매개변수는 항상 필드가 아닌 변수로 분류된다는 것이다. 이 내용은 나중에 튜토리얼에서 알게 될 다른 매개변수 구성(생성자나 예외처리)에도 모두 동일하게 적용된다.\n    \n  \n\n\n \n\n📕 결론\n\n\n\n\n  \n    필드는 상태가 저장되는 곳을 말한다. (Stack Area)\n\n    \n      객체의 상태가 저장되는 곳은 필드로 분류한다.\n      필드는 모두 변수라고 부를 수도 있다.\n      다만 모든 변수를 필드라고 부를 수 있는 것은 아니다.\n        \n          ex. 매개변수\n        \n      \n    \n  \n\n\n \n\n\n  \n    인스턴스 변수 = 비정적 필드 (Heap Area를 참조하는 개체)\n\n    \n      인스턴스 변수는 각 클래스의 인스턴스마다 독립적으로 존재한다. (당연한 소리다.) 인스턴스가 뭔지 아직 잘 모른다면 이를 먼저 이해해야 할 것이다.\n    \n  \n\n\n \n\n\n  \n    클래스 변수 = 정적 필드 (Method Area를 참조하는 개체)\n\n    \n      static을 선언해 정적 멤버임을 컴파일러에게 알려준다. 이는 JVM에 의해 메모리에 적재될 때 가장 먼저 적재된다. JVM에 대한 이해 역시 필요하다.\n    \n  \n\n\n \n\n\n  \n    지역 변수는 메서드 안에 위치한 필드를 말한다.\n\n    \n      메서드는 일반적인 함수와 다르게 클래스에 종속된 함수를 의미하며 클래스 함수라고도 부른다.\n      컴파일러는 메서드에 종속된 필드를 지역 변수로 판단한다.\n    \n  \n\n\n \n\n\n  \n    매개변수는 절대로 필드가 될 수 없다.\n\n    \n      매개변수는 무조건 변수로 분류된다.\n    \n  \n\n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2021-01-19-field-var/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "ORA-01882 Timezone region not found",
      "date": "2021-01-19 17:04:00 +0000",
      "description": "Oracle DB Time Zone 이슈\n",
      "content": "\n \n\n\n  Time Zone ?\n\n  UTC, GMT, KST 같은 각 나라별 시간 대역을 말함\n\n\n \n\n이 에러는 AWS EC2를 만지던 중 발생했다.\n\n이 에러의 근본적인 원인은 한참의 삽질 끝에 알아냈다.\n\n타임존 4박자가 모두 일치하지 않을 경우 발생하는 에러였다.\n\n\n  AWS 서비스의 타임존\n  EC2 인스턴스 OS의 타임존\n  EC2에 설치된 WAS의 타임존\n  DB의 타임존\n\n\nAWS 인스턴스가 한국에 있지 않다는게 가장 큰 원인이었던 것으로 보인다.\n\n그래서 EC2 인스턴스를 이미지화해 AWS 리전(Region)을 한국으로 변경하였으며,\n\n나머지 모든 타임존을 KST로 변경하니 해결 되었다.\n\n이 문제로 인해 타임존이 일치하지 않으면 서로 접속이 안된다는 것도 처음 알았다.\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-01-19-debugging-2/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Martin Fowler's Refactoring",
      "date": "2021-01-20 19:46:00 +0000",
      "description": "개발일기\n",
      "content": "\n  🤔 리팩토링을 해야하는 이유 ?    \n      💡 소프트웨어 설계가 개선된다\n      💡 소프트웨어를 이해하기가 더 쉬워진다\n      💡 버그를 찾기가 쉬워진다\n      💡 개발 속도가 빨라진다\n    \n  \n  😎 결론\n\n\n \n\n\n  \n    \n      \n    \n  \n  \n    \n      절판돼서 구하기 너무 어려웠던 책…\n    \n  \n\n\n \n\n읽다 보니 너무 교훈적인 내용이 있어서 기록해두고자 한다.\n\n내가 개발자로서의 삶을 살아가는데 있어 가장 밑바탕이 되어야 할 자세라고 생각했다.\n\n또한, 여러 커뮤니티에서 개발자의 필독서로 강력 추천하는 이유를 알 것 같은 책이다.\n\n여러 차례에 걸쳐 책의 내용을 많이 인용할 것 같다.\n\n \n\n\n  누가 나한테 “리팩토링은 그냥 코드 정리 작업을 뜻하는 건가요”하고 물어본 적이 있다.\n\n  어떻게 보면 그것도 맞지만(피식했다), 리팩토링으로 인해 코드 효율성이 높아지고 구조도 체계화된다는 점을 생각해볼 때 리팩토링은 단순한 코드 정리보다는 더 포괄적인 개념이라고 할 수 있다.\n\n\nRefactoring - Martin Fowler p.76 中\n\n \n\n서문에서 마틴 파울러는 리팩토링이 좁게 보면\n\n단순히 개개인의 심미적 태도에 의한 코드 정리 작업으로 볼 수도 있지만,\n\n \n\n\n  예를 들면 깔끔한 사람이 지저분한 사람의 집에 가면 불편함? 언짢음? 과 같은 감정을 느끼는 것과 비슷한 뉘앙스다.\n\n\n \n\n이보다 더 넓은 포괄적인 시선으로 바라봐야 한다고 여러차례에 걸쳐 강조하고 있다.\n\n여기서 또 한 번 느낀 게 있는데, 개발 업계에서 선구자라고 불리는 사람들의 공통적인 특징에 대해서다.\n\n이 사람들은 항상 인과율을 생각한다.\n\n그러니까 현재 자신이 맡은 임무의 완수에만 매달리는 게 아닌,\n\n자신이 한 행동으로 인해 일어날 결과에 대해서 많은 고민을 하는 게 보인다.\n\n \n\n많은 일반적인 개발자들은 오늘 완성해야 할 기능만을 쳐다보지만,\n\n이 사람들은 오늘 완성해야 할 기능을 생각하면서 동시에 미래까지 생각한다.\n\n이는 로이 필딩이 REST를 도출해낸 과정과 매우 유사하다.\n\n \n\n관련 포스팅 - 📜 REST API 에 대한 고찰\n\n \n\n\n  리팩토링의 정의에 대해 강조할 내용은 두가지다.\n\n  첫째, 리팩토링의 목적은 소프트웨어를 더 이해하기 쉽고 수정하기 쉽게 만드는 것이다. 리팩토링을 수행하면 겉으로 드러나는 기능에 거의 또는 아예 영향을 주지 않은 채 소프트웨어의 각종 기능을 변경할 수 있다. 소프트웨어를 더 이해하기 쉽게 고치는 방법은 오직 리팩토링밖에 없다.\n\n  둘째, 리팩토링은 겉으로 드러나는 소프트웨어 기능에 영향을 주지 않는다. 따라서 리팩토링하기 전의 소프트웨어 기능은 리팩토링을 수행하고 나서도 그대로이며, 최종 사용자나 다른 프로그래머는 그 소프트웨어에 변화가 있음을 눈치채지 못한다.\n\n\nRefactoring - Martin Fowler p.76 中\n\n \n\n🤔 리팩토링을 해야하는 이유 ?\n\n\n\n마틴 파울러는 리팩토링을 해야 하는 이유에 대해 다음과 같이 설명하고 있다.\n\n💡 소프트웨어 설계가 개선된다\n\n\n\n흔히 스파게티 코드라고 말하는 코드가 되지 않게끔 계속해서 가꾸고 다듬는다.\n\n아무리 꼬인 코드라도 컴퓨터는 쉽게 이해할 수 있지만 사람이 이해할 수 있는 코드는 실력있는 프로그래머만 작성할 수 있다.\n\n \n\n💡 소프트웨어를 이해하기가 더 쉬워진다\n\n\n\n많은 개발자가 실수하는 부분이라고 꼬집고 있는 점이 하나 있는데,\n\n어떤 기능 구현에만 집착한 나머지 나중에 그 코드를 유지 보수하게 될 동료에 대한 배려를 생각하지 않는다는 것이다.\n\n이런 말을 하면서도 또 그렇다고 항상 타인만을 위해 코드를 작성하지는 말라고 한다.\n\n대부분의 경우 자신의 코드를 자신이 수정하게 되는 경우가 훨씬 많기 때문이라고 한다.\n\n(여기서 나는 “그럼 애초에 타인을 배려하며 코드를 짜면 결과적으로 내가 나 자신을 배려하는 게 아닐까?” 라는 생각을 잠깐 해봤다.)\n\n \n\n아무튼 리팩토링을 계속해서 실시하면 코드에 대해 이해하기가 쉬워진다고 하며,\n\n최초 단계의 리팩토링에 대해 랄프 존슨의 비유를 들려주고있다.\n\n \n\n\n  “우선 창 밖이 보이게 뿌연 유리창부터 닦는 일” - 랄프 존슨\n\n\n \n\n💡 버그를 찾기가 쉬워진다\n\n\n\n계속해서 리팩토링을 해 나가다 보면 코드가 전체적으로 알아보기 쉬운 구조가 되어 버그를 찾기도 수월하다는 것이다.\n\n이 말을 하며 켄트 백의 말을 인용하고 있다.\n\n \n\n\n  “난 뛰어난 프로그래머는 아니고, 단지 습관을 잘 들인 착실한 프로그래머다.” - 켄트 백\n\n\n \n\n저 말은 정말 금과옥조처럼 받아들여야 할 프로그래머로서의 삶의 태도가 아닐까 싶다.\n\n \n\n💡 개발 속도가 빨라진다\n\n\n\n나무만을 보지 말고 숲을 보라는 얘기다.\n\n완성된 소프트웨어는 요구사항의 변화, 기능의 추가 등으로 계속해서 덩치를 부풀리며 발전해 나간다.\n\n완성했다고 끝나는 게 아니라는 말이다.\n\n그러니까 당장의 완성에만 급급하지 말고 미래를 보고 변화에 유연한 구조를 생각하라는 뜻이다.\n\n그런 습관과 태도를 들인다면 나중에 스파게티 코드를 끌어안고 유지보수에 끙끙대는 시간을\n\n획기적으로 줄일 수 있다. 당장에는 더 느리다고 느낄 수 있지만,\n\n결과론적으로 놓고 봤을 때 결국에는 전체적인 개발 속도가 더 단축된다는 것이다.\n\n이 포스팅의 마지막으로 마틴 파울러의 리팩토링에서 가장 핵심적인 글귀라고 생각되는 부분을 기록한다.\n\n \n\n\n  나는 리팩토링을 일부러 시간 내서 하지 말라고 한다.\n\n  리팩토링은 따로 시간을 정해서 하는 게 아니라 일상적으로 틈틈히 해야 한다.\n\n  리팩토링은 작정하고 몰아서 하는게 아니라,\n\n  뭔가 다른 걸 해야겠는데 리팩토링을 실시하면 그 작업이 쉬워지기 때문에 하는 것이다.\n\n\nRefactoring - Martin Fowler p.80 中\n\n \n\n😎 결론\n\n\n\n이번 포스팅에는 마틴 파울러가 추구하는 핵심적인 가치가 들어있다.\n\n코드를 작성 할 때 중요한 것은 코드가 목표로하는 하는 기능이 명확해야 한다.\n\n리팩토링을 할 때에도 이 부분을 명심하고 진행해야 한다.\n\n \n\n그리고, 좋은 습관을 들여라\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-01-20-diary-10/"
    },{
      "image": "/assets/img/ide/Intellij.png",
      "title": "인텔리제이(IntelliJ) 단축키",
      "date": "2021-01-22 21:52:00 +0000",
      "description": "Windows10과 Linux(Mac) 환경에서 인텔리제이(IntelliJ)의 단축키를 살펴봅니다\n",
      "content": "\n \n\n\n  생성자/수정자 등 메서드 생성 목록 보기\n    \n      psvm입력 + Enter (Live Template)\n    \n  \n  Main() Method 생성\n    \n      psvm입력 + Enter (Live Template)\n    \n  \n  System.out.println() 생성\n    \n      sout입력 + Enter (Live Template)\n    \n  \n  System.out.println(“args = “ + args) 생성\n    \n      soutv입력 + Enter (Live Template)\n    \n  \n  Main Method 실행\n    \n      Shift + F10\n    \n  \n  Return 변수명 생성\n    \n      Ctrl + Alt + V\n    \n  \n  단어 단위로 Focus 이동\n    \n      Ctrl  + ← or →\n    \n  \n  매개변수 속성 보기\n    \n      Ctrl + P\n    \n  \n\n\n\n\n\n  Reference 보기\n    \n      Ctrl + Q\n    \n  \n\n\n\n\n\n  구현부 즉시 보기\n    \n      Shift + Ctrl + I\n    \n  \n\n\n\n\n\n  자동완성\n    \n      Ctrl + Space\n    \n  \n  스마트 자동완성\n    \n      Shift + Ctrl + Space\n    \n  \n  정적 메서드 자동완성\n    \n      Ctrl + Space + Space\n    \n  \n  Override 자동완성\n    \n      Ctrl + I\n    \n  \n  라인 복사\n    \n      해당 라인 Focus 후 Ctrl + D (아래 줄로 복사됨)\n    \n  \n  문자열 합치기\n    \n      Shift + Ctrl + J\n    \n  \n  라인 단위로 옮기기\n    \n      Shift + Ctrl + ↑or↓\n    \n  \n  요소 단위 옮기기 (HTML, XML 등 마크 업 언어)\n    \n      Shift + Ctrl + Alt + ← or →\n    \n  \n  열린 페이지 다음 탭으로 이동\n    \n      Alt + ← or →\n    \n  \n  검색\n    \n      Shift x2\n    \n  \n  Debug Step Into (내부 코드로 진입)\n    \n      F7\n    \n  \n  Debug Step Out (포커스 탈출)\n    \n      Shift + F8\n    \n  \n  Debug Step Over (다음 라인으로 넘어가기)\n    \n      F8\n    \n  \n  Git Pull\n    \n      Ctrl + T\n    \n  \n  Git Commit\n    \n      Ctrl + K\n    \n  \n  Git Push\n    \n      Shift + Ctrl + K\n    \n  \n\n",
      "categories": ["ide","intellij"],
      "tags": [],
      
      "collection": "posts",
      "url": "/ide/intellij/2021-01-22-intellij-command/"
    },{
      "image": "/assets/img/spring/spring-boot/spring-boot-logo.png",
      "title": "Dependency Injection, DI",
      "date": "2021-01-23 17:38:00 +0000",
      "description": "의존관계 설정(Dependency Injection, DI)의 3가지 방법\n",
      "content": "\n  Spring DI    \n      필드 주입 (Field Injection)\n      수정자 주입 (Setter Injection)\n      생성자 주입 (Constructor Injection)\n    \n  \n  생성자 설정을 권장하는 이유    \n      테스트 코드 작성이 편리하다\n      인스턴스 변수가 불변성을 가질 수 있다\n      버그를 더 확실하게 찾아낼 수 있다.\n    \n  \n\n\n \n\n📜 참고 도서 - 토비의 스프링 3.1\n\n \n\nSpring DI\n\n\n\nSpring DI에는 3가지 방법이 있다.\n\n\n  \n    필드 주입(Field Injection)\n  \n  \n    수정자 주입 (Setter Injection)\n  \n  \n    생성자 주입 (Constructor Injection)\n  \n\n\n그리고 Spring에서는 생성자를 사용한 설정을 권장한다.\n\n그 이유에 대해 알아보자.\n\n \n\n필드 주입 (Field Injection)\n\n\n\n@Controller\npublic class TestController {\n    @Autowired\n    private TestService testService;\n}\n\n\n내가 가장 많이 본 작성법이다.\n\n제일 코드를 적게 치므로 편하긴 하다.\n\n \n\n수정자 주입 (Setter Injection)\n\n\n\n@Controller\npublic class TestController {\n    private TestService testService;\n\n    @Autowired\n    public void setTestService(TestService testService) {\n        this.testService = testService;\n    }\n}\n\n\n\n자바의 암묵적인 약속을 굳이 지키지 않더라도(property는 set~ or get~),\n\n같은 기능을 하는 메서드이기만 하면 상관없다.\n\n그래도 작성자만 알아보기 편한 코드 작성은 지양해야 하기에 항상 명확한 네이밍 패턴을 사용하는 것이 좋지 않을까?\n\n \n\n생성자 주입 (Constructor Injection)\n\n\n\n@Controller\npublic class TestController {\n    private TestService testService;\n\n    @Autowired\n    public TestController(TestService testService) {\n        this.testService = testService;\n    }\n}\n\n\n\n두 번째로 많이 본 작성법이다.\n\n처음에는 “필드 주입하면 되지 왜 귀찮게 이런 긴 코드를 작성할까?”라는 의문이 들었다.\n\n그 이유가 있다.\n\n그리고 Spring에서는 이 생성자를 이용한 설정을 매우 권장하고 있다.\n\n\n  참고로 단일 생성자인 경우 Spring 4.3 버전부터는 @Autowired를 생략할 수 있다.\n다만, 생성자가 두 개 이상인 경우엔 4.3 이상의 버전이더라도 @Autowired를 명시적으로 선언해줘야만 한다.\n\n\n \n\n생성자 설정을 권장하는 이유\n\n\n\nSpring의 구조에 대한 이해가 필요하다.\n\n애플리케이션을 실행하면 WAS가 기동하며 빈 팩토리(BeanFactory)가 초기화되는데,\n\n이때 컴포넌트 스캔(Component Scan)을 진행하며 Bean을 등록한다.\n\n여기서 생성자 주입과 필드 &amp; 수정자 주입의 차이가 생기는데\n\n필드 &amp; 수정자 주입은 이때 같이 Bean을 주입받고\n\n생성자 주입은 초기화 과정에 Bean을 주입받지 않고 해당 객체가 실제로 사용되는 시점에서야 Bean을 주입받는다.\n\n그러므로 생성자 주입을 한다면 클래스 자체가 필드 &amp; 수정자 주입보다 더 독립적으로 변하게 된다.\n\n그렇다면 어떤 장점이 있을까?\n\n \n\n테스트 코드 작성이 편리하다\n\n\n\nIoC Container에 대해 독립적인 코드를 작성할 수 있어진다.\n\n테스트는 빠른 피드백과 정확성을 위해 항상 가볍고 독립적으로 작성하는 게 올바른 작성법이다.\n\n만약 DI를 생성자에 걸어두었다면 테스트 케이스 내에서 인스턴스를 직접 만들어 사용하기가 용이해진다.\n\n왜냐하면 생성자 주입은 독립적으로 인스턴스화가 가능해지는 POJO의 형태를 갖기 때문이다.\n\nDI를 생성자에 걸지 않았다면 어떻게 될까?\n\n아마 테스트 코드를 작성할 때 IoC Container를 불러오거나 Mock객체를 이용해야 하는 빈도가 늘어날 것이다.\n\n결과 자체야 같겠지만 테스트 코드가 더 무거워지고 결합도가 올라간다는 단점이 있는데\n\n더 좋은 방법을 사용하지 않을 이유가 없다.\n\n \n\n인스턴스 변수가 불변성을 가질 수 있다\n\n\n\n보통 MVC 패턴에서 DI가 설정되는 인스턴스 변수는 불변적으로 사용되는 경우가 많기에,\n\n가능하다면 final로 선언해주는 것이 혹시 모를 버그를 미연에 방지할 수 있는 한 방법이 될 수 있다.\n\n참고로 필드 &amp; 수정자 주입은 인스턴스 변수를 final로 선언할 수 없다.\n\n \n\n버그를 더 확실하게 찾아낼 수 있다.\n\n\n\n필드 &amp; 수정자 주입의 경우 얼렁뚱땅 주입이 되고 넘어가서 나중에서야 에러가 발생하는 경우가 많다.\n\n하지만 생성자 주입의 경우 Bean 설정이 잘 못 되어있을 경우 아예 실행 에러가 나버린다.\n\n에러가 숨겨진 채로 애플리케이션이 동작하는 상황이 아예 실행이 안 되는 상황보다 더 무섭다는 것을 알아야 한다.\n\n이와 비슷한 예로 순환 참조(Circular Reference)라는 게 있는데, A가 B를 참조하고 B가 A를 참조하는 상황을 말한다.\n\n@Service\npublic class TestService {\n    @Autowired\n    private TestService2 testService2;\n\n    public void circularReference(){\n        testService2.circularReference2();\n    }\n}\n\n\n\n@Service\npublic class TestService2 {\n    @Autowired\n    private TestService testService;\n\n    public void circularReference2(){\n        testService.circularReference();\n    }\n}\n\n\n\npublic class CircularReferenceTest extends SpringbootApplicationTests {\n    @Autowired\n    private TestService testService;\n\n    @Autowired\n    private TestService2 testService2;\n\n    @Test\n    public void runTest(){\n        testService.circularReference();\n        testService2.circularReference2();\n    }\n}\n\n\n \n\n이런 말도 안 되는 코드가 실제로 실행이 가능하다..!\n\n \n\n  .                           \n /\\\\ / '   ()     \\ \\ \\ \\\n( ( )\\ | ' | '| | ' \\/ ` | \\ \\ \\ \\\n \\\\/  )| |)| | | | | || (| |  ) ) ) )\n  '  || .|| ||| |\\, | / / / /\n =========||==============|/=////\n :: Spring Boot ::                (v2.4.1)\n\n2021-01-23 17:23:08.718  INFO 10780 &amp;nbsp;   [    Test worker] c.s.service.CircularReferenceTest        : Starting CircularReferenceTest using Java 11.0.8 on Changhoon-Han with PID 10780 (started by Han in D:\\Project\\springboot)\n2021-01-23 17:23:08.721  INFO 10780 &amp;nbsp;   [    Test worker] c.s.service.CircularReferenceTest        : No active profile set, falling back to default profiles: default\n2021-01-23 17:23:09.646  INFO 10780 &amp;nbsp;   [    Test worker] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\n2021-01-23 17:23:09.916  INFO 10780 &amp;nbsp;   [    Test worker] c.s.service.CircularReferenceTest        : Started CircularReferenceTest in 1.399 seconds (JVM running for 2.37)\n\njava.lang.StackOverflowError\n\tat com.springboot.service.TestService2.circularReference2(TestService2.java:13)\n\tat com.springboot.service.TestService.circularReference(TestService.java:13)\n\n\n어처구니없게도 실행이 되면서 StackOverflowError가 발생했다.\n\n무한 루프가 발생하니 계속해서 실행이 되다가 스택이 가득 차 버린 것이다.\n\n저렇게 매복한 버그는 발견하기가 매우 귀찮거나 어렵기 때문에 런타임에서 갑자기 나타날 경우 큰 피해가 발생할 수도 있다.\n\n그래서 아예 에러가 뜨면서 실행이 안 돼버리는 게 더 좋다고 이야기하는 것이다.\n\n \n\n그렇다면 생성자 주입으로 설정 한다면 어떻게 될까?\n\n@Service\npublic class TestService {\n    private final TestService2 testService2;\n\n    @Autowired\n    public TestService(TestService2 testService2) {\n        this.testService2 = testService2;\n    }\n\n    public void circularReference() {\n        testService2.circularReference2();\n    }\n}\n\n\n\n@Service\npublic class TestService2 {\n    private fianl TestService testService;\n\n    @Autowired\n    public TestService2(TestService testService) {\n        this.testService = testService;\n    }\n\n    public void circularReference2() {\n        testService.circularReference();\n    }\n}\n\n\n\npublic class CircularReferenceTest extends SpringbootApplicationTests {\n    @Autowired\n    private TestService testService;\n\n    @Autowired\n    private TestService2 testService2;\n\n    @Test\n    public void runTest(){\n        testService.circularReference();\n        testService2.circularReference2();\n    }\n}\n\n\n\nThe dependencies of some of the beans in the application context form a cycle:\n\n   testController defined in file [D:\\Project\\springboot\\build\\classes\\java\\main\\com\\springboot\\controller\\TestController.class]\n┌─────┐\n|  testService defined in file [D:\\Project\\springboot\\build\\classes\\java\\main\\com\\springboot\\service\\TestService.class]\n↑     ↓\n|  testService2 defined in file [D:\\Project\\springboot\\build\\classes\\java\\main\\com\\springboot\\service\\TestService2.class]\n└─────┘\n\n\n보다시피 순환 참조가 발생했다는 경고문이 발생하며 실행 자체가 안된다.\n\n이러면 개발자는 해당 버그를 쉽게 찾아내어 고치고 추후에 발생할 피해를 미연에 방지할 수 있다.\n\n그러니까 가급적이면 생성자 설정을 애용해야겠다.\n\n \n",
      "categories": ["spring","spring-boot"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-boot/2021-01-23-di/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "About the AssertJ",
      "date": "2021-01-24 02:24:00 +0000",
      "description": "테스트 코드 작성 시 가장 많이 쓰게 될 AssertJ에 대한 정리\n",
      "content": "\n  AssertJ Overview\n  AssertJ 인사말\n  AssertJ 시작하기\n\n\n \n\n\n  📜 참고 - AssertJ Docs\n\n\n \n\nAssertJ Overview\n\n\n\n테스트 코드 가독성을 높이고 테스트의 유지보수를 더 쉽게 하기 위해 제작된 라이브러리이다.\n\nJUnit이나 TestNG 또는 기타 테스트 프레임워크와 함께 사용할 수 있다.\n\nJUnit에서 사용하기 위해서는 다음과 같은 Java 버전이 필요하다.\n\n \n\n\n  AssertJ 3.x - Java 8 이상 필요\n  AssertJ 2.x - Java 7 이상 필요\n  AssertJ 1.x - Java 6 이상 필요\n\n\n \n\nAssertJ 3.x는 2.x의 모든 기능을 포함하며 람다와 같은 Java 8의 일부 기능을 지원한다.\n\n \n\nAssertJ 인사말\n\n\n\n제작자가 여가시간에 사이드 프로젝트로 만들었으며\n\n프로젝트에 대한 기여는 언제든지 환영한다고 한다. (오픈 소스라는 뜻)\n\n기여를 하더라도 제작자의 생활이 있기에 빠른 피드백을 주기 힘들 수 있지만,\n\n항상 빠른 피드백을 주기 위해 최선을 다할 것이라고 한다.\n\n \n\nAssertJ 시작하기\n\n\n\n&lt;dependency&gt;\n  &lt;groupId&gt;org.assertj&lt;/groupId&gt;\n  &lt;artifactId&gt;assertj-core&lt;/artifactId&gt;\n  &lt;!-- use 2.9.1 for Java 7 projects --&gt;\n  &lt;version&gt;3.11.1&lt;/version&gt;\n  &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n\n\n \n\nMaven을 사용할 경우 위와 같이 dependency를 포함시켜준다.\n\n \n\ntestCompile(\"org.assertj:assertj-core:3.11.1\")\n\n\n \n\nGradle을 사용할 경우는 위의 코드를 추가해준다.\n\n(Spring Boot은 기본으로 포함시켜준다)\n\n \n\nimport static org.assertj.core.api.Assertions.*;\n\n\n \n\nAssertJ를 사용하기 위해선 항상 위의 패키지를 import 해줘야 한다.\n\n \n\nassertThat(objectUnderTest). // code completion -&gt; assertions specific to objectUnderTest\n\n\n \n\nassertThat을 입력하고 테스트 중인 객체를 매개변수로 전달한 후 .을 입력하면 IDE에 자동완성이 뜰 것이다.\n\n여기서 전달하는 매개변수는 Actually, 실제로 나오는 값이며 뒤에 작성되는 값은 Expected, 기댓값이다.\n\n \n\n\n\n \n\nassertEquals(expected, actual);\n\n\n \n\nJUnit의 위와 같은 단정문은\n\n \n\nassertThat(actual).isEqualTo(expected);\n\n\n \n\nAssertJ에서 이처럼 치환될 수 있다.\n\n(영어처럼 읽히므로 가독성 증가)\n\n혹은\n\n \n\nimport static org.hamcrest.CoreMatchers.is;\nimport static org.junit.Assert.assertThat;\n\nassertThat(result, is(10));\n\n\n \n\nHamcrest Matchers를 import 하여 위와 같이 사용할 수도 있다.\n\n아래는 AssertJ의 사용 예이다.\n\n \n\nConverting JUnit assertions to AssertJ assertions on files matching pattern : *Test.java\n\n 1 - Replacing : assertEquals(0, myList.size()) ............... by : assertThat(myList).isEmpty()\n 2 - Replacing : assertEquals(expectedSize, myList.size()) .... by : assertThat(myList).hasSize(expectedSize)\n 3 - Replacing : assertEquals(expectedDouble, actual, delta) .. by : assertThat(actual).isCloseTo(expectedDouble, within(delta))\n 4 - Replacing : assertEquals(expected, actual) ............... by : assertThat(actual).isEqualTo(expected)\n 5 - Replacing : assertArrayEquals(expectedArray, actual) ..... by : assertThat(actual).isEqualTo(expectedArray)\n 6 - Replacing : assertNull(actual) ........................... by : assertThat(actual).isNull()\n 7 - Replacing : assertNotNull(actual) ........................ by : assertThat(actual).isNotNull()\n 8 - Replacing : assertTrue(logicalCondition) ................. by : assertThat(logicalCondition).isTrue()\n 9 - Replacing : assertFalse(logicalCondition) ................ by : assertThat(logicalCondition).isFalse()\n10 - Replacing : assertSame(expected, actual) ................. by : assertThat(actual).isSameAs(expected)\n11 - Replacing : assertNotSame(expected, actual) .............. by : assertThat(actual).isNotSameAs(expected)\n\n12 - Replacing JUnit static imports by AssertJ ones, at this point you will probably need to :\n12 --- optimize imports with your IDE to remove unused imports\n12 --- add \"import static org.assertj.core.api.Assertions.within;\" if you were using JUnit number assertions with deltas\n\n\n \n\n그 외에 람다나 스트림 등의 assert도 굉장히 많은데,\n\n이건 너무 많아서 추후에 또 정리할 일이 있을 것 같다.\n\n \n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-01-24-assertj/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "Test 용어 정리",
      "date": "2021-01-24 02:24:00 +0000",
      "description": "Test 용어들에 대한 정리\n",
      "content": "\n  📜 단위 테스트(Unit Test)\n  📜 통합 테스트(Integration Test)\n  📜 기능 테스트(Functional Test)\n  📜 테스트 스위트(Test Suite)\n  📜 공유 픽스처(Share Fixture)\n\n\n \n\n\n  📜 참고 - Code Utopia\n\n\n \n\n📜 단위 테스트(Unit Test)\n\n\n\nJUnit 4 or 5의 @Test를 말함.\n\n혹은 테스트 케이스(Test Case)라고도 부름\n\n \n\n📜 통합 테스트(Integration Test)\n\n\n\n여러 단위 코드(Unit)를 묶어서 해보는 것.\n\n각 코드가 복합적으로 실행됐을 때 잘 동작하는지 여부를 확인함.\n\n \n\n📜 기능 테스트(Functional Test)\n\n\n\n정보처리기사에서 블랙박스 테스트(Black Box Test)라고 부르는 기법과 동일하다.\n\n그냥 애플리케이션을 실행시켜서 어떤 기능을 실행했을 때 원하는 결과가 나오는지 확인하는 것이다.\n\n경계값 분석, 동등분할 등의 테스트 기법이 있다.\n\n \n\n📜 테스트 스위트(Test Suite)\n\n\n\n테스트 스위트는 테스트 케이스들을 하나로 묶은 것이다.\n\nJUnit 5의 @TestTemplate과 같은 것을 말하는 듯. (왠지 옛날 용어 같음)\n\n \n\n📜 공유 픽스처(Share Fixture)\n\n\n\n테스트 케이스를 실행하기 전이나 후에 필요한 모든 것들을 테스트 픽스처(Test Fixture)라고 부름.\n\n이를 JUnit 5에서는 @BeforeEach나 @AfterEach 같은 애노테이션으로 작성한다.\n\n공유 픽스처라는 것은 모든 테스트 케이스가 공유하는 픽스처를 말하는데\n\nJUnit 5의 @BeforeAll이나 @AfterAll과 같다고 보면 된다.\n\n잘못 작성된 공유 픽스처는 반복되지 않는 테스트,\n\n테스트 실행 전쟁 같은 부작용(Side Effect)을 낳을 수 있다.\n\n \n\n\n  💡 테스트 실행 전쟁(Test Run War)\n\n  각 테스트에서 동시에 같은 픽스처를 사용하려고 하면서 테스트가 무작위로 실패하게 되는 문제\n\n\n \n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-01-24-test-terms/"
    },{
      "image": "/assets/img/spring/spring-boot/spring-boot-logo.png",
      "title": "Spring Boot 살펴보기",
      "date": "2021-01-24 21:52:00 +0000",
      "description": "Spring Boot 입문\n",
      "content": "\n  그래서 차이점은 ?\n\n\n \n\nSpring 5.x를 공부하다가 Spring Boot 2.x로 넘어왔는데\n\n이건 뭐 전체적인 추상화가 너무너무너무 고수준이고 설정이 전부 다 자동으로 된다. (-ㅅ-)\n\nSpring은 내가 무슨 설정을 안 했는지 찾아야 해서 힘들었는데\n\nSpring Boot는 내가 뭐만 해야 하는지 잘 모르겠어서 헷갈린다.\n\n직접 다 설정해야 하는 Spring에 비해서 너무 편하긴 한데\n\n대체 이게 어떻게 동작하는 건지 이해가 안 되는 경우가 정말 많다.\n\n개발환경 구축하면서 구경하고,\n\n테스트 코드 작성해보면서 또 구경하고,\n\n결국 하루를 통째로 날려먹어서 정리를 해 놔야겠다 싶었다.\n\n \n\n우선 Gradle도 처음이라 전체적으로 뭐가 뭔지는 잘 모르겠는데\n\n딱 보아하니 dependencies에 패키지를 포함시키면 되는 것 같았다.\n\n찾아보니 MavenRepository에 Gradle 코드도 올려져 있기에 편했다.\n\n\n\n \n\n// build.gradle\n\nplugins {\n    id 'org.springframework.boot' version '2.4.1'\n    id 'io.spring.dependency-management' version '1.0.10.RELEASE'\n    id 'java'\n}\n\ngroup = 'com.springboot'\nversion = '0.0.1-SNAPSHOT'\nsourceCompatibility = '11'\n\nconfigurations {\n    compileOnly {\n        extendsFrom annotationProcessor\n    }\n}\n\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    implementation 'org.springframework.boot:spring-boot-starter-thymeleaf'\n    implementation 'org.springframework.boot:spring-boot-starter-web'\n    implementation 'org.bgee.c-log4j2:log4jdbc-log4j2-jdbc4.1:1.16'\n    implementation 'org.mariadb.jdbc:mariadb-java-client:2.7.1'\n    runtimeOnly 'org.mariadb.jdbc:mariadb-java-client'\n    implementation 'org.springframework.boot:spring-boot-starter-data-jpa'\n    compileOnly 'org.projectlombok:lombok'\n    developmentOnly 'org.springframework.boot:spring-boot-devtools'\n    annotationProcessor 'org.projectlombok:lombok'\n    testImplementation 'org.springframework.boot:spring-boot-starter-test'\n}\n\n\ntest {\n    useJUnitPlatform()\n}\n\n\n내가 이번에 학습하고자 하는 패키지를 dependency에 포함시켜주고..!\n\n그다음에 한참을 헤맸는데\n\nSpring 5.x는 Tomcat DBCP가 기본 설정이지만\n\nSpring Boot 2.x부터는 Hikari CP가 기본 DBCP로 바뀌었다고 한다.\n\nSpring 5.x하다와서 그런지 DataSource 설정하고 HikariConfig 설정을 직접 또 하고 있었는데\n\n안돼서 히카리 문서를 찾아보니까 Spring 2.x부터는 그냥 안해도 자동으로 잘 동작한다고 한다.\n\n📜 관련 글 : 2021/01/25 - [일기] - 光 HikariCP\n\n \n\n\n\n \n\n📜 출처 : HikariCP GitHub\n\n\n\n# file: 'application.yml'\nspring:\n  datasource:\n    url: jdbc:mariadb://localhost:3306/*?characterEncoding=UTF-8&amp;serverTimezone=KST\n    username: *\n    password: *\n\n  jpa:\n    show-sql: true\n\n\n참고로 Spring Boot 2.x 기준 클래스패스는 src/main/resources/이다.\n\n기본 설정 파일로 application.properties가 만들어져 있었는데\n\n이 녀석보다 yml(=yaml)이 가독성면에서 더 좋다고 하기에 한번 써봤다.\n\n역시 사람들이 좋다고 하는 데는 다 이유가 있다.(항상 그런건 아니지만)\n\n설정파일은 HikariCP GitHub를 참고하여 설정하였다.\n\n \n\n대충 설정은 끝냈고 커넥션 테스트를 해본다.\n\npublic class HikariTest extends SpringbootApplicationTests {\n\n    @Autowired\n    private HikariDataSource hikariDataSource;\n\n    @Test\n    public void dbConnectionTest() throws Exception {\n        Connection connection = hikariDataSource.getConnection();\n        assertThat(connection).isNotNull();\n        System.out.println(\"connection = \" + connection);\n    }\n\n}\n\n\n\n커넥션이 제대로 추출 되는지 null 체크를 하고,\n\n정확히 어떤 객체가 나오는지 확인하기 위해 콘솔에 표시했다.\n\nconnection = HikariProxyConnection@892903721 wrapping org.mariadb.jdbc.MariaDbConnection@766db6f9\n\n\n테스트 성공과 함께 HikariCP 커넥션 추출이 성공했고,\n\n내부엔 MariaDB의 커넥션 객체가 들어있음을 확인했다.\n\n \n\n대충 이 정도 설정을 마치고 SpringbootApplication을 실행하면..!\n\n\n\n \n\n성공적으로 서버가 기동된다.\n\n \n\n그래서 차이점은 ?\n\n\n\n아직 뭐 제대로 알지도 못하지만 우선 크게 느껴지는 Spring과 Spring Boot의 차이점은\n\n폴더 구조가 전체적으로 다르고 이 구조의 차이에서 가장 중요한 부분은\n\n@SpringBootApplication과 main() 메서드가 선언되어있는 클래스가\n\nTop-level Package 바로 아래에 위치해야 한다는 점이었다.\n\n이는 바뀐 구조와 컴포넌트 스캔 방식때문인 것 같았다.\n\n또한, Spring Boot의 경우 WAS를 내장하고 있기 때문에 따로 설정이 필요 없다는 것과 (배포 시 매우 유용할 듯하다)\n\n그 외에 대부분의 설정이 모두 자동화되어있다는 점이 가장 큰 것 같다.\n\n그 외에는\n\n설정 파일을 application.properties나 application.yml을 사용하도록 권장하고 있으며\n\nDBCP가 Hikari CP이고, 빌드 툴은 Gradle을 주로 사용한다는 점,\n\n템플릿 엔진은 Thymeleaf 를 사용한다는 점 등등이 있겠다.\n\n \n",
      "categories": ["spring","spring-boot"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-boot/2021-01-24-spring-boot-basic/"
    },{
      "image": "/assets/img/backend/hikari-logo.png",
      "title": "Hikari DBCP",
      "date": "2021-01-25 17:50:00 +0000",
      "description": "Hikari DBCP 초고성능 DBCP에 대해 알아봅시다\n",
      "content": "\n  서문\n  성능\n  구성\n  자주 사용되는 속성들\n  자주 사용되지 않는 속성들\n  초기화\n\n\n \n\nSpring 5.x로 학습을 할 때도 HikariCP를 쓰긴 했었다.\n\n그때는 DBCP를 구성해야 하는데 어떤 라이브러리를 쓸지 몰라서 그냥 인터넷에 있는걸 보고 썻었다.\n\n(애초에 DBCP란 용어를 처음 봤었다.)\n\n좀 찾아보니 자카르타 DBCP라고 불리는 Commons DBCP를 쓸 건지 Tomcat DBCP를 쓸 건지 헷갈리던 와중\n\n다른거 다 필요없고 HikariCP가 요즘 성능이 가장 좋다는 포스팅을 봤었기에\n\n별생각 없이 HikariCP로 시작을 하긴 했었는데\n\n막상 학습이 Spring Boot 2.x로 들어오니까 HikariCP가 아예 기본 DBCP였다.\n\n“아 이건 내가 한번 짚고 넘어가야 하는 부분이다” 라는 확신이 생겨서 레퍼런스를 뜯어보았다.\n\n \n\n서문\n\n\n\n시작부터 찬란하다.\n\n눈에 확 띄는 光이라는 한자와 함께 온갖 미사여구가 달려있다.\n\n\n  Fast, simple, reliable. HikariCP is a “zero-overhead” production ready JDBC connection pool. At roughly 130Kb, the library is very light. - 서문\n\n  빠르고, 간단하고, 신뢰성 있다. HikariCP는 “오버헤드가 없는” JDBC 커넥션 풀입니다. 용량은 약 130Kb밖에 안돼서 매우 가볍습니다.\n\n\n\n  “Simplicity is prerequisite for reliability.” - Edsger Dijkstra\n\n  “신뢰성의 전제조건은 단순성이다” - 에츠허르 다익스트라\n\n\n \n\n성능\n\n\n\n\n\n \n\n\n  벤치마크에 사용된 버전\n    \n      HikariCP 2.6.0\n      commons-dbcp2 2.1.1\n      Tomcat 8.0.24\n      Vibur 16.1\n      c3p0 0.9.5.2\n      Java 8u111\n    \n  \n  벤치마크에 사용된 CPU\n    \n      Intel Core i7-3770 CPU @ 3.40 GHz\n    \n  \n  비경쟁 벤치마크\n    \n      32 스레드 / 32 커넥션\n    \n  \n  경쟁 벤치마크\n    \n      32 스레드 / 16 커넥션\n    \n  \n\n\n \n\n위와 같이 시작해서 밑으로 성능지표가 쭉 나열되어 있는데\n\n한마디로 “그냥 HikariCP가 최고니까 이거 쓰세요!”라고 할 수 있겠다.\n\n \n\n구성\n\n\n\n아래 두 가지 속성은 필수적으로 설정해줘야 하는 속성이다.\n\n \n\n\n  📎 HikariCP uses milliseconds for all time values.\n\n  🚨 HikariCP relies on accurate timers for both performance and reliability. It is imperative that your server is synchronized with a time-source such as an NTP server. Especially if your server is running within a virtual\n\n  machine. Why? Read more here. Do not rely on hypervisor settings to “synchronize” the clock of the virtual machine. Configure time-source synchronization inside the virtual machine. If\n\n  you come asking for support on an issue that turns out to be caused by lack time synchronization, you will be taunted publicly on Twitter.\n\n\n \n\nHikariCP는 모든 시간 값에 밀리초 단위를 사용한다고 한다.\n\n또한, 정확한 성능을 위해 NTP(Network Time Protocol)에 의존한다는 것 같다.\n\nNTP는 나도 기억이 잘 안 나긴 하는데, 각 장비의 시간 동기화를 위한 표준이었던 것 같다.\n\nUTC, KST, GMT 이런 거랑 관련이 있을 것같다.\n\n아무튼 특히 VM(Virtual Machine)에서 구동할 때 타임존을 직접 세팅하라는 얘기 같다.\n\n \n\n\n\n \n\n\n  🔠 dataSourceClassName\nThis is the name of the DataSource class provided by the JDBC driver. Consult the documentation for your specific JDBC driver to get this class name, or see the table below. Note XA data sources are not supported. XA requires a real transaction manager like bitronix. Note that you do not need this property if you are using jdbcUrl for “old-school” DriverManager-based JDBC driver configuration. Default: none\n\n\n \n\n- or -\n\n\n  🔠 jdbcUrl\nThis property directs HikariCP to use “DriverManager-based” configuration. We feel that DataSource-based configuration (above) is superior for a variety of reasons (see below), but for many deployments there is little significant difference. When using this property with “old” drivers, you may also need to set the driverClassName property, but try it first without. Note that if this property is used, you may still use DataSource properties to configure your driver and is in fact recommended over driver parameters specified in the URL itself. Default: none\n\n\n \n\n여타 DB커넥션 세팅할 때 많이 보던 것들인데\n\n위 속성을 두 개 다 사용해도 무방하지만 jdbcUrl 속성으로 세팅하는 걸 권장한다고 한다.\n\ndataSourceClassName은 아래 표를 참고해서 하라고 하고 있다.\n\n \n\n\n  \n    \n      Database\n      Driver\n      DataSource class\n    \n  \n  \n    \n      Apache Derby\n      Derby\n      org.apache.derby.jdbc.ClientDataSource\n    \n    \n      Firebird\n      Jaybird\n      org.firebirdsql.ds.FBSimpleDataSource\n    \n    \n      H2\n      H2\n      org.h2.jdbcx.JdbcDataSource\n    \n    \n      HSQLDB\n      HSQLDB\n      org.hsqldb.jdbc.JDBCDataSource\n    \n    \n      IBM DB2\n      IBM JCC\n      com.ibm.db2.jcc.DB2SimpleDataSource\n    \n    \n      IBM Informix\n      IBM Informix\n      com.informix.jdbcx.IfxDataSource\n    \n    \n      MS SQL Server\n      Microsoft\n      com.microsoft.sqlserver.jdbc.SQLServerDataSource\n    \n    \n      MySQL\n      지원 종료\n      com.mysql.jdbc.jdbc2.optional.MysqlDataSource\n    \n    \n      MariaDB\n      MariaDB\n      org.mariadb.jdbc.MariaDbDataSource\n    \n    \n      Oracle\n      Oracle\n      oracle.jdbc.pool.OracleDataSource\n    \n    \n      OrientDB\n      OrientDB\n      com.orientechnologies.orient.jdbc.OrientDataSource\n    \n    \n      PostgreSQL\n      pgjdbc-ng\n      com.impossibl.postgres.jdbc.PGDataSource\n    \n    \n      PostgreSQL\n      PostgreSQL\n      org.postgresql.ds.PGSimpleDataSource\n    \n    \n      SAP MaxDB\n      SAP\n      com.sap.dbtech.jdbc.DriverSapDB\n    \n    \n      SQLite\n      xerial\n      org.sqlite.SQLiteDataSource\n    \n    \n      SyBase\n      jConnect\n      com.sybase.jdbc4.jdbc.SybDataSource\n    \n  \n\n\n \n\n\n\n \n\n\n  🔠 username\nThis property sets the default authentication username used when obtaining Connections from the underlying driver. Note that for DataSources this works in a very deterministic fashion by calling DataSource.getConnection(*username*, password) on the underlying DataSource. However, for Driver-based configurations, every driver is different. In the case of Driver-based, HikariCP will use this username property to set a user property in the Properties passed to the driver’s DriverManager.getConnection(jdbcUrl, props) call. If this is not what you need, skip this method entirely and call addDataSourceProperty(“username”, …), for example. Default: none\n\n\n \n\nDB에 접속할 때 입력하는 사용자 이름을 입력해야 한다.\n\n기본값 : 없음\n\n \n\n\n\n \n\n\n  🔠 password\nThis property sets the default authentication password used when obtaining Connections from the underlying driver. Note that for DataSources this works in a very deterministic fashion by calling DataSource.getConnection(username, *password*) on the underlying DataSource. However, for Driver-based configurations, every driver is different. In the case of Driver-based, HikariCP will use this password property to set a password property in the Properties passed to the driver’s DriverManager.getConnection(jdbcUrl, props) call. If this is not what you need, skip this method entirely and call addDataSourceProperty(“pass”, …), for example. Default: none\n\n\n \n\n역시 DB에 접속할 때 입력하는 사용자 비밀번호를 입력하면 된다.\n\n기본값 : 없음\n\n \n\n\n\n \n\n자주 사용되는 속성들\n\n이제부턴 선택적으로 설정해야 하는 속성들에 대한 설명이다.\n\n\n\n\n  ✅ autoCommit\nThis property controls the default auto-commit behavior of connections returned from the pool. It is a boolean value. Default: true\n\n\n \n\n커넥션이 만료되거나 풀에 반환될 때 내부에 속해있는 트랜잭션을 자동으로 커밋할 것인지를 결정함\n\n기본값 : true\n\n \n\n\n\n \n\n\n  ⌚ connectionTimeout\nThis property controls the maximum number of milliseconds that a client (that’s you) will wait for a connection from the pool. If this time is exceeded without a connection becoming available, a SQLException will be thrown. Lowest acceptable connection timeout is 250 ms. Default: 30000 (30 seconds)\n\n\n \n\n풀에서 커넥션을 가져오기까지 기다리는 시간.\n\n이 시간이 설정된 시간을 넘으면 SQLException을 던짐.\n\n최소 시간은 250 ms이며 기본값은 30,000 ms (30초)\n\n \n\n\n\n \n\n\n  ⌚ idleTimeout\nThis property controls the maximum amount of time that a connection is allowed to sit idle in the pool. This setting only applies when minimumIdle is defined to be less than maximumPoolSize. Idle connections will not be retired once the pool reaches minimumIdle connections. Whether a connection is retired as idle or not is subject to a maximum variation of +30 seconds, and average variation of +15 seconds. A connection will never be retired as idle before this timeout. A value of 0 means that idle connections are never removed from the pool. The minimum allowed value is 10000 ms (10 seconds). Default: 600000 (10 minutes)\n\n\n \n\n풀에서 커넥션이 사용되지 않아도 유지되는 시간.\n\n이 세팅은 minimumIdle이 maximumPoolSize보다 작게 설정되어 있을 때만 유효함.\n\n허용되는 최솟값은 10,000 ms (10초)이며, 기본값은 600,000 ms (10분)이다.\n\n만약 이걸 0으로 설정한다면 커넥션은 사용되지 않더라도 폐기되지 않으며,\n\n이 속성에 정의된 시간이 지나도록 커넥션이 사용되지 않으면 해당 커넥션은 폐기된다.\n\n \n\n\n\n \n\n\n  ⌚ keepaliveTime\nThis property controls how frequently HikariCP will attempt to keep a connection alive, in order to prevent it from being timed out by the database or network infrastructure. This value must be less than the maxLifetime value. A “keepalive” will only occur on an idle connection. When the time arrives for a “keepalive” against a given connection, that connection will be removed from the pool, “pinged”, and then returned to the pool. The ‘ping’ is one of either: invocation of the JDBC4 isValid() method, or execution of the connectionTestQuery. Typically, the duration out-of-the-pool should be measured in single digit milliseconds or even sub-millisecond, and therefore should have little or no noticible performance impact. The minimum allowed value is 30000 ms (30 seconds), but a value in the range of minutes is most desirable. Default: 0 (disabled)\n\n\n \n\n이 속성은 DB나 네트워크 인프라에 의해 연결이 끊어지는 것을 방지하기 위해\n\nHikariCP가 연결을 시도하는 주기를 설정할 때 사용한다고 한다.\n\n기본값 : 사용 안 함\n\n \n\n\n\n \n\n\n  ⌚ maxLifetime\nThis property controls the maximum lifetime of a connection in the pool. An in-use connection will never be retired, only when it is closed will it then be removed. On a connection-by-connection basis, minor negative attenuation is applied to avoid mass-extinction in the pool. We strongly recommend setting this value, and it should be several seconds shorter than any database or infrastructure imposed connection time limit. A value of 0 indicates no maximum lifetime (infinite lifetime), subject of course to the idleTimeout setting. The minimum allowed value is 30000 ms (30 seconds). Default: 1800000 (30 minutes)\n\n\n \n\nIdleTimeout이랑 비슷한 것 같은데 IdleTimeout은 풀 자체에 적용되는 속성이고\n\n이건 각 커넥션 각각에 적용된다는 뜻 같다.\n\n좀 더 강력한 기능인 듯.\n\n이 값은 가급적이면 설정해주는 게 성능상 유리하지만\n\ndB나 인프라에서 지정한 연결 시간보다 몇 초 더 짧아야 한다고 한다.\n\n값을 0으로 지정하면 수명이 무한임을 나타내며\n\n최소 허용 값은 30,000 ms (30초)이고 기본값은 1,800,000 ms (30분)이다.\n\n \n\n\n\n \n\n\n  🔠 connectionTestQuery\nIf your driver supports JDBC4 we strongly recommend not setting this property. This is for “legacy” drivers that do not support the JDBC4 Connection.isValid() API. This is the query that will be executed just before a connection is given to you from the pool to validate that the connection to the database is still alive. Again, try running the pool without this property, HikariCP will log an error if your driver is not JDBC4 compliant to let you know. Default: none\n\n\n \n\n드라이버가 JDBC 4 이상을 지원하면 건들지 말라고 한다.\n\nJDBC 4 이전의 레거시 드라이버를 위한 설정이라고 한다.\n\n기본값 : 없음\n\n \n\n\n\n \n\n\n  🔢 minimumIdle\nThis property controls the minimum number of idle connections that HikariCP tries to maintain in the pool. If the idle connections dip below this value and total connections in the pool are less than maximumPoolSize, HikariCP will make a best effort to add additional connections quickly and efficiently. However, for maximum performance and responsiveness to spike demands, we recommend not setting this value and instead allowing HikariCP to act as a fixed size connection pool. Default: same as maximumPoolSize\n\n\n \n\nHikariCP가 풀에서 유지하려고 하는 최소 커넥션 수를 설정하는 속성이다.\n\n유효한 커넥션이 이 값 아래로 떨어지면(폐기되거나 사용 중인 경우인 듯)\n\nHikariCP는 이 값을 충족하기 위해 최선을 다할 것이며,\n\n가급적이면 기본값을 건들지 않거나 maximumPoolSize와 값을 같게 해 주는 게 좋다고 함.\n\n기본값 : maximumPoolSize와 동일\n\n \n\n\n\n \n\n\n  🔢 maximumPoolSize\nThis property controls the maximum size that the pool is allowed to reach, including both idle and in-use connections. Basically this value will determine the maximum number of actual connections to the database backend. A reasonable value for this is best determined by your execution environment. When the pool reaches this size, and no idle connections are available, calls to getConnection() will block for up to connectionTimeout milliseconds before timing out. Please read about pool sizing. Default: 10\n\n\n \n\n풀에서 유효한 커넥션의 최대 개수를 말함.\n\n이 값을 초과하는 커넥션을 호출할 경우 getConnection()이 connectionTimeout에 설정된 시간 동안 차단된다.\n\n그리고 connectionTimeout이 초과해버리면 SQLException이 발생한다는 뜻으로 보임.\n\n따로 문서도 정의되어 있는걸 보니 아주 중요한 속성으로 사료된다.\n\n기본값 : 10\n\n \n\n\n\n \n\n\n  📈 metricRegistry\nThis property is only available via programmatic configuration or IoC container. This property allows you to specify an instance of a Codahale/Dropwizard MetricRegistry to be used by the pool to record various metrics. See the Metrics wiki page for details. Default: none\n\n\n \n\nIoC container를 사용해 메트릭을 기록할 때 사용한다는데 메트릭이 뭔지 정확히 모르겠다.\n\n유추하기로는 DBCP의 성능지표나 로그를 기록하는 용도인 것 같은데\n\n정확히 아시는 분은 댓글 달아주시면 감사하겠습니다.\n\n기본값 : 없음\n\n \n\n\n\n \n\n\n  📈 healthCheckRegistry\nThis property is only available via programmatic configuration or IoC container. This property allows you to specify an instance of a Codahale/Dropwizard HealthCheckRegistry to be used by the pool to report current health information. See the Health Checks wiki page for details. Default: none\n\n\n \n\nmetricRegistry와 비슷함.\n\n기본값 : 없음\n\n \n\n\n\n \n\n\n  🔠 poolName\nThis property represents a user-defined name for the connection pool and appears mainly in logging and JMX management consoles to identify pools and pool configurations. Default: auto-generated\n\n\n \n\nHikariCP의 이름을 정의할 수 있음.\n\n기본값 : 자동생성\n\n \n\n자주 사용되지 않는 속성들\n\n\n\n\n  ⌚ initializationFailTimeout\nThis property controls whether the pool will “fail fast” if the pool cannot be seeded with an initial connection successfully. Any positive number is taken to be the number of milliseconds to attempt to acquire an initial connection; the application thread will be blocked during this period. If a connection cannot be acquired before this timeout occurs, an exception will be thrown. This timeout is applied after the connectionTimeout period. If the value is zero (0), HikariCP will attempt to obtain and validate a connection. If a connection is obtained, but fails validation, an exception will be thrown and the pool not started. However, if a connection cannot be obtained, the pool will start, but later efforts to obtain a connection may fail. A value less than zero will bypass any initial connection attempt, and the pool will start immediately while trying to obtain connections in the background. Consequently, later efforts to obtain a connection may fail. Default: 1\n\n\n \n\n풀이 초기화되지 못하는 상황이면 빠르게 실패하도록 한다.\n\n기본값은 1이며(양수), 0으로 설정할 경우 빠르게 실패하지 않고 유효성 검사를 시도한 후 실패한다고 함.\n\n \n\n\n\n \n\n\n  ❎ isolateInternalQueries\nThis property determines whether HikariCP isolates internal pool queries, such as the connection alive test, in their own transaction. Since these are typically read-only queries, it is rarely necessary to encapsulate them in their own transaction. This property only applies if autoCommit is disabled. Default: false\n\n\n \n\nautoCommit이 비활성화돼있을 경우에만 작동한다고 한다.\n\n근데 내부 쿼리를 격리한다? (무슨 뜻인지 잘 모르겠다.)\n\n \n\n\n\n \n\n\n  ❎ allowPoolSuspension\nThis property controls whether the pool can be suspended and resumed through JMX. This is useful for certain failover automation scenarios. When the pool is suspended, calls to getConnection() will not timeout and will be held until the pool is resumed. Default: false\n\n\n \n\nJMX를 통해 풀을 중지할 수 있는지 여부를 제어한다. (역시 무슨 뜻인지 잘 모르겠다.)\n\n기본값 : false\n\n \n\n\n\n \n\n\n  ❎ readOnly\nThis property controls whether Connections obtained from the pool are in read-only mode by default. Note some databases do not support the concept of read-only mode, while others provide query optimizations when the Connection is set to read-only. Whether you need this property or not will depend largely on your application and database. Default: false\n\n\n \n\n기본값 : false인데\n\ntrue로 하면 커넥션을 읽기 전용으로만 사용할 수 있다는 것 같다.\n\n(SELECT문만 쓸 수 있는 건가?)\n\n \n\n\n\n \n\n\n  ❎ registerMbeans\nThis property controls whether or not JMX Management Beans (“MBeans”) are registered or not. Default: false\n\n\n \n\nJMX에서 관리하는 Bean (MBeans)의 등록 여부를 결정 (??)\n\n기본값 : false\n\n \n\n\n\n \n\n\n  🔠 catalog\nThis property sets the default catalog for databases that support the concept of catalogs. If this property is not specified, the default catalog defined by the JDBC driver is used. Default: driver default\n\n\n \n\n카탈로그 개념을 지원하는 DB의 카탈로그를 설정한다.\n\n기본값 : 드라이버 기본값\n\n \n\n\n\n \n\n\n  🔠 connectionInitSql\nThis property sets a SQL statement that will be executed after every new connection creation before adding it to the pool. If this SQL is not valid or throws an exception, it will be treated as a connection failure and the standard retry logic will be followed. Default: none\n\n\n \n\n새로운 커넥션이 생성될 때마다 풀에 추가되기 전 특정 SQL문이 실행되도록 설정할 수 있다.\n\n기본값 : 없음\n\n \n\n\n\n \n\n\n  🔠 driverClassName\nHikariCP will attempt to resolve a driver through the DriverManager based solely on the jdbcUrl, but for some older drivers the driverClassName must also be specified. Omit this property unless you get an obvious error message indicating that the driver was not found. Default: none\n\n\n \n\nHikariCP는 jdbcUrl 속성으로 드라이버 연결을 시도하지만\n\n일부 레거시 드라이버의 경우 driverClassName 속성도 설정해주어야만 하는 경우가 있다.\n\n다만 jdbcUrl 속성으로 설정을 했음에도 드라이버를 찾을 수 없다는 에러 메시지가 나타날 때만 설정해야 한다.\n\n기본값 : 없음\n\n \n\n\n\n \n\n\n  🔠 transactionIsolation\nThis property controls the default transaction isolation level of connections returned from the pool. If this property is not specified, the default transaction isolation level defined by the JDBC driver is used. Only use this property if you have specific isolation requirements that are common for all queries. The value of this property is the constant name from the Connection class such as TRANSACTION\\READ\\COMMITTED, TRANSACTION\\REPEATABLE\\READ, etc. Default: driver default\n\n\n \n\n풀에서 리턴되는 커넥션의 트랜잭션 수준을 제어한다.\n\n기본값 : 드라이버 기본값\n\n \n\n\n\n \n\n\n  ⌚ validationTimeout\nThis property controls the maximum amount of time that a connection will be tested for aliveness. This value must be less than the connectionTimeout. Lowest acceptable validation timeout is 250 ms. Default: 5000\n\n\n \n\n커넥션이 활성 상태인지 테스트하는 최대 시간을 설정한다.\n\n이 값은 connectionTimeout보다 작아야 하며\n\n허용 가능한 최소 값은 250 ms이고 기본값은 5,000 ms (5초)이다.\n\n \n\n\n\n \n\n\n  ⌚ leakDetectionThreshold\nThis property controls the amount of time that a connection can be out of the pool before a message is logged indicating a possible connection leak. A value of 0 means leak detection is disabled. Lowest acceptable value for enabling leak detection is 2000 (2 seconds). Default: 0\n\n\n \n\n커넥션이 누수(Leak) 상태임을 나타내는 메시지가 기록되기 전에 풀에서 벗어날 수 있는 시간을 설정한다.\n\n최솟값은 2,000 ms (2초)이며, 기본값 : 0\n\n \n\n\n\n \n\n\n  ➡ dataSource\nThis property is only available via programmatic configuration or IoC container. This property allows you to directly set the instance of the DataSource to be wrapped by the pool, rather than having HikariCP construct it via reflection. This can be useful in some dependency injection frameworks. When this property is specified, the dataSourceClassName property and all DataSource-specific properties will be ignored. Default: none\n\n\n \n\nHikariCP를 구성할 때 IoC container를 통해 사용할 수 있는 속성\n\n이 속성을 사용해 HikariCP를 구성하면 dataSourceClassName 등의 모든 DataSource관련 속성이 무시됨.\n\n기본값 : 없음\n\n \n\n\n\n \n\n\n  🔠 schema\nThis property sets the default schema for databases that support the concept of schemas. If this property is not specified, the default schema defined by the JDBC driver is used. Default: driver default\n\n\n \n\n스키마 개념을 지원하는 모든 DB의 기본 스키마를 설정함\n\n기본값 : 드라이버 기본값\n\n \n\n초기화\n\n\n\nBuild Tool 로 Maven을 사용할 경우 아래와 같이 dependency를 설정하라고 되어 있다.\n\n&lt;!-- file: 'pom.xml'--&gt;\n&lt;!--자바 8~11--&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;com.zaxxer&lt;/groupId&gt;\n  &lt;artifactId&gt;HikariCP&lt;/artifactId&gt;\n  &lt;version&gt;4.0.0&lt;/version&gt;\n&lt;/dependency&gt;\n\n\n\n&lt;!--자바 7 (유지보수 모드)--&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;com.zaxxer&lt;/groupId&gt;\n  &lt;artifactId&gt;HikariCP-java7&lt;/artifactId&gt;\n  &lt;version&gt;2.4.13&lt;/version&gt;\n&lt;/dependency&gt;\n\n\n\n&lt;!--자바 6 (유지보수 모드)--&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;com.zaxxer&lt;/groupId&gt;\n  &lt;artifactId&gt;HikariCP-java6&lt;/artifactId&gt;\n  &lt;version&gt;2.3.13&lt;/version&gt;\n&lt;/dependency&gt;\n\n\n \n\nHikariConfig 클래스를 다음과 같이 설정할 수 있다.\n\n \n\nHikariConfig config = new HikariConfig();\nconfig.setJdbcUrl(\"jdbc:mysql://localhost:3306/simpsons\");\nconfig.setUsername(\"bart\");\nconfig.setPassword(\"51mp50n\");\nconfig.addDataSourceProperty(\"cachePrepStmts\", \"true\");\nconfig.addDataSourceProperty(\"prepStmtCacheSize\", \"250\");\nconfig.addDataSourceProperty(\"prepStmtCacheSqlLimit\", \"2048\");\n\nHikariDataSource ds = new HikariDataSource(config);\n\n\n \n\n혹은 HikariDataSource를 직접 인스턴스화 할 수 있다.\n\n \n\nHikariDataSource ds = new HikariDataSource();\nds.setJdbcUrl(\"jdbc:mysql://localhost:3306/simpsons\");\nds.setUsername(\"bart\");\nds.setPassword(\"51mp50n\");\n\n- - - other attr - - -\n\n\n \n\n혹은 설정 파일을 가져다 사용할 수도 있다.\n\n \n\n// Examines both filesystem and classpath for .properties file\nHikariConfig config = new HikariConfig(\"/some/path/hikari.properties\");\nHikariDataSource ds = new HikariDataSource(config);\n\n\n \n\n위와 같이 설정 파일을 가져오도록 하고,\n\n아래와 같이 설정파일을 따로 만든다\n\n \n\n# file: 'application.properties'\ndataSourceClassName=org.postgresql.ds.PGSimpleDataSource\ndataSource.user=test\ndataSource.password=test\ndataSource.databaseName=mydb\ndataSource.portNumber=5432\ndataSource.serverName=localhost\n\n\n \n\n혹은 java.util.Properties 기반으로도 가능하다\n\n \n\nProperties props = new Properties ();\nprops.setProperty(\"dataSourceClassName\", \"org.postgresql.ds.PGSimpleDataSource\");\nprops.setProperty(\"dataSource.user\", \"test\");\nprops.setProperty(\"dataSource.password\", \"test\");\nprops.setProperty(\"dataSource.databaseName\", \"mydb\");\nprops.put(\"dataSource.logWriter\", new PrintWriter(System.out));\n\nHikariConfig config = new HikariConfig(props);\nHikariDataSource ds = new HikariDataSource(config);\n\n\n \n\njdbcUrl를 사용하여 설정하는 것을 권장한다.\n\njdbcUrl으로 설정이 안 될 경우(레거시 드라이버)에는 dataSourceClassName을 사용해야 한다.\n\nSpring Boot 사용자는 자동으로 구성되므로 jdbcUrl만 설정하면 된다\n\n \n\n# file: 'application.yml'\nspring:\n  datasource:\n    url: jdbcUrl\n    username: username\n    password: password\n    \n# Spring Boot은 이렇게 설정하고\n# Dependency만 포함시켜주면 끝난다. (매우간단)\n\n\n \n\nMySQL은 dataSourceClassName이 지원 중단되었으므로 jdbcUrl을 사용해야 한다.\n\n또한 MySQL에서 최고의 성능을 발휘하기 위해 아래와 같은 설정을 권장한다.\n\n \n\n# file: 'application.properties'\njdbcUrl = jdbc:mysql://localhost:3306/simpsons\n username = test\n password = test\n dataSource.cachePrepStmts = true\n dataSource.prepStmtCacheSize = 250\n dataSource.prepStmtCacheSqlLimit = 2048\n dataSource.useServerPrepStmts = true\n dataSource.useLocalSessionState = true\n dataSource.rewriteBatchedStatements = true\n dataSource.rewriteBatchedStatements.cacheResultSetMetadata = true\n dataSource.cacheServerConfiguration = true\n dataSource.elideSetAutoCommits = true\n dataSource.maintainTimeStats = false\n\n\n \n\n마지막으로 Java8+을 사용하는 걸 권장하고,\n\nslf4j 라이브러리가 있어야 한다.(slf4j는 Spring에서 기본으로 포함)\n\n \n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-01-25-hikari-dbcp/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "BeanDefinitionOverrideException",
      "date": "2021-01-28 10:17:00 +0000",
      "description": "Spring Boot 2+에서 발생하는 예외\n",
      "content": "\n \n\n같은 이름의 Spring Bean이 두개이상 생성되었다는 예외다.\n\nSpring Boot 2.x부터는 Spring 5x가 반영되었다.\n\nSpring 5 부터는 컴포넌트 탐색과정에서 발생하는 오버헤드를 감소시키기 위한 여러가지 정책이 반영되었는데,\n\n그 중에 하나가 생성한 빈을 덮어쓰는 상황을 강제적으로 제한한다.\n\n그래서 동일한 이름을 가진 스프링 빈이 등록되려고 하면 BeanDefinitionOverrideException 이 발생한다.\n\n@Qualifier를 이용해 Spring Bean을 구분하거나\n\n아래와 같은 옵션을 설정파일에 반영해 해당 옵션을 비활성화 시키면 해결된다.\n\nspring.main.allow-bean-definition-overriding: true\n\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-01-28-debugging-3/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "객체(Object)와 자료구조(Data Structures)의 차이가 뭘까?",
      "date": "2021-03-02 19:58:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n📕 클린코드(Clean Code)를 읽다가 의문이 생겼다.\n\n근데 구글링을 아무리 해봐도 책의 내용을 그대로 옮겨쓴 블로그들밖에 없어\n\n현재 의문에 대해 납득이 되는 해답이 생기질 않는다.\n\n \n\npublic class Person {\n  String name; \n  int age; \n}\n\n\n \n\n클린코드 책의 내용을 보면 자료구조에 대해 이런 방식으로 표현한다\n\n내부의 변수를 외부에 공개하는 클래스 정도로 이해가 된다.\n\n의문이 생긴 부분의 내용이다.\n\n \n\n\n  자료/객체 비대칭 앞서 소개한 두 가지 예제는 객체와 자료 구조 사이에 벌어진 차이를 보여준다.\n객체는 추상화 뒤로 자료를 숨긴 채 자료를 다루는 함수만 공개한다.\n자료 구조는 자료를 그대로 공개하며 별다른 함수는 제공하지 않는다.\n문단을 처음부터 다시 읽어보기 바란다.\n두 정의는 본질적으로 상반된다.\n두 개념은 사실상 정반대다.\n사소한 차이로 보일지 모르지만 그 차이가 미치는 영향은 굉장하다.\n\n   \n\n\n위 글을 보면 BigDecimal 같은 경우는 대체 뭔가 싶은 의문이 생긴다.\n\n \n\npublic class BigDecimal extends Number implements Comparable&lt;BigDecimal&gt; { \n  private final BigInteger intVal; \n  private final int scale; \n  private transient int precision; \n  private transient String stringCache;\n  ...\n}\n\n\n \n\n\n\n \n\n모든 필드를 private으로 제한했고, 메서드를 통해 외부에 노출하고있다.\n\n또한 메서드를 통해 내부의 자료를 조작하고 있다.\n\n \n\n전형적인 객체에 대한 설명에 들어맞는데\n\n내 생각에 그럼에도 불구하고 BigDecimal은 분명히 자료구조라고 생각한다.\n\nBigDecimal은 대체로 금액에 관련된 정확한 정수형 값을 가지고 있고,\n\n이는 언제든지 호출해 확인할 수 있기때문이다.\n\n \n\n일단 계속해서 책을 보다보면 BigDecimal은 잡종구조라는 결론으로 귀결되는데,\n\n이후 책에서 잡종구조에 대해 설명하고 있기를\n\n객체와 자료구조의 단점만 모아둔 구조이므로 되도록이면 피하라고 설명하고 있다.\n\n \n\n근데 그렇게 이해하고 넘어가자니\n\n그토록 안좋다고 설명하고있는 잡종구조의 클래스가 자바 패키지에 들어있고,\n\n전세계에서 유용하게 사용되어지고 있는게 맞나? 라는 의문이 생긴다.\n\n그래서 이도저도아닌 상태에서 자료구조는 대체 뭐고 객체는 뭔가라는 의문에서 해답을 찾지 못하고 있다.\n\n \n\n자료구조는 크게보면 객체의 부분집합인가?\n\nDTO는 자료구조인가? 객체인가?\n\n내 생각엔 일단 자료구조인 것 같다.\n\n \n\nObjects vs Data Structures를 보면 이런 구문들이 있다.\n\n \n\npublic class Person {\n  public String firstName; \n  public String lastName; \n  public String phoneNumber; \n}\n\n\n \n\n타 언어들의 자료구조와 비교하며 명백한 자료구조라고 설명하고 있다.\n\n \n\npublic class Person {\n    public String firstName;\n    public String lastName;\n    public String phoneNumber;\n}\n\n\n \n\npublic class Person {\n    private String firstName;\n    private String lastName;\n    private String phoneNumber;\n\n    public String getFirstName() {\n        return firstName;\n    }\n\n    public void setFirstName(String firstName) {\n        this.firstName = firstName;\n    }\n\n    public String getLastName() {\n        return lastName;\n    }\n\n    public void setLastName(String lastName) {\n        this.lastName = lastName;\n    }\n\n    public String getPhoneNumber() {\n        return phoneNumber;\n    }\n\n    public void setPhoneNumber(String phoneNumber) {\n        this.phoneNumber = phoneNumber;\n    }\n\n}\n\n\n \n\n클린코드 책의 내용대로라면 위의 클래스는 자료구조며\n\n아래의 클래스는 객체라고 보는게 맞다고 생각한다.\n\n하지만 필드의 접근제한자가 public 에서 private으로 바뀌었고, 접근자와 수정자가 정의되었으나\n\n여전히 외부에서 Person의 변수가 뭔지 짐작할 수 있고 객체의 목적또한 바뀐것이 없기때문에\n\n본질적으로 두 코드는 같으며 결국 두 클래스 모두 자료구조라고 얘기하고 있다.\n\n \n\n자바빈즈의 경우 접근자와 수정자 없이 필드를 public으로 공개할 경우\n\n프레임워크에서 프로퍼티로 사용하기 위해 접근자와 수정자가 필요하기 때문에\n\n굳이 필드를 private으로 제한하고 모든 필드에 대해 접근자와 수정자를 정의한\n\n표준규약으로 약속되어 사용되고 있다고 납득하고 넘어갈 수는 있었다.\n\n \n\npublic class Person {\n    private String firstName;\n    private String lastName;\n    private String phoneNumber;\n\n    public String getFirstName() {\n        return firstName;\n    }\n\n    public void setFirstName(String firstName) {\n        this.firstName = firstName;\n    }\n\n    public String getLastName() {\n        return lastName;\n    }\n\n    public void setLastName(String lastName) {\n        this.lastName = lastName;\n    }\n\n    public String getPhoneNumber() {\n        return phoneNumber;\n    }\n\n    public void setPhoneNumber(String phoneNumber) {\n        this.phoneNumber = phoneNumber;\n    }\n\n    private void validatePhoneNumber (String phoneNumber) throws FormatException {\n        // Do validation here to ensure we have a legit phone number.\n        // Throw an exception if its invalid.\n    }\n\n}\n\n\n \n\n위의 클래스에 validatePhoneNumber() 라는 핸드폰번호 유효성 검사 메서드가 생겼다.\n\n이제 이 객체에는 다른 목적과 행동(Methods)이 생겼기 때문에 이젠 객체로 볼수 있느냐고 묻는다.\n\n \n\n나는 잡종구조라고 생각했다.\n\n \n\n자료구조도 맞는것 같고 객체도 맞다고 생각했기 때문이다.\n\n하지만 위 글에서는 Person에 유효성검사 기능이 생기므로서 다른 목적과 행동이 생겼으나\n\n여전히 모든 필드가 외부에 공개되어있다시피 하고(캡슐화가 되어있지 않고),\n\n누구나 내부의 자료를 짐작하고 조작할 수 있기 때문에 여전히 자료구조라고 얘기하고 있다.\n\n \n\n\n  No matter how much lipstick you put on this pig, Person is a data structure, not an object.\n\n   \n\n\n심지어 Person 이라는 돼지에 아무리 립스틱을 바르더라도 Person은 객체가 아니고 자료구조라고 한다.\n\n책을 보면서 계속 쓸데없는 의문만 생기고 있는 것 같다. 😭\n\n아무리 고민해도 나혼자는 답을 못찾겠다.\n\n주변에 의견을 구해봐야겠다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-03-02-diary-11/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "Ubuntu 20.04 Jenkins 설치하기",
      "date": "2021-03-07 02:38:00 +0000",
      "description": "CI/CD 필수 툴 Jenkins를 설치해봅시다\n",
      "content": "\n\n\n출퇴근 시간에 지하철에서 핸드폰으로 보려고\n\n네카라쿠배토당야 등 IT 기업들의 기술 블로그의 RSS 피드를 수집하여\n\n링크페이지를 구성해주는 애플리케이션을 만들었다.\n\n백엔드 로직은 개발하는데 쉽게 쉽게 3시간 정도 걸렸는데 프론트단 디자인과 인프라 구축에서 한참을 더 걸렸다.\n\nCI/CD 환경을 처음 구축하면서 젠킨스랑 사투를 벌인 끝에\n\n빌드에 대해 조금 더 자세히 알게 됐고 젠킨스가 어떻게 돌아가는지도 파악하게 된 소중한 경험이었다.\n\n\n\n\n\n\n\nEC2를 우분투 20.04로 선택했다.\n\n젠킨스를 설치할 것이다.\n\n자바 8 또는 11이 설치되어있고, 환경변수가 잡혀있어야 한다.\n\n아래 스크립트를 순서대로 입력한다.\n\n# 리눅스 업데이트\n$ sudo apt-get update &amp;&amp; sudo apt-get upgrade\n\n#자바 11 설치\n$ sudo apt-get install openjdk-11-jdk\n\n#자바설치 후 버전 확인\n$ java -version\nopenjdk version \"11.0.9.1\" 2020-11-04\nOpenJDK Runtime Environment (build 11.0.9.1+1-Ubuntu-0ubuntu1.20.04)\nOpenJDK 64-Bit Server VM (build 11.0.9.1+1-Ubuntu-0ubuntu1.20.04, mixed mode, sharing)\n\n$ javac -version\njavac 11.0.9.1\n\n# 환경변수 편집\n$ sudo nano ~/.bashrc\n\n# 맨 아래에 추가\nexport JAVA_HOME=$(dirname $(dirname $(readlink -f $(which java))))\nexport PATH=$PATH:$JAVA_HOME/bin\n\n# 환경변수 적용\n$ source ~/.bashrc\n\n# 환경변수 확인\n$ echo $JAVA_HOME\n/usr/lib/jvm/java-11-openjdk-amd64\n\n==================================================================================\n\n# 젠킨스 외부 저장소\n$ wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -\n\n$ echo deb http://pkg.jenkins.io/debian-stable binary/ | sudo tee /etc/apt/sources.list.d/jenkins.list\n\n# 저장소 업데이트\n$ sudo apt update\n\n#젠킨스 설치\n$ sudo apt-get install jenkins\n\n#젠킨스는 8080을 쓰는데 스프링부트도 8080을 쓴다. 설정을 변경하자.\n$ sudo nano /etc/default/jenkins\n\n#아래 부분을 사용할 포트로 변경\nHTTP_PORT=8080\n\n#설정 적용을 위한 재시작\n$ sudo service jenkins restart\n\n#초기 패스워드 확인\n$ sudo cat /var/lib/jenkins/secrets/initialAdminPassword\n\n\n\n\nAWS 고정 IP:젠킨스 포트를 웹 브라우저에 입력하여 접속한다.\n\n\n  EX ) 115.6.13.52:8080\n\n\n\n\n\n\n\n\n초기 패스워드를 입력한다.\n\n\n\n\n\n\n\nadmin 계정을 만든다.\n\n\n\n\n\n\n\n젠킨스가 추천하는 플러그인을 설치할 것인지 묻는다.\n\n설치할 것이므로 Install suggested plugins를 선택한다.\n\n\n\n\n\n\n\n젠킨스 서버를 띄우고 접속 성공\n\n\n\n\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-03-07-jenkins/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "AWS 프리티어 EC2 메모리 부족",
      "date": "2021-03-09 23:22:00 +0000",
      "description": "AWS 프리티어 사용시 꼭 명심해야 할 내용\n",
      "content": "\n  프로젝트\n  현상\n  점검\n  해결    \n      스왑 파일 생성        \n          1. dd 명령을 사용하여 루트 파일 시스템에 스왑 파일을 생성한다.\n          2. 스왑 파일에 대한 읽기 및 쓰기 권한을 업데이트\n          3. Linux 스왑 영역을 설정\n          4. 스왑 공간에 스왑 파일을 추가하여 스왑 파일을 즉시 사용할 수 있도록 만든다\n          5. 절차가 성공했는지 확인\n          6. /etc/fstab 파일을 편집하여 부팅 시 스왑 파일을 활성화\n        \n      \n      후기\n    \n  \n\n\n \n\nAWS 프리티어 EC2를 사용 중 겪은 문제다.\n\n깃허브 웹 훅과 젠킨스를 이용한 CI/CD 구축을 성공적으로 마치고\n\njar를 실행하면 스프링 부트가 실행되며 EC2가 먹통이 돼버리는 현상이 발생했다.\n\n젠킨스 로그는 온통 성공했다는 내역뿐이고\n\nEC2가 그냥 갑자기 멈춰버려 시스템 로그조차 없는 상황이었다.\n\n \n\n\n  키보드 입력도 안 먹히고 외부 접속도 안된다. 강제 종료 - 재시작밖에 할 수 없는 상황이었다\n\n\n \n\n젠킨스의 로그는 온통 성공뿐이고, 젠킨스가 쉘 스크립트를 실행한 직후 EC2가 뻗어버려서\n\n“쉘 스크립트가 잘못됐나?”\n\n라는 생각을 갖게 됐다.\n\n그래서 아무 잘못 없는 애꿎은 쉘 스크립트를 붙잡고 반나절을 허비했다.\n\n프로젝트\n\n\n\n\n  spring boot 2.4.3\n  gradle 6.8.2\n  java 11\n  jenkins 2.263.4\n\n\n현상\n\n\n\nJenkins Build Excute Shell 단계\n\njava -jar 명령어 입력 시 EC2가 정지되어 배포가 되지 않는 문제\n\nAWS EC2 대시보드에서 재부팅하면 EC2는 정상화되나 이후 jar 재실행시 계속 멈춤\n\n젠킨스에서 배포 자동화를 시도할 때에만 EC2가 멈추는 문제가 발생하며\n\nSFTP로 EC2 접속해 직접 쉘 스크립트를 동작시키면 정상 배포\n\n점검\n\n\n\ngradle wrapper를 이용한 jar 빌드 자동화 테스트 정상\n\nGitHub push시 webhook을 이용한 jar 빌드 자동화 테스트 정상\n\n위 상황에서 빌드 자동화 후 쉘 스크립트 실행(배포)까지 넣으면 현재 문제 발생\n\ngradle build 완료 후 jar을 이용한 쉘 스크립트\n\n\n\n젠킨스가 job을 끝낼 시 하위 프로세스를 kill 하게끔 설계되어 있어 job이 끝나고\n\n하위 프로세스가 배포를 진행 중 강제로 죽어버리는 상황이 발생.\n\n때문에 dontKillMe 옵션을 추가하여 job이 끝나더라도 하위 프로세스는 죽이지 않도록 설정.\n\nnohup 실행(no hang up) 시 출력 스트림이 종료되지 않아 프로세스가 대기상태로 들어가는 현상이 발생함으로,\n\n출력 스트림을 끊어주기 위해  /dev/null &amp; 옵션 추가\n\n \n\n# file: 'jenkinsScript.sh'\ntarget=/home/ubuntu\njenkins=/var/lib/jenkins/workspace/aaaaa/build/libs\nfilename=aaaaa.jar\n\necho \"deleting ${filename}!\"\ncd $target\nif test -e $filename\nthen sudo rm -f $filename\nfi\necho \"delete done!\"\n\necho \"copying ${filename}!\"\nsudo cp $jenkins/*.jar $target/$filename\nsudo chmod 755 $target/$filename\nsudo chown -R jenkins:jenkins $filename\necho \"copy done!\"\n\necho \"stop service!\"\nsudo pkill -9 -f $filename\nsleep 3\n\n\n빌드후 생성된 jar를 따로 만든 폴더에 복사하고 권한을 젠킨스로 바꿔줌.\n\n그리고 방금 가져온 jar를 실행하기 전에 실행 중인 jar 프로세스를 kill\n\n \n\nChecking out Revision b513a321cdc7a84a6e3b605d69eb23d307dd9822 (refs/remotes/origin/master)\n &gt; git config core.sparsecheckout # timeout=10\n &gt; git checkout -f b513a321cdc7a84a6e3b605d69eb23d307dd9822 # timeout=10\nCommit message: \"웹훅 테스트\"\n &gt; git rev-list --no-walk b513a321cdc7a84a6e3b605d69eb23d307dd9822 # timeout=10\n[Gradle] - Launching build.\n[aaaaa] $ /var/lib/jenkins/workspace/aaaaa/gradlew\nStarting a Gradle Daemon, 3 busy and 1 incompatible and 4 stopped Daemons could not be reused, use --status for details\n&gt; Task :help\n\nWelcome to Gradle 6.8.2.\n\nTo run a build, run gradlew &lt;task&gt; ...\n\nTo see a list of available tasks, run gradlew tasks\n\nTo see a list of command-line options, run gradlew --help\n\nTo see more detail about a task, run gradlew help --task &lt;task&gt;\n\nFor troubleshooting, visit https://help.gradle.org\n\nBUILD SUCCESSFUL in 12s\n1 actionable task: 1 executed\nBuild step 'Invoke Gradle script' changed build result to SUCCESS\n[aaaaa] $ /bin/sh -xe /tmp/jenkins9723117549153308943.sh\n+ /home/ubuntu/aaaaa/jenkinsScript.sh\ndeleting aaaaa.jar!\ndelete done!\ncopying aaaaa.jar!\ncopy done!\nstop service!\nKilled\n+ echo start service!\nstart service!\n+ export JENKINS_NODE_COOKIE=dontKillMe\n+ export BUILD_ID=dontKillMe\n+ echo started service success!\nstarted service success!\n+ nohup java -jar -Duser.timezone=KST /home/ubuntu/aaaaa-1.0.jar &gt;&gt; /dev/null &amp;\nFinished: SUCCESS\n\n\n빌드 - 배포까지 정상적으로 완료됐다는 로그가 뜨며\n\n직후 EC2가 정지됨.\n\n\n\n해결\n\n\n\n문득 어린 시절의 똥컴이 생각나며 “설마…메모리가 부족한가?” 라는 막연한 의심이 생겼다.\n\n프리티어의 사양을 보니 맙소사.. 메모리가 1GB였다.\n\n즉시 EC2를 재부팅시켜 정상화시키고 젠킨스만 띄운 후 메모리를 확인해보니 가용 메모리가 10%가 남은 상태였다.\n\n\n  리눅스에서 메모리의 상태를 확인하는 명령어는 free를 입력하면 된다\n\n\n그 상태에서 스프링 부트를 띄우니 EC2가 멈춰버렸구나 라는 생각이 섬광처럼 스쳐 지나갔다.\n\n메모리를 늘리거나 젠킨스와 스프링 부트를 분리시켜야 한다고 생각했다.\n\n메모리를 늘리자니 과금을 해야 하고 분리시키자니 귀찮았다.\n\nAWS에서 관련 키워드를 검색해보니 리눅스는 하드디스크를 가상 메모리로 전환시켜 사용할 수 있다는 정보를 확인했다.\n\n이를 스와핑(Swapping)이라고 부른댄다.\n\n\n  AWS 고객지원 센터 링크\n\n\nAWS에서는 메모리의 양에 따라 스왑 메모리의 크기를 아래와 같이 권장하고 있다.\n\n \n\n\n  \n    \n      물리적 RAM 크기\n      권장 스왑 메모리\n    \n  \n  \n    \n      RAM 2GB 이하\n      RAM 용량의 2배(최소 32MB)\n    \n    \n      RAM 2GB 초과, 32GB 미만\n      4GB + (RAM – 2GB)\n    \n    \n      RAM 32GB 이상\n      RAM 용량의 1배\n    \n  \n\n\n\n  💥 주의: 스왑 메모리는 절대로 32MB 미만이 되지 않아야 한다.\n\n\n스왑 파일 생성\n\n\n\n$ sudo dd if=/dev/zero of=/swapfile bs=128M count=16\n\n\n1. dd 명령을 사용하여 루트 파일 시스템에 스왑 파일을 생성한다.\n\n\n\n명령에서 bs는 블록 크기이고 count는 블록 수이다.\n\n지정한 블록 크기는 인스턴스에서 사용 가능한 메모리보다 작아야 한다.\n\n그렇지 않으면 memory exhausted 오류가 발생한다.\n\n프리티어의 메모리는 1GB이니, 권장사항대로라면 2GB를 증설시켜야 한다.\n\n이 예제 dd 명령에서 스왑 파일은 2GB(128MB x 16 = 2,048MB)이다.\n\n$ sudo chmod 600 /swapfile\n\n\n2. 스왑 파일에 대한 읽기 및 쓰기 권한을 업데이트\n\n\n\n$ sudo mkswap /swapfile\n\n\n3. Linux 스왑 영역을 설정\n\n\n\n$ sudo swapon /swapfile\n\n\n4. 스왑 공간에 스왑 파일을 추가하여 스왑 파일을 즉시 사용할 수 있도록 만든다\n\n\n\n$ sudo swapon -s\n\n\n5. 절차가 성공했는지 확인\n\n\n\n$ sudo vi /etc/fstab\n\n\n6. /etc/fstab 파일을 편집하여 부팅 시 스왑 파일을 활성화\n\n\n\n/swapfile swap swap defaults 0 0\n\n\n편집기에서 파일을 연 후 파일 끝에 다음 줄을 새로 추가하고 파일을 저장한 다음 종료하고,\n\nfree를 다시 입력하여 메모리를 확인해본다.\n\n\n\n후기\n\n컴퓨터가 뻗어버리면 메모리가 부족할 거라는 생각을 가장 처음으로 했어야 했는데,\n\n평소 메모리 16GB 또는 32GB만 쓰다 보니 애초에 메모리가 부족할 것이라는 생각자체를 못했다.\n\n결과론적으로 보면 정말 어처구니없는 실수다.\n\n그래도 해결해내서 다행이고,\n\n다음에 또 생각지 못한 상황을 마주친다면 그때에는 꼭 기초적인 것부터 점검해나가는 시도를 해야겠다.\n\n그리고 평소 프리티어를 자주 사용하는데, 메모리를 2GB 늘려 총 3GB로 써보니 EC2가 정말 많이 빨라졌다.\n\n앞으로 프리티어를 사용할 일이 생긴다면 이 옵션은 Default로 놓고 가야겠다고 생각했다.\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-03-09-debugging-4/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "한글과 유니코드",
      "date": "2021-03-14 11:34:00 +0000",
      "description": "CS와 PS\n",
      "content": "\n  문제\n  입력\n  출력\n  예제 입력\n  예제 출력\n  풀이    \n      문제를 잘 봐야한다\n    \n  \n\n\n \n\n백준에서 문제를 풀다 문제번호 11283: 한글 2 이라는 문제가 나왔다\n\n문제\n\n\n\n한글의 각 글자는 초성, 중성, 종성으로 이루어져 있고, 이 세 가지를 모아써서 한 글자를 나타낸다.\n\n초성은 ㄱ, ㄲ, ㄴ, ㄷ, ㄸ, ㄹ, ㅁ, ㅂ, ㅃ, ㅅ, ㅆ, ㅇ, ㅈ, ㅉ, ㅊ, ㅋ, ㅌ, ㅍ, ㅎ로 총 19개가 있고, 중성은 ㅏ, ㅐ, ㅑ, ㅒ, ㅓ, ㅔ, ㅕ ㅖ, ㅗ, ㅘ, ㅙ, ㅚ, ㅛ, ㅜ, ㅝ, ㅞ, ㅟ, ㅠ, ㅡ, ㅢ, ㅣ로 총 21개, 종성은 없음, ㄱ, ㄲ, ㄳ, ㄴ, ㄵ, ㄶ, ㄷ, ㄹ, ㄺ, ㄻ, ㄼ, ㄽ, ㄾ, ㄿ, ㅀ, ㅁ, ㅂ, ㅄ, ㅅ, ㅆ, ㅇ, ㅈ, ㅊ, ㅋ, ㅌ, ㅍ, ㅎ로 총 28개가 있다.\n\n첫 번째 글자는 초성에서 ㄱ, 중성에서 ㅏ, 종성에서 없음을 합친 \"가\"가 되고, 두 번째 글자는 초성에서 ㄱ, 중성에서 ㅏ, 종성에서 ㄱ을 합친 \"각\"이 된다. 마지막 글자는 초성에서 ㅎ, 중성에서 ㅣ, 종성에서 ㅎ를 합친 \"힣\"이 된다.\n\n초성과 중성, 그리고 종성을 합쳐서 만들 수 있는 글자의 개수는 총 19*21*28 = 11,172개가 된다.\n\n한글이 주어졌을 때, 몇 번째 글자인지 구하는 프로그램을 작성하시오.\n\n\n입력\n\n\n\n첫째 줄에 글자 하나가 주어진다. \n주어지는 글자는 UTF-8로 인코딩 되어 있는 한글이며, \n문제 설명에 나온 방법으로 만들 수 있다.\n\n\n출력\n\n\n\n입력으로 주어진 글자가 몇 번째인지 출력한다.\n\n\n예제 입력\n\n\n\n가\n\n\n\n\n힣\n\n\n\n\n백\n\n\n예제 출력\n\n\n\n1\n\n\n\n\n11172\n\n\n\n\n4146\n\n\n풀이\n\n\n\n문제를 잘 봐야한다\n\n\n  첫째 줄에 글자 하나가 주어진다.\n주어지는 글자는 UTF-8로 인코딩 되어 있는 한글이며,\n문제 설명에 나온 방법으로 만들 수 있다.\n\n\n얼핏보면 배열을 이용해서 풀 수 있다고도 생각되는데 조금 더 컴퓨터과학적으로 접근해보자\n\nUTF-8은 Unicode의 일종으로 한글을 3Byte로 표현한다\n\n정규식(Regular Expression) 표현상 한글은 가-힣 에 해당하는데\n\n문제를 잘 보면 정규식 표현의 순서를 따라간다\n\n그리고 이는 유니코드 도표의 순서와도 일치한다\n\n가는 유니코드 UTF-8 도표상 EA B0 80 으로 표현된다\n\n자바의 String에서는 codePointAt이라는 메서드를 제공하는데,\n\n이 메서드는 문자열을 내부적으로 UTF-16방식으로 인코딩한 후\n\n이를 char -&gt; int 로 변환한 10진수 정수형 값을 반환해준다\n\nSystem.out.println(\"가\".codePointAt(0)); // 출력: 44032\n\n\n문제에서는 가를 1번 시작으로 정의하고 있으므로 이 값에서 44031을 빼주면 된다\n\npublic class baekjoon_11283 {\n\n    public static void main (String[] args) {\n        Scanner scanner = new Scanner(System.in);\n        String str = scanner.nextLine();\n        System.out.println(str.codePointAt(0) - 44031);\n        scanner.close();\n    }\n\n}\n\n",
      "categories": ["cs","data-structure-algorithm"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/data-structure-algorithm/2021-03-14-unicode/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "Java로 알고리즘 풀 때 유의사항",
      "date": "2021-03-14 23:16:00 +0000",
      "description": "CS와 PS\n",
      "content": "\n  ✅ BufferdReader\n  ✅ StringBuilder\n  ✅ BigInteger, BigDecimal\n\n\n \n\n✅ BufferdReader\n\n\n\n입력 시간을 단축 시키고 싶다면 BufferdReader를 사용한다.\n\nBufferedReader br = new BufferedReader(new InputStreamReader(System.in));\n\n\n너무 좋은 글이 있어 링크를 첨부한다.\n\n\n  JAVA [자바] - 입력 뜯어보기 [Scanner, InputStream, BufferedReader]\n\n\n \n\n✅ StringBuilder\n\n\n\n출력 시간을 단축 시키고 싶다면 StringBuilder를 사용한다.\n\n \n\n\n  출력 시간을 단축시키고 싶다면 여러번의 System.out.print 가 아닌 StringBuilder 혹은 StringBuffer를 사용하여 문자열을 완성하고 한번의 System.out.print 를 호출한다\n  Java의 String은 대표적인 VO(Value Object) 로서 불변성을 갖기 때문에 매번 연산시 새로운 인스턴스를 생성하므로 메모리의 낭비가 심하다\n  StringBuilder와 StringBuffer의 차이는 Thread Safe 여부이며, 단일 Thread의 경우 StringBuilder의 성능이 압도적이므로 알고리즘 풀이 시 StringBuilder사용을 권장한다\n\n\n \n\nStringBuilder stringBuilder = new StringBuilder();\n\nstringBuilder.append(\" _.-;;-._\\n\") \n\t\t\t .append(\"'-..-'| || |\\n\") \n\t\t\t .append(\"'-..-'|_.-;;-._|\\n\") \n\t\t\t .append(\"'-..-'| || |\\n\") \n\t\t\t .append(\"'-..-'|_.-''-._|\"); \n    \nSystem.out.println(stringBuilder);\n\n\n \n\n✅ BigInteger, BigDecimal\n\n\n\n큰 수 계산은 BigInteger, BigDecimal을 사용한다.\n\n \n\n\n  Java의 각 정수 자료형은 다음과 같은 크기를 갖는다\n\n\n// 2^31 \n// -2,147,483,648 ~ 2,147,483,647 \nint iNum; \n\n// 2^63 \n// -9,223,372,036,854,775,808~9,223,372,036,854,775,807 \nlong lNum;\n\n\n\n  이 이상의 크기를 갖는 정수형을 표현하기 위해선 직접정수형↔문자열타입 변환을 통한 문자열 계산을 해야만 한다\n  하지만 이러한 계산을 이미 구현 해놓은 클래스가 바로 BigInteger 와 BigDecimal 이다\n  내부적으로 문자열 연산을 하기에 일반적인 자료형처럼 +, - , *, / , % 등의 연산자를 사용 할 수 없으며, 해당 클래스에 정의된 메서드를 통해 연산을 해야만 한다\n  두 객체의 공통점은 내부적으로 모두문자열계산을 통한 값의 표현을 하기에 사실상 무한한 정수를 표현 할 수 있다(API 문서에 따르면 2^5억의 크기를 표현할 수 있다)\n  두 객체의 차이점으로 BigInteger 는 정수형의 표현을 목표로하며, BigDecimal 은 실수형의 표현을 목표로 하고, 무한한 정밀도를 보장한다\n  BigDecimal 은 완벽에 가까운 정밀도로 인해 돈에 대한 데이터를 다루는 금융권, 핀테크 회사에서 많이 볼 수 있는 자료형이지만, Java에 현존하는 모든 자료형 중 손에 꼽을 만큼 무거운 자료형이므로(클래스 내부 코드라인만 5,000라인, 대부분의 로직이 문자열 연산) PS에 사용 시 TLE(Time Limit Exceeded) 혹은 MLE(Memory Limit Exceeded)가 발생 할 가능성이 있다\n  BigInteger 는 상대적으로 가벼워 알고리즘 풀이에 쏠쏠하게 사용할 수 있으나, 역시 TLE가 발생 할 경우 어쩔수 없이 직접 문자열 연산을 구현해야만 한다\n  생성자를 통해 객체를 생성할 경우 인수로 int, long등의 타입도 넘겨줄 수 있긴하나, API 문서에 따르면 문자열을 넘겨 객체를 생성하는 것을 권장하고 있다\n\n\n \n\n\tBigInteger bigInteger1 = new BigInteger(\"11111111111111111111111111111\");\n\tBigInteger bigInteger2 = new BigInteger(\"22222222222222222222222222222\"); \n\tSystem.out.println(\"bigInteger1: \"+bigInteger1); \n\tSystem.out.println(\"bigInteger2: \"+bigInteger2); \n\tSystem.out.println(\"더하기: \"+bigInteger1.add(bigInteger2)); \n\tSystem.out.println(\"빼기: \"+bigInteger1.subtract(bigInteger2));\n\tSystem.out.println(\"곱하기: \"+bigInteger1.multiply(bigInteger2)); \n\tSystem.out.println(\"나누기: \"+bigInteger1.divide(bigInteger2)); \n\tSystem.out.println(\"나머지: \"+bigInteger1.remainder(bigInteger2)); \n\tSystem.out.println(\"이진수 변환: \"+bigInteger1.toString(2)); \n\tSystem.out.println(\"팔진수 변환: \"+bigInteger1.toString(8)); \n\tSystem.out.println(\"십육진수 변환: \"+bigInteger1.toString(16));\n\t\n//\tbigInteger1:11111111111111111111111111111\n//\tbigInteger2:22222222222222222222222222222\n//\t더하기:33333333333333333333333333333\n//\t빼기:-11111111111111111111111111111\n//\t곱하기:246913580246913580246913580241975308641975308641975308642\n//\t나누기:0\n//\t나머지:11111111111111111111111111111\n//\t이진수 변환:10001111100110111001010100110001000101\n//             00001100101011010100111101100111000111000111000111000111\n//\t팔진수 변환:10763345230424145324754707070707\n//\t십육진수 변환:23e6e54c450cad4f671c71c7\n\n",
      "categories": ["cs","data-structure-algorithm"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/data-structure-algorithm/2021-03-14-java-algorithm/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "IntelliJ IDEA Command line is too long.",
      "date": "2021-03-15 09:30:00 +0000",
      "description": "Spring Boot 2+에서 발생하는 예외\n",
      "content": "\n \n\nError running 'All in project-name': Command line is too long.\n\n\n규모가 큰 프로젝트의 경우 실행 커맨드라인이 너무 길어 발생하는 에러다\n\n(특히 Windows는 경로가 C:~~~~~~~ 매우 길다. Mac에서는 잘 안나는 에러이다)\n\n\n\n&lt;component name = \"PropertiesComponent\"&gt;\n\n\n태그 하위에\n\n&lt;property name=\"dynamic.classpath\" value=\"true\" /&gt;\n\n\n태그를 추가하면 해결된다\n\n \n\n&lt;!--file: '.idea/workspace.xml'--&gt;\n&lt;component name=\"PropertiesComponent\"&gt;\n    &lt;property name=\"dynamic.classpath\" value=\"true\" /&gt; &lt;\n    &lt;property name=\"Git.Branch.Popup.ShowAllRemotes\" value=\"true\" /&gt;\n    &lt;property name=\"RequestMappingsPanelOrder0\" value=\"0\" /&gt;\n    \n     .\n     .\n    중략\n     .\n     .\n     \n    &lt;property name=\"RequestMappingsPanelOrder1\" value=\"1\" /&gt;\n    &lt;property name=\"RequestMappingsPanelWidth0\" value=\"75\" /&gt;\n&lt;/component&gt;\n\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-03-15-debugging-5/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "JPA 엔티티의 id로 Long을 사용하는 이유",
      "date": "2021-03-23 21:47:00 +0000",
      "description": "JPA 짤막 지식\n",
      "content": "\n \n\n@Entity\n@Getter\n@ToString\n@AllArgsConstructor (staticName = \"of\")\npublic class Covid extends BaseTime implements Serializable {\n    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)\n    @Column (name = \"covid_id\")\n    private Long id;\n    private String createDt;\n    private String stateTime;\n    private String updateDt;\n    private int accExamCnt;\n    private int accExamCompCnt;\n    private int careCnt;\n    private int clearCnt;\n    private int deathCnt;\n    private int decideCnt;\n    private int examCnt;\n    private int resultNegCnt;\n    private int seq;\n    private int stateDt;\n    private double accDefRate;\n}\n\n\n \n\nid 값으로 String UUID를 써도 되고 long을 써도 되는데 대부분의 자료에선 래퍼 타입인 Long을 쓴다\n\n왜 그런가 했더니 이런 이유가 있다.\n\nid의 타입이 long일 경우 long은 primitive type이므로 값이 없을 경우 0으로 초기화 된다.\n\n그럼 id가 0일 때 실제로 이 값의 식별자가 0인건지, 아니면 값이 없어서 0인건지 알 수 없다.\n\n \n\n하지만 래퍼 클래스인 Long을 사용할 경우 Object type이기 때문에 nullable하므로\n\n값이 없다면 null이 들어갈 수 있게 되어 null로 초기화가 된다.\n\n식별자가 0이라면 실제로 값이 있고 이 값의 식별자가 0임을 보장해줄 수 있게 된다.\n\n \n\n\n  📜 하이버네이트 API 문서\n\n  We recommend that you declare consistently-named identifier attributes\non persistent classes and that you use a nullable (i.e., non-primitive) type.\n\n\n \n\n공식문서에서도 nullable한 값을 사용하라고 권장하고 있다.\n\n \n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-03-23-what-long/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "Long 동일성 비교",
      "date": "2021-03-23 22:00:00 +0000",
      "description": "Wrapper도 동일성 비교(==)가 된다?\n",
      "content": "\n \n\n지인이 Long 끼리 == 연산을 했더니 이상한 결과가 나오더라는 경험담을 전했다\n\n하지만 나는 평소에 Wrapper로 == 연산을 해볼 생각 자체를 안했었다. 당연히 안될 줄 알아서.\n\n그래서 그 이야기를 듣고 호기심이 생겨서 직접 파봤다\n\n \n\nLong num1 = 127;\nLong num2 = 127;\n\nSystem.out.println(num1 == num2); // true\n\nLong num3 = 128;\nLong num4 = 128;\n\nSystem.out.println(num3 == num4); // false\n\n\n \n\n놀랍게도 Object끼리 == 연산이 된다는 것도 신기한데 128부터 안된다는 게 더 신기했다\n\n바로 Long 구현부를 뜯어보니 Long 클래스는 내부적으로 -128~127의 상수 값을 캐시 하여\n\n이 값으로 == 비교를 수행하고, 이 상수풀을 넘어가는 값이 들어올 경우\n\nvalueOf()를 호출해 새로운 Object를 만들어냄을 확인했다.\n\n \n\npublic static Long valueOf(long l) {\n    final int offset = 128;\n    if (l &gt;= -128 &amp;&amp; l &lt;= 127) { // will cache\n        return LongCache.cache[(int)l + offset];\n    }\n    return new Long(l);\t\n}\n\n\n \n\n따라서 이 상수풀을 넘어가는 Long 타입의 값을 비교하려면 다른 방법을 사용해야 한다\n\n\n  \n    정석대로 Object끼리의 값 비교인 equlas()를 사용한다\n  \n  \n    Wrapper`를 언박싱하여 처리하고 다시 박싱한다\n  \n  \n    Java5 이후로 가능해진 오토박싱, 오토언박싱`을 사용한다\n  \n\n\n \n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2021-03-23-long/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Couldn't checkout ... invalid path ...",
      "date": "2021-04-19 11:06:00 +0000",
      "description": "Git 파일명 특수문자에 의한 오류. OS 호환성에 주의할 것\n",
      "content": "\n  ❗ 증상    \n      ✅ 해결\n    \n  \n\n\n \n\n❗ 증상\n\n\n\n알고리즘 스터디를 진행하며 발생한 오류다.\nmaster 브랜치를 관리하고 있는데, 스터디원들의 운영체제가 모두 달라 발생한 현상이다.\n\nWindows의 파일 시스템(NTFS)에서는 파일명에 일부 특수문자를 사용할 수 없다.\n\n\n\n반면 MacOS의 파일 시스템은 파일명에 특수문자를 사용 할 수 있다.\n\n그래서 이런 특징들로 인해 도대체 무슨 문제가 발생하느냐?\n\n윈도우에서 git pull/checkout을 하려는데 원격 리파지토리에서 내려받으려는 파일명이 특수문자로 작성돼있는 경우\n\n윈도우에선 파일명에 특수문자가 있을 수 없다는 제약으로 인해 해당 파일을 가져올 수 없다는 에러가 발생한다.\n\n\n\n✅ 해결\n\n\n\n세가지 방법이 있다.\n\n\n  가장 좋은 방법으로 파일명에 특수문자를 사용하지 않는다.\n  모든 구성원이 동일한 OS환경을 갖춘다. (어렵다)\n  윈도우에서 아래 명령어를 입력한다.\n\n\ngit config core.protectNTFS false \ngit checkout -f HEAD\n\n\n이 방법은 NTFS를 비활성화 시키는 방법인데,\n\n윈도우에서 pull/checkout을 할 때 파일명에 특수문자가 포함된 파일을 제외하고 가져와버린다.\n\n가장 간단하지만 파일이 손상될 수 있으므로 정말 추천하지 않는 방법이다.\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-04-19-debugging-6/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "정보처리기사 실기 약술형 정리",
      "date": "2021-04-19 11:11:00 +0000",
      "description": "개발일기\n",
      "content": "\n  ✅ WSDL\n  ✅ 데이터마이닝\n  ✅ 인스펙션\n  ✅ 워크스루\n  ✅ ESB\n  ✅ 정규화\n  ✅ 티어드롭\n  ✅ 로킹기법\n  ✅ 병행제어\n  ✅ 살충제 패러독스\n  ✅ 파레토의 법칙\n  ✅ 트랜잭션\n  ✅ 테일러링\n  ✅ 시맨틱 웹\n  ✅ 온톨로지\n  ✅ 트리거\n  ✅ 프로시저\n  ✅ CSRF\n  ✅ 파티셔닝\n  ✅ 테스트 오라클\n  ✅ 동등 분할 테스트\n  ✅ NoSQL\n  ✅ VPN\n  ✅ REST\n  ✅ 외계인 코드(에일리언 코드)\n  ✅ 시스템 카탈로그\n  ✅ 스머프 공격\n  ✅ 알파테스트\n  ✅ 베타테스트\n  ✅ XSS\n  ✅ IPSec\n  ✅ SSL/TLS\n  ✅ 타임스탬프 오더링\n  ✅ 낙관적 검증\n  ✅ 옵티마이저\n  ✅ 보안 운영체제\n  ✅ SDN(Software Defined Network)\n  ✅ NFV(Network Function Virtualization)\n  ✅ 결합도\n  ✅ 응집도\n  ✅ 데이터 흐름도\n  ✅ 자료사전\n  ✅ HIPO(Hierarchy Input Process Output)\n  ✅ 고가용성(HA: High Availability)\n  ✅ 단일 책임 원칙(SRP:Single Reposibility Principle)\n  ✅ CRUD\n  ✅ 데이터베이스 인덱스\n  ✅ 메타데이터\n  ✅ 테스트 케이스\n  ✅ 소프트웨어 아키텍처\n  ✅ API\n  ✅ 오류-부재의 궤변\n  ✅ 데이터베이스 슈퍼키\n  ✅ 관계 대수\n  ✅ 맵리듀스\n  ✅ 그룹 함수\n  ✅ 스레싱\n  ✅ LOC(Lines of Code)\n  ✅ 은행가 알고리즘\n  ✅ 링크 상태 알고리즘\n  ✅ 와이어 프레임\n  ✅ UML\n  ✅ 멀티캐스트 프로토콜\n  ✅ 제어 흐름 테스트\n  ✅ UDDI(Universal Description, Discovery and Integration)\n  ✅ 애자일\n  ✅ 유스케이스 다이어그램\n  ✅ RIP(Routing Information Protocol)\n  ✅ 랜섬웨어\n  ✅ SQL 힌트\n  ✅ 방화벽\n  ✅ 스레드\n  ✅ 델파이 기법\n\n\n \n\n✅ WSDL\n\n\n\n웹 서비스명, 제공 위치, 메시지 포맷, 프로토콜 정보 등 웹 서비스에 대한 상세 정보가 기술된 XML 형식으로 구현돼있는 언어이다.\n\n \n\n✅ 데이터마이닝\n\n\n\n대규모로 저장된 데이터 안에서 체계적이고 자동적으로 통계적 규칙이나 데이터 간의 관계, 패턴, 추세를 발견하고, 이를 의미 있는 정보로 변환하여 기업 의사결정에 활용하는 기술이다.\n\n \n\n✅ 인스펙션\n\n\n\n소프트웨어 요구, 설계, 원시 코드 등의 저작자 외의 다른 전문가 또는 팀이 검사하여 오류를 찾아내는 공식적 검토 기법\n\n \n\n✅ 워크스루\n\n\n\n검토 자료를 회의 전에 배포해서 사전에 검토를 진행한 후 짧은 시간 동안 회의를 통해 코드의 오류를 검출하고 문서화하는 비공식적 기법이다.\n\n \n\n✅ ESB\n\n\n\n기업에서 운영되는 서로 다른 플랫폼(이기종) 및 애플리케이션들 간을 연계해서 관리 운영할 수 있도록 서비스 중심의 통합을 지향하는 아키텍처 또는 기술\n\n \n\n✅ 정규화\n\n\n\n관계형 데이터베이스의 설계에서 중복 최소화될 수 있도록 데이터를 구조화하여, 각 릴레이션에서 이상현상이 생기지 않도록 하는 데이터 모델링 기법이다.\n\n \n\n✅ 티어드롭\n\n\n\nIP 패킷의 재조합 과정에서 잘못된 Fragment Offset 정보로 인해 타겟 시스템이 단편화된 패킷이 재조합 과정에서 문제를 발생하도록 만드는 Dos공격이다.\n\n \n\n✅ 로킹기법\n\n\n\n하나의 트랜잭션이 데이터를 액세스하는 동안, 다른 트랜잭션이 그 데이터 항목에 액세스 할 수 없도록 제어하는 기법이다. 트랜잭션의 격리성과 관련 있음\n\n \n\n✅ 병행제어\n\n\n\n동시에 여러개의 트랜잭션을 수행할 때, 데이터베이스의 일관성 유지를 위해서 트랜잭션 간의 상호 작용을 제어하는 기법이다.\n\n \n\n✅ 살충제 패러독스\n\n\n\n동일한 테스트 케이스로 반복적인 테스트를 수행하면 더 이상 결함을 발견할 수 없다는 테스트의 원리이다.\n\n \n\n✅ 파레토의 법칙\n\n\n\n구성원의 20%가 전체 생산량의 80%를 책임진다는 법칙. 소프트웨어에선 전체 결함의 80%가 20%의 코드영역에서 발생한다고 설명하고 있다.\n\n \n\n✅ 트랜잭션\n\n\n\n데이터베이스 관리 시스템 또는 유사한 시스템에서 하나의 논리적 기능을 정상적으로 수행하기 위한 작업의 기본 단위이자 한꺼번에 모두 수행되어야 할 일련의 연산이다.\n\n \n\n✅ 테일러링\n\n\n\n프로젝트의 특성과 필요에 따라 소프트웨어 개발 프로세스, 기법, 산출물 등을 비즈니스적으로 또는 기술적인 요구에 맞도록 최적화하는 과정 및 방법론이다.\n\n \n\n✅ 시맨틱 웹\n\n\n\n인터넷과 같은 분산환경에서 리소스에 대한 정보와 자원 사이의 관계-의미 정보를 기계(컴퓨터)가 처리할 수 있는 온톨로지 형태로 표현하고, 이를 자동화 된 기계(컴퓨터)가 처리하도록 하는 지능형 웹이다.\n\n \n\n✅ 온톨로지\n\n\n\n실세계에 존재하는 모든 개념들과 개념들의 속성, 그리고 개념들 간의 관계 정보를 컴퓨터가 이해할 수 있도록 서술해 놓은 개념화 명세서\n\n \n\n✅ 트리거\n\n\n\n특정 테이블에 삽입, 수정, 삭제 등의 데이터 변경 이벤트가 발생 시 DBMS에서 자동적으로 실행되도록 구현된 프로그램이다.\n\n \n\n✅ 프로시저\n\n\n\n일련의 SQL 쿼리의 집합으로 마치 하나의 함수처럼 쿼리의 집합을 실행하여 데이터를 조작하는 프로그램이다.\n\n \n\n✅ CSRF\n\n\n\n공격자가 웹 서버의 취약점을 이용하여 악성 스크립트 구문을 삽입하고, 정상적인 사용자로 하여금 자신의 의지와는 무관하게 게시판 설정 변경, 회원 정보 변경 등 공격자가 의도한 행위를 특정 웹사이트에 요청하게 하는 공격이다. CSRF 토큰을 발행하여 이를 미연에 방지한다.\n\n \n\n✅ 파티셔닝\n\n\n\n대용량의 데이터베이스를 파티션이라는 보다 작은 단위로 분할함으로써 관리 용이성, 성능 향상, 가용성 등을 용이하게 하는 기술이다.\n\n샤딩이라는 용어로도 많이 부르며, 일반적으로 테이블의 row가 너무 많을 경우 특정 시점을 기준으로 row를 분할하여 여러개의 테이블로 만드는 행위를 말한다.\n\n \n\n✅ 테스트 오라클\n\n\n\n테스트를 수행한 결과가 참인지 거짓인지를 판단하기 위해서 미리 정의된 참 값을 대입하여 비교하는 기법이다. 테스트 오라클은 테스트 수행 결과를 검증하는 기법을 말한다.\n\n \n\n✅ 동등 분할 테스트\n\n\n\n입력 데이터의 영역을 유사한 도메인별로 유효값/무효값으로 그룹핑해 대표값을 테스트 케이스로 도출하여 테스트하는 기법이다.\n\n \n\n✅ NoSQL\n\n\n\n데이터 저장에 고정된 스키마가 필요하지 않고 조인 연산을 사용할 수 없으며 수평적으로 확장이 가능한 DBMS이다.\n\n일반적으로 JSON과 같이 key=value의 형태로 이루어져있다. 몽고DB등이 이에 해당한다.\n\n \n\n✅ VPN\n\n\n\n인터넷과 같은 공중망에서 터널링, 암호화기법 등을 사용해서 마치 전용회선으로 연결된 사설망과 같은 서비스를 제공하는 가상의 네트워크이다.\n\n \n\n✅ REST\n\n\n\nHTTP URI를 통해 자원을 명시하고, HTTP 메소드를 통해 해당 자원에 대한 CRUD를 적용할 수 있는 분산 하이퍼미디어 시스템을 위한 소프트웨어 아키텍처이다. 로이 필딩이 제안했다.\n\n \n\n✅ 외계인 코드(에일리언 코드)\n\n\n\n배드 코드의 유형으로, 아주 오래되거나 참고문서 또는 개발자가 없어 유지보수 작업이 아주 어려운 응용프로그램의 소스코드이다. 보통 레거시라는 용어로도 많이 부른다.\n\n \n\n✅ 시스템 카탈로그\n\n\n\n데이터베이스에 저장되어 있는 모든 데이터 개체들에 관한 정보나 명세에 대한 정보가 수록되어 있는, DBMS가 생성하고 유지하는 데이터베이스 내의 테이블들의 집합체이다.\n\n \n\n✅ 스머프 공격\n\n\n\n출발지 주소를 공격 대상의 IP로 설정하여 네트워크 전체에 ICMP Echo 패킷을 직접 브로드캐스팅하여 타겟 시스템을 마비시키는 공격기법이다. (DDOS와 유사함)\n\n \n\n✅ 알파테스트\n\n\n\n선택된 사용자가 개발자 환경에서 통제된 상태로 개발자와 함께 수행하는 인수 테스트이다.\n\n \n\n✅ 베타테스트\n\n\n\n실제 운영 환경에서 불특정다수의 사용자에게 대한 소프트웨어를 사용토록 하고 피드백을 받는 인수테스트이다.\n\n \n\n✅ XSS\n\n\n\n크로스 사이트 스크립트의 약자로 공격자가 웹 사이트에 악의적인 스크립트(자바 스크립트 등)을 삽입한 후 악의적인 스크립트가 삽입된 웹 사이트 파일을 사용자에게 보내 사용자가 실행하도록 유도한 후에 사용자의 정보를 탈취하는 공격기법이다. (이메일의 링크를 함부로 클릭하지 말라고 하는 이유가 이 공격때문이다.)\n\n \n\n✅ IPSec\n\n\n\nIP계층(OSI 3계층)에서 무결성과 인증을 보장하는 인증헤더(AH)와 기밀성을 보장하는 암호화(ESP)를 이용하여 양 종단 간 구간에 보안 서비스를 제공하는 터널링 프로토콜이다.\n\n \n\n✅ SSL/TLS\n\n\n\n전송계층(OSI 4계층)과 응용계층(OSI 7계층) 사이에서 클라이언트와 서버간의 웹 데이터와 암호화(기밀성), 상호 인증 및 전송 시 데이터 무결성을 보장하는 보안 프로토콜이다,\n\n \n\n✅ 타임스탬프 오더링\n\n\n\n시스템에서 생성하는 고유 번호인 시간스탬프를 트랜잭션에 부여하는 것으로 트랜잭션 간의 순서를 미리 선택하고 동시성 제어의 기준으로 사용하는 기법이다.\n\n \n\n✅ 낙관적 검증\n\n\n\n트랜잭션을 수행하는 동안 어떠한 검사도 하지 않고, 트랜잭션 종료 시 일괄적으로 검증을 수행하여 데이터베이스에 반영하는 기법이다.\n\n \n\n✅ 옵티마이저\n\n\n\n옵티마이저는 사용자가 질의한 SQL문을 처리할 수 있는 실행계획을 탐색하고 각 실행계획에 대한 비용을 추정하여 최적의 실행계획을 수립하는 DBMS 핵심 엔진이다\n\n \n\n✅ 보안 운영체제\n\n\n\n컴퓨터 운영체제의 커널에 보안 기능 및 참조 모니터링을 추가하여 운영체제의 보안상 결함으로 인하여 발생 가능한 각종 해킹으로부터 시스템을 보호하기 위한 운영체제이다.\n\n \n\n✅ SDN(Software Defined Network)\n\n\n\n오픈 API기반으로 네트워크 장비의 트래픽 경로를 지정하는 컨트롤 플레인과 트래픽 전송을 수행하는 데이터 플레인을 분리하여 네트워크 트래픽을 중앙 집중적으로 관리하는 소프트웨어 기반의 네트워크 기술이다\n\n \n\n✅ NFV(Network Function Virtualization)\n\n\n\nNFV는 범용 하드웨어(서버/스토리지/스위치)에 가상화 기술을 적용하여 네트워크 기능을 가상 기능으로 모듈화하고 필요한 곳에 기능을 제공하는 네트워크 가상화 기술이다.\n\n \n\n✅ 결합도\n\n\n\n결합도는 모듈 내부가 아닌 외부의 모듈과의 연관도나 모듈간의 상호 의존성을 나타내는 정도이다.\n\n \n\n✅ 응집도\n\n\n\n모듈의 독립성을 나타내는 개념으로, 모듈 내부 구성요소 간 연관 정도이다.\n\n \n\n✅ 데이터 흐름도\n\n\n\n데이터가 각 프로세스를 따라 흐르면서 변환되는 모습을 나타낸 그림으로, 시스템 분석과 설계에서 매우 유용하게 사용되는 다이어그램이다\n\n \n\n✅ 자료사전\n\n\n\n자료 요소, 자료 요소들의 집합, 자료의 흐름, 자료 저장소의 의미와 그들간의 관계, 관계 값, 범위, 단위들을 구체적으로 명시하는 사전이다\n\n \n\n✅ HIPO(Hierarchy Input Process Output)\n\n\n\n시스템의 분석 및 설계나 문서화할 때 사용되며 하향식 소프트웨어 개발을 위한 문서화 도구이다.\n\n \n\n✅ 고가용성(HA: High Availability)\n\n\n\n서버, 네트워크, 프로그램 등 정보시스템이 장애에 대응하여 긴 시간 동안 지속적으로 정상 운영이 가능한 상태(성질)을 뜻한다.\n\n \n\n✅ 단일 책임 원칙(SRP:Single Reposibility Principle)\n\n\n\n객체지향(OOP)의 5대 원칙(SOLID)중 하나로,하나의 클래스는 하나의 목적을 위해 생성되고 사용되어야 한다는 원칙이다.\n\n \n\n✅ CRUD\n\n\n\nCreate, Read, Update, Delete로 입력, 읽기, 변경, 삭제를 말한다.\n\n \n\n✅ 데이터베이스 인덱스\n\n\n\n인덱스는 검색 연산의 최적화를 위해 데이터베이스의 특정 컬럼을 복사하여 정렬시켜놓은 자료구조이다. select 쿼리 실행 시 인덱스를 타게 되면 검색 속도가 기하급수적으로 증가한다.\n\n다만 인덱스가 과할 경우 insert, update의 속도가 떨어질 수 있으므로 꼭 필요한 경우에만 사용하도록 해야 한다.\n\n \n\n✅ 메타데이터\n\n\n\n데이터를 설명하기 위한 데이터를 말한다.\n\n \n\n✅ 테스트 케이스\n\n\n\n특정 요구사항에 준수하는지 확인하기 위해 개발된 입력값, 실행조건, 예상된 결과의 집합이다.\n\n \n\n✅ 소프트웨어 아키텍처\n\n\n\n여러가지 소프트웨어 구성요소와 그 구성요소가 가진 특성 중에서 외부에 드러나는 특성, 그리고 구성요소 간의 관계를 표현하는 시스템의 구조이다.\n\n소프트웨어를 설계하고 전개하기 위한 지침과 원칙이며, 제약조건의 묶음이라고도 부른다.\n\n \n\n✅ API\n\n\n\n응용 프로그램에서 사용할 수 있도록 운영체제나 프로그래밍 언어가 제공하는 기능을 제어할 수 있게 만든 인터페이스이다.\n\n \n\n✅ 오류-부재의 궤변\n\n\n\n요구사항을 충족시키지 못하는 소프트웨어는 결함이 없다고 하더라도 품질이 좋다고 볼 수 없다.\n\n \n\n✅ 데이터베이스 슈퍼키\n\n\n\n데이터베이스에서 테이블에 있는 모든 row에 대해 유일성은 만족시키지만, 최소성은 만족시키지 못하는 키이다.\n\n \n\n✅ 관계 대수\n\n\n\n관계형 데이터베이스에서 원하는 정보와 그 정보를 어떻게 유도하는가를 기술하고, 관계로 표현된 데이터를 취급하는 대수적인 연산 체계이자 절차적 정형언어이다.\n\n \n\n✅ 맵리듀스\n\n\n\n구글에서 대용량 데이터 처리를 분산 병렬 컴퓨팅에서 처리하기 위한 목적으로 제작한 소프트웨어 프레임워크이다.\n\n \n\n✅ 그룹 함수\n\n\n\n테이블의 전체 행을 하나 이상의 컬럼을 기준으로 컬럼 값에 따라 그룹화하여 그룹별로 결과를 출력하는 함수이다.\n\n \n\n✅ 스레싱\n\n\n\n어떤 프로세스에 계속적인 페이지 부재가 발생해 프로세스의 실제 처리 시간 보다 페이지 교체 시간이 더 많아지는 현상을 말한다.\n\n \n\n✅ LOC(Lines of Code)\n\n\n\n소프트웨어 각 기능의 원시 코드 라인 수의 낙관치, 중간치, 비관치를 측정하여 예측치를 구하고 이를 이용하여 비용을 산정하는 비용산정 모델이다.\n\n \n\n✅ 은행가 알고리즘\n\n\n\n사전에 작업에 필요한 자원의 수를 제시하고 운영체제가 자원의 상태를 감시, 안정상태일 때만 자원을 프로세스에게 할당하는 교착상태 회피기법이다.\n\n \n\n✅ 링크 상태 알고리즘\n\n\n\n다익스트라 알고리즘을 이용하여 링크 상태 정보를 모든 라우터에 전달하여 최단 경로트리를 구성하는 라우팅 프로토콜 알고리즘이다.\n\n \n\n✅ 와이어 프레임\n\n\n\n이해 관계자들과의 UI 화면 구성을 협의하거나 서비스의 간략한 흐름을 공유하기 위해 화면 단위의 레이아웃을 설계하는 작업이다.\n\n\n\n \n\n✅ UML\n\n\n\n객체지향 소프트웨어 개발 과정에서 산출물을 명세화, 시각화, 문서화할 때 사용되는 모델링 기술과 방법론을 통합해서 만든 표준화된 범용 모델링 언어이다.\n\n \n\n✅ 멀티캐스트 프로토콜\n\n\n\n인터넷에서 같은 내용의 데이터를 여러명의 특정한 그룹의 수신자들에게 동시에 전송할 수 있는 프로토콜이다.\n\n \n\n✅ 제어 흐름 테스트\n\n\n\n프로그램 제어구조를 그래프 형태로 나타내어 내부 로직을 테스트하는 기법이다.\n\n \n\n✅ UDDI(Universal Description, Discovery and Integration)\n\n\n\n웹 서비스에 대한 정보인 WSDL을 등록하고 검색하기 위한 저장소로 공개적으로 접근, 검색이 가능한 레지스트리이자 표준이다.\n\n \n\n✅ 애자일\n\n\n\n절차보다는 사람이 중심이 되어 변화에 유연하고, 프로젝트의 생명주기 동안 반복적으로 시스템을 개발 할 수 있는 신속 적응적 경량 개발 방법론이다. 폭포수 모델(WaterFall) 과 대비되는 개념\n\n \n\n✅ 유스케이스 다이어그램\n\n\n\n시스템이 제공하고 있는 기능 및 그와 관련된 외부 요소를 유스케이스, 액터, 시스템 등을 활용하여 사용자의 관점에서 표현한 다이어그램이다.\n\n \n\n✅ RIP(Routing Information Protocol)\n\n\n\nAS(Autonomous System: 자율 시스템) 내에서 사용하는 거리 벡터 알고리즘에 기초하여 개발된 15홉 제한의 특징이 있는 내부 라우팅 프로토콜이다.\n\n \n\n✅ 랜섬웨어\n\n\n\n악성 코드의 한 종류로 감염된 시스템의 파일들(문서, 사진, 동영상 등)을 암호화하여 복호화 할 수 없도록 하고, 피해자로 하여금 암호화된 파일을 인질처럼 잡고 몸값을 요구하는 악성 소프트웨어이다.\n\n랜섬(몸값) + 웨어(소프트웨어)\n\n \n\n✅ SQL 힌트\n\n\n\nSQL문에 액세스 경로 및 조인 순서 등의 정보를 하드코딩하여 SQL문 실행 계획을 강제하는 기법이다\n\n \n\n✅ 방화벽\n\n\n\n미리 정의된 보안 규칙을 기반으로 외부로부터 불법 침입과 내부의 불법 정보 유출을 방지하고, 내/외부 네트워크의 상호 간 영향을 차단하기 위한 보안 시스템이다.\n\n \n\n✅ 스레드\n\n\n\n프로세스에서 실행 제어만 분리한 실행 단위로 프로세스보다 가볍고, 독립적으로 수행되는 흐름의 단위이다. 한 개의 프로세스는 여러 개의 스레드를 가질 수 있다.\n\n \n\n✅ 델파이 기법\n\n\n\n전문가의 경험적 지식을 통한 문제 해결 및 미래예측을 위한 방법이다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-04-19-diary-12/"
    },{
      "image": "/assets/img/ide/Intellij.png",
      "title": "Json으로 DTO 자동 생성하기",
      "date": "2021-04-19 16:34:00 +0000",
      "description": "DTO generator 사용 방법을 알아봅니다\n",
      "content": "\n \n\n외부 API를 통한 개발을 하다 보면 DTO를 직접 만들어야 하는 경우가 매우 많다.\n\n근데 외부 API가 제공하는 필드가 수십개 이상이라면 DTO를 만드는 일 자체가 무지막지한 노가다가 되기 십상이다.\n\n이때 인텔리제이를 사용하고 있다면 DTO generator라는 플러그인으로 이를 자동화 할 수 있다.\n\n\n\nWindow 10 기준 단축키 Alt + Insert - DTO from JSON\n\n\n\n테스트를 위한 임의의 JSON 을 생성한다.\n\n\n  www.json-generator.com\n\n\n[\n  {\n    \"_id\": \"607d3156142c30528819d2a4\",\n    \"index\": 0,\n    \"guid\": \"70f0588d-d869-423c-8e4e-aaa8f3b5b91d\",\n    \"isActive\": true,\n    \"balance\": \"$2,004.25\",\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 33,\n    \"eyeColor\": \"brown\",\n    \"name\": \"Schmidt Macdonald\",\n    \"gender\": \"male\",\n    \"company\": \"MOLTONIC\",\n    \"email\": \"schmidtmacdonald@moltonic.com\",\n    \"phone\": \"+1 (815) 529-2108\",\n    \"address\": \"570 Ferris Street, Greensburg, New Jersey, 780\",\n    \"about\": \"Incididunt incididunt proident veniam irure enim ipsum et commodo proident occaecat aute nulla sit elit. Laboris Lorem aliquip et pariatur laborum id commodo excepteur cillum irure cupidatat minim. Enim do ut sint dolore qui amet eu cillum sunt incididunt consectetur.\\r\\n\",\n    \"registered\": \"2014-06-17T12:07:21 -09:00\",\n    \"latitude\": -30.624318,\n    \"longitude\": 165.328733,\n    \"tags\": [\n      \"sit\",\n      \"in\",\n      \"ex\",\n      \"ex\",\n      \"quis\",\n      \"dolor\",\n      \"ut\"\n    ],\n    \"friends\": [\n      {\n        \"id\": 0,\n        \"name\": \"Luann Wallace\"\n      },\n      {\n        \"id\": 1,\n        \"name\": \"Finley Juarez\"\n      },\n      {\n        \"id\": 2,\n        \"name\": \"Morris Richards\"\n      }\n    ],\n    \"greeting\": \"Hello, Schmidt Macdonald! You have 2 unread messages.\",\n    \"favoriteFruit\": \"apple\"\n  },\n  {\n    \"_id\": \"607d3156c95b5860bac69af5\",\n    \"index\": 1,\n    \"guid\": \"2dbf28a7-6cef-42db-8a39-79cf867330ea\",\n    \"isActive\": false,\n    \"balance\": \"$1,832.38\",\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 29,\n    \"eyeColor\": \"brown\",\n    \"name\": \"Fay Yang\",\n    \"gender\": \"female\",\n    \"company\": \"FITCORE\",\n    \"email\": \"fayyang@fitcore.com\",\n    \"phone\": \"+1 (834) 432-2007\",\n    \"address\": \"608 Fillmore Avenue, Day, California, 764\",\n    \"about\": \"Nisi culpa occaecat dolore laborum pariatur excepteur minim in cillum sunt. Est non exercitation nostrud culpa. Aute irure elit mollit cillum occaecat ullamco laborum nisi incididunt voluptate deserunt magna fugiat aliqua. Nostrud eu do culpa mollit culpa consectetur ut quis cillum enim esse duis ea.\\r\\n\",\n    \"registered\": \"2020-05-15T06:25:11 -09:00\",\n    \"latitude\": 30.702522,\n    \"longitude\": -75.24621,\n    \"tags\": [\n      \"consectetur\",\n      \"labore\",\n      \"nisi\",\n      \"deserunt\",\n      \"pariatur\",\n      \"anim\",\n      \"nulla\"\n    ],\n    \"friends\": [\n      {\n        \"id\": 0,\n        \"name\": \"Odessa Walls\"\n      },\n      {\n        \"id\": 1,\n        \"name\": \"Austin Wright\"\n      },\n      {\n        \"id\": 2,\n        \"name\": \"Dean Hensley\"\n      }\n    ],\n    \"greeting\": \"Hello, Fay Yang! You have 10 unread messages.\",\n    \"favoriteFruit\": \"banana\"\n  },\n  {\n    \"_id\": \"607d31566edb6dc998d53c6f\",\n    \"index\": 2,\n    \"guid\": \"51e41d3f-aeb1-4c2e-b364-d8adafccf3ec\",\n    \"isActive\": true,\n    \"balance\": \"$3,686.37\",\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 24,\n    \"eyeColor\": \"blue\",\n    \"name\": \"Alice Key\",\n    \"gender\": \"female\",\n    \"company\": \"HELIXO\",\n    \"email\": \"alicekey@helixo.com\",\n    \"phone\": \"+1 (948) 433-3978\",\n    \"address\": \"928 Sandford Street, Herlong, Indiana, 7905\",\n    \"about\": \"Do dolore occaecat veniam ipsum velit mollit eiusmod laborum ipsum esse consectetur reprehenderit consectetur minim. Voluptate laboris duis sit minim. Aliquip deserunt eiusmod fugiat anim eiusmod nostrud nostrud anim consectetur.\\r\\n\",\n    \"registered\": \"2019-06-09T05:21:11 -09:00\",\n    \"latitude\": 75.855307,\n    \"longitude\": 114.791753,\n    \"tags\": [\n      \"ullamco\",\n      \"ad\",\n      \"nostrud\",\n      \"cillum\",\n      \"mollit\",\n      \"id\",\n      \"deserunt\"\n    ],\n    \"friends\": [\n      {\n        \"id\": 0,\n        \"name\": \"Boyle Clayton\"\n      },\n      {\n        \"id\": 1,\n        \"name\": \"Lenora Ellis\"\n      },\n      {\n        \"id\": 2,\n        \"name\": \"Adele Cantrell\"\n      }\n    ],\n    \"greeting\": \"Hello, Alice Key! You have 6 unread messages.\",\n    \"favoriteFruit\": \"strawberry\"\n  },\n  {\n    \"_id\": \"607d31562075cc4afd328069\",\n    \"index\": 3,\n    \"guid\": \"5ceb438d-62e1-4451-acdb-4a440a1aec4d\",\n    \"isActive\": false,\n    \"balance\": \"$2,019.58\",\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 34,\n    \"eyeColor\": \"blue\",\n    \"name\": \"Diana Mcmahon\",\n    \"gender\": \"female\",\n    \"company\": \"MARKETOID\",\n    \"email\": \"dianamcmahon@marketoid.com\",\n    \"phone\": \"+1 (952) 509-3778\",\n    \"address\": \"779 Pilling Street, Allison, Texas, 7453\",\n    \"about\": \"Consectetur sunt esse Lorem id in labore adipisicing pariatur ipsum officia exercitation cupidatat. Anim dolore nostrud commodo magna reprehenderit pariatur ea sunt dolor consectetur irure aliquip. Laborum occaecat nostrud cupidatat mollit et quis aliqua est amet.\\r\\n\",\n    \"registered\": \"2016-04-09T02:15:05 -09:00\",\n    \"latitude\": 88.641443,\n    \"longitude\": 138.585076,\n    \"tags\": [\n      \"excepteur\",\n      \"esse\",\n      \"minim\",\n      \"commodo\",\n      \"deserunt\",\n      \"veniam\",\n      \"reprehenderit\"\n    ],\n    \"friends\": [\n      {\n        \"id\": 0,\n        \"name\": \"Angel Holman\"\n      },\n      {\n        \"id\": 1,\n        \"name\": \"Sherri Barrett\"\n      },\n      {\n        \"id\": 2,\n        \"name\": \"Shannon Morin\"\n      }\n    ],\n    \"greeting\": \"Hello, Diana Mcmahon! You have 10 unread messages.\",\n    \"favoriteFruit\": \"apple\"\n  },\n  {\n    \"_id\": \"607d3156b24dd50ada66f36d\",\n    \"index\": 4,\n    \"guid\": \"11cce06b-71c6-4ca0-82bf-ae5fe4c773d9\",\n    \"isActive\": false,\n    \"balance\": \"$3,831.83\",\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 31,\n    \"eyeColor\": \"blue\",\n    \"name\": \"Camacho Vaughn\",\n    \"gender\": \"male\",\n    \"company\": \"ORBIFLEX\",\n    \"email\": \"camachovaughn@orbiflex.com\",\n    \"phone\": \"+1 (961) 513-3111\",\n    \"address\": \"552 Buffalo Avenue, Kapowsin, Marshall Islands, 9553\",\n    \"about\": \"Id aliquip consectetur dolore veniam dolor aliquip velit sunt anim cillum. In deserunt nostrud aute Lorem id minim ullamco ad consequat anim ex quis. Laborum nostrud do duis id consequat elit deserunt voluptate enim. Cupidatat eu eiusmod dolor dolor duis consequat aliquip. Pariatur et qui reprehenderit enim consectetur do dolor ea veniam eu. Ut officia velit consectetur id occaecat velit.\\r\\n\",\n    \"registered\": \"2015-05-12T10:49:10 -09:00\",\n    \"latitude\": -6.862965,\n    \"longitude\": -124.81059,\n    \"tags\": [\n      \"exercitation\",\n      \"sunt\",\n      \"irure\",\n      \"ut\",\n      \"pariatur\",\n      \"magna\",\n      \"laboris\"\n    ],\n    \"friends\": [\n      {\n        \"id\": 0,\n        \"name\": \"Stevens Hamilton\"\n      },\n      {\n        \"id\": 1,\n        \"name\": \"Salazar Gutierrez\"\n      },\n      {\n        \"id\": 2,\n        \"name\": \"Benson Carney\"\n      }\n    ],\n    \"greeting\": \"Hello, Camacho Vaughn! You have 2 unread messages.\",\n    \"favoriteFruit\": \"apple\"\n  },\n  {\n    \"_id\": \"607d31568c50f2ba61c44204\",\n    \"index\": 5,\n    \"guid\": \"e989d780-ae44-4708-8560-1937a4d3fe6b\",\n    \"isActive\": false,\n    \"balance\": \"$1,730.45\",\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 37,\n    \"eyeColor\": \"blue\",\n    \"name\": \"Mcneil Leach\",\n    \"gender\": \"male\",\n    \"company\": \"APPLIDECK\",\n    \"email\": \"mcneilleach@applideck.com\",\n    \"phone\": \"+1 (834) 580-2201\",\n    \"address\": \"910 Bergen Court, Ventress, Idaho, 9545\",\n    \"about\": \"Velit adipisicing voluptate qui labore do ipsum veniam pariatur. Reprehenderit aliqua tempor deserunt elit officia Lorem. Aliquip ex id eiusmod nulla. Lorem culpa pariatur est amet magna in cupidatat dolor nisi.\\r\\n\",\n    \"registered\": \"2019-08-05T01:47:35 -09:00\",\n    \"latitude\": -1.124338,\n    \"longitude\": -8.656636,\n    \"tags\": [\n      \"ea\",\n      \"velit\",\n      \"culpa\",\n      \"deserunt\",\n      \"ea\",\n      \"sunt\",\n      \"fugiat\"\n    ],\n    \"friends\": [\n      {\n        \"id\": 0,\n        \"name\": \"Guy Stanley\"\n      },\n      {\n        \"id\": 1,\n        \"name\": \"Cathleen Diaz\"\n      },\n      {\n        \"id\": 2,\n        \"name\": \"Fitzgerald Sweeney\"\n      }\n    ],\n    \"greeting\": \"Hello, Mcneil Leach! You have 8 unread messages.\",\n    \"favoriteFruit\": \"banana\"\n  },\n  {\n    \"_id\": \"607d315694e52cd3ec38645b\",\n    \"index\": 6,\n    \"guid\": \"38cb43d4-7a78-4c18-9349-ce83cfff0ecd\",\n    \"isActive\": false,\n    \"balance\": \"$2,836.65\",\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 29,\n    \"eyeColor\": \"green\",\n    \"name\": \"Hebert Williams\",\n    \"gender\": \"male\",\n    \"company\": \"KAGGLE\",\n    \"email\": \"hebertwilliams@kaggle.com\",\n    \"phone\": \"+1 (890) 411-2746\",\n    \"address\": \"558 Glendale Court, Ticonderoga, Maryland, 2994\",\n    \"about\": \"Aute esse voluptate laboris ipsum eiusmod est. Cupidatat consectetur occaecat id deserunt ex veniam dolor consectetur deserunt minim mollit labore eiusmod. Sint tempor nulla Lorem in aliquip. Ut qui laboris ut eiusmod deserunt cupidatat est Lorem. Sunt ad mollit elit est dolore ad. Excepteur cupidatat occaecat minim sunt qui reprehenderit laborum voluptate tempor sint pariatur sunt. Excepteur elit velit aute Lorem cillum laboris duis ad magna nulla fugiat.\\r\\n\",\n    \"registered\": \"2021-02-16T07:06:25 -09:00\",\n    \"latitude\": -73.545452,\n    \"longitude\": -47.98675,\n    \"tags\": [\n      \"enim\",\n      \"consequat\",\n      \"veniam\",\n      \"exercitation\",\n      \"enim\",\n      \"dolor\",\n      \"est\"\n    ],\n    \"friends\": [\n      {\n        \"id\": 0,\n        \"name\": \"Gibson Leonard\"\n      },\n      {\n        \"id\": 1,\n        \"name\": \"Vance Wilcox\"\n      },\n      {\n        \"id\": 2,\n        \"name\": \"Jeannette Tanner\"\n      }\n    ],\n    \"greeting\": \"Hello, Hebert Williams! You have 10 unread messages.\",\n    \"favoriteFruit\": \"banana\"\n  }\n]\n\n\n\n\nGetter와 Setter를 같이 생성하도록 체크할 수 있는데,\n\n요즘은 대부분 Lombok을 사용하기 때문에 굳이 따로 생성할 필요는 없고,\n\n생성 후에 @Getter, @Setter를 붙여주면 된다.\n\nType의 경우 필자가 사용하는 Spring Boot의 경우 Jackson이 기본으로 사용되므로 체크했다.\n\n만약 Gson을 사용한다면 Gson을 체크해주면 될 것이다.\n\n\n\n생성 후 @JsonProperty 가 달린 필드들이 자동으로 생성되는데,\n\n이 플러그인의 단점으로 메인 클래스에 abstract가 선언되고,\n\n내부 클래스에는 static이 선언되므로 이정도만 직접 수정해주고 사용하면 된다.\n\n\n\n\n",
      "categories": ["ide","intellij"],
      "tags": [],
      
      "collection": "posts",
      "url": "/ide/intellij/2021-04-19-dto-generator/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "FileNotFoundException cannot be resolved to absolute ...",
      "date": "2021-04-23 22:56:00 +0000",
      "description": "FileNotFoundException : cannot be resolved to absolute file path because it does not reside in the file system\n",
      "content": "\n  ❗ 증상    \n      ✅ 해결\n    \n  \n\n\n \n\n❗ 증상\n\n\n\n출퇴근길 지하철에서 사용할 토이 프로젝트를 개발하다 발생한 문제다.\n\n이 문제는 Gradle을 사용해 프로젝트를 jar로 빌드하고 jar환경에서 실행하며 나타났다.\n\nif-else를 제거하기 위해 resource 폴더 하위에 json 형식의 프로퍼티 파일을 작성해서 해결했는데,\n\n배포하고 보니 로그에 계속 예외가 뜨는 걸 확인했다.\n\njava.io.FileNotFoundException: class path resource [static/properties/propertiesFactory.json] cannot be resolved to absolute file path because it does not reside in the file system: jar:file:/home/ubuntu/SubscribeTechBlogs-1.0.jar!/BOOT-INF/classes!/static/properties/propertiesFactory.json\n        at org.springframework.util.ResourceUtils.getFile(ResourceUtils.java:217)\n        at org.springframework.core.io.AbstractFileResolvingResource.getFile(AbstractFileResolvingResource.java:154)\n        at toy.subscribe.parser.JsonReader.readUrls(JsonReader.java:16)\n        at toy.subscribe.service.impl.CollectPostServiceImpl.loopCrawl(CollectPostServiceImpl.java:32)\n        at toy.subscribe.service.impl.CollectPostServiceImpl.getAllGroupFeed(CollectPostServiceImpl.java:28)\n        at toy.subscribe.service.impl.CollectPostServiceImpl$$FastClassBySpringCGLIB$$dc747bec.invoke(&lt;generated&gt;)\n        at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)\n        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779)\n        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)\n        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750)\n        at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123)\n        at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388)\n        at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119)\n        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\n        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750)\n        at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:692)\n        at toy.subscribe.service.impl.CollectPostServiceImpl$$EnhancerBySpringCGLIB$$3d4d0c29.getAllGroupFeed(&lt;generated&gt;)\n        at toy.subscribe.scheduler.RSSScheduler.collect(RSSScheduler.java:21)\n        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.base/java.lang.reflect.Method.invoke(Method.java:566)\n        at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)\n        at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)\n        at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n        at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n        at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n        at java.base/java.lang.Thread.run(Thread.java:834)\n\n\n\n로컬에서는 아무런 문제가 없었다.\n\npublic class JsonReader {\n\n    public static List&lt;String&gt; readUrls() throws Exception {\n        File file = ResourceUtils.getFile(\"classpath:properties/propertiesFactory.json\");\n        FileReader reader = new FileReader(file);\n        JSONParser parser = new JSONParser();\n        JSONObject jsonObj = (JSONObject) parser.parse(reader);\n\n        return (ArrayList&lt;String&gt;) jsonObj.get(\"urls\");\n    }\n}\n\n\n보다시피 classpath:를 이용해 resource 하위 폴더에서 json 파일을 읽어오고 있다.\n\n✅ 해결\n\n\n\n파일을 찾지 못한다니 의아했지만(로컬에선 잘됐으니까.. 🤔)\n\n우선 경로를 점검해봤다.\n\njar -tf 파일명 // jar 내부의 내용을 확인하는 명령어\n\n\nBOOT-INF/classes/static/images/favicon.ico\nBOOT-INF/classes/static/images/github.jpg\nBOOT-INF/classes/static/images/blog.png\nBOOT-INF/classes/static/images/yanolja.png\nBOOT-INF/classes/static/images/woowabros.png\nBOOT-INF/classes/static/images/toss.png\nBOOT-INF/classes/static/images/line.png\nBOOT-INF/classes/static/css/\nBOOT-INF/classes/static/css/style.css\nBOOT-INF/lib/\nBOOT-INF/lib/querydsl-apt-4.1.4.jar\nBOOT-INF/lib/poi-ooxml-5.0.0.jar\nBOOT-INF/lib/poi-5.0.0.jar\nBOOT-INF/lib/querydsl-jpa-4.4.0.jar\nBOOT-INF/lib/json-simple-1.1.1.jar\nBOOT-INF/lib/mysql-connector-java-8.0.23.jar\nBOOT-INF/lib/querydsl-codegen-4.1.4.jar\nBOOT-INF/lib/jdo-api-3.0.1.jar\nBOOT-INF/lib/spring-boot-autoconfigure-2.4.3.jar\nBOOT-INF/lib/spring-boot-2.4.3.jar\nBOOT-INF/lib/jakarta.transaction-api-1.3.3.jar\nBOOT-INF/lib/jakarta.persistence-api-2.2.3.jar\nBOOT-INF/lib/hibernate-core-5.4.28.Final.jar\nBOOT-INF/lib/spring-data-jpa-2.4.5.jar\nBOOT-INF/lib/spring-aspects-5.3.4.jar\nBOOT-INF/lib/thymeleaf-spring5-3.0.12.RELEASE.jar\nBOOT-INF/lib/thymeleaf-extras-java8time-3.0.4.RELEASE.jar\nBOOT-INF/lib/jakarta.el-3.0.3.jar\nBOOT-INF/lib/hibernate-validator-6.1.7.Final.jar\nBOOT-INF/lib/spring-webmvc-5.3.4.jar\n\n\n\njar로 빌드하게되면 보다시피 내부의 경로가 바뀌므로\n\n기존의 코드로는 읽지 못하게 되어 FileNotFoundException 예외가 발생하게 됐다.\n\n이를 해결하기 위해 파일을 읽어오는 작업을 ClassLoader에 위임해야 했다.\n\n따라서 내부 json 파일에 InputStream을 열고\n\nInputStream을 활용해 File 객체를 생성한 후 사용했다.\n\npublic class JsonReader {\n\n    public static List&lt;String&gt; readUrls() throws Exception {\n        FileReader reader = new FileReader(createInputStreamToFile());\n        JSONParser parser = new JSONParser();\n        JSONObject jsonObj = (JSONObject) parser.parse(reader);\n\n        return (ArrayList&lt;String&gt;) jsonObj.get(\"urls\");\n    }\n\n    private static File createInputStreamToFile() throws IOException {\n        InputStream inputStream = new ClassPathResource(\"static/properties/propertiesFactory.json\").getInputStream();\n        File file = File.createTempFile(\"propertiesFactory\", \".json\");\n        try {\n            FileUtils.copyInputStreamToFile(inputStream, file);\n        }\n        finally {\n            IOUtils.closeQuietly(inputStream);\n        }\n        return file;\n    }\n\n}\n\n\n \n\n비효율적인 것 같지만 어쩌겠나.. 일단 돌리고 봐야지 😢\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-04-23-debugging-7/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Bootstrap pagination",
      "date": "2021-04-23 23:02:00 +0000",
      "description": "모바일에서 페이지 버튼이 잘리는 현상 발생\n",
      "content": "\n \n\n나는 프론트 삼대장(html, css, javascript)과 친하지 않다.\n\n서버 개발자이기 때문이다(?)\n\n아무튼 그래서 평소에 bootstrap을 정말 많이 사용한다.\n\n솔직히 이거 만든사람은 노벨상을 줘야하지 않을까 생각한다. 너무너무 감사하다. 🙇‍♂️\n\n각설하고, bootstrap의 pagination을 그냥 사용 할 경우 모바일에서 잘리는 현상이 발생함을 확인했다.\n\n \n\n&lt;div &gt;\n     &lt;ul class=\"pagination justify-content-center\" id=\"pagingArea\" &gt;&lt;/ul &gt;\n&lt;/div &gt;\n\n\n \n\n\n\n \n\n당연히 이미 뭔가 만들어져 있는게 있지 않을까하는 생각에\n\nBootstrap docs를 찾아보니,\n\npagination-sm 이라는 클래스를 달면 된다는 내용을 확인했다.\n\n \n\n\n\n \n\n역시 문제 생기면 메뉴얼 확인하는 것 만큼 좋은게 없다.\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-04-23-debugging-8/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "수습 딱지를 떼며...",
      "date": "2021-04-23 23:25:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n요즘 정말 정신없이 바빠서 통 포스팅을 할 여유가 없다.\n\n \n\n비전공자로서 작년 8월쯤부터 개발 공부를 본격적으로 시작해 2월 1일에 현재 다니고 있는 회사에 입사했다.\n\n공부하던 기간에는 아침 6시에 일어나서 저녁 11시까지 공부하고 자며 정말 힘들었었는데 웬걸, 취업하고 보니 더 힘든 것 같다.\n\n \n\n회사 업무를 마치면 귀가 후 스터디 운영하고, 토이 프로젝트 진행하고, 책을 보거나 강의도 들어야 하고, 내가 사용하는 기술들의 문서도 계속 봐야 했다.\n\n그 와중에 정보처리기사 실기시험까지 준비를 해야 했다. 🤢\n\n \n\n정보처리기사는 당초 CS 기초를 공부하려고 시작한 건데, 필기시험을 공부하면서 정말 너무 많은 도움이 됐었다.\n\n근데 실기는 공부를 하면 할수록 의미 없다는 생각이 너무 강하게 들지 않나?\n\n막말로 현업에서 온톨리지라던가 테스트 오라클 같은 용어는 듣지도 보지도 못했고, 유닉스가 몇 년도에 개발된 게 대체 나랑 무슨 상관이 있나 싶더라…\n\n그야말로 실무랑 아무런 관련 없는 내용들이니 닥치고 암기의 연속인데, 시험 한번 치고 두 번 다시 쓸 일 없는 내용들이 암기가 잘 될 리가 만무하지 않은가?\n\n재미도 감동도 없는 그저 무의미한 시간 때려 박기일뿐…\n\n \n\n실기 공부를 붙잡고 있을수록 강하게 드는 생각이\n\n \n\n“아.. 이 시간에 내가 Spring Boot 문서를 보면 얻는 게 훨씬 많을 텐데…“\n\n \n\n따위의 생각들이었다.\n\n \n\n빨리 붙고 때려치웠으면 좋겠는데 개정 후 범위가 너무 광범위하고 기출문제는 없고, 외워야 할 건 많은데 잘 외워지진 않고. 이거랑 언제까지 씨름할지 막막하다. 😥\n\n \n\n최근 출퇴근길에 지하철에서 책 보기가 힘들어서(종이책을 선호하는 사람😎) 핸드폰으로 유명 IT기업들의 기술 블로그들을 접근성 좋게 보려고 토이 프로젝트를 진행했다.\n\n \n\n\n\n \n\n모바일 환경에 특화되게 만든 건데 만들고 보니 정말 큰 교훈을 얻은 게 있다.\n\n그게 뭐냐하면, 취업할 때는 포트폴리오랍시고 내가 두 번 다시 쓸 일도 없는 것들을 만들었었기에 그야말로 취업용 포트폴리오로서의 1회용 프로젝트가 됐었는데, 내가 필요한 걸 만드니 계속 사용 -&gt;계속 업데이트 -&gt;계속 리팩토링 의 선순환이 반복됐다.\n\n그 와중에 DAU도 50~100명으로 꾸준히 나와주니 보람도 많이 느껴졌다.\n\n좋은 기술 블로그를 찾으면 계속 추가하고, 채용공고나 컨퍼런스 같은 뉴스들도 빠르게, 접근성 좋게 뿌려보려고 계획 중이다.\n\n \n\n요즘 참 힘들지만 그래도 알찬 시간을 보내고 있다는 생각이 든다.\n\n남들과 비교하기 시작하면 그 순간이 불행의 시작이라는 걸 이미 잘 알고 있다.\n\n남들보다 느리고 빠르고는 중요하지 않다.\n\n \n\n비록 느리더라도 밥알을 한 톨 한 톨 정성스레 눌러 담듯, 내 페이스대로 기본기를 충실하게 다지고 좋은 습관들을 착실하게 들이다 보면 언젠가 당당하게 1인분의 몫을 해내는 좋은 개발자가 돼있을 거라 확신한다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-04-23-diary-13/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "Jmeter 맛보기",
      "date": "2021-04-26 19:48:00 +0000",
      "description": "자바 플랫폼 성능 분석 도구\n",
      "content": "\n  🤔 Jmeter?\n  📜 Documentation\n  🚀 Test\n\n\n\n\n\n\n\n\n🤔 Jmeter?\n\n\n\n간단하게 이해하자면 내가 구축한 서버가 어느 정도의 트래픽을 버텨낼 수 있는지 측정할 수 있게 해주는 툴이다.\n\n비슷한 툴로 네이버가 개발한 nGrinder 등이 있다.\n\n내가 이 Jmeter를 검색해서 실행해보게 된 계기는 HikariCP 때문이었다.\n\n회사에서 스프링 부트를 사용하다 보니 DBCP는 HikariCP로 설정돼있었는데,\n\n피크타임에 DB에 병목이 생기는 경우가 종종 있어서 찾아보게 됐다.\n\n이때 HikariCP의 커넥션 풀 사이즈가 200으로 설정돼있었고,\n\n나도 평소에\n\n\n\n“풀사이즈? 그거 하드웨어가 허락하는 한 클수록 좋은 거 아니야?”\n\n\n\n라는 단순한 생각을 갖고 있었는데,\n\nDB병목 관련 이것저것 찾아보다 HikariCP 문서를 다시 한번 세심하게 보게 됐다.\n\n\n\n📜 Documentation\n\n\n\n여기서 maximumPoolSize 옵션에 대한 하위 문서를 보고 약간의 충격을 받았다.\n\n\n\n\n\n\n\n내용에 대해 말해보자면, 만 명의 사용자가 DB커넥션을 요청하는 사이트의 경우 대략적으로 20,000 TPS가 발생한다고 한다.\n\n이때 히카리의 커넥션 풀 사이즈가 얼마나 되어야 효율적이냐는 질문에 오히려 얼마나 적어야 효율적인지 물어야 한다고 한다. (엥?🤔)\n\n그러면서 그 이유로 CPU의 멀티쓰레딩에 대해 이야기한다.\n\n하나의 CPU 코어가 수십 또는 수백 개의 쓰레드를 동시에 처리할 수 있다고 하나, 이는 실제로는 CPU가 한번에 처리하는 작업은 쓰레드 하나에 국한되며 단지 이 속도가 말도안되게 빨라 동시에 진행되는 것처럼 보이고, 이렇게 하나의 코어가 여러개의 쓰레드를 처리하는 환경에선 소위 컨텍스트 스위칭이라고 하는 작업이 많이 발생하여 큰 오버헤드가 생기기에 비 효율적이라고 설명하고 있다.\n\n히카리의 풀 사이즈를 결정하는 요소에는 세 가지가 있다.\n\n\n\n\n  \n    CPU 코어\n  \n  \n    디스크\n  \n  \n    네트워크\n  \n\n\n\n\n정말 간단하게 디스크와 네트워크를 배제하고 이야기하면,\n\n8코어 CPU를 사용한다고 하면 커넥션 풀 사이즈가 8개일 때 최고의 효율을 발휘한다고 한다.\n\n그 이상 적용하면 컨텍스트 스위칭으로 인해 오히려 성능 저하가 발생하기 시작할 것이라는 설명이다.\n\n다만 디스크와 네트워크를 배제할 수 없기 때문에 히카리의 커넥션 풀 기본 사이즈가 10인 걸로 추정된다.\n\n히카리의 풀 사이즈로 어느 정도의 크기가 적당 하겠느냐에 대해 아래와 같은 공식을 예제로 보여준다.\n\n\n\n\n  The calculation of pool size in order to avoid deadlock is a fairly simple resource allocation formula:\n\n  pool size = Tnx (Cm\\- 1) + 1\n\n  Where Tn is the maximum number of threads, andCmis the maximum number ofsimultaneous connectionsheld by a single thread. \nFor example, imagine three threads (Tn=3), each of which requires four connections to perform some task (Cm=4). The pool size required to ensure that deadlock is never possible is:\n\n  pool size = 3 x (4 - 1) + 1 = 10\n\n  Another example, you have a maximum of eight threads (Tn=8), each of which requires three connections to perform some task (Cm=3). The pool size required to ensure that deadlock is never possible is:\n\n  pool size = 8 x (3 - 1) + 1 = 17\n\n\n\n\n🚀 Test\n\n\n\n아무튼 진짜 본론으로 들어가서\n\n이러한 이유들로 인해 풀 사이즈가 어느 정도여야 가장 좋은 효율을 낼 수 있을까?라는 의문으로 시작해\n\n열심히 구글을 뒤지다가 Jmeter를 알게 됐고, 정말 실험 같지도 않은 간단한 실험을 해보게 됐다.\n\n관련 문서를 보고 Jmeter를 설치, 설정하고 테스트를 시작했다.\n\n결과가 정말 놀라운데\n\n\n\n\n\n\n\n\n  실험 컴퓨터 CPU : 6코어\n  QPS : 10,000\n  y축 한 칸 : 2,000 TPS\n  파란색 : 커넥션 풀 사이즈\n  분홍색 : 요청 성공\n  빨간색 : 요청 실패\n\n\n\n\n히카리의 기본 세팅인 10에서 가장 좋은 퍼포먼스를 보였고 역시 6코어이기 때문에 디스크와 네트워크 등의 요청으로 인해 커넥션이 부족해 풀사이즈 6에서 많은 실패가 발생했다.\n\n놀라운 부분은 풀사이즈 100에서 미친듯한 요청 실패가 발생했다.\n\n100에서 저러니 200에선 얼마나 더 큰 오버헤드가 발생할 것이며, 어떤 실패들이 발생할지 대략 짐작이 됐다.\n\n아무튼 결론적으로 풀사이즈를 재조정해서 배포했고 나름 효과를 보았던 것 같다.\n\n주니어 개발자고 백오피스를 담당하고 있어서 아직 대용량 트래픽에 맞아본 경험은 없지만, 이런 유용한 도구들이 있다는 배경지식정도는 정말 알아두는게 큰 도움이 된다는 생각이 든다.\n\n나중에 비슷한 문제가 발생하면 관련 키워드를 금방 떠올릴 수 있을것이고, 알맞은 솔루션을 조금 더 빠른 시간내에 도출해 낼 수 있을거란 기대 때문이다.\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-04-26-jmeter/"
    },{
      "image": "/assets/img/ide/Intellij.png",
      "title": "인텔리제이(IntelliJ) 2021.1 업데이트",
      "date": "2021-04-26 20:02:00 +0000",
      "description": "인텔리제이(IntelliJ) 2021.1 패치노트를 소개합니다\n",
      "content": "\n  패치노트    \n      1. Code With Me\n      2. HTML 미리 보기\n      3. Git Commit Template\n      4. 내장 DataGrip 라이브 템플릿\n    \n  \n\n\n \n\n패치노트\n\n\n  www.jetbrains.com/ko-kr/idea/whatsnew/\n\n\n \n\n이번에 인텔리제이가 업데이트됐는데, 추가된 업데이트 내역 중 유용한 부분을 소개하고자 한다.\n\n세부 사항은 패치노트를 살펴볼 것!\n\n눈여겨볼 내용이 몇 가지 있다.\n\n1. Code With Me\n\n\n\n회사에서 선임분들이랑 간략하게 실험해봤다.\n\n중요한 포인트로는 이 기능을 실행하는 주체자는 반드시 2021.1 버전으로 업데이트를 해야 했으며, 참여자는 업데이트를 하지 않아도 된다.\n\n이게 가능한 이유는 주체자는 초대 코드를 발급하고, 코드를 받아 참여하는 자는 따로 클라이언트 툴을 설치하는 안내 창이 뜨며 관련 클라이언트가 구비된다면 발급받은 초대 코드를 입력하기만 하면 되기 때문이다.\n\n누가 어떤 코드를 보고있는지 실시간으로 모두가 볼 수 있으며, 하나의 프로젝트에 여러 명이 동시에 작업을 할 수 있었다.\n\n화상통화 또한 가능하다.\n\n정말 유용한 기능이라고 생각한다.\n\n2. HTML 미리 보기\n\n\n\nVSCode의 Live Server Plugin처럼 웹 서버를 올려 실시간 미리보기를 제공해준다.\n\n3. Git Commit Template\n\n\n\n원래 Git에는 자체적으로 지원이 되는 기능이었지만, 인텔리제이에는 공식적으로 지원이 되질 않아 플러그인을 사용했었다.\n\n이번에 관련 설정을 하면 인텔리제이에서 이 설정을 읽어와 인텔리제이의 내장 Git에 적용해주게끔 지원이 됐다.\n\n실제로 사용해보니 이 또한 정말 편리한 기능이었다.\n\n4. 내장 DataGrip 라이브 템플릿\n\n\n\n\n\n진짜 좋은 기능이 생긴 듯하다.\n\n일반적으로 자바에서 사용하는 soutv, psvm 등의 약어와 사용법이 똑같다.\n\n자세한 내용은 구글에 인텔리제이 라이브템플릿 이라는 키워드로 검색하면 된다 !\n\n여러 가지 기본 명령어가 있는데 우선 쓸만한 걸 간추려보자면\n\ndel - 딜리트\ntab - 테이블 생성\nsel - 셀렉트\nselw - 셀렉트 조건절\nselc - 셀렉트 카운트 함수\nins - 인서트\n\n이 정도가 있고, 추가적으로 필요한 건 커스터마이징이 가능하다.\n\n자주 사용하는 쿼리의 경우 따로 작성해두면 매우 도움이 된다.\n",
      "categories": ["ide","intellij"],
      "tags": [],
      
      "collection": "posts",
      "url": "/ide/intellij/2021-04-26-intellij-2021.1/"
    },{
      "image": "/assets/img/spring/spring-security/security-logo.png",
      "title": "Spring Security 개요",
      "date": "2021-04-29 21:39:00 +0000",
      "description": "Spring Security란 무엇일까?\n",
      "content": "\n  ✅ 개요\n  ✅ DelegatingFilterProxy    \n      Servelt Filter\n      DelegatingFilterProxy\n      FilterChainProxy\n    \n  \n\n\n \n\n✅ 개요\n\n스프링 시큐리티는 필터를 기반으로 동작한다.\n\n\n\n프로젝트에 스프링 시큐리티의 의존성을 추가하면 Spring seucurity filterchain이 필터 계층에 추가된다.\n\n\n\n이를 실제로 확인해보려면 애플리케이션 내부 스프링 시큐리티 설정 파일에 debug = true 옵션을 지정해주면 아래와 같이 콘솔에서도 확인할 수 있다.\n\n@EnableWebSecurity(debug = true)\npublic class SecurityConfiguration extends WebSecurityConfigurerAdapter {\n    …\n}\n\n\nRequest received for GET '/':\n\norg.apache.catalina.connector.RequestFacade@26e603b1\n\nservletPath:/\npathInfo:null\nheaders: \nhost: localhost:8080\nconnection: keep-alive\nsec-ch-ua: \"Chromium\";v=\"88\", \"Google Chrome\";v=\"88\", \";Not A Brand\";v=\"99\"\nsec-ch-ua-mobile: ?0\nupgrade-insecure-requests: 1\nuser-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36\naccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\nsec-fetch-site: none\nsec-fetch-mode: navigate\nsec-fetch-user: ?1\nsec-fetch-dest: document\naccept-encoding: gzip, deflate, br\naccept-language: ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\ncookie: Idea-f86efe9=a6990472-c796-42ff-9425-84f5743f5e79\n\n\nSecurity filter chain: [\n  WebAsyncManagerIntegrationFilter\n  SecurityContextPersistenceFilter\n  HeaderWriterFilter\n  CsrfFilter\n  LogoutFilter\n  UsernamePasswordAuthenticationFilter\n  ConcurrentSessionFilter\n  RequestCacheAwareFilter\n  SecurityContextHolderAwareRequestFilter\n  AnonymousAuthenticationFilter\n  SessionManagementFilter\n  ExceptionTranslationFilter\n  FilterSecurityInterceptor\n]\n\n\n\n/ URL로 접속했을 때의 접속 정보들이 콘솔에 표시된다.\n\n필터가 굉장히 많고 복잡하고 어렵지만 간단하게 생각하자면 어차피 프레임워크이기 때문에 개발자는 필요한 부분만을 커스터마이징 할 줄 알면 사용하는 데는 큰 지장이 없다.\n\n \n\n그러기 위해서 스프링 시큐리티의 전체적인 윤곽을 머릿속에 그리고 있어야 하고, 이를 이해하려는 노력이 필요하다고 생각된다.\n\n \n\n그리고 스프링 시큐리티를 커스터마이징 한다는 것은 결국 원하는 이벤트를 핸들링해주는 필터를 커스터마이징 한다고 생각하면 될 것 같다.\n\n아래는 스프링 시큐리티 필터들의 순서를 나타낸 목록이다.\n\n \n\n\n  ChannelProcessingFilter\n  WebAsyncManagerIntegrationFilter\n  SecurityContextPersistenceFilter\n  HeaderWriterFilter\n  CorsFilter\n  CsrfFilter\n  LogoutFilter\n  OAuth2AuthorizationRequestRedirectFilter\n  Saml2WebSsoAuthenticationRequestFilter\n  X509AuthenticationFilter\n  AbstractPreAuthenticatedProcessingFilter\n  CasAuthenticationFilter\n  OAuth2LoginAuthenticationFilter\n  Saml2WebSsoAuthenticationFilter\n  UsernamePasswordAuthenticationFilter\n  OpenIDAuthenticationFilter\n  DefaultLoginPageGeneratingFilter\n  DefaultLogoutPageGeneratingFilter\n  ConcurrentSessionFilter\n  DigestAuthenticationFilter\n  BearerTokenAuthenticationFilter\n  BasicAuthenticationFilter\n  RequestCacheAwareFilter\n  SecurityContextHolderAwareRequestFilter\n  JaasApiIntegrationFilter\n  RememberMeAuthenticationFilter\n  AnonymousAuthenticationFilter\n  OAuth2AuthorizationCodeGrantFilter\n  SessionManagementFilter\n  ExceptionTranslationFilter\n  FilterSecurityInterceptor\n  SwitchUserFilter\n\n\n \n\n\n\n \n\n기본적으로 클라이언트에서 어떤 요청이 올 때 해당 요청은 각 필터를 거쳐 모든 필터에 대한 검사가 통과되야만 해당 요청이 애플리케이션에서 처리되는 방식으로 동작한다.\n\n그러니까 요청 한 번이 오면 저 위의 수십개가 넘어가는 필터에 대한 모든 검사가 통과되어야 하기 때문에 기본적인 보안이 보장된다고 말하는 것이다.\n\n이 스프링 시큐리티를 애플리케이션에 도입하게 되면\n\n\n  서블릿 API 통합\n  인증과 권한 부여에 대한 지원과 유연한 확장\n  세션 고정 공격 방지\n  클릭 재킹 공격 방지\n  무차별 대입 공격(Brute force) 방지\n  CSRF 공격 방지\n  XSS 공격 방지\n  Java 설정 지원\n  Spring MVC 통합\n\n\n등의 장점들이 있다.\n\n \n\n✅ DelegatingFilterProxy\n\nServelt Filter\n\n\n\n\n  Servlet Container에 속한 Filter\n  표준 서블릿 스펙을 지원한다\n\n\n \n\nDelegatingFilterProxy\n\n\n\n\n  springframework.web.filter의 Servlet Filter 구현체이다\n  이름 그대로 불특정 필터에 위임하는 객체이다. 위임을 하기 위해선 필터의 이름이 필요하다\n  Spring Security는 이 객체를 이용하여 동작한다\n  Spring Security는 springSecurityFilterChain라는 이름을 갖고있다\n  Spring Security 사용 시 Spring이라면 DelgatingFilterProxy가 springSecurityFilterChain라는 이름을 갖는 클래스에게 위임하도록 직접 설정해야 한다\n  Spring Boot이라면 starter로 인해 자동설정 된다\n\n\n\n\n \n\nFilterChainProxy\n\n\n\n\n  Spring Security 설정 시 기본적으로 사용되는 필터들은 위의 이미지와 같다\n  추가적으로 사용자 정의 필터를 구현하여 추가 할 수 있다(순서를 신중히 배치하는게 중요하다)\n  WebSecurityConfigurerAdapter를 상속하거나 WebSecurityConfigurer를 구현한 클래스에서 사용자 설정이 가능하다. 이 경우 @EnableWebSecurity이 필요하다\n  Spring Security의 대부분의 보안 기능은 FilterChainProxy에 들어 있으며 FilterChainProxy의 아키텍처를 이해하고 커스터마이징 하는 것이 Spring Security 사용의 핵심이다\n\n\npublic class SecurityConfig implements WebSecurityConfigurer {\n\n    @Override public void init(SecurityBuilder builder) throws Exception {\n        \n    }\n\n    @Override public void configure(SecurityBuilder builder) throws Exception {\n\n    }\n\n}\n\n\n\nWebSecurityConfigurer를 구현한 경우 기본 구성\n\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n        super.configure(auth);\n    }\n\n    @Override public void configure(WebSecurity web) throws Exception {\n        super.configure(web);\n    }\n\n    @Override protected void configure(HttpSecurity http) throws Exception {\n        super.configure(http);\n    }\n\n}\n\n\nWebSecurityConfigurerAdapter를 상속한 경우 기본 구성\n\n일반적으로는 WebSecurityConfigurerAdapter를 상속하여 필요한 부분만 커스터마이징해 사용한다.\n\n \n",
      "categories": ["spring","spring-security"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-security/2021-04-29-security-basic/"
    },{
      "image": "/assets/img/spring/spring-security/security-logo.png",
      "title": "Spring Security - ExceptionTranslationFilter",
      "date": "2021-05-01 18:52:00 +0000",
      "description": "예외 처리를 도와주는 ExceptionTranslationFilter에 대해 알아봅니다\n",
      "content": "\n  ✅ ExceptionTranslationFilter\n\n\n \n\n✅ ExceptionTranslationFilter\n\n\n\nExceptionTranslationFilter는 FilterChainProxy의 보안필터 중 하나로\n\nAccessDeniedException 과 AuthenticationException을 HTTP 응답으로 변환해주는 역할을 한다.\n\n \n\n\n\n \n\n\n  먼저 ExceptionTranslationFilter는 FilterChain.doFilter(request, response)를 호출하여 애플리케이션의 나머지 작업을 처리한다.\n  만약 인증되지 않은 사용자였거나, AuthenticationException이 발생한다면 인증절차를 시작한다.\n    \n      SecurityContextHolder 를 비운다\n      RequestCache 에 HttpServletRequest를 저장하고 사용자임이 인증되면 이후의 요청에 RequestCache를 사용한다\n      AuthenticationEntryPoint는 클라이언트에 자격증명을 요청할 때 사용된다. 예를 들자면, 로그인 페이지로 리다이렉트하거나 WWW-Authenticate 헤더를 보낸다\n    \n  \n  반대로 AccessDeniedException이 발생한 경우, 접근을 거부하고 AccessDeniedHandler를 호출하여 이후의 처리를 위임한다.\n\n\n\n  애플리케이션에서 AccessDeniedException이나 AuthenticationException이 발생하지 않는다면,\nExceptionTranslationFilter는 아무런 동작도 하지 않는다.\n\n\nExceptionTranslationFilter 의 의사코드는 다음과 같다.\n\n \n\ntry {\n\n    // 1\n    filterChain.doFilter(request, response);\n} \ncatch (AccessDeniedException | AuthenticationException ex) {\n\n    // 2\n    if (!authenticated || ex instanceof AuthenticationException) {\n        startAuthentication();\n    } \n    \n    // 3\n    else {\n        accessDenied();\n    }\n}\n\n\n \n\n\n  이전 내용에서 FilterChain.doFilter(request, response)를 호출하여 애플리케이션의 나머지 작업을 처리한다고 한 것을 기억할 것이다. 즉, 애플리케이션의 다른 코드에서 (i.e.FilterSecurityInterceptor 나 시큐리티 메소드) AuthenticationException이나 AccessDeniedException을 발생시키면 이 부분에서 예외를 포착하고 처리한다.\n  인증되지 않은 사용자거나, AuthenticationException이 발생한다면 인증 절차를 시작한다.\n  이도저도 아니므로 접근을 거부한다.\n\n\n \n",
      "categories": ["spring","spring-security"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-security/2021-05-01-ExceptionTranslationFilter/"
    },{
      "image": "/assets/img/spring/spring-security/security-logo.png",
      "title": "Spring Security - 인증(Authentication)",
      "date": "2021-05-02 00:59:00 +0000",
      "description": "스프링 시큐리티의 핵심인 인증(Authentication)에 대해 정리합니다\n",
      "content": "\n  ✅ 인증(Authentication)\n  ✅ 인증 메커니즘    \n      1. Username and Password\n      2. OAuth 2.0 Login\n      3. SAML 2.0 Login\n      4. Central Authentication Server (CAS)\n      5. Remember Me\n      6. JAAS Authentication\n      7. OpenID\n      8. Pre-Authentication Scenarios\n      9. X509 Authentication\n    \n  \n  ✅ SecurityContextHolder\n  ✅ SecurityContext\n  ✅ Authentication\n  ✅ GrantedAuthority\n  ✅ AuhenticationManager\n  ✅ ProviderManager\n\n\n \n\n✅ 인증(Authentication)\n\n\n\n\n  📜 인증(Authentication)\n\n  특정 리소스에 접근하려고 하는 사용자가 누구인지를 확인하는 절차다.\n\n  보통 사용자가 이름과 비밀번호를 입력하는 것으로 사용자를 인증하곤 한다. (로그인)\n\n  한 번 인증하고 나면 사용자를 식별하고 권한을 부여할 수 있다. (세션)\n\n\n\n  📜 인가(Authorization)\n\n  인증된 사용자가 어떠한 자원(URI)에 접근 할 권한 이 있는지 판별.\n\n\n스프링 시큐리티는 인증절차에 대해 많은 지원을 해준다.\n\n아래는 스프링 시큐리티의 인증을 처리해주는 주요 객체들이다.\n\n \n\n\n  \n    SecurityContextHolder - 인증된 사용자에 대한 정보들을 저장한다. 비유하자면 SecurityContextHolder가 카드팩이라면 SecurityContext는 카드팩에 들어있는 카드들이다.\n  \n  \n    SecurityContext - SecurityContextHolder에서 얻을 수 있으며, 인증된 사용자의 Authentication을 갖고있다.\n  \n  \n    Authentication - 사용자가 인증을 위해 입력한 자격증명(아이디, 비밀번호 등)이나 SecurityContext에 들어있는 자격증명을 표현하는 일종의 토큰이다. 이 객체는 AuthenticationManager의 입력으로 사용될 수 있다.\n  \n  \n    GrantedAuthority - Authentication이 갖고있는 유저에게 허용된 권한정보이다. (즉, role, scope 등. 일반적으로 ROLE_USER 같은 것들을 말한다)\n  \n  \n    AuthenticationManager - 스프링 시큐리티의 필터가 처리할 인증 절차를 정의한 인터페이스이다.\n  \n  \n    ProviderManager - 스프링 시큐리티에 정의된 AuthenticationManager의 기본 콘크리트 클래스\n  \n  \n    AuthenticationEntryPoint - 클라이언트에 자격증명을 요청할 때 사용된다. (즉, 로그인 페이지로 리다이렉트 시키거나, WWW-Authenticate 헤더를 전송하는 등)\n  \n  \n    AbstractAuthenticationProcessingFilter - 인증에 사용할 Filter의 베이스 추상 클래스이며, 이 추상 클래스의 기본 콘크리트 클래스가 바로 UsernamePasswordAuthenticationFilter이다. 즉, 스프링 시큐리티를 프로젝트에 적용할 경우 기본적으로 폼 로그인 방식으로 동작한다. 이 추상 클래스가 정의한 메소드 중 핵심 메소드가 attemptAuthentication(request, response)이며, 위의 Authentication을 리턴한다. 여기서 리턴되는 Authentication은 사용자가 서버에 자격증명을 요청하기 위해 입력한 정보를 의미한다.(아이디, 비밀번호 등). 이 필터를 잘 이해하면 여러가지 인증 객체를 조합하여 고수준의 인증플로우를 구성하는데 유의미한 도움이 될 것이다.\n  \n\n\n \n\n@Override\npublic Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response)\nthrows AuthenticationException {\n  if (this.postOnly &amp;&amp; !request.getMethod().equals(\"POST\")) {\n  \tthrow new AuthenticationServiceException(\"Authentication method not supported: \" + request.getMethod());\n  }\n  String username = obtainUsername(request);\n  username = (username != null) ? username : \"\";\n  username = username.trim();\n  String password = obtainPassword(request);\n  password = (password != null) ? password : \"\";\n  UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(username, password);\n  \n  // Allow subclasses to set the \"details\" property\n  setDetails(request, authRequest);\n  \n  return this.getAuthenticationManager().authenticate(authRequest);\n}\n\n\n \n\n✅ 인증 메커니즘\n\n1. Username and Password\n\n\n\n\n\n\n  \n    클라이언트 자격증명 요청 발생(ID, PW 입력)\n  \n  \n    Security filterchain에서 인증 정보 생성(Authentication)\n  \n  \n    ProviderManager(AuthenticationManager의 콘크리트 클래스)에 클라이언트가 입력한 ID, PW를 전달해줌\n  \n  \n    ProviderManager에 정의된 AuthenticationProvider에서 자격증명 처리 시작\n  \n  \n    AuthenticationProvider에 정의된 PasswordEncoder를 초기화(기본 bcrypt)\n  \n  \n    AuthenticationProvider가 UserDetailsService를 호출\n  \n  \n    UserDetailsService에서 UserDetails를 호출\n  \n  \n    UserDetails가 입력받은 ID로 데이터베이스에서 해당 유저에 대한 정보를 조회(ID=기본키)\n  \n  \n    UserDetails가 조회해온 유저 정보와 입력받은 ID, PW를 AuthenticationProvider에서 비교\n  \n  \n    인증 성공 시 값을 ProviderManager에 리턴\n  \n  \n    AuthenticationManager는 해당 값을 필터 체인에 리턴\n  \n  \n    인증 정보를 SecurityContextHolder에 저장\n  \n\n\n \n\n2. OAuth 2.0 Login\n\n\n\n\n  OpenID Connect를 이용한 OAuth 2.0과, 비표준 OAuth 2.0 로그인 (구글, 카카오를 이용한 로그인 같은 표준)\n\n\n\n\n \n\n3. SAML 2.0 Login\n\n\n\nSAML - 위키백과, 우리 모두의 백과사전\n\n \n\n4. Central Authentication Server (CAS)\n\n\n\n중앙 인증 서비스 - 위키백과, 우리 모두의 백과사전\n\n \n\n5. Remember Me\n\n\n\n\n  세션이 만료된 사용자를 기억하는 방법(로그인 상태 유지같은 기능들)\n\n\n \n\n6. JAAS Authentication\n\n\n\nJAAS - 위키백과, 우리 모두의 백과사전\n\n \n\n7. OpenID\n\n\n\n\n  OpenID Connect와 혼동하지 말 것\n\n\n \n\n8. Pre-Authentication Scenarios\n\n\n\n\n  SiteMinder나 Java EE Security와 같은 외부 메커니즘으로 인증을 처리하고, 스프링 시큐리티로 인가(Authorization) 처리를 하고, 취약점 공격을 대비할 수 있다.\n\n\n \n\n9. X509 Authentication\n\n\n\nX.509 - 위키백과, 우리 모두의 백과사전\n\n \n\n✅ SecurityContextHolder\n\n\n\nSecurityContextHolder는 스프링 시큐리티 인증모델의 핵심이다.\n\n이것은 SecurityContext를 포함하고 있다.\n\n즉, SecurityContextHolder가 카드팩이라면, SecurityContext는 카드팩에 들어있는 각각의 카드와 같다.\n\n\n\nSecurtyContextHolder는 인증된 사용자의 상세한 정보들을 저장하는 곳이다.\n\n스프링 시큐리티는 SecurityContextHolder가 어떻게 구성되든 신경쓰지 않는다.\n\n오직 인증된 사용자의 정보를 활용하기만 할 뿐이다.\n\n스프링 시큐리티에서 인증된 사용자의 정보에 접근하기 위해서는 아래와 같은 코드를 작성 할 수 있다.\n\nSecurityContext context = SecurityContextHolder.getContext();\nAuthentication authentication = context.getAuthentication();\nString username = authentication.getName();\nObject principal = authentication.getPrincipal();\nCollection&lt;? extends GrantedAuthority&gt; authorities = authentication.getAuthorities();\n\n\n기본적으로 SecurityContextHolder는 ThreadLocal을 사용하여 저장되며,\n\n이것은 같은 스레드영역 내에서라면 언제든지 어디서나 접근 할 수 있음을 의미한다.\n\n또한, ThreadLocal 방식으로 사용하는 것은 사용자의 요청이 처리되고 난 후 이 스레드를 지우기만 한다면 매우 안전한 방법이며,\n\n스프링 시큐리티의 FilterChainProxy는 항상 SecurityContext를 지우도록 설계되어 있다.\n\n이 ThreadLocal과 관련하여 스프링 시큐리티는 세가지 방식을 지원한다.\n\n \n\n\n  \n    MODE_THREADLOCAL: 기본값, 각 Thread에 SecurityContext를 저장하므로 Thread Safe하다\n  \n  \n    MODE_INHERITABLETHREADLOCAL: 자식 Thread까지 SecurityContext를 상속\n  \n  \n    MODE_GLOBAL: SecurityContext를 static으로 사용\n  \n\n\n \n\nSecurityContextHolder.setStrategyName(SecurityContextHolder.MODE_THREADLOCAL);\nSecurityContextHolder.setStrategyName(SecurityContextHolder.MODE_INHERITABLETHREADLOCAL);\nSecurityContextHolder.setStrategyName(SecurityContextHolder.MODE_GLOBAL);\n\n\n아마도 이 부분은 가급적 건들일이 없지 않을까 싶은데, 그냥 이런것도 있구나 하고 넘어가도록 하자.\n\n \n\n✅ SecurityContext\n\n\n\n\n  SecurityContext는 Authentication을 보관한다\n  ThreadLocal에 저장되어 아무곳에서나 참조가 가능하며, 기본적으로 Thread Safe하게 설계되어 있다\n  정리하자면 SecurityContextHolder -&gt; SecurityContext -&gt; Authentication 순으로 포함한다\n\n\nAuthentication authentication = SecurityContextHolder.getContext().getAuthentication();\n\n\n스레드에서 사용자의 정보에 접근할 일이 많다면 유틸리티 클래스를 정의하여 사용하는 것도 좋은 방법이다.\n\npublic class SecurityUtils {\n\n    public static String getUserName() {\n        return SecurityContextHolder.getContext().getAuthentication().getName();\n    }\n\n    public static Collection&lt;? extends GrantedAuthority&gt; getAuthorities() {\n        return SecurityContextHolder.getContext().getAuthentication().getAuthorities();\n    }\n\n    public static Authentication getAuthentication() {\n        return SecurityContextHolder.getContext().getAuthentication();\n    }\n\n}\n\n\n \n\n✅ Authentication\n\n\n\n\n\nAuthentication는 스프링 시큐리티에서 두 가지의 중요한 목적을 갖는다.\n\n\n  사용자가 자격증명을 요청하기 위해 입력한 데이터(ID/PW 등)를 AuthenticationManager에 전달해준다.\n  현재 인증된 사용자를 나타낸다. 이 때의 Authentication은 SecurityContext에서 얻을 수 있다.\n\n\nSecurityContextHolder.getContext().getAuthentication();\n\n\n또한 Authentication은 다음 데이터를 포함한다.\n\n\n  principal - 사용자를 식별한다. 이 정보는 인증시 UserDetails 인스턴스로 캐스팅되어 사용된다.\n  credentials - 사용자가 입력한 암호이다. 일반적으로 이 정보는 사용자 인증이 완료된 후 삭제한다.\n\n\ncredentials = null;\n\n\n\n  authorities - 사용자에게 허락된 권한을 나타낸다. 권한(ROLE_USER 같은 것들)이 담긴다.\n\n\n \n\n✅ GrantedAuthority\n\n\n\nGrantedAuthority는 사용자에게 부여되는 권한이다.\n\n이 객체엔 일반적으로 ROLE_이라는 접두사(prefix)가 들어간 권한 표현식이 저장된다.\n\n예를 들자면 ROLE_USER, ROLE_ADMIN등이 있다.\n\n이 표현식들은 스프링 시큐리티의 콤포넌트들에서 폭넓게 사용되며 특히 UserDetailsService에서 빈번하게 사용된다.\n\nAuthentication.getAuthorites() 메소드에서 얻을 수 있다.\n\n이 메소드를 호출하면 Collection&lt;GrantedAuthority&gt;를 반환한다.\n\nAuthentication authentication = SecurityUtils.getAuthentication();\n\nCollection&lt;? extends GrantedAuthority&gt; authorities = authentication.getAuthorities();\n\n\n \n\n✅ AuhenticationManager\n\n\n\nAuthenticationManager는 스프링 시큐리티 필터의 인증절차를 정의한 인터페이스이다.\n\n스프링 시큐리티에는 이 인터페이스를 구현한 콘크리트 클래스가 있는데 이 클래스가 ProviderManager이다.\n\n이 인터페이스에서 처리된 인증결과는 SecurityContextHolder에 저장되며\n\n콘크리트 클래스는 사용자가 임의로 변경할 수 있다.\n\n \n\n✅ ProviderManager\n\n\n\n\n\n스프링 시큐리티에서 가장 일반적으로 사용되는 AuthenticationManager의 콘크리트 클래스이다.\n\nProviderManager는 List&lt;AuthenticationProvider&gt;에 동작을 위임한다.\n\n이 AuthenticationProvider는 각각의 인증처리를 수행할 수 있다.\n\n예를들자면 AuthenticationProvider A는 아이디/비밀번호로 인증처리를 진행할 수 있고,\n\nAuthenticationProvider B는 SAML 인증을 처리할 수 있다.\n\n이런 구조라면 각 인증 유형을 담당하는 AuthenticationProvider가 존재하게 되며, AuthenticationManager 하나만 외부에 노출하면서도 다양한 인증 유형을 지원할 수 있어진다.\n\n모든 AuthenticationProvider는 인증처리의 성공, 실패여부를 결정할 수 있고 아니면 결정을 다음 AuthenticationProvider에 떠넘길 수 있다.\n\npublic class ProviderManager implements AuthenticationManager, MessageSourceAware, InitializingBean {\n\t\n    ...\n    \n\tprivate List&lt;AuthenticationProvider&gt; providers = Collections.emptyList();\n    \n    ...\n\n\t@Override\n\tpublic Authentication authenticate(Authentication authentication) throws AuthenticationException {\n\t\tClass&lt;? extends Authentication&gt; toTest = authentication.getClass();\n\t\tAuthenticationException lastException = null;\n\t\tAuthenticationException parentException = null;\n\t\tAuthentication result = null;\n\t\tAuthentication parentResult = null;\n\t\tint currentPosition = 0;\n\t\tint size = this.providers.size();\n\t\tfor (AuthenticationProvider provider : getProviders()) {\n\t\t\tif (!provider.supports(toTest)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(LogMessage.format(\"Authenticating request with %s (%d/%d)\",\n\t\t\t\t\t\tprovider.getClass().getSimpleName(), ++currentPosition, size));\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tresult = provider.authenticate(authentication);\n\t\t\t\tif (result != null) {\n\t\t\t\t\tcopyDetails(authentication, result);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (AccountStatusException | InternalAuthenticationServiceException ex) {\n\t\t\t\tprepareException(ex, authentication);\n\t\t\t\t// SEC-546: Avoid polling additional providers if auth failure is due to\n\t\t\t\t// invalid account status\n\t\t\t\tthrow ex;\n\t\t\t}\n\t\t\tcatch (AuthenticationException ex) {\n\t\t\t\tlastException = ex;\n\t\t\t}\n\t\t}\n\t\tif (result == null &amp;&amp; this.parent != null) {\n\t\t\t// Allow the parent to try.\n\t\t\ttry {\n\t\t\t\tparentResult = this.parent.authenticate(authentication);\n\t\t\t\tresult = parentResult;\n\t\t\t}\n\t\t\tcatch (ProviderNotFoundException ex) {\n\t\t\t\t// ignore as we will throw below if no other exception occurred prior to\n\t\t\t\t// calling parent and the parent\n\t\t\t\t// may throw ProviderNotFound even though a provider in the child already\n\t\t\t\t// handled the request\n\t\t\t}\n\t\t\tcatch (AuthenticationException ex) {\n\t\t\t\tparentException = ex;\n\t\t\t\tlastException = ex;\n\t\t\t}\n\t\t}\n\t\tif (result != null) {\n\t\t\tif (this.eraseCredentialsAfterAuthentication &amp;&amp; (result instanceof CredentialsContainer)) {\n\t\t\t\t// Authentication is complete. Remove credentials and other secret data\n\t\t\t\t// from authentication\n\t\t\t\t((CredentialsContainer) result).eraseCredentials();\n\t\t\t}\n\t\t\t// If the parent AuthenticationManager was attempted and successful then it\n\t\t\t// will publish an AuthenticationSuccessEvent\n\t\t\t// This check prevents a duplicate AuthenticationSuccessEvent if the parent\n\t\t\t// AuthenticationManager already published it\n\t\t\tif (parentResult == null) {\n\t\t\t\tthis.eventPublisher.publishAuthenticationSuccess(result);\n\t\t\t}\n\n\t\t\treturn result;\n\t\t}\n\n\t\t// Parent was null, or didn't authenticate (or throw an exception).\n\t\tif (lastException == null) {\n\t\t\tlastException = new ProviderNotFoundException(this.messages.getMessage(\"ProviderManager.providerNotFound\",\n\t\t\t\t\tnew Object[] { toTest.getName() }, \"No AuthenticationProvider found for {0}\"));\n\t\t}\n\t\t// If the parent AuthenticationManager was attempted and failed then it will\n\t\t// publish an AbstractAuthenticationFailureEvent\n\t\t// This check prevents a duplicate AbstractAuthenticationFailureEvent if the\n\t\t// parent AuthenticationManager already published it\n\t\tif (parentException == null) {\n\t\t\tprepareException(lastException, authentication);\n\t\t}\n\t\tthrow lastException;\n\t}\n    \n    ...\n    \n}\n\n\n \n\n개발자가 원한다면 ProviderManager에 더 이상 인증을 수행할 수 있는 AuthenticationProvider가 없을 경우 다음에 사용할 AuthenticationManager를 설정할 수 있다.\n\n이 Authentication은 어떤 클래스를 써도 무방하지만 일반적으로 ProviderManager를 많이 사용한다.\n\n\n\n또한 여러 ProviderManager 인스턴스에 같은 부모 AuthenticationManager를 공유할 수도 있다.\n\n이 경우 인증 유형이 다른 ProviderManager 여러개가 공통 인증을 수행해야 할 필요성이 있을 경우 흔히 사용되는 패턴이다.\n\n\n\n마지막으로, ProviderManager는 기본적으로 인증에 성공 시 비밀번호 같은 민감정보를 HttpSession에 필요 이상으로 길게 보관하지 않기 위해 반환받은 Authentication 객체에 저장된 자격증명(credentail) 정보를 지운다.\n\n사용자 정보를 캐시를 사용할 때 반드시 고려해야 할 점이 있는데, 사용자 정보를 캐시할 경우 Authentication이 캐시 안에 있는 객체를 참조하므로(UserDetails 인스턴스 등), credential을 제거한다면 캐시된 값으로는 더 이상 인증이 통과되지 않는다.\n\n이 경우엔 캐시 구현부나 Authentication 객체를 생성하는 AuthenticationProvider에서 객체의 복사본을 만들거나 ProviderManager의 eraseCredentialAfterAuthentication 프로퍼티를 비활성화 시키면 해결된다.\n\n더 상세한 정보는 Javadoc 을 참고하기 바란다.\n",
      "categories": ["spring","spring-security"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-security/2021-05-02-authentication/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Unable to access jarfile Dspring.profiles.active=",
      "date": "2021-05-02 14:05:00 +0000",
      "description": "Windows10에서 jar를 실행하다 발생한 문제\n",
      "content": "\n \n\n토이프로젝트 배포테스트를 하다 발생한 문제다.\n\n환경은 Windows10이었으며, PowerShell에서 발생했다.\n\n \n\n//입력\njava -jar Dspring.profiles.active=prod .\\dev-dictionary-3.0.jar\n\n//에러발생\nError: Unable to access jarfile Dspring.profiles.active=prod\n\n\n \n\n너무 당연하게 돼야할게 안돼면서 뜬금없는 에러가 발생해 약간 헤맸는데,\n\n곰곰이 생각해보니 실행옵션을 jar파일로 인식하여 발생하는 오류로 생각이됐다.\n\n윈도우는 실행옵션을 주는 방식이 약간 다른가보다.\n\n아래와 같이 실행옵션을 쌍따옴표로 묶어 문자열임을 명시해주니 문제없이 실행됐다.\n\n \n\njava -jar \"-Dspring.profiles.active=prod\" .\\dev-dictionary-3.0.jar\n\n\n \n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-05-02-debugging-9/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "테스트 코드 은근 재미있는데?",
      "date": "2021-05-02 15:04:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n\n\n \n\n최근 토스 첫 컨퍼런스가 열린다 하여 이것저것 보다가 가장 감명깊었던 세션이 이거였다.\n\n테스트 커버리지 100%… 광기라는 생각도 들었지만 정말 대단하다고 생각했다.\n\n그러면서 존경심이 피어올랐다. 저걸 진짜 해보고 발표하는 사람이 있다니…👍\n\nJUnit5를 공부하면서 StackOverflow에서 가장 많이 본 내용 중 하나가 테스트 커버리지에 너무 집착하지 말라는 글이었기 때문이다.\n\n예를들자면 스프링 부트의 메인 메소드가 가장 대표적이다.\n\n \n\n@SpringBootApplication\npublic class Application {\n    public static void main(String[] args) {\n        SpringApplication.run(Application.class, args);\n    }\n}\n\n\n \n\n이 코드의 테스트 코드를 작성하지 않으면 테스트 커버리지가 떨어진다.\n\n이 코드의 테스트 코드를 작성한다면 테스트 커버리지는 상승하겠지만, 테스트 시간이 매우 길어진다.\n\n \n\nclass ApplicationTest {\n    @Test\n    @DisplayName(\"스프링부트_메인메소드\")\n    @Disabled(value = \"테스트_시간이_너무_오래_걸려_비활성화_함\")\n    public void main() {\n        Application.main(new String[] {});\n    }\n    \n}\n\n\n \n\n\n\n \n\n테스트 시간이 무려 4.167초나 증가해버렸다.\n\n테스트에서 이 4초는 무척이나 큰 시간이다.\n\n원래 나는 테스트 커버리지를 따지면서 테스트를 작성하진 않았었다.\n\n핵심 비즈니스 로직에만 작성한다는 마인드를 갖고 있었기 때문이다.\n\n아무튼 저 세션을 보고 본격적으로 커버리지를 따져가면서 테스트 코드를 짜다보니 긍정적인 현상이 하나 있었다.\n\n바로 성취감.\n\n \n\n\n\n \n\n커버리지가 상승하는 것을 시각화하여 보고 있자니 상당한 성취감이 따라오더라.\n\n물론 앞으로도 커버리지 100%에 집착하지는 않을 것이다.\n\n그래도 커버리지를 시각화해서 보는것은 내게 매우 긍정적인 피드백으로 작용하므로\n\n앞으로 커버리지를 신경쓰긴 해야겠다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-05-02-diary-14/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "첫 공식 업무와 JPA 쿼리 튜닝",
      "date": "2021-05-05 17:05:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n회사에서 신입으로 맡은 프로젝트는 백오피스 유지보수, 개발이고 첫 공식 업무는 백오피스에 Dynamic ACL을 도입하는 것이었다.\n\n \n\n이 기능에 대한 요구사항은 예를 들자면 회사에서 데이터를 관리하는 아르바이트생을 한 명 뽑는다고 한다면 이 알바생에게 관리해야 할 데이터에 관련된 허락된 기능만 접근할 수 있게끔 권한을 제어할 수 있는 시스템을 개발하면 되는 업무였다.\n\n그리고 이 권한을 생성하고 제어하는 기능이 런타임에 가능해야 했다.\n\n \n\n내가 포트폴리오를 만들 때 작성한 시큐리티 설정 파일의 인가처리 부분은\n\n \n\n\n\n \n\n이런 식으로 모든 URI와 그 URI에 접근할 수 있는 권한이 모두 하드코딩돼있는 방식이었고, 여태 이게 당연한 건 줄 알았다.\n\n실제로 회사에서 내가 맡은 백오피스도 저런 식으로 돼있었기도 했고…\n\n근데 팀장님이 이 하드 코딩돼있는 정보들을 모두 DB로 옮기고, 런타임에 시스템 관리자가 권한을 동적으로 생성, 제어하고 그 권한에 여러 URI를 인가할 수 있게 해 보라는 말씀을 하셨다.\n\n \n\n그날부터 스프링 시큐리티 문서를 줄곧 뜯어보기 시작했는데\n\n보면 볼수록 “이건 진짜 천재가 만든 건가?” 라는 생각이 물씬 드는 프레임워크였다.\n\n여태까지 나는 스프링 시큐리티를 겉핥기 식으로 사용하고 있었다는 생각밖에 들지 않았다.\n\n \n\n아무튼 결론적으로 기능 구현 자체는 공식 문서를 뜯어보면서 해내긴 했다.\n\n대략적인 구조는 이렇다.\n\n \n\n\n  \n    FilterSecurityInterceptor의 앞단에 커스텀 필터를 만들어 붙인다\n  \n  \n    DB에 권한과 자원(URI)을 표시하는 테이블 두 개와 이 두개 테이블을 매핑해주는 매핑 테이블을 생성한다\n  \n  \n    매핑 테이블에서 정보들을 읽어와(이를 인가 정보라 하겠다) 만들어낸 커스텀 필터에 인가 정보를 입력한다\n  \n  \n    이 인가 정보는 런타임에 업데이트될 수 있으며 업데이트 시 커스텀 필터와 동기화한다.\n  \n  \n    커스텀 필터에서 모든 요청에 대해 인가 처리를 한다\n  \n\n\n \n\n여기서 FilterSecurityInterceptor는 FilterChainProxy의 종단에 위치한 인가 처리 필터인데 이 필터의 앞단에 내가 작성한 커스텀 필터를 추가하여 인가처리를 동적으로 해낼 수 있는 기반을 만들었다.\n\n \n\n현 상태에서 권한과 자원 테이블에 새로운 데이터를 추가할 경우 커스텀 필터를 reload 하여 인가 정보를 실시간으로 업데이트해주는 방식이다.\n\n \n\n이때, 우선 기능 구현에 목적을 두고 개발을 하다 보니 큰 문제가 하나 있었음을 알았다.\n\nWAS가 초기화되거나 필터가 reload 될 경우 모든 URI와 권한을 매번 읽어와야만 하는 구조이고 이렇게 매번 읽어오는 것은 구조상 어쩔 수 없는 일이긴 했는데 문제는 코드레벨에 있었다.\n\n \n\n대략 7개의 권한이 있고, 총 300여 개의 URI가 있었으며, 각 권한당 약 100~300개 사이의 URI에 접근이 가능한 상태에서 이를 2중 루프를 돌려 읽다 보니 약 1,600회의 루프가 발생하고 있었고 정말 큰 문제는 이 2중 루프 안에서 select 쿼리를 건 바이 건으로 날리고 있었다는 것이다.\n\n한마디로 1,600회의 루프가 돈다면 1,600회의 select가 발생하고 있었다는 말과 일맥상통한다.\n\n \n\nfor(List&lt;SecurityAuthorization&gt; authorizations : result) {\n    ...\n    for(SecurityAuthorization authorization : authorizations) {\n            ...\n        backofficeAuthorityRepository.findByAdmins();\n            ...\n    }\n}\n\n\n \n\n그래서 WAS가 초기화되거나 필터가 reload 될 경우마다 약 1,600회의 select 쿼리가 발생하고 그 시점마다 약 2초 정도의 로딩 시간이 발생했다.\n\n \n\n이를 해결하는 방법은 생각보다 간단했지만, 약 2~3시간여의 고민이 필요했다.\n\n바로 네이티브 쿼리를 사용할 것인가 말 것인가였다.\n\n이 인가 정보를 매핑하기 위해서 스프링 시큐리티의 AntPathRequestMatcher를 이용해야 하는데 이 객체의 구조가 생각보다 복잡성이 커서 한방 쿼리로 해결하자니 쿼리가 통계성 쿼리처럼 무지막지하게 복잡해졌다.\n\n이를 Querydsl로 구현하자니 도저히 안되겠어서 네이티브 쿼리밖에 생각이 나질 않았다.\n\n(mybatis는 쓰기 싫었다.)\n\n그렇다고 네이티브 쿼리를 사용하지 않으려 하니 쿼리를 쪼개 여러 번 보내야 했다.\n\n \n\n결과적으로 네이티브 쿼리를 사용하려고 마음을 먹었는데, 이 근거는 다음과 같다.\n\n\n\n첫째, 이 시스템이 앞으로 더 손댈 일이 없을 거라는 판단을 했다.\n\n사실상 실무에서 스프링 시큐리티로 만들 수 있는 인가(Authorization) 아키텍처로 과연 이 이상의 시스템이 더 필요할까?라는 생각이 들었고, 아니라는 생각이 들었다.\n\n따라서, 네이티브 쿼리를 쓰더라도 유지보수 관련 리스크가 매우 적다는 판단이 섰다.\n\n \n\n둘째, 성능차이가 너무 압도적이었다.\n\n쿼리를 여러번 쪼개 날리는 것과 네이티브 쿼리 단 한방으로 모든 처리를 끝내버리는 것에서 압도적인 성능차이가 발생했다.\n\n아무튼 Spring Data JPA의 Projections과 네이티브 쿼리를 사용했고 약 1,600회의 쿼리로 처리했을 일이 단 한방에 끝나는 압도적인 퍼포먼스를 보여줬다.\n\n실 체감 로딩 시간은 2초에서 클릭 시 즉시 수준으로 변했음은 당연지사다.\n\n이 외에 2중 루프에서 select를 날리는 부분을 모두 찾아내어 JPA의 fetch join을 활용해 모두 최적화했다.\n\n \n\n아마 이날 줄인 쿼리발생 수가 클릭당 약 2,000회 정도가 아닐까 싶었다.\n\n \n\nfetch join과 네이티브 쿼리는 JPA를 공부하면서도 실제로 사용해 볼 일이 많지 않았는데 이번에 제대로 적용해보면서 체화하듯이 학습한 게 너무 큰 도움이 됐던 것 같다.\n\n덤으로 내가 담당하는 프로젝트의 성능이 눈에 띄게 향상됐다는 게 가장 큰 기쁨이었다.\n\n \n\n그동안 시간이 더 오래 걸리더라도 원리와 구조에 대한 이해에 큰 비중을 두면서 공부했는데, 이러한 공부 방식들이 이번에 정말 큰 도움이 됐던 것 같다.\n\n문제에 맞닥트렸을 때 알맞은 솔루션을 찾아낼 수 있는 단단한 기반이 되어줬던 것 같다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-05-05-diary-15/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Vue.js 입문",
      "date": "2021-05-08 20:59:00 +0000",
      "description": "개발일기\n",
      "content": "\n  ✅ JQuery\n  ✅ 모던 JavaScript\n  ✅ Vue.js (1차)\n  ✅ Vue.js (2차)\n  ✅ 후기\n\n\n \n\n최근 프론트에 부쩍 관심이 늘었다.\n\n백엔드가 많이 능숙해져서 생산성이 폭발적으로 늘어난데 비해, 상대적으로 화면구성 속도가 너무 빈약하다고 느끼고 있기 때문이다.\n\n \n\n더불어 JQuery로 수백 수천 줄의 코드들을 작성하고, 수정하다 보면 너무 피로하다.\n\n그래서 모던 자바스크립트와 프론트 프레임워크에 계속 관심을 기울이다가 이번 주말에 본격적으로 공부를 시작했다.\n\n \n\nJQuery로 작성된 토이 프로젝트를 모던 자바스크립트로 마이그레이션 하고, 이를 다시 Vue.js로 마이그레이션 해봤다.\n\n \n\n✅ JQuery\n\n\n\nconst CONTEXT_PATH = \"\";\nlet ajaxResponse;\nlet allVisitors;\nlet dau;\n\n/**\n * @author shirohoo\n * 페이지 초기화\n */\n$(function () {\n\t$.ajax({\n\t\t       url        : \"/boards?page=0&amp;size=10\",\n\t\t       type       : \"GET\",\n\t\t       contentType: \"application/x-www-form-urlencoded;charset=utf-8\",\n\t\t       dataType   : \"json\",\n\t\t       success    : function (data) {\n\t\t\t       ajaxResponse = data.pages;\n\t\t\t       allVisitors = data.allVisitors;\n\t\t\t       dau = data.dau;\n\t\t\t       listRendering()\n\t\t       },\n\t\t       error      : function () {\n\t\t\t       alert(\"Error. 관리자에게 문의하십시오.\");\n\t\t       },\n\t       });\n});\n\nfunction requestAjax(url, param) {\n\ttry {\n\t\t$.ajax({\n\t\t\t       url        : url + param,\n\t\t\t       type       : \"GET\",\n\t\t\t       contentType: \"application/x-www-form-urlencoded;charset=utf-8\",\n\t\t\t       dataType   : \"json\",\n\t\t\t       success    : function (data) {\n\t\t\t\t       ajaxResponse = data.pages;\n\t\t\t\t       allVisitors = data.allVisitors;\n\t\t\t\t       dau = data.dau;\n\t\t\t\t       listRendering()\n\t\t\t       },\n\t\t\t       error      : function () {\n\t\t\t\t       alert(\"Error. 관리자에게 문의하십시오.\");\n\t\t\t       },\n\t\t       });\n\n\t}\n\tcatch (e) {\n\t\talert(\"[requestAjax] :: \" + e.message);\n\t}\n}\n\n/**\n * 셀렉트 박스 회사 선택시 검색\n */\nfunction selectedCompany() {\n\t$('#company').val($('#selectCompany').val());\n\tsearchPost();\n}\n\n/**\n * 각 페이지 버튼에 페이지 이동기능 추가\n * @param selectedPageNum 이동하려는 페이지 번호\n * @param size 보여주려는 목록의 갯수\n */\nfunction pageMove(selectedPageNum, size) {\n\ttry {\n\t\tsearchResultList(selectedPageNum, size);\n\t\twindow.scrollTo({\n\t\t\t                top: 0, left: 0, behavior: 'smooth'\n\t\t                });\n\t}\n\tcatch (e) {\n\t\talert(\"[pageMove] :: \" + e.message);\n\t}\n}\n\n/**\n * 선택한 페이지에 해당하는 게시글을 불러옴\n * @param selectedPageNum 선택한 페이지\n * @param size 보여주려는 목록의 갯수\n */\nfunction searchResultList(selectedPageNum, size) {\n\ttry {\n\t\tlet url = CONTEXT_PATH + \"/boards?\";\n\t\tlet param = $('#searchForm :input').filter(function (idx, element) {\n\t\t\treturn $(element).val() != '';\n\t\t}).serialize();\n\n\t\tparam += param == \"\" ? \"\" : \"&amp;\";\n\t\tparam += \"page=\" + selectedPageNum + \"&amp;size=\" + size;\n\n\t\trequestAjax(url, param);\n\n\t}\n\tcatch (e) {\n\t\talert(\"[searchResultList] :: \" + e.message);\n\t}\n}\n\n/**\n * 검색 버튼 클릭시 호출될 함수\n */\nfunction searchPost() {\n\ttry {\n\t\tlet url = CONTEXT_PATH + \"/boards?\";\n\t\tlet currentPageNum = $('#currentPageNum').val() == \"\" ? 0 : $('#currentPageNum').val();\n\t\tlet size = $('#renderingCount').val();\n\t\tlet param = $('#searchForm :input').filter(function (idx, element) {\n\t\t\treturn $(element).val() != '';\n\t\t}).serialize();\n\n\t\tparam += param == \"\" ? \"\" : \"&amp;\";\n\t\tparam += \"page=\" + currentPageNum + \"&amp;size=\" + size;\n\n\t\trequestAjax(url, param);\n\t}\n\tcatch (e) {\n\t\talert(\"[searchResultList] \" + e.message);\n\t}\n}\n\n/**\n * 게시글 목록 렌더링\n */\nfunction listRendering() {\n\ttry {\n\t\t$('#listTbody').empty();\n\n\t\t$('.SHOW-allVisitors').empty();\n\t\t$('.SHOW-allVisitors').text(numberFormat(allVisitors) + ' 명');\n\n\t\t$('.SHOW-DAU').empty();\n\t\t$('.SHOW-DAU').text(numberFormat(dau) + ' 명');\n\n\t\tlet postList = ajaxResponse.content;\n\n\t\tif (postList.length &lt;= 0) {\n\t\t\tlet eleTr = $(\"&lt;tr /&gt;\");\n\t\t\tlet eleTd = $(\"&lt;td /&gt;\")\n\t\t\t\t.css(\"text-align\", \"center\")\n\t\t\t\t.css(\"width\", \"100%\")\n\t\t\t\t.text(\"No matching search results found\");\n\n\t\t\t$(eleTr).append(eleTd);\n\n\t\t\t$('#listTbody').append(eleTr);\n\t\t} else {\n\t\t\t$.each(postList, function () {\n\t\t\t\tlet regDateArray = this.regDate.split('-');\n\t\t\t\tlet regDate = new Date(regDateArray[0], regDateArray[1] - 1, regDateArray[2])\n\n\t\t\t\tlet nowDate = new Date();\n\t\t\t\tlet betweenDay = Math.floor((nowDate.getTime() - regDate.getTime()) / 1000 / 60 / 60 / 24);\n\n\t\t\t\tlet eleTr = $(\"&lt;tr class='graph_tr1'/&gt;\")\n\t\t\t\t\t.append($(\"&lt;td style='text-align:center'/&gt;\").append($(\"&lt;img src=\" + this.imgPath + \" height='48px' width='96px' title='\" + this.company + \"'/&gt;\")))\n\t\t\t\t\t.append($(\"&lt;td style='text-align:center'/&gt;\").append($(\"&lt;span/&gt;\").attr(\"class\", (betweenDay == 0 ? \"badge badge-danger\" : \"\"))\n\t\t\t\t\t                                                                .text((betweenDay == 0 ? \"Today\" : \"\")))\n\t\t\t\t\t                                            .css(\"text-align\", \"left\")\n\t\t\t\t\t                                            .css(\"font-weight\", \"bold\")\n\t\t\t\t\t                                            .css(\"color\", \"skyblue\")\n\t\t\t\t\t                                            .append($(\"&lt;a/&gt;\").attr(\"href\", this.link)\n\t\t\t\t\t                                                             .attr(\"target\", \"blank\")\n\t\t\t\t\t                                                             .text(\" \" + this.title)))\n\t\t\t\t\t.append($(\"&lt;td style='text-align:center'/&gt;\").text(this.regDate));\n\n\t\t\t\t$('#listTbody').append(eleTr);\n\t\t\t});\n\t\t}\n\t\t$('#totalResultCount').empty().append(\"TOTAL  : \" + ajaxResponse.totalElements);\n\t\trenderingPagingArea();\n\t}\n\tcatch (e) {\n\t\talert(\"[listRendering] \" + e.message);\n\t}\n}\n\nfunction renderingPagingArea() {\n\ttry {\n\t\t$('#pagingArea').empty();\n\n\t\tif (ajaxResponse.first != true) {\n\t\t\tlet prePagebutton = $(\"&lt;li/&gt;\").attr(\"class\", \"page-item\")\n\t\t\t                              .append(\n\t\t\t\t                              $(\"&lt;a/&gt;\").attr(\"class\", \"page-link\")\n\t\t\t\t                                       .attr(\"href\", \"javascript:pageMove('\"\n\t\t\t\t                                                     + (ajaxResponse.pageable.pageNumber - 1)\n\t\t\t\t                                                     + \"', \" + ajaxResponse.size + \");\")\n\t\t\t\t                                       .text(\"&lt;\")\n\t\t\t                              );\n\t\t\t$('#pagingArea').append(prePagebutton);\n\t\t}\n\n\t\tlet endPage = Math.ceil((ajaxResponse.pageable.pageNumber + 1) / 10.0) * 10 - 1;\n\t\tlet trueEndPage = Math.ceil(ajaxResponse.totalElements / ajaxResponse.size);\n\t\tlet startPage = endPage - 9;\n\n\t\tif (trueEndPage &lt;= endPage) endPage = trueEndPage - 1;\n\n\t\tfor (let i = startPage; i &lt;= endPage; i++) {\n\t\t\tlet pageNumButton = $(\"&lt;li/&gt;\").attr(\"class\", \"page-item\");\n\n\t\t\tif (ajaxResponse.pageable.pageNumber == i) {\n\t\t\t\t$(pageNumButton).attr(\"class\", \"page-item active\");\n\t\t\t}\n\n\t\t\t$(pageNumButton).append(\n\t\t\t\t$(\"&lt;a/&gt;\").attr(\"class\", \"page-link\")\n\t\t\t\t         .attr(\"href\", \"javascript:pageMove('\"\n\t\t\t\t                       + i\n\t\t\t\t                       + \"', \" + ajaxResponse.size + \");\")\n\t\t\t\t         .text(i + 1)\n\t\t\t);\n\n\t\t\t$('#pagingArea').append(pageNumButton);\n\t\t}\n\n\t\tif (ajaxResponse.last != true) {\n\n\t\t\tlet nextPagebutton = $(\"&lt;li/&gt;\").attr(\"class\", \"page-item\")\n\t\t\t                               .append(\n\t\t\t\t                               $(\"&lt;a/&gt;\").attr(\"class\", \"page-link\")\n\t\t\t\t                                        .attr(\"href\", \"javascript:pageMove('\"\n\t\t\t\t                                                      + (ajaxResponse.pageable.pageNumber + 1)\n\t\t\t\t                                                      + \"', \" + ajaxResponse.size + \");\")\n\t\t\t\t                                        .text(\"&gt;\")\n\t\t\t                               );\n\n\t\t\t$('#pagingArea').append(nextPagebutton);\n\t\t}\n\t}\n\tcatch\n\t\t(e) {\n\t\talert(\"[renderingPagingArea] :: \" + e.message);\n\t}\n}\n\nfunction resetSearchForm(searchFormId) {\n\ttry {\n\t\t$(\"#\" + searchFormId)[0].reset();\n\t\t$('#company').val(\"\");\n\t\tsearchPost();\n\t}\n\tcatch (e) {\n\t\talert(\"[ resetSearchForm() ] :: \" + e.message);\n\t}\n}\n\nfunction enterKeyup() {\n\tif (event.keyCode == 13) {\n\t\tsearchPost();\n\t}\n}\n\nfunction numberFormat(num) {\n\tlet regexp = /\\B(?=(\\d{3})+(?!\\d))/g;\n\treturn num.toString().replace(regexp, ',');\n}\n\n\n \n\n✅ 모던 JavaScript\n\n\n\n'use strict';\n\n/**\n * @author shirohoo\n * 페이지 초기화\n */\n(function init() {\n\tlet url = '/boards?';\n\tlet param = 'page=0&amp;size=10';\n\tapiFetch(url, param, callbackDataBinding);\n})();\n\nconst CONTEXT_PATH = '';\n\nlet response = {\n\tpages           : '',\n\tvisitorsOfReduce: '',\n\tvisitorsOfDay   : ''\n};\n\nfunction apiFetch(url, param, callback) {\n\tfetch(url + param)\n\t\t.then(res =&gt; {\n\t\t\tif (res.status === 200) return res.json()\n\t\t})\n\t\t.then(data =&gt; callback(data))\n\t\t.catch(() =&gt; alert('400, Bad Request'));\n}\n\nfunction callbackDataBinding(data) {\n\tresponse.pages = data.pages;\n\tresponse.visitorsOfReduce = data.visitorsOfReduce;\n\tresponse.visitorsOfDay = data.visitorsOfDay;\n\trenderingBoardArea()\n}\n\n/**\n * 검색 시 엔터키 감지\n */\nfunction enterKeyUp() {\n\tif (event.keyCode == 13) {\n\t\tsearch();\n\t}\n}\n\n/**\n * 숫자 3자리마다 ,추가\n */\nfunction formatNumber(num) {\n\tlet regexp = /\\B(?=(\\d{3})+(?!\\d))/g;\n\treturn num.toString()\n\t          .replace(regexp, ',');\n}\n\n/**\n * 초기화 버튼\n */\nfunction resetSearchForm() {\n\ttry {\n\t\tdocument.querySelector('#searchForm').reset();\n\t\tdocument.querySelector('#company').value = '';\n\t\tsearch();\n\t}\n\tcatch (e) {\n\t\talert(`[resetSearchForm] :: ${e.message}`);\n\t}\n}\n\n/**\n * 검색 버튼 클릭시 호출될 함수\n */\nfunction search() {\n\ttry {\n\t\tlet url = `${CONTEXT_PATH}/boards?`;\n\t\tlet param = new URLSearchParams();\n\t\tlet searchConditions = Array.from(\n\t\t\tdocument.querySelector('#searchForm')\n\t\t\t        .getElementsByTagName('input')\n\t\t).filter((element) =&gt; {\n\t\t\treturn element.id != '';\n\t\t});\n\n\t\tfor (const conditions of searchConditions) {\n\t\t\tparam.append(conditions.name, conditions.value);\n\t\t}\n\n\t\tlet currentPage = document.querySelector('#currentPageNum').value == ''\n\t\t                  ? 0 : document.querySelector('#currentPageNum').value;\n\t\tlet size = document.querySelector('#renderingCount').value;\n\n\t\tparam += param == '' ? '' : '&amp;';\n\t\tparam += `page=${currentPage}&amp;size=${size}`;\n\n\t\tapiFetch(url, param, callbackDataBinding);\n\t}\n\tcatch (e) {\n\t\talert(`[search] :: ${e.message}`);\n\t}\n}\n\n/**\n * 셀렉트 박스 회사 선택시 검색\n */\nfunction selectedCompany() {\n\tlet company = document.querySelector('#company');\n\tlet selectCompany = document.querySelector('#selectCompany');\n\tcompany.value = selectCompany.value;\n\tsearch();\n}\n\n/**\n * 각 페이지 버튼에 페이지 이동기능 추가\n * @param targetPage 이동하려는 페이지\n * @param size 보여주려는 목록의 갯수\n */\nfunction pageMove(targetPage, size) {\n\ttry {\n\t\tgetPage(targetPage, size);\n\t\twindow.scrollTo({\n\t\t\t                top     : 0,\n\t\t\t                left    : 0,\n\t\t\t                behavior: 'smooth'\n\t\t                });\n\t}\n\tcatch (e) {\n\t\talert(`[pageMove] :: ${e.message}`);\n\t}\n}\n\n/**\n * 선택한 페이지에 해당하는 게시글을 불러옴\n * @param selectedPage 선택한 페이지\n * @param size 보여주려는 목록의 갯수\n */\nfunction getPage(selectedPage, size) {\n\ttry {\n\t\tlet url = `${CONTEXT_PATH}/boards?`;\n\t\tlet param = new URLSearchParams();\n\n\t\tlet searchConditions = Array.from(\n\t\t\tdocument.querySelector('#searchForm')\n\t\t\t        .getElementsByTagName('input')\n\t\t).filter((element) =&gt; {\n\t\t\treturn element.id != '';\n\t\t});\n\n\t\tfor (const ele of searchConditions) {\n\t\t\tparam.append(ele.name, ele.value);\n\t\t}\n\n\t\tparam += param == '' ? '' : '&amp;';\n\t\tparam += `page=${selectedPage}&amp;size=${size}`;\n\n\t\tapiFetch(url, param, callbackDataBinding);\n\t}\n\tcatch (e) {\n\t\talert(`[getPage] :: ${e.message}`);\n\t}\n}\n\n/**\n * 게시글 목록 렌더링\n */\nfunction renderingBoardArea() {\n\ttry {\n\t\t// 게시판 초기화\n\t\tlet listTbody = document.querySelector('#boards');\n\t\twhile (listTbody.firstChild) {\n\t\t\tlistTbody.removeChild(listTbody.firstChild);\n\t\t}\n\n\t\t// 누적 방문자 초기화\n\t\tlet allVisitors = document.querySelector('.SHOW-allVisitors');\n\t\twhile (allVisitors.firstChild) {\n\t\t\tallVisitors.removeChild(allVisitors.firstChild);\n\t\t}\n\t\tallVisitors.textContent = `${formatNumber(response.visitorsOfReduce)} 명`;\n\n\t\t// 오늘 방문자 초기화\n\t\tlet dau = document.querySelector('.SHOW-DAU');\n\t\twhile (dau.firstChild) {\n\t\t\tdau.removeChild(dau.firstChild);\n\t\t}\n\t\tdau.textContent = `${formatNumber(response.visitorsOfDay)} 명`;\n\n\t\t// 렌더링\n\t\tlet posts = response.pages.content;\n\t\tif (posts.length &lt;= 0) {\n\t\t\tlet eleTr = $('&lt;tr /&gt;');\n\t\t\tlet eleTd = $('&lt;td /&gt;')\n\t\t\t\t.css('text-align', 'center')\n\t\t\t\t.css('width', '100%')\n\t\t\t\t.text('No matching search results found');\n\n\t\t\t$(eleTr).append(eleTd);\n\t\t\t$('#boards').append(eleTr);\n\t\t} else {\n\t\t\t$.each(posts, function () {\n\t\t\t\tlet regDateArray = this.regDate.split('-');\n\t\t\t\tlet regDate = new Date(regDateArray[0], regDateArray[1] - 1, regDateArray[2])\n\n\t\t\t\tlet nowDate = new Date();\n\t\t\t\tlet betweenDay = Math.floor((nowDate.getTime() - regDate.getTime()) / 1000 / 60 / 60 / 24);\n\n\t\t\t\tlet eleTr = $(\"&lt;tr class='graph_tr1'/&gt;\").append($(`&lt;td style=\"text-align:center\"/&gt;`)\n\t\t\t\t\t                                                .append($(`&lt;img src=\"${this.imgPath}\" height=\"48px\" width=\"96px\" title=\"${this.company}\" /&gt;`)))\n\n\t\t\t\t                                        .append($(`&lt;td style=\"text-align:center\"/&gt;`)\n\t\t\t\t\t                                                .append($('&lt;span/&gt;')\n\t\t\t\t\t\t                                                        .attr('class', (betweenDay == 0 ? 'badge badge-danger' : ''))\n\t\t\t\t\t\t                                                        .text((betweenDay == 0 ? 'Today' : '')))\n\t\t\t\t\t                                                .css('text-align', 'left')\n\t\t\t\t\t                                                .css('font-weight', 'bold')\n\t\t\t\t\t                                                .css('color', 'skyblue')\n\t\t\t\t\t                                                .append($(\"&lt;a/&gt;\")\n\t\t\t\t\t\t                                                        .attr('href', this.link)\n\t\t\t\t\t\t                                                        .attr('target', 'blank')\n\t\t\t\t\t\t                                                        .text(' ' + this.title)))\n\n\t\t\t\t                                        .append($(`&lt;td style=\"text-align:center\"/&gt;`)\n\t\t\t\t\t                                                .text(this.regDate));\n\n\t\t\t\t$('#boards').append(eleTr);\n\t\t\t});\n\t\t}\n\t\t$('#totalResultCount').empty().append(`TOTAL : ${response.pages.totalElements}`);\n\t\trenderingPagingArea();\n\t}\n\tcatch (e) {\n\t\talert(`[listRendering] :: ${e.message}`);\n\t}\n}\n\n/**\n * 페이지네이션 렌더링\n */\nfunction renderingPagingArea() {\n\ttry {\n\t\t$('#pagingArea').empty();\n\t\tif (response.pages.first != true) {\n\t\t\tlet prePagebutton = $('&lt;li/&gt;').attr('class', 'page-item')\n\t\t\t                              .append($('&lt;a/&gt;')\n\t\t\t\t                                      .attr('class', 'page-link')\n\t\t\t\t                                      .attr('href', `javascript:pageMove(${(response.pages.pageable.pageNumber - 1)}, ${response.pages.size});`)\n\t\t\t\t                                      .text('&lt;')\n\t\t\t                              );\n\n\t\t\t$('#pagingArea').append(prePagebutton);\n\t\t}\n\n\t\tlet endPage = Math.ceil((response.pages.pageable.pageNumber + 1) / 10.0) * 10 - 1;\n\t\tlet trueEndPage = Math.ceil(response.pages.totalElements / response.pages.size);\n\t\tlet startPage = endPage - 9;\n\n\t\tif (trueEndPage &lt;= endPage) {\n\t\t\tendPage = trueEndPage - 1;\n\t\t}\n\n\t\tfor (let i = startPage; i &lt;= endPage; i++) {\n\t\t\tlet pageNumButton = $(\"&lt;li/&gt;\").attr('class', 'page-item');\n\t\t\tif (response.pages.pageable.pageNumber == i) {\n\t\t\t\t$(pageNumButton).attr('class', 'page-item active');\n\t\t\t}\n\t\t\t$(pageNumButton).append($('&lt;a/&gt;')\n\t\t\t\t                        .attr('class', 'page-link')\n\t\t\t\t                        .attr('href', `javascript:pageMove(${i}, ${response.pages.size});`)\n\t\t\t\t                        .text(i + 1)\n\t\t\t);\n\t\t\t$('#pagingArea').append(pageNumButton);\n\t\t}\n\n\t\tif (response.pages.last != true) {\n\t\t\tlet nextPageButton = $('&lt;li/&gt;').attr('class', 'page-item')\n\t\t\t                               .append($(\"&lt;a/&gt;\").attr('class', 'page-link')\n\t\t\t                                                .attr('href',\n\t\t\t                                                      `javascript:pageMove(${(response.pages.pageable.pageNumber + 1)}, ${response.pages.size});`\n\t\t\t                                                )\n\t\t\t                                                .text('&gt;')\n\t\t\t                               );\n\t\t\t$('#pagingArea').append(nextPageButton);\n\t\t}\n\n\t}\n\tcatch (e) {\n\t\talert(`[renderingPagingArea] :: ${e.message}`);\n\t}\n}\n\n\n \n\n✅ Vue.js (1차)\n\n\n\n'use strict';\n\nconst app = new Vue({\n\t                    el  : '#app',\n\t                    data: {\n\t\t                    CONTEXT : '',\n\t\t                    response: {\n\t\t\t                    pages           : '',\n\t\t\t                    visitorsOfReduce: '',\n\t\t\t                    visitorsOfDay   : ''\n\t\t                    },\n\t\t                    pager   : {},\n\t                    },\n\n\t                    mounted: function () {\n\t\t                    let url = '/boards?';\n\t\t                    let param = 'page=0&amp;size=10';\n\t\t                    this.apiFetch(url, param, this.callbackDataBinding);\n\t                    },\n\n\t                    methods: {\n\t\t                    apiFetch(url, param, callback) {\n\t\t\t                    fetch(url + param)\n\t\t\t\t                    .then(res =&gt; {\n\t\t\t\t\t                    if (res.status === 200) return res.json()\n\t\t\t\t                    })\n\t\t\t\t                    .then(data =&gt; callback(data))\n\t\t\t\t                    .catch(() =&gt; alert('400, Bad Request'));\n\t\t                    },\n\t\t                    callbackDataBinding(data) {\n\t\t\t                    this.response.pages = data.pages;\n\t\t\t                    this.response.visitorsOfReduce = data.visitorsOfReduce;\n\t\t\t                    this.response.visitorsOfDay = data.visitorsOfDay;\n\t\t\t                    this.pager = this.setPage(data.pages.pageable.pageNumber, data.pages.size, data.pages.totalElements);\n\t\t                    },\n\t\t                    setPage(currentPage, size, total) {\n\t\t\t                    let endPage = Math.ceil((currentPage + 1) / 10.0) * 10 - 1;\n\t\t\t                    let trueEndPage = Math.ceil(total / size);\n\t\t\t                    let startPage = endPage - 9;\n\n\t\t\t                    if (trueEndPage &lt;= endPage) {\n\t\t\t\t                    endPage = trueEndPage - 1;\n\t\t\t                    }\n\n\t\t\t                    let index = [];\n\t\t\t                    for (let i = startPage; i &lt;= endPage; i++) {\n\t\t\t\t                    index.push(i);\n\t\t\t                    }\n\n\t\t\t                    return {\n\t\t\t\t                    index      : index,\n\t\t\t\t                    currentPage: currentPage,\n\t\t\t\t                    startPage  : startPage,\n\t\t\t\t                    endPage    : endPage,\n\t\t\t\t                    trueEndPage: trueEndPage,\n\t\t\t\t                    size       : size,\n\t\t\t\t                    total      : total\n\t\t\t                    };\n\t\t                    },\n\t\t                    enterKeyUp() {\n\t\t\t                    if (event.keyCode == 13) {\n\t\t\t\t                    this.search();\n\t\t\t                    }\n\t\t                    },\n\t\t                    formatNumber(num) {\n\t\t\t                    let regexp = /\\B(?=(\\d{3})+(?!\\d))/g;\n\t\t\t                    return num.toString().replace(regexp, ',');\n\t\t                    },\n\t\t                    resetSearchForm() {\n\t\t\t                    document.querySelector('#searchForm').reset();\n\t\t\t                    document.querySelector('#company').value = '';\n\t\t\t                    this.search();\n\t\t                    },\n\t\t                    selectedCompany() {\n\t\t\t                    let company = document.querySelector('#company');\n\t\t\t                    let selectCompany = document.querySelector('#selectCompany');\n\t\t\t                    company.value = selectCompany.value;\n\t\t\t                    this.search();\n\t\t                    },\n\t\t                    search() {\n\t\t\t                    let url = `${this.CONTEXT}/boards?`;\n\t\t\t                    let param = new URLSearchParams();\n\t\t\t                    let searchConditions = Array.from(\n\t\t\t\t                    document.querySelector('#searchForm')\n\t\t\t\t                            .getElementsByTagName('input')\n\t\t\t                    ).filter((element) =&gt; {\n\t\t\t\t                    return element.id != '';\n\t\t\t                    });\n\n\t\t\t                    for (const conditions of searchConditions) {\n\t\t\t\t                    param.append(conditions.name, conditions.value);\n\t\t\t                    }\n\n\t\t\t                    let currentPage = document.querySelector('#currentPageNum').value == '' ? 0 : document.querySelector('#currentPageNum').value;\n\t\t\t                    let size = document.querySelector('#renderingCount').value;\n\n\t\t\t                    param += param == '' ? '' : '&amp;';\n\t\t\t                    param += `page=${currentPage}&amp;size=${size}`;\n\n\t\t\t                    this.apiFetch(url, param, this.callbackDataBinding);\n\t\t                    },\n\t\t                    isBetweenDay(regDate) {\n\t\t\t                    let regDateArray = String(regDate).split('-');\n\t\t\t                    let date = new Date(regDateArray[0], regDateArray[1] - 1, regDateArray[2])\n\n\t\t\t                    let nowDate = new Date();\n\t\t\t                    let betweenDay = Math.floor((nowDate.getTime() - date.getTime()) / 1000 / 60 / 60 / 24);\n\t\t\t                    return betweenDay === 0;\n\t\t                    },\n\t\t                    pageMove(targetPage, size) {\n\t\t\t                    let url = `${this.CONTEXT}/boards?`;\n\t\t\t                    let param = new URLSearchParams();\n\n\t\t\t                    let searchConditions = Array.from(\n\t\t\t\t                    document.querySelector('#searchForm')\n\t\t\t\t                            .getElementsByTagName('input')\n\t\t\t                    ).filter((element) =&gt; {\n\t\t\t\t                    return element.id != '';\n\t\t\t                    });\n\n\t\t\t                    for (const ele of searchConditions) {\n\t\t\t\t                    param.append(ele.name, ele.value);\n\t\t\t                    }\n\n\t\t\t                    param += param == '' ? '' : '&amp;';\n\t\t\t                    param += `page=${targetPage}&amp;size=${size}`;\n\n\t\t\t                    this.apiFetch(url, param, this.callbackDataBinding);\n\t\t                    },\n\t                    },\n                    });\n\n\n \n\n✅ Vue.js (2차)\n\n\n\n'use strict';\nconst app = new Vue({\n\t                    el     : '#app',\n\t                    data   : {\n\t\t                    search          : {\n\t\t\t                    page   : 0,\n\t\t\t                    size   : 10,\n\t\t\t                    company: '',\n\t\t\t                    title  : ''\n\t\t                    },\n\t\t                    contents        : {},\n\t\t                    pager           : {},\n\t\t                    visitorsOfReduce: 0,\n\t\t                    visitorsOfDay   : 0\n\t                    },\n\t                    mounted: function () {\n\t\t                    this.$nextTick(function () {\n\t\t\t                    this.findContents();\n\t\t                    });\n\t                    },\n\t                    methods: {\n\t\t                    findContents(page) {\n\t\t\t                    if (page !== undefined) this.search.page = page;\n\t\t\t                    let query = Object.keys(this.search)\n\t\t\t                                      .map(k =&gt; encodeURIComponent(k) + '=' + encodeURIComponent(this.search[k]))\n\t\t\t                                      .join('&amp;');\n\t\t\t                    let url = '/boards?' + query;\n\t\t\t                    fetch(url)\n\t\t\t\t                    .then(res =&gt; {\n\t\t\t\t\t                    if (res.status === 200) return res.json()\n\t\t\t\t                    })\n\t\t\t\t                    .then(data =&gt; {\n\t\t\t\t\t                    this.contents = data.pages.content;\n\t\t\t\t\t                    this.visitorsOfReduce = data.visitorsOfReduce;\n\t\t\t\t\t                    this.visitorsOfDay = data.visitorsOfDay;\n\t\t\t\t\t                    this.pager = this.setPage(data.pages);\n\t\t\t\t                    })\n\t\t\t\t                    .catch(() =&gt; alert('400, Bad Request'));\n\t\t                    },\n\t\t                    setPage(pages) {\n\t\t\t                    let endPage = Math.ceil((pages.pageable.pageNumber + 1) / 10.0) * 10 - 1;\n\t\t\t                    let startPage = endPage - 9;\n\t\t\t                    if (pages.totalPages &lt;= endPage) {\n\t\t\t\t                    endPage = pages.totalPages - 1;\n\t\t\t                    }\n\n\t\t\t                    let index = [];\n\t\t\t                    for (let i = startPage; i &lt;= endPage; i++) {\n\t\t\t\t                    index.push(i);\n\t\t\t                    }\n\n\t\t\t                    return {\n\t\t\t\t                    index        : index,\n\t\t\t\t                    size         : pages.size,\n\t\t\t\t                    first        : pages.first,\n\t\t\t\t                    last         : pages.last,\n\t\t\t\t                    currentPage  : pages.pageable.pageNumber,\n\t\t\t\t                    totalPages   : pages.totalPages,\n\t\t\t\t                    totalElements: pages.totalElements\n\t\t\t                    };\n\t\t                    },\n\t\t                    formatNumber(num) {\n\t\t\t                    let regexp = /\\B(?=(\\d{3})+(?!\\d))/g;\n\t\t\t                    return num.toString().replace(regexp, ',');\n\t\t                    },\n\t\t                    enterKeyUp() {\n\t\t\t                    if (event.keyCode === 13) {\n\t\t\t\t                    this.findContents();\n\t\t\t                    }\n\t\t                    },\n\t\t                    resetSearchForm() {\n\t\t\t                    this.search.page = 0;\n\t\t\t                    this.search.size = 10;\n\t\t\t                    this.search.company = '';\n\t\t\t                    this.search.title = '';\n\t\t\t                    this.findContents();\n\t\t                    },\n\t\t                    isBetweenDay(regDate) {\n\t\t\t                    let regDateArray = String(regDate).split('-');\n\t\t\t                    let date = new Date(regDateArray[0], regDateArray[1] - 1, regDateArray[2])\n\n\t\t\t                    let nowDate = new Date();\n\t\t\t                    let betweenDay = Math.floor((nowDate.getTime() - date.getTime()) / 1000 / 60 / 60 / 24);\n\t\t\t                    return betweenDay === 0;\n\t\t                    },\n\t                    },\n                    });\n\n\n \n\n✅ 후기\n\n\n\n일단 코드가 확연히 줄어들긴 했는데, 양방향 바인딩, 템플릿, 컴포넌트, 상태관리 등의 기능을 적극 활용한다면 여기서 훨씬 더 좋은 코드가 될 거라는 생각이 들었다.\n\n \n\n결국 Vue.js를 다루는 실력이 아직 비루한 게 문제인 것 같다.\n\nVue.js를 처음 공부하고 사용해보니 ORM과 비슷한 느낌이 든다.\n\nJPA 같은 경우 RDB를 가상의 인메모리 DB(영속성 컨텍스트)와 연결하고 이를 조작하는 방식으로 RDB를 사용하더라도 객체지향적인 프로그래밍이 가능하게 해 준다.\n\n \n\n이와 비슷하게 Vue.js는 가상의 DOM을 만들어 DOM과 연결하고 이를 조작하는 방식으로 돌아가는 듯했다.\n\n항상 이런 신기술을 학습할 때 가장 어려운 것은 급격한 사고의 전환이 필요하다는 점이다.\n\n사용하는 기술은 바뀌었는데 작업하던 방식은 기존방식이라면 이런 좋은 기술들을 도입하더라도 눈에 띄는 효과를 보기가 어려운 것 같다.\n\n \n\n그러니 신기술을 학습하고 도입할 땐 구조와 원리에 대해 깊게 학습하고 이를 의식하며 점진적으로 체화시켜 나가야 하겠다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-05-08-diary-16/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "시간복잡도와 공간복잡도",
      "date": "2021-05-09 00:08:00 +0000",
      "description": "CS와 PS\n",
      "content": "\n  📜 Big-O 표기법\n  📜 시간복잡도를 고민해야 한다    \n      📕 문제 : 1부터 N까지 수의 합 구하기\n      1초가 걸리는 입력값 N의 크기\n      문제에 알맞은 알고리즘 찾기\n      자바 컬렉션의 시간 복잡도\n    \n  \n  📜 공간 복잡도    \n      📕 문제 : 소수(Prime Number) 구하기\n    \n  \n  📜 결론\n\n\n \n\n📜 Big-O 표기법\n\n\n\n입력값 n과 관계된 최대 연산을 표기하는 방법이다.\n\n여기서 최대라는 뜻은 Worst-Case, 최악의 경우만 본다는 뜻이다.\n\n왜냐하면 예를 들자면선형 탐색(Linear Search) 알고리즘의 경우\n\n\n  \n    \n      index(0)\n      index(1)\n      index(2)\n      index(3)\n      index(4)\n    \n  \n  \n    \n      5\n      3\n      2\n      1\n      4\n    \n  \n\n\n위와 같은 상자 5개에서 5라는 값을 찾고자 할 때 index 0부터 4까지 순차적으로 탐색하는데,\n\n보다시피 5는 맨 앞에 있으므로 첫 탐색에 결과 값이 나온다. 그러니까 말하자면 Best-Case인 것이다.\n\n이처럼 운이 좋을 경우 신뢰할 수 없는 데이터가 나올 가능성이 있기 때문에 항상 최악의 경우를 상정하고 보는 것이다.\n\n그러면 적어도 더 이상의 나쁜 경우는 없을 것이기 때문에 신뢰할 수 있는 데이터가 되는 것.\n\n위 상자에서 Worst-Case를 보면, 값 5가 index4에 위치한 경우\n\nindex 0~4까지 총 5번의 탐색을 거치므로 시간 복잡도는 O(n)이 된다.\n\n왜냐하면 n은 상자의 길이(Length)로 볼 수 있기 때문이다.\n\n\n\n\n  O(1) - Constant\n    \n      입력 데이터의 크기에 상관없이 언제나 일정한 시간이 걸리는 알고리즘.\n    \n  \n  O(log2 n) - Logarithmic\n    \n      입력 데이터의 크기가 커질수록 처리 시간이 로그(log)만큼 짧아지는 알고리즘. 이진 탐색이 대표적이며, 재귀가 순기능으로 이루어지는 경우도 해당\n    \n  \n  O(n) - Linear\n    \n      입력 데이터의 크기에 비례해 처리 시간이 증가하는 알고리즘. 예를 들어 데이터가 10배가 되면, 처리 시간도 10배가 된다. 대표적으로 for문이 있다.\n    \n  \n  O(n log2 n) - Linear-Logarithmic\n    \n      데이터가 많아질수록 처리시간이 로그(log) 배만큼 더 늘어나는 알고리즘. 예를 들어 데이터가 10배가 되면, 처리 시간은 약 20배가 된다. 정렬 알고리즘 중 병합 정렬, 퀵 정렬이 대표적.\n    \n  \n  O(n^2) - quadratic\n    \n      데이터가 많아질수록 처리시간이 제곱으로 늘어나는 알고리즘. 예를 들어 데이터가 10배가 되면, 처리 시간은 최대 100배(10x10)가 된다. 이중 루프(n^2 matrix)가 대표적이며 단, m이 n보다 작을 때는 반드시 O(nm)로 표시하는 것이 바람직하다.\n    \n  \n  O(2^n) - Exponential\n    \n      데이터가 많아질수록 처리시간이 기하급수적으로 늘어나는 알고리즘. 대표적으로 피보나치 수열이 있으며, 재귀가 역기능을 할 경우도 해당.\n    \n  \n\n\n  // O(1)\n  System.out.println(\"Hello world!\");     \n\n\n입력값 n이 몇이든 연산이 1이므로 시간 복잡도는 O(1)이다.\n\n  // O(n)\n  for (int i = 0; i &lt; n; i++) {\n      System.out.println(\"Hello world!\");\n  }\n\n\n입력값 n에 따라 연산이 정비례하므로 시간 복잡도는 O(n)이다.\n\n  // O(n^2)\n  for (int i = 0; i &lt; n; i++) {\n      for (int j = 0; j &lt; n; j++) {\n          System.out.println(\"Hello world!\");\n      }\n  }\n\n\n이중 루프. 입력값 n에 따라 연산이 n의 제곱만큼 늘어나므로 시간 복잡도는 O(n^2)이다.\n\n예를 들어 n=5일 경우 for문 두 개가 5번씩 돌아가기 때문에“Hello World!”는 25번이 찍히게 된다.\n\n  for (int i = 0; i &lt; N; i++) {\n      System.out.println(\"Hello world!\");\n  }\n\n  for (int i = 0; i &lt; N; i++) {\n      System.out.println(\"Hello world!\");\n  }\n\n\n또한, 위와 같이 for문 두 개가 따로따로 있을 경우는 시간 복잡도가 O(n^2)이 아니고  O(n)이다.\n\n왜냐하면 한 블록에서의 Worst-Case만을 표기하기 때문\n\n \n\n\n\n \n\n\n\n \n\n📜 시간복잡도를 고민해야 한다\n\n\n\n알고리즘 문제를 풀다 보면 같은 문제라도 어떤 해법을 선택하는지에 따라 수행에 걸리는 시간이 크게 차이 난다.\n\n일반적으로 알고리즘에선 1억번의 연산 횟수를 어림잡아 1초정도 걸릴 거라고 기준을 잡는다.\n\n이 등가 개념은 개인용 PC의 CPU 연산속도를 근거로 나온 수치라고 하는데,\n\n현대의 상용 CPU는 대충 초당 1억 번의 연산을 하기 때문이란다.\n\n📕 문제 : 1부터 N까지 수의 합 구하기\n\n\n\n// solution 1\n// 시간복잡도 O(N^2)\nint sum = 0;\nfor (int i = 1; i &lt;= N; i++) {\n    for (int j = 1; j &lt;= N; j++) {\n        if (i == j) {\n            sum += j;\n        }\n    }\n}\n\n\n// solution 2\n// 시간복잡도 O(N)\nint sum = 0;\nfor (int i = 1; i &lt;= N; i++) {\n    sum += i;\n}\n\n\n// solution 3\n// 시간복잡도 O(1)\nint sum = 0;\nsum = N * ( N + 1 ) / 2;\n\n\n입력값 N에 대해 2중 for문으로 돌려 푼 1번 방법은 O(N^2)의 시간 복잡도가 나온다.\n\n입력값 N에 대해 for문 한 번으로 푼 2번 방법은 O(N)의 시간 복잡도가 나온다.\n\n입력값 N에 대해 수학공식을 대입한 3번 방법은 O(1)의 시간 복잡도가 나온다.\n\n예를 들어 1부터 10만까지 수의 합을 구하여야 한다면,\n\n\n  1번 : 10만 x 10만 = 100억\n2번 : 10만 = 10억\n3번 : 10만 = 1\n\n\n이 값들을 가지고 수행 시간을 예상해본다면,\n\n1억 = 1초이므로\n\n\n  1번 : 100억 = 100초\n2번 : 10만 = 0.001초\n3번 : 1 = 즉시(이루 말할 수 없이 빠름)\n\n\n위와같은 값을 예상할 수 있다.\n\n1초가 걸리는 입력값 N의 크기\n\n\n\n\n  \n    \n      BigO\n      입력\n    \n  \n  \n    \n      O(1)\n      -\n    \n    \n      O(lgN)\n      -\n    \n    \n      O(N)\n      1억\n    \n    \n      O(NlgN)\n      500만\n    \n    \n      O(N^2)\n      1만\n    \n    \n      O(N^3)\n      500\n    \n    \n      O(2^N)\n      20\n    \n    \n      O(N!)\n      10\n    \n  \n\n\n문제에 알맞은 알고리즘 찾기\n\n\n\n\n\n자바 컬렉션의 시간 복잡도\n\n\n\n\n\n📜 공간 복잡도\n\n\n\n시간 복잡도는 어떤 명령을 수행하는데 걸리는 시간을 말한다\n공간 복잡도는 어떤 명령을 수행하는데 필요한 메모리의 크기를 말한다\n\n가장 이상적인 프로그램은 시간 복잡도와 공간복잡도가 모두 낮은 것이지만,\n\n일반적으로 시간복잡도와 공간 복잡도는 반비례 관계이다.\n\n우선 왜 그런지 한번 살펴보자.\n\n📕 문제 : 소수(Prime Number) 구하기\n\n\n\n\n  소수(Prime Number) ?\n1과 자기자신으로만 나누어 떨어지는 수\n\n  3, 5, 7 …\n\n  간단하게 정리하자면 소수를 구하기 위한 조건은 아래와 같다고 볼 수 있다\n\n  2부터 n-1 까지의 어떤 정수로도 나누어 떨어지지 않는 수\n\n\npublic static void main(String[] args) {\n\n    // 연산 횟수를 체크하기 위한 변수\n    int operationCount = 0;\n\n    // 1000이하의 모든 소수를 구하기 위한 조건 (n&lt;=1000)\n    for(int primeNumber = 2; primeNumber &lt;= 1000; primeNumber++) {\n\n        // 소수를 판별하기 위한 값을 갖는 지역변수\n        int operation;\n\n        // 연산횟수를 증가시킴\n        // 2부터 n-1까지의 모든 값으로 나누다 나누어떨어지면 \n        // 소수가 아니므로 반복문을 탈출하고 다음 수를 연산\n        for(operation = 2; operation &lt; primeNumber; operation++) {\n            operationCount++;\n            if(primeNumber % operation == 0) {\n                break;\n            }\n        }\n\n        // 2부터 n-1까지의 모든 값으로 나누어떨어지지 않았으므로 소수이다. 출력 !\n        if(primeNumber == operation) {\n            System.out.println(\"primeNumber = \" + primeNumber);\n        }\n    }\n\n    // 최종 연산 횟수를 출력\n    System.out.println(\"operations count = \" + operationCount);\n}\n\n\n\n  출력 값\nprimeNumber =2\nprimeNumber =3\nprimeNumber =5\n… 중략 …\nprimeNumber = 983\nprimeNumber = 991\nprimeNumber = 997\n\n  operations count = 78022\n\n\n\n\n2부터 n-1 까지의 어떤 정수로도 나누어 떨어지지 않는 수\n\n또한 이렇게도 볼 수 있다\n\n소수 = 소수로 나누었을때 나누어 떨어지지 않는 수\n\n그렇다면 2는 소수이므로 4이상의 모든 짝수또한 제외할 수 있겠다\n\n소수를 찾을 때 4이상의 짝수를 제외한 1000이하의 홀수를 대상으로\n\n구해놓은 소수들을 이용하여 찾으면 더 빠르게 연산할 수 있지 않을까?\n\npublic static void main(String[] args) {\n\n    // 연산 횟수를 체크하기 위한 변수\n    int operationCount = 0;\n\n    // 찾은 소수의 개수\n    int primeCount = 0;\n\n    // 찾은 소수를 저장하는 배열\n    int[] primeNumbers = new int[300];\n\n    // 배열 첫 칸에 소수 2를 집어넣고 찾은 소수의 개수를 1 증가시킴\n    primeNumbers[primeCount++] = 2;\n\n    // 2까지의 소수를 찾았으므로 3이상의 '홀수'를 대상으로 루프\n    for(int n = 3; n &lt;= 1000; n += 2) {\n\n        int i;\n        for(i = 1; i &lt; primeCount; i++) {\n\n            // 연산횟수를 증가시킴\n            operationCount++;\n\n            // 찾은 소수로 나누어봄\n            // 나누어 떨어질 경우 소수가 아니므로 반복문 탈출\n            if(n % primeNumbers[i] == 0) {\n                break;\n            }\n        }\n\n        // 마지막까지 나누어떨어지지 않았다. \n        // 이는 소수이므로 배열에 저장하고 찾은 소수의 개수를 증가시킴\n        if(primeCount == i) {\n            primeNumbers[primeCount++] = n;\n        }\n    }\n\n    // 배열 전체를 대상으로 루프하며 찾아낸 소수들을 출력\n    for(int i = 0; i &lt; primeCount; i++) {\n        System.out.println(\"primeNumbers = \" + primeNumbers[i]);\n    }\n\n    // 최종 연산 횟수를 출력\n    System.out.println(\"operations count = \" + operationCount);\n}\n\n\n\n  출력 값\nprimeNumber =2\nprimeNumber =3\nprimeNumber =5\n… 중략 …\nprimeNumber = 983\nprimeNumber = 991\nprimeNumber = 997\n\n  operations count = 14622\n\n\n📜 결론\n\n\n\n시간복잡도와 공간복잡도가 어떻게 반비례 관계가 되는지 간단하게 살펴보았다.\n\n이와 같이 빠른 알고리즘은 더 많은 메모리를 사용한다.\n\n78022 - 14622 = 63400 만큼의 연산을 덜 수행했지만,\n\n배열을 사용했으므로 메모리를 더 많이 사용했다.\n\n상기의 코드에서 300칸짜리 정수형 배열을 사용했는데.\n\n정수형은 4Byte의 크기를 가지므로 300x4 = 1,200Byte (약 1.2KB)정도의 메모리를 더 사용했음을 알 수 있다.\n\n \n\n결론적으로 시간복잡도에서 연산횟수 63,400만큼의 이득을 보았으나\n\n공간복잡도에서 메모리 1.2KB정도의 손해를 보았다.\n\n결국 항상 두 개의 가치 중 한 가지를 일부 포기해야만 하는(trade-off) 상황이 생기는데,\n\n단도직입적으로 얘기하자면 우리는 시간 복잡도를 우선으로 생각해야만 한다.\n\n예를 들어 어떤 프로그램을 짜고 보니 이 녀석이 명령 A를 수행하는데 10일이라는 시간이 걸리지만,\n\n메모리를 더 많이 쓴다면 시간을 10일에서 1일까지 줄일 수 있다고 가정해보자.\n\n그럼 메모리를 더 사다가 꼽으면 된다 !\n\n \n\n이렇게 시간은 돈을 주고도 살 수 없지만 메모리는 돈주면 살 수 있다.\n\n \n\n또한 현대의 하드웨어는 성능이 너무 엄청나서 대부분의 개발자들은 말도 안 되는 삽질을 하지 않는 한\n\n평소 메모리의 부족을 느낄 일이 사실상 없다고 봐도 무방하다. (가끔 헛짓해서 OutOfMememory 뜨는 경우가 있긴 하다)\n\n일반적으로 개발자들이 사용하는 개발용 노트북의 경우 메모리를\n\n작게는 8GB부터 64GB까지 다양하게 사용하는데 이게 얼마나 큰 메모리인지 계산해보자면,\n\nint[] ints = new int[10000][10000];\n\n\nJava에서 정수형(int)은4byte의 크기를 갖는다\n\n위 배열의 크기를 계산해보면\n\n10,000 x 10,000 x 4 =400,000,000 Byte\n\n1024 Byte=1 KB\n\n1024 KB=1 MB\n\n400,000,000 Byte= 약400 MB\n\n우리가 사실상 사용할 일 없는 비현실적인 배열의 크기에 비해\n\n정말 별 볼일 없는 메모리 크기가 나옴을 알 수 있다.\n\n그러니 항상 메모리보다는 수행 시간(시간 복잡도)을 중요하게 여겨야 한다.\n",
      "categories": ["cs","data-structure-algorithm"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/data-structure-algorithm/2021-05-09-big-o/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "Java 숫자 리터럴 언더바(_)에 대하여",
      "date": "2021-05-09 13:49:00 +0000",
      "description": "큰 숫자의 가독성을 개선해봅니다\n",
      "content": "\n  ✅ 숫자 리터럴 언더바    \n      ✅ 사용 예\n    \n  \n\n\n \n\n✅ 숫자 리터럴 언더바\n\n\n\nlong creditCardNumber = 1234_5678_9012_3456L;\nlong socialSecurityNumber = 999_99_9999L;\nfloat pi = \t3.14_15F;\nlong hexBytes = 0xFF_EC_DE_5E;\nlong hexWords = 0xCAFE_BABE;\nlong maxLong = 0x7fff_ffff_ffff_ffffL;\nbyte nybbles = 0b0010_0101;\nlong bytes = 0b11010010_01101001_10010100_10010010;\n\n\n \n\n우선 이 기능은 자바 7이상에서만 사용 가능한 기능인데,\n\n요즘 대부분은 8이나 11을 사용하므로 이 기능을 사용하는데 문제가 없다.\n\n(은행권은 아직 자바 4쓰는데도 있다 카더라…😨)\n\n \n\n아무튼 자바에서는 위 예제처럼 숫자의 가독성을 위해 숫자 사이에 언더바(_)를 사용할 수 있다.\n\n다만 몇 가지 규칙이 있다.\n\n\n  숫자의 시작이나 끝에는 사용할 수 없다 (ex: int a = _100_;)\n  부동소수점 리터럴의 소수점에 인접하는 경우 (ex: float pi = 3._1415;)\n  접미사 F 또는 L의 앞 (ex: long a = 100_L;)\n  숫자나 문자열이 예상되는 위치\n\n\n \n\nfloat pi1 = 3_.1415F;      // Invalid; cannot put underscores adjacent to a decimal point\nfloat pi2 = 3._1415F;      // Invalid; cannot put underscores adjacent to a decimal point\nlong l = 999_99_9999_L;    // Invalid; cannot put underscores prior to an L suffix\n\nint x1 = _52;              // This is an identifier, not a numeric literal\nint x2 = 5_2;              // OK (decimal literal)\nint x3 = 52_;              // Invalid; cannot put underscores at the end of a literal\nint x4 = 5_______2;        // OK (decimal literal)\n\nint x5 = 0_x52;            // Invalid; cannot put underscores in the 0x radix prefix\nint x6 = 0x_52;            // Invalid; cannot put underscores at the beginning of a number\nint x7 = 0x5_2;            // OK (hexadecimal literal)\nint x8 = 0x52_;            // Invalid; cannot put underscores at the end of a number\n\nint x9 = 0_52;             // OK (octal literal)\nint x10 = 05_2;            // OK (octal literal)\nint x11 = 052_;            // Invalid; cannot put underscores at the end of a number\n\n\n \n\n✅ 사용 예\n\n\n\n예를 들어 어떤 로직의 대략적인 수행 시간을 알고 싶다고 해보자.\n\n \n\npublic class TimeTest {\n    public static void main(String[] args) {\n        long start = System.nanoTime();\n        \n        long count = 0;\n        \n        for(long i = 0; i &lt; 1000000000; i++) {\n            count++;\n        }\n        \n        long end = System.nanoTime();\n        \n        System.out.println(\"total count = \" + count); // total count = 1000000000\n        System.out.println(\"duration time : \" + (double) (end - start) / 1000000000 + \" s\"); // duration time : 0.3019148 s\n    }\n}\n\n\n \n\nSystem.nanoTime의 경우 완벽한 결과를 보장하지 않지만 대략적인 성능에 대한 감을 잡을 수는 있다.\n\n(완벽한 테스트를 원한다면 JMH같은 전문 벤치마킹 라이브러리를 써야 한다)\n\n위 코드는 루프를 10억번 돌린 후 얻어낸 수행 시간의 단위가 ns(나노초)이므로,\n\n이를 초단위로 바꾸기 위해서는 10억(10^9)으로 나누어주어야 한다.\n\n이 경우 10억을 1,000,000,000라고 표현하면 정말 알아보기 쉽겠지만\n\n자바는 숫자에 쉼표를 넣으면 컴파일에러가 발생한다.\n\n이럴 때 바로 언더바를 사용할 수 있다.\n\n \n\npublic class TimeTest {\n    public static void main(String[] args) {\n        long start = System.nanoTime();\n        \n        long count = 0;\n        \n        for(long i = 0; i &lt; 1_000_000_000; i++) {\n            count++;\n        }\n        \n        long end = System.nanoTime();\n        \n        System.out.println(\"total count = \" + count); // total count = 1000000000\n        System.out.println(\"duration time : \" + (double) (end - start) / 1_000_000_000 + \" s\"); // duration time : 0.3019148 s\n    }\n}\n\n\n \n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2021-05-09-number-literal/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "중첩 for문 성능 차이",
      "date": "2021-05-11 19:55:00 +0000",
      "description": "여러가지 루프의 성능차이에 대한 정리\n",
      "content": "\n  ✅ Nested For 루프    \n      ❓ 캐시와 오버헤드로 인한 성능차이\n    \n  \n  ✅ 결론\n\n\n \n\n✅ Nested For 루프\n\n\n\n최근 회사에서 피크타임에 트래픽이 5배나 증가해 서버가 뻗어버리는 일이 있었다.\n\n(이 일로 사업담당자분은 그날의 손해액을 계산하시느라 다크서클이 생기셨고, 우리팀도 야근을했다…😢)\n\n \n\n원래도 성능 최적화에 관심이 있었는데,\n\n실제로 장애를 겪고 보니 아예 목을 매는 수준까지 가는 것 같다.\n\n아무튼 이번 주제인 중첩 for문에서의 성능차이에 대해 한번 실험을 해봤다.\n\n \n\n@Benchmark\npublic void test1() {\n    long count = 0;\n    for(long i = 0; i &lt; 10_000_000; i++) {\n        for(long j = 0; j &lt; 100; j++) {\n            BigDecimal big = new BigDecimal(\"1000\");\n            count++;\n        }\n    }\n}\n@Benchmark\npublic void test2() {\n    long count = 0;\n    for(long i = 0; i &lt; 100; i++) {\n        for(long j = 0; j &lt; 10_000_000; j++) {\n            BigDecimal big = new BigDecimal(\"1000\");\n            count++;\n        }\n    }\n}\n\n\n \n\ntest1() 은 외부 10,000,000회 / 내부 100회로 총 10억회의 루프를 돌며\n\ntest2() 은 외부 100회 / 내부 10,000,000회로 역시 총 10억회의 루프를 돈다.\n\n루프 내부에 BigDecimal을 생성하는 부분이 있는데,\n\n그냥 루프에 약간의 부하를 주기 위한 장치다.\n\n아무튼 도는 횟수는 같지만 유의미한 성능차이가 발생하였다.\n\n결과부터 보자면\n\n \n\n// test1()\nResult \"bench.ForLoop.test1\":\n  15981.999 ±(99.9%) 1890.234 ms/op [Average]\n  (min, avg, max) = (15350.046, 15981.999, 16617.751), stdev = 490.888\n  CI (99.9%): [14091.766, 17872.233] (assumes normal distribution)\n  \n  \n// test2()\nResult \"bench.ForLoop.test2\":\n  16013.786 ±(99.9%) 520.377 ms/op [Average]\n  (min, avg, max) = (15836.663, 16013.786, 16182.794), stdev = 135.140\n  CI (99.9%): [15493.410, 16534.163] (assumes normal distribution)\n\n\n \n\nJMH로 JVM 워밍업, 메모리 최적화 등을 가한 후 뽑아낸 결과다.\n\ntest1() 메소드의 경우 1.89초의 수행 시간이 발생했고\n\ntest2() 메소드의 경우 0.52초의 수행 시간이 발생했다.\n\n그렇다면 이렇게 되는 원인이 대체 뭔가?라는 의문이 생긴다.\n\n정확히 어떤원리로 이런 결과가 나오는 건지는 모르겠지만\n\n내 짧은 지식으로는 한 가지 원인이 가장 유의미하다고 생각된다.\n\n \n\n❓ 캐시와 오버헤드로 인한 성능차이\n\n\n\n컴퓨터 구조와 운영체제 과목에서 데이터의 지역성에 관해 공간 지역성, 시간 지역성 등의 내용이 있었다.\n\nJVM에서 어느정도 다 최적화가 돼있긴 하겠지만, 아무리 생각해도 이 이유가 가장 크지않을까 싶다.\n\n \n\nfor(int i=0; i&lt;10; i++;){}\n\n\n \n\nfor문도 내부적으로 지역변수 선언 / 조건 판단&amp;분기 / 연산의 과정을 거치는데\n\n이 일련의 과정들이 캐시 되고 이 최적화로인해 발생하는 오버헤드의 차이가\n\n유의미한 성능의 차이로 나타나는게 아닐까?라는 생각이 강하다.\n\n무슨 말이냐면,\n\n \n\nfor(long i = 0; i &lt; 10_000_000; i++) {\n    for(long j = 0; j &lt; 100; j++) {\n        BigDecimal big = new BigDecimal(\"1000\");\n        count++;\n    }\n}\n\n\n \n\n이 경우 for 루프가 100회동안 선형 상태를 유지한다.\n\n즉 for 루프의 방향성을 10,000,000회 갱신해야한다.\n\n \n\nfor(long i = 0; i &lt; 100; i++) {\n    for(long j = 0; j &lt; 10_000_000; j++) {\n        BigDecimal big = new BigDecimal(\"1000\");\n        count++;\n    }\n}\n\n\n \n\n이 경우엔 for 루프가 10,000,000회 동안 선형 상태를 유지한다.\n\n즉 for 루프의 방향성을 100회만 갱신하면 된다.\n\n뭐 전부 다 추측일 뿐이고,\n\n정확한 원리는 아직 모르겠지만\n\n결론은 확실하다.\n\n \n\n✅ 결론\n\n\n\n더 작은 수를 for문의 외곽으로 뽑아낼수록 유의미한 성능 향상이 있다.\n\n또 한 가지 유의사항으로는\n\n \n\n// 좋지않음\nfor(int i=0; i&lt;list.size(); i++){}\n\n// 좋음\nint size = list.size();\nfor(int i=0; j&lt;size; i++){}\n\n\n \n\n위 방법의 경우 주소 참조 연산(list.size())이 루프마다 일어나기 때문에\n\n큰 배열을 루프할 때 좋지 않다.\n\n이 경우에는 미리 주소를 참조하여 값을 스택에 할당해두고\n\n계속 사용하는 두 번째 방법이 더 효율이 좋았다.\n\n \n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2021-05-11-for-loop/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "Elasticsearch + Logstash + Kibana 설치하기",
      "date": "2021-05-13 22:22:00 +0000",
      "description": "ELK Stack\n",
      "content": "\n  📕 참고\n  📕 환경\n  ✅ Elasticsearch 설치    \n      💡 설치 페이지\n      💡 LINUX X84_64\n      💡 LINUX AARCH64\n    \n  \n  ✅ Logstash 설치    \n      💡 설치 페이지\n      💡 LINUX X84_64\n      💡 LINUX AARCH64\n      Logstash에서 Kafka 에 정상적으로 연동됐는지 확인\n    \n  \n  ✅ Kibana 설치    \n      💡 설치 페이지\n      💡 LINUX X84_64\n      💡 LINUX AARCH64\n    \n  \n\n\n\n\n📕 참고\n\n\n\n\n  https://www.elastic.co/guide/en/logstash/current/config-setting-files.html\n  https://www.elastic.co/guide/en/logstash/current/configuration.html\n  https://www.elastic.co/guide/en/logstash/current/logstash-settings-file.html\n  https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html\n  https://www.elastic.co/guide/en/logstash/current/logging.html#log4j2\n\n\n\n\n📕 환경\n\n\n\n\n  \n    \n      OS\n      WSL2-Ubuntu 20.04-x86_64\n    \n  \n  \n    \n      Elasticsearch\n      7.12.1\n    \n    \n      Logstash\n      7.12.1\n    \n    \n      Kibana\n      7.12.1\n    \n  \n\n\n\n\n✅ Elasticsearch 설치\n\n\n\nElasticsearch는 검색엔진이면서 일종의 데이터베이스이다.\n\n주로 수행하는 것은 인덱싱과 적재이다.\n\n한마디로 SELECT만 되는 SELECT에 최적화된 데이터베이스라고 생각하면 편하다.\n\n설치 전 OS의 환경을 알아야 한다. 매우 중요하다.\n\n\n\n$ uname -a\nLinux shirohoo 5.4.72-microsoft-standard-WSL2 #1 SMP Wed Oct 28 23:40:43 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\n\n\n\n\n필자는 x86_64이다.\n\n적당한 위치에 설치를 시작한다.\n\n\n\n💡 설치 페이지\n\n\n\n\n  https://www.elastic.co/kr/downloads/logstash\n\n\n\n\n💡 LINUX X84_64\n\n\n\n$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.12.1-linux-x86_64.tar.gz\n\n\n\n\n💡 LINUX AARCH64\n\n\n\n$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.12.1-linux-aarch64.tar.gz\n\n\n\n\n잠시 기다린다.\n\n\n\n\n\n다음 명령어를 입력하여 압축을 푼다.\n\n\n\n$ tar xvf elasticsearch-7.12.1-linux-x86_64.tar.gz\n\n\n\n\n\n\n\n\n압축파일은 이제 필요 없으니 삭제해줘야겠다.\n\n이 포스팅을 보고 따라 하시는 분은 굳이 지우지 않으셔도 된다.\n\n개인적인 습관이다.\n\n\n\n$ cd elasticsearch-7.12.1/\n$ vi config/elasticsearch.yml\n\n\n\n\nElasticsearch의 전체적인 동작 설정을 해준다.\n\n아래와 같이 설정해주도록 한다.\n\n중괄호({})로 묶인 부분만 중괄호를 지우고 설정해주면 된다.\n\n\n\n\n  예 : “{elasticsearch_host}” -&gt; “my_elasticsearch”\n\n\n\n\nvim의 입력방법은 키보드 i를 누르면 INSERT모드로 변경되어 편집이 가능해진다.\n\n\n\n# -- Cluster --\ncluster.name: {cluster_name}\nnode.name: {node_name}\n\n# -- Paths --\npath.data: {path}\npath.logs: {path}\n\n# -- network --\nnetwork.host: \"{elasticsearch_host}\" // 엘라스틱서치를 구동하는 서버의 IP주소\nhttp.port: {elasticsearch_port} // default: 9200\n\n# -- discovery --\ndiscovery.seed_hosts: [\"127.0.0.1\", \"[::1]\"]\n\ncluster.initial_master_nodes: [\"{elasticsearch_host}\"]\n\n\n\n\n설정을 완료하였으면 저장하고 나온다.\n\n저장 후 나오는 방법은 키보드 ESC를 입력하면 편집 모드가 종료되며\n\n이 상태에서 콜론(:) - wq - ENTER를 순서대로 입력하면 된다.\n\n필자의 설정은 아래와 같다.\n\n\n\n# ======================== Elasticsearch Configuration =========================\n#\n# NOTE: Elasticsearch comes with reasonable defaults for most settings.\n#       Before you set out to tweak and tune the configuration, make sure you\n#       understand what are you trying to accomplish and the consequences.\n#\n# The primary way of configuring a node is via this file. This template lists\n# the most important settings you may want to configure for a production cluster.\n#\n# Please consult the documentation for further information on configuration options:\n# https://www.elastic.co/guide/en/elasticsearch/reference/index.html\n#\n# ---------------------------------- Cluster -----------------------------------\n#\n# Use a descriptive name for your cluster:\n#\n# cluster.name: my-application\n#\ncluster.name: first_elasticsearch\n#\n# ------------------------------------ Node ------------------------------------\n#\n# Use a descriptive name for the node:\n#\n# node.name: node-1\n#\nnode.name: es-node-1\n#\n# Add custom attributes to the node:\n#\n# node.attr.rack: r1\n#\n# ----------------------------------- Paths ------------------------------------\n#\n# Path to directory where to store the data (separate multiple locations by comma):\n#\n# path.data: /path/to/data\n#\npath.data: ~/es_base/data\n#\n# Path to log files:\n#\n# path.logs: /path/to/logs\n#\npath.logs: ~/es_base/logs\n#\n# ----------------------------------- Memory -----------------------------------\n#\n# Lock the memory on startup:\n#\n# bootstrap.memory_lock: true\n#\n# Make sure that the heap size is set to about half the memory available\n# on the system and that the owner of the process is allowed to use this\n# limit.\n#\n# Elasticsearch performs poorly when the system is swapping the memory.\n#\n# ---------------------------------- Network -----------------------------------\n#\n# By default Elasticsearch is only accessible on localhost. Set a different\n# address here to expose this node on the network:\n#\n# network.host: 127.0.0.1\n#\n# By default Elasticsearch listens for HTTP traffic on the first free port it\n# finds starting at 9200. Set a specific HTTP port here:\n#\n# http.port: 9200\n#\n# For more information, consult the network module documentation.\n#\n# --------------------------------- Discovery ----------------------------------\n#\n# Pass an initial list of hosts to perform discovery when this node is started:\n# The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\n#\n# discovery.seed_hosts: [\"host1\", \"host2\"]\n#\ndiscovery.seed_hosts: [\"127.0.0.1\", \"[::1]\"]\n#\n# Bootstrap the cluster using an initial set of master-eligible nodes:\n#\n# cluster.initial_master_nodes: [\"node-1\", \"node-2\"]\n#\ncluster.initial_master_nodes: [\"127.0.0.1\"]\n#\n# For more information, consult the discovery and cluster formation module documentation.\n#\n# ---------------------------------- Various -----------------------------------\n\n\n\n\n계속 설정한다.\n\n이번엔 Elasticsearch의 구동에 필요한 자원들을 설정해준다.\n\n\n\n$ sudo vi /etc/sysctl.conf\n\n\n\n\nElasticsearch는 부팅 과정에 mmap 수가 262,144 이하이면 실행되지 않도록 되어있다.\n\nvm.max_map_count 값을 엘라스틱서치가 동작할 수 있는 최소 값인 262,144로 수정해준다.\n\n다음 코드를 파일 최하단에 추가한다.\n\n\n\nvm.max_map_count=262144 \n\n\n\n\n아래 명령어를 입력하여 이 설정을 적용시켜준다\n\n\n\n# 변경내역 적용\n$ sudo sysctl -p\nvm.max_map_count = 262144\n\n\n\n\n계속 진행한다.\n\n\n\n$ sudo vi /etc/security/limits.conf\n\n\n\n\n리눅스 사용자가 제어할 수 있는 프로세스의 개수를\n\nElasticsearch가 요구하는 사양대로 늘려준다.\n\n\n\n#최하단에 추가\n{linux_user_name} - nofile 65536\n{linux_user_name} - nproc 65536\n{linux_user_name} - memlock unlimited\n\n\n\n\nElasticsearch를 실행해본다.\n\n\n\n$ pwd\n/home/khan/elasticsearch-7.12.1\n\n$ ./bin/elasticsearch\n\n\n\n\n이런 저런 warning이 뜰 수 있는데 일단 error만 없으면 상관없다.\n\n\n\n[2021-05-13T20:56:13,898][INFO ][o.e.n.Node               ] [es-node-1] initialized\n[2021-05-13T20:56:13,900][INFO ][o.e.n.Node               ] [es-node-1] starting ...\n[2021-05-13T20:56:13,916][INFO ][o.e.x.s.c.f.PersistentCache] [es-node-1] persistent cache index loaded\n[2021-05-13T20:56:14,011][INFO ][o.e.t.TransportService   ] [es-node-1] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}\n[2021-05-13T20:56:14,150][WARN ][o.e.b.BootstrapChecks    ] [es-node-1] max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]\n[2021-05-13T20:56:14,158][INFO ][o.e.c.c.ClusterBootstrapService] [es-node-1] skipping cluster bootstrapping as local node does not match bootstrap requirements: [192.168.0.1]\n[2021-05-13T20:56:24,167][WARN ][o.e.c.c.ClusterFormationFailureHelper] [es-node-1] master not discovered yet, this node has not previously joined a bootstrapped (v7+) cluster, and this node must discover master-eligible nodes [192.168.0.1] to bootstrap a cluster: have discovered [{es-node-1}{Q59cZ2_jTFeb_LoPG1eZsQ}{ac1qydF0Rayti-2_HcvapA}{127.0.0.1}{127.0.0.1:9300}{cdfhilmrstw}{ml.machine_memory=26878091264, xpack.installed=true, transform.node=true, ml.max_open_jobs=20, ml.max_jvm_size=1037959168}]; discovery will continue using [] from hosts providers and [{es-node-1}{Q59cZ2_jTFeb_LoPG1eZsQ}{ac1qydF0Rayti-2_HcvapA}{127.0.0.1}{127.0.0.1:9300}{cdfhilmrstw}{ml.machine_memory=26878091264, xpack.installed=true, transform.node=true, ml.max_open_jobs=20, ml.max_jvm_size=1037959168}] from last-known cluster state; node term 0, last-accepted version 0 in term 0\n[2021-05-13T20:56:34,172][WARN ][o.e.c.c.ClusterFormationFailureHelper] [es-node-1] master not discovered yet, this node has not previously joined a bootstrapped (v7+) cluster, and this node must discover master-eligible nodes [192.168.0.1] to bootstrap a cluster: have discovered [{es-node-1}{Q59cZ2_jTFeb_LoPG1eZsQ}{ac1qydF0Rayti-2_HcvapA}{127.0.0.1}{127.0.0.1:9300}{cdfhilmrstw}{ml.machine_memory=26878091264, xpack.installed=true, transform.node=true, ml.max_open_jobs=20, ml.max_jvm_size=1037959168}]; discovery will continue using [] from hosts providers and [{es-node-1}{Q59cZ2_jTFeb_LoPG1eZsQ}{ac1qydF0Rayti-2_HcvapA}{127.0.0.1}{127.0.0.1:9300}{cdfhilmrstw}{ml.machine_memory=26878091264, xpack.installed=true, transform.node=true, ml.max_open_jobs=20, ml.max_jvm_size=1037959168}] from last-known cluster state; node term 0, last-accepted version 0 in term 0\n[2021-05-13T20:56:44,166][WARN ][o.e.n.Node               ] [es-node-1] timed out while waiting for initial discovery state - timeout: 30s\n[2021-05-13T20:56:44,177][WARN ][o.e.c.c.ClusterFormationFailureHelper] [es-node-1] master not discovered yet, this node has not previously joined a bootstrapped (v7+) cluster, and this node must discover master-eligible nodes [192.168.0.1] to bootstrap a cluster: have discovered [{es-node-1}{Q59cZ2_jTFeb_LoPG1eZsQ}{ac1qydF0Rayti-2_HcvapA}{127.0.0.1}{127.0.0.1:9300}{cdfhilmrstw}{ml.machine_memory=26878091264, xpack.installed=true, transform.node=true, ml.max_open_jobs=20, ml.max_jvm_size=1037959168}]; discovery will continue using [] from hosts providers and [{es-node-1}{Q59cZ2_jTFeb_LoPG1eZsQ}{ac1qydF0Rayti-2_HcvapA}{127.0.0.1}{127.0.0.1:9300}{cdfhilmrstw}{ml.machine_memory=26878091264, xpack.installed=true, transform.node=true, ml.max_open_jobs=20, ml.max_jvm_size=1037959168}] from last-known cluster state; node term 0, last-accepted version 0 in term 0\n[2021-05-13T20:56:44,179][INFO ][o.e.h.AbstractHttpServerTransport] [es-node-1] publish_address {127.0.0.1:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}\n[2021-05-13T20:56:44,179][INFO ][o.e.n.Node               ] [es-node-1] started\n\n\n\n\n정상 실행되는게 확인되었으면 CTRL+C를 입력하여 종료하고 빠져나온다.\n\n\n\n✅ Logstash 설치\n\n\n\nLogstash는 Kafka와 Elasticsearch를 잇는 pipeline역할을 한다.\n\n더불어 데이터를 정제하는 작업도 가능하다.\n\n데이터 정제 없이 단지 pipeline 용도로 쓰기 위한 경우라면 Filebeat를 쓰는 경우가 많다고 한다.\n\n\n\n💡 설치 페이지\n\n\n\n\n  https://www.elastic.co/kr/downloads/logstash\n\n\n\n\n💡 LINUX X84_64\n\n\n\n$ wget https://artifacts.elastic.co/downloads/logstash/logstash-7.12.1-linux-x86_64.tar.gz\n\n\n\n\n💡 LINUX AARCH64\n\n\n\n$ wget https://artifacts.elastic.co/downloads/logstash/logstash-7.12.1-linux-aarch64.tar.gz\n\n\n\n\n다운로드가 완료되었으면 압축을 푼 후 폴더에 진입한다.\n\n역시 필자는 압축을 풀고난 후 압축파일을 삭제할 것이다.\n\n\n\n$ pwd\n/home/khan/\n\n$ tar xvf logstash-7.12.1-linux-x86_64.tar.gz\n\n$ cd logstash-7.12.1/\n\n\n\n\nLogstash의 전체적인 설정에 들어간다.\n\npipeline이 정의된 first_elasticsearch_pipeline.conf 파일을 만들어 사용할 것이다.\n\n\n\n$ vi config/logstash.yml\n\n# 적당한 곳에 추가\npath.config: \"/{logstash_path}/config/first_elasticsearch_pipeline.conf\"\n\n\n\n\npipeline의 명세를 대충 정의해준다.\n\n\n\n$ vi config/pipelines.yml\n\n# 적당한 곳에 추가\n- pipeline.id: first-log\n  queue.type: persisted\n  config.config: \"/{logstash_path}/config/first_elasticsearch_pipeline.conf\"\n\n\n\n\n이제 pipeline이 어떻게 동작할 것인지 설정해준다.\n\n필자의 경우 이미 구축해둔 Kafka가 있어서 해당 Kafka의 정보를 입력해줬다.\n\n코드를 보시면 알겠지만 단순히 Kafka의 특정 topic에 접근하여 데이터를 뽑아다가\n\n이를 정의한 인덱스 패턴으로 인덱싱하여 Elasticsearch에 적재해주는 방식이다.\n\n\n\n# 신규 파일 생성하며 진입\n$ vi config/first_elasticsearch_pipeline.conf\n\ninput {\n  kafka {\n    bootstrap_servers =&gt; \"{kafka_host}:{kafka_port}\"\n    group_id =&gt; \"{group_id}\"\n    topics =&gt; \"{kafka_topic}\"\n    consumer_threads =&gt; 1\n    decorate_events =&gt; true\n    }\n}\n\noutput {\n  elasticsearch{\n        hosts =&gt; \"{elasticsearch_host}:{elasticsearch_port}\"\n        index =&gt; \"server-status-%{+YYYY.MM.dd}\"\n  }\n}\n\n\n\n\nLogstash에서 Kafka 에 정상적으로 연동됐는지 확인\n\n\n\n$ cd {kafka_directory} bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --bootstrap-server {kafka_host}:{kafka_port} --group logstash --topic {topic_name}\n\n\n\n\n# 결과\nGroup           Topic     Pid     Offset      logSize     Lag       Owner\nconsumer        logs       0       3           3           0         none\n\n\n\n\n\n  Group : 컨슈머 그룹\n  logSize : 전체 메세지 수\n  Offset : 소비된 메세지 수\n  Log : 남은 메세지 수\n\n\n\n\n이제 Logstash가 제대로 설치되었는지 실행해본다.\n\n\n\n$ ./bin/logstash\n\n\n\n\n역시 error가 보이지 않는다면 CTRL+C를 입력하여 종료하고 빠져나온다.\n\n\n\n✅ Kibana 설치\n\n\n\nKibana는 Elasticsearch에 인덱싱되어 적재된 데이터를 보기 좋게 시각화해주는 역할을 한다.\n\n앞에서 별 문제없이 진행되었다면 설정 또한 매우 간단하다.\n\n\n\n💡 설치 페이지\n\n\n\n\n  https://www.elastic.co/kr/downloads/kibana\n\n\n\n\n💡 LINUX X84_64\n\n\n\n$ wget https://artifacts.elastic.co/downloads/kibana/kibana-7.12.1-linux-x86_64.tar.gz\n\n\n\n\n💡 LINUX AARCH64\n\n\n\n$ wget https://artifacts.elastic.co/downloads/kibana/kibana-7.12.1-linux-aarch64.tar.gz\n\n\n\n\n$ pwd\n/home/khan/\n\n$ tar xvf kibana-7.12.1-linux-x86_64.tar.gz\n\n$ cd kibana-7.12.1-linux-x86_64/\n\n\n\n\n$ vi config/kibana.yml\n\nserver.port: 5601\nserver.host: \"0.0.0.0\"\n\nelasticsearch.hosts: \"http://{elasticsearch_host}:{elasticsearch_port}/\"\n\n\n\n\nKibana를 실행해본다.\n\n먼저 Elasticsearch를 백그라운드로 실행해준다.\n\n\n\n$ ./bin/elasticsearch -d\n\n\n\n\n이어서 Kibana를 실행해본다.\n\n\n\n$ ./bin/kibana\n\n\n\n\n  log   [21:44:08.687] [info][listening] Server running at http://0.0.0.0:5601\n  log   [21:44:09.063] [info][server][Kibana][http] http server running at http://0.0.0.0:5601\n  log   [21:44:09.174] [info][plugins][watcher] Your basic license does not support watcher. Please upgrade your license.\n  log   [21:44:09.179] [info][crossClusterReplication][plugins] Your basic license does not support crossClusterReplication. Please upgrade your license.\n  log   [21:44:09.191] [info][kibana-monitoring][monitoring][monitoring][plugins] Starting monitoring stats collection\n  log   [21:44:12.559] [info][plugins-system] Stopping all plugins.\n  log   [21:44:12.561] [info][kibana-monitoring][monitoring][monitoring][plugins] Monitoring stats collection is stopped\n\n\n\n\nlistening이 뜨면 성공이다.\n\n우선 제대로 연결이 됐는지 확인해보자.\n\n\n\ncurl -XGET 'http://{elasticsearch_host}:{elasticsearch_port}/{index}/_search?pretty&amp;pretty'\n\n# 예시\n$ curl -XGET 'http://127.0.0.1:9200/server-status-*/_search?pretty&amp;pretty'\n\n\n\n\n설정이 제대로 되었다면\n\n여러가지 데이터가 튀어나올것이다.\n\n이제 콘솔에 출력된 경로에 웹브라우저로 접근해보면…\n\n\n\n\n\n\n\nCTRL+C를 입력하여 Kibana를 종료하고 빠져나온다.\n\nElasticsearch는 이미 백그라운드에 실행되어 있으니\n\nLogstash와 Kibana를 백그라운드로 실행해줄 것이다.\n\n\n\n$ pwd\n/home/khan/logstash-7.12.1\n\n# background 실행\n$ bin/logstash &amp;\n \n$ pwd\n/home/khan/kibana-7.12.1-linux-x86_64\n\n# background 실행\n$ bin/kibana &amp;\n\n\n\n\n이제 다시 Kibana에 접속한다.\n\nKibana는 Elasticsearch에 정렬되어 적재된 데이터를 시각화해주므로\n\nElasticsearch에 적재되어 있는 인덱스에 대한 정보를 입력해줄 것이다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npipeline output에 입력했던 인덱스 패턴을 입력해준다.\n\n\n\n\n\n\n\n나머지는 대충 입력해주고 넘긴 후\n\n메인 페이지로 이동한다.\n\n\n\n\n\n\n\n필자가 개발한 웹앱의 로그를 Kafka로 보내게 설정했고,\n\n금방 구축한 ELK를 Kafka에 연동했다.\n\n웹앱이 보낸 로그를 Kibana가 시각화해서 보여주고 있는 모습이다.\n\n\n\n\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-05-13-elk-install/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "첫 머신러닝 라이브러리 사용기",
      "date": "2021-05-16 23:36:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n원체 실용주의자라 내가 필요하다고 느끼면 미친 듯이 몰입해서 학습하고 사용하는 편인데,\n\n스스로 쓸모가 없다고 느끼면 아예 관심을 안 가져버리는 성격이다.\n\n \n\n30살 다되도록 영어로 대화해 본 일이 버거킹에서 어떤 외국인이\n\n키오스크를 어떻게 쓰냐고 물어본 적 한 번밖에 없었다.\n\n그 정도로 평소에 영어를 접할일이 없었기 때문에 큰 관심을 갖지 않고 있었다.\n\n \n\n그런데 최근에 목표가 생겨서 영어를 공부하기 시작했다.\n\n우선 실력향상을 위해서 원서를 읽어야 할 일이 매우 많아졌기 때문이고,\n\n나중에 오픈소스 활동을 해보고 싶어졌기 때문이다.\n\n그러자면 외국인들이 무슨 소리를 하는지 잘 알아먹고 키배(?)도 뜨고 그래야 할 것 같다.\n\n그러니 읽기와 쓰기만큼이라도 열심히 갈고닦아 보려는 중이다.\n\n \n\n영어 문법을 중학교 1학년 수준부터 기초공부를 차근차근하고 있는데,\n\n생각보다 아는 단어가 많이 부족하다 여겼다.\n\n그래서 기왕에 외울 단어인데, 내가 접하고 사용할 단어 위주로 외워보자는 생각에\n\n내가 자주 보는 스프링 부트, 스프링 시큐리티 문서 같은 것들을 파싱해서\n\n그 문서에서 많이 나온 단어들을 보기 좋게 정제해 단어 사전을 만들면 큰 도움이 되지 않을까?라는 생각을 했다.\n\n \n\n처음엔 단순히 공식문서의 URI를 호출하여 바로 파싱을 하려고 했다.\n\n헌데 URI를 호출하고 보니 문서가 제대로 렌더링이 되어있질 않았다.\n\n그래서 문서를 직접 HTML 파일로 다운로드하여 이를 스트림으로 읽어 들여 파싱하기로 계획을 바꿨다.\n\n \n\npublic class DocumentParser {\n    public String read(String path) {\n        StringBuilder sb = new StringBuilder();\n        File file = new File(path);\n        try(BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(file)))) {\n            String read;\n            while((read = br.readLine()) != null) {\n                sb.append(read).append(\"\\n\");\n            }\n        }\n        catch(IOException e) {\n            log.error(e.getMessage());\n        }\n        return sb.toString();\n    }\n\t...\n}\n\n\n \n\nHTML 문서를 읽고 보니 온갖 HTML 태그가 덕지덕지 붙어있었다.\n\n이를 제거하기 위한 로직을 또 작성했다.\n\n \n\npublic Set&lt;String&gt; parsing(String html) throws IOException {\n        StringBuilder sb = new StringBuilder();\n        Pattern pattern = Pattern.compile(\"&lt;p&gt;.*&lt;/p&gt;\");\n        Matcher matcher = pattern.matcher(html);\n        \n        while(matcher.find()) {\n            String s = \" \" + html.substring(matcher.start(), matcher.end())\n                                 .replaceAll(\"&lt;b&gt;\", \"\").replaceAll(\"&lt;/b&gt;\", \"\")\n                                 .replaceAll(\"&lt;a [^&lt;&gt;]*&gt;\", \"\").replaceAll(\"&lt;/a&gt;\", \"\")\n                                 .replaceAll(\"&lt;p&gt;\", \"\").replaceAll(\"&lt;/p&gt;\", \"\")\n                                 .replaceAll(\"&lt;sup [^&lt;&gt;]*&gt;\", \"\").replaceAll(\"&lt;/sup&gt;\", \"\")\n                                 .replaceAll(\"&lt;span [^&lt;&gt;]*&gt;\", \"\").replaceAll(\"&lt;/span&gt;\", \"\")\n                                 .replaceAll(\"&lt;i [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/i&gt;\", \"\")\n                                 .replaceAll(\"&lt;table [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/table&gt;\", \"\")\n                                 .replaceAll(\"&lt;block [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/block&gt;\", \"\")\n                                 .replaceAll(\"&lt;ul [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/ul&gt;\", \"\")\n                                 .replaceAll(\"&lt;li [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/li&gt;\", \"\")\n                                 .replaceAll(\"&lt;div [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/div&gt;\", \"\")\n                                 .replaceAll(\"&lt;h [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/h&gt;\", \"\")\n                                 .replaceAll(\"www\\\\.\", \"\").replaceAll(\"http\", \"\")\n                                 .replaceAll(\"\\\\.com\", \"\").replace(\".\", \" \")\n                                 .replaceAll(\"\\\\[[^\\\\[\\\\]]*\\\\]\", \"\");\n            \n            String s1 = splitCamelCase(s);\n            if(s1.contains(\" \")) {\n                String[] strings1 = s1.split(\" \");\n                for(String s2 : strings1) {\n                    sb.append(s2).append(\" \");\n                }\n            }\n            else {\n                sb.append(s);\n            }\n        }\n        ...\n}\n\nprivate String splitCamelCase(String s) {\n \treturn s.replaceAll(String.format(\"%s|%s|%s\",\n                                  \"(?&lt;=[A-Z])(?=[A-Z][a-z])\",\n                                  \"(?&lt;=[^A-Z])(?=[A-Z])\",\n                                  \"(?&lt;=[A-Za-z])(?=[^A-Za-z])\"),\" \");\n}\n\n\n \n\n보통 HTML 문서에서 서술하는 부분은 p 태그 안에 들어있으므로 p 태그 위주로 읽고\n\n읽어 들인 p 태그에서 잡다한 HTML 태그를 제거해준다.\n\n또한 그 외에 필요 없는 문자들도 정리를 해준 후\n\n프로그래밍 언어에서 자주 사용되는 용어들을 또 분리해줬다\n\n이건 무슨 소리냐면\n\n \n\nInputStreamReader\nInput\nStream\nReader\n\n\n \n\n이처럼 카멜 케이스나 파스칼 케이스로 작성된 프로그래밍 용어들은 쪼개면 여러 단어로 바뀐다.\n\n여기까지 하고 보니 그럼에도 불구하고 너무 무의미한 단어가 많았다.\n\n \n\n이를 깔끔하게 처리하려고 많은 생각을 해보고 정보를 뒤져보다가 머신러닝 라이브러리를 알게 됐다.\n\n여러 종류가 있었는데 그중 Apache OpenNLP라는 자연어 처리 라이브러리를 사용해보게 됐다.\n\n \n\n항상 그렇듯이 우선 공식문서를 보면서 사용법을 익히는 게 먼저다.\n\n나 같은 경우 단순히 단어장을 만드는 게 목표기 때문에 문장을 처리할 필요가 없다.\n\n따라서 Tokenizer를 이용하면 될 것 같았다.\n\n \n\npublic Set&lt;String&gt; parsing(String html) throws IOException {\n        StringBuilder sb = new StringBuilder();\n        Pattern pattern = Pattern.compile(\"&lt;p&gt;.*&lt;/p&gt;\");\n        Matcher matcher = pattern.matcher(html);\n        \n        while(matcher.find()) {\n            String s = \" \" + html.substring(matcher.start(), matcher.end())\n                                 .replaceAll(\"&lt;b&gt;\", \"\").replaceAll(\"&lt;/b&gt;\", \"\")\n                                 .replaceAll(\"&lt;a [^&lt;&gt;]*&gt;\", \"\").replaceAll(\"&lt;/a&gt;\", \"\")\n                                 .replaceAll(\"&lt;p&gt;\", \"\").replaceAll(\"&lt;/p&gt;\", \"\")\n                                 .replaceAll(\"&lt;sup [^&lt;&gt;]*&gt;\", \"\").replaceAll(\"&lt;/sup&gt;\", \"\")\n                                 .replaceAll(\"&lt;span [^&lt;&gt;]*&gt;\", \"\").replaceAll(\"&lt;/span&gt;\", \"\")\n                                 .replaceAll(\"&lt;i [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/i&gt;\", \"\")\n                                 .replaceAll(\"&lt;table [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/table&gt;\", \"\")\n                                 .replaceAll(\"&lt;block [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/block&gt;\", \"\")\n                                 .replaceAll(\"&lt;ul [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/ul&gt;\", \"\")\n                                 .replaceAll(\"&lt;li [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/li&gt;\", \"\")\n                                 .replaceAll(\"&lt;div [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/div&gt;\", \"\")\n                                 .replaceAll(\"&lt;h [^&lt;&gt;]*&gt;&gt;\", \"\").replaceAll(\"&lt;/h&gt;\", \"\")\n                                 .replaceAll(\"www\\\\.\", \"\").replaceAll(\"http\", \"\")\n                                 .replaceAll(\"\\\\.com\", \"\").replace(\".\", \" \")\n                                 .replaceAll(\"\\\\[[^\\\\[\\\\]]*\\\\]\", \"\");\n            \n            String s1 = splitCamelCase(s);\n            if(s1.contains(\" \")) {\n                String[] strings1 = s1.split(\" \");\n                for(String s2 : strings1) {\n                    sb.append(s2).append(\" \");\n                }\n            }\n            else {\n                sb.append(s);\n            }\n        }\n        \n        String s = sb.toString().trim().toLowerCase()\n                     .replaceAll(\"[^a-zA-Z\\\\s\\\\.]\", \" \")\n                     .replaceAll(\" +\", \" \");\n        \n        InputStream inputStream = getClass()\n                .getResourceAsStream(\"/models/en-token.bin\");\n        TokenizerModel model = new TokenizerModel(inputStream);\n        TokenizerME tokenizer = new TokenizerME(model);\n        String[] tokens = tokenizer.tokenize(s);\n        \n        Set&lt;String&gt; set = new HashSet&lt;&gt;();\n        for(String s1 : tokens) {\n            if(s1.length() &gt; 2) {\n                set.add(s1);\n            }\n        }\n        return set;\n    }\n\n\n \n\n우선 HashSet을 이용해 중복제거를 할 것이기 때문에 정제된 단어를 모두 소문자로 변경한다.\n\n이후 영어 소문자, 영어 대문자, 공백, 점(.)을 제외한 모든 문자를 제거해준다.\n\n그리고 두 칸 이상 떨어진 공백을 모두 한 칸으로 바꿔주면\n\n단어인지 아닌지 모를 것들이 공백한칸 단위로 구분이 될 것이다.\n\n이를 Apache-OpenNLP 라이브러리를 활용해 영단어가 학습된 모델과 비교하여 구분해준 후\n\n길이가 2보다 큰 단어들을 모두 HashSet에 집어넣어줬다.\n\n이후 테스트 코드를 돌려보는데, 제대로 정제가 됐는지 눈으로 확인하고 싶으므로\n\n평소엔 잘 쓰지 않는 표준 출력 로직을 추가해줬다.\n\n \n\npublic class DocumentParserTest {\n    \n    @ParameterizedTest\n    @DisplayName(\"Document_파싱\")\n    @MethodSource(\"whereDocuments\")\n    public void parsingDocumentationFromHTMLFile(String path) throws Exception {\n        // when\n        DocumentParser parser = new DocumentParser();\n        String html = parser.read(path);\n        Set&lt;String&gt; set = parser.parsing(html);\n    \n        StringBuilder sb = new StringBuilder();\n        for(String s : set) {\n            sb.append(set + \"\\n\");\n        }\n        System.out.println(sb);\n    \n        // then\n        assertThat(set).isNotNull();\n    }\n    \n    // given\n    private static Stream&lt;Arguments&gt; whereDocuments() {\n        return Stream.of(\n                Arguments.of(\"src/test/resources/springboot_document.html\"),\n                Arguments.of(\"src/test/resources/springsecurity_document.html\")\n                        );\n    }\n    \n}\n\n\n \n\n\n\n \n\n차근차근 읽어보니 나름 만족할만한 퀄리티로 단어들이 뽑혀 나온다.\n\n머신러닝, 딥러닝 같은 단어는 자주 들어봤는데 관심은 잘 안갖고 있다가\n\n갑자기 머신러닝이 필요해져서 사용해보니 정말 좋은 것 같다는 생각이 들었다.\n\n아무튼 이제 이를 잘 활용해서 단어 사전을 만들어봐야겠다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-05-16-diary-17/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "Apache-Kafka",
      "date": "2021-05-17 13:37:00 +0000",
      "description": "최고의 메시지 브로커\n",
      "content": "\n  ✅ Apache-Kafka ?    \n      📗 카프카의 특징\n      📗 카프카의 활용사례\n    \n  \n  ✅ 카프카의 구조    \n      ✅ 프로듀서 &amp; 컨슈머        \n          📙 컨슈머 그룹\n        \n      \n      ✅ 클러스터 &amp; 브로커\n      ✅ 토픽        \n          📙 토픽 이름 제약조건\n        \n      \n      ✅ 파티션\n      ✅ 레코드 &amp; 로그 세그먼트        \n          📖 데이터의 처리속도를 늘리는 방법\n        \n      \n    \n  \n  ✅ 빅데이터 처리 솔루션\n\n\n\n\n✅ Apache-Kafka ?\n\n\n\n카프카는 대규모 데이터의 흐름을 제어하기 위한 메시지 브로커이다.\n\n보통 스프링 부트 애플리케이션을 개발하여 사용할 경우 로그백(Logback)을 이용해 로깅을 하는데\n\n기록된 로그를 보통 애플리케이션이 돌아가는 서버에 저장하게 된다.\n\n이 경우 애플리케이션의 로그를 보고 싶다면 해당 서버에 ssh 등을 통해 직접 접속한 후 로그 파일이 저장된 위치에 찾아들어가 로그를 일일이 까 봐야 한다.\n\n\n\n# 🤢\ntail -f app-2021.05.17.log \n\n\n\n\n혹은 서버끼리 데이터의 교환이 일어날 경우 시스템의 규모가 작다면 이를 어느 정도 제어할 수 있으나,\n\n시스템의 규모가 커진다면 이 데이터의 흐름을 제어하긴 커녕 파악하는 것 부터 매우 어렵다.\n\n\n\n\n\n\n\n이러한 문제들을 해결하기 위해 각 서버 사이에 메시지 브로커를 두는데 이 용도로 사용되는 것이 카프카이다.\n\n\n\n\n\n\n\n카프카는 데이터를 저장하는데 리소스를 절약하기 위해 기본적으로 데이터베이스를 사용하거나,\n\n캐시 메모리를 구현하여 사용하지 않는다. 단지 페이지 캐시와 파일 시스템(=하드디스크)만을 사용한다.\n\n페이지 캐시는 하드디스크를 사용할 경우 느린 입출력 속도를 보완하기 위해 사용하며, 이 페이지 캐시는\n\n리눅스 명령어 free를 입력하여 cache탭을 보면 알 수 있다.\n\n\n\n\n\n\n\n📗 카프카의 특징\n\n\n\n\n  하드디스크 기반 저장 방식\n    \n      중요 리소스 사용 최소화(캐시 메모리, RAM)\n    \n  \n  확장에 유연한 구조\n    \n      다수의 브로커로 상황에 맞게 스케일업, 스케일아웃\n    \n  \n  내결함성\n    \n      장애 허용 시스템\n    \n  \n  고가용성\n    \n      자동화된 시스템으로 가동중지 시간이 최소화됨\n    \n  \n  저지연성(10ms 미만)\n    \n      대규모 병렬 처리로 인한 고성능\n    \n  \n\n\n\n\n📗 카프카의 활용사례\n\n\n\n\n  사용자 활동 추적\n    \n      페이지 열람, 클릭이벤트 추적 등\n    \n  \n  알람 시스템\n    \n      슬랙, 라인 등과 연동\n    \n  \n  메트릭 수집\n    \n      모니터링 및 경고(알람과 연동)\n    \n  \n  로그 수집\n    \n      모니터링 및 경고(알람과 연동)\n    \n  \n  커밋 로그\n    \n      카프카에 대한 데이터 변경사항 수집\n    \n  \n  스트림 처리\n    \n      데이터 변환 처리\n    \n  \n  시스템 종속성 분리\n    \n      모든 시스템이 서로가 아닌 오로지 카프카만을 의존하게 만듦\n    \n  \n  다른 데이터 기술과 통합\n    \n      RDBMS, 하둡, 스파크, 엘라스틱서치 등과 유연한 통합\n    \n  \n\n\n\n\n✅ 카프카의 구조\n\n\n\n\n\n\n\n카프카는 크게 클러스터, 브로커, 프로듀서, 컨슈머로 이루어져 있다.\n\n그리고 브로커는 다시 토픽으로 이루어져 있으며,\n\n토픽은 파티션으로 이루어져 있다.\n\n마지막으로 파티션은 레코드로 이루어져 있다.\n\n\n\n✅ 프로듀서 &amp; 컨슈머\n\n\n\n카프카에 데이터를 전달하는 주체를 프로듀서라고 칭하며,\n\n카프카에서 데이터를 가져다 사용하는 주체는 컨슈머라고\n\n\n\n프로듀서는 필수 옵션으로 직렬화 방식을 정해줘야 하며, 컨슈머는 역직렬화 방식을 정해줘야 한다.\n\n프로듀서는 카프카에 메시지를 직렬화하여 전달하고, 카프카는 이 데이터를 보관하는데 이를 레코드라고 부른다.\n\n\n\n이 레코드에는 실질적인 유의미한 데이터가 들어있으며, 이 데이터를 사용하기 위해서는 프로듀서가 데이터를 보내며 직렬화한 방식과 동일한 방식으로 컨슈머가 역직렬화 해줘야 한다.\n\n예를 들어 프로듀서에서 StringSerializer로 직렬화해서 보낸 값은 컨슈머도 StringSerializer로 역직렬화 해야 올바른 데이터를 얻을 수 있다.\n\n\n\n컨슈머는 자신이 구독한 토픽에서 마지막으로 소비한 메시지의 오프셋을 __consumer_offsets 토픽에 저장한다.\n\n따라서 컨슈머가 장애로 중단되었다가 다시 재가동되더라도 마지막으로 처리했던 부분부터 다시 작업을 시작할 수 있다.\n\n\n\n📙 컨슈머 그룹\n\n\n\n컨슈머는 그룹 단위로 지정하여 운영할 수 있다.\n\n특정 토픽에 대해 컨슈머 그룹으로 구독할 수 있으며,\n\n컨슈머 그룹에 소속된 컨슈머는 각자 파티션을 1개 이상 맡아 레코드를 소비한다.\n\n이때 토픽에 속한 파티션은 컨슈머 그룹에 속한 컨슈머중 한 개에만 할당될 수 있다.\n\n따라서 3개의 파티션을 가진 토픽을 4개의 컨슈머로 이루어진 컨슈머 그룹으로 운영할 경우 1개의 컨슈머는 아무런 파티션도 할당받지 못하고 유휴 상태로 남기 때문에 이 컨슈머는 불필요하게 스레드만 차지하게 된다.\n\n\n\n\n\n\n\n✅ 클러스터 &amp; 브로커\n\n\n\n브로커는 카프카가 실행되는 단일 서버를 말한다.\n\n그리고 클러스터는 브로커의 논리적인 묶음을 말한다.\n\n\n\n클러스터는 보통 세 개의 브로커로 구성되는데 이 이유는 장애에 대응하기 위해서다.\n\n카프카는 장애로 브로커가 다운되는 경우를 대비해 브로커를 복제해두고 이를 클러스터라는 논리적인 개념으로 묶어서 운영하게 된다.\n\n이 경우 브로커의 특정 파티션이 리더 역할을 하며, 나머지 파티션은 팔로워 역할을 한다.\n\n오로지 리더만이 프로듀서, 컨슈머와 직접 통신하고, 리더는 자신을 바라보는 팔로워에 데이터를 복제한다.\n\n\n\n\n\n\n\n그리고 리더의 데이터를 완벽하게 복제한 팔로워들을 ISR(In-Sync-Replicas)로 묶였다고 표현하며,\n\n이 ISR로 묶인 팔로워는 위기상황에 리더로 선출될 자격을 갖는다.\n\n\n\n만일 리더가 장애로 인해 다운된다면 ISR로 묶인 팔로워 중에 새로운 리더가 선출되어 이전 리더가 하던 작업을 이어받는다.\n\n이러한 특징으로 인해 카프카는 장애 허용 시스템이라고도 불린다.\n\n\n\n단점은 말 그대로 서버를 세 개 사용하는 것이기 때문에 물리적인 리소스 또한 3배로 증가한다는 것이지만,\n\n장애에 안전하다는 강점이 워낙 강력하기 때문에 이러한 단점을 감수하고 사용한다.\n\n\n\n\n\n\n  카프카의 장애 = 전체 시스템의 장애가 될 수 있다\n\n\n\n\n브로커 한 개로 운영할 수도 있지만 이 경우 브로커가 다운된다면 전체 시스템의 장애로 이어지므로 추천하지 않는다.\n\n브로커는 다시 토픽, 파티션, 레코드로 이루어진다.\n\n\n\n✅ 토픽\n\n\n\n\n\n\n\n토픽은 레코드의 메인 주제이다. RDBMS의 테이블과 비슷한 위치를 갖는다.\n\n\n\n예를 들어 APP서버의 데이터를 주로 전송하고 싶다면 토픽 이름을 APP서버와 관련되게 명명하고, APP서버의 데이터를 해당 토픽에만 보내고 꺼내면 된다.\n\n토픽은 최소 한 개 이상의 파티션을 소유하며, 이 파티션에는 프로듀서가 보낸 데이터들이 저장된다.\n\n\n\n📙 토픽 이름 제약조건\n\n\n\n\n  빈 문자열 토픽 이름은 지원하지 않는다\n  토픽 이름은 마침표 하나(.) 또는 마침표 둘(..)로 생성될 수 없다.\n  토픽 이름의 길이는 249자 미만으로 생성되어야 한다\n  토픽 이름은 영어 대소문자와 숫자 0부터 9 그리고 마침표(.), 언더바(_), 하이픈(-) 조합으로 생성할 수 있다. 이외의 문자열이 포함된 토픽 이름은 생성 불가하다\n  카프카 내부 로직 관리 목적으로 사용되는 2개 토픽(__consumer_offsets, __transaction_state)과 동일한 이름으로 생성할 수 없다\n  카프카 내부적으로 사용하는 로직 때문에 토픽 이름에 마침표(.)와 언더바(_)가 동시에 들어가면 안 된다. 생성은 할 수 있지만 사용 시 이슈가 발생하기 때문에 마침표(.)와 언더바(_)가 들어간 토픽 이름을 사용하면 WARNING 메시지가 발생한다.\n  이미 생성된 토픽 이름의 마침표(.)를 언더바(_)로 바꾸거나 언더바(_)를 마침표(.)로 바꾼 경우 신규 토픽 이름과 동일하다면 생성할 수 없다. 예를 들어, to.pic이라는 이름의 토픽이 생성되어 있다면 to_pic이라는 이름의 토픽을 생성할 수없다\n\n\n\n\n✅ 파티션\n\n\n\n\n\n\n\n파티션은 데이터를 병렬 처리하기 위한 단위이다.\n\n파티션은 큐와 같은 구조로 선입선출(FIFO)을 보장한다.\n\n다만 일반적인 큐는 데이터를 꺼내면(pop) 데이터가 삭제되지만, 카프카의 파티션은 데이터를 꺼내더라도 데이터가 보존된다는 특징이 있다.\n\n\n\n이러한 특징으로 카프카의 데이터는 1개 이상의 컨슈머 그룹에서 다양한 목적으로 동일한 데이터를 꺼내다 사용할 수 있다.\n\n이를 컨슈머가 토픽을 구독(Subscribe)한다고 칭하며, 각 컨슈머는 자신이 구독한 토픽의 파티션에 대해 오프셋을 갖는다.\n\n\n\n컨슈머가 갖고 있는 오프셋과 컨슈머가 구독 중인 파티션의 오프셋의 차이를 컨슈머 랙이라고 부르며 컨슈머 랙이 크면 그만큼 처리에 지연이 발생하고 있다는 지표로 본다.\n\n\n\n파티션의 개수는 기본적으로 1개로 설정되지만, 이 파티션을 여러 개로 늘릴 경우 병렬 처리를 할 수 있어 커다란 성능 향상을 기대할 수 있다.\n\n다만 이 경우 데이터의 순서가 보장되지 않는다.\n\n\n\n✅ 레코드 &amp; 로그 세그먼트\n\n\n\n프로듀서가 카프카에 전달한 메시지의 최소단위를 레코드라고 칭한다.\n\n레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋으로 구성되어 있다.\n\n\n\n카프카에레코드가 저장되는 기본 경로는 /tmp/kafka-logs이며 이 경로는 사용자가 임의로 변경할 수 있다.\n\n\n\n레코드는 00000000000000000.log 같은 이름으로 저장돼있으며, 이를 로그 세그먼트라 칭한다.\n\n\n\n로그 세그먼트는 카프카가 저장한 레코드를 묶은 파일의 최소 단위이다.\n\n로그 세그먼트는 기본적으로 1GB 단위로 갱신되며 브로커의 로그 리텐션 정책에 의해 자동으로 삭제된다.\n\n기본값으로 7일간 보존 후 삭제하게 돼있으며 이는 임의로 조절할 수 있다.\n\n혹은 용량 단위로 제어하거나 아예 삭제하지 않고 압축하여 보관하도록 할 수도 있다.\n\n\n\n프로듀서에서 보낸 데이터가 브로커에 저장될 때 오프셋과 타임스탬프가 지정되어 저장되며, 타임스탬프는 브로커가 설치된 서버의 유닉스 시간이 설정된다.\n\n혹은 프로듀서가 레코드를 전송할 때 임의의 타임스탬프를 설정하여 보낼 수도 있다.\n\n\n\n레코드는 수정될 수 없고 오직 삭제만 가능한데, 프로듀서나 컨슈머가 삭제를 요청할 수도 없으며 오로지 브로커만이 레코드를 삭제할 수 있다.\n\n그리고 이 삭제마저도 로그 세그먼트 단위로만 가능하다.\n\n따라서 특정 레코드만 디테일하게 삭제하는 것은 불가능하다.\n\n만약 특정 레코드를 삭제하고자 해당 레코드가 속한 로그 세그먼트를 삭제해야 하므로 데이터의 유실이 발생한다.\n\n\n\n메시지 키의 경우 해시값을 토대로 파티션에 저장된다.\n\n메시지가 메시지 키를 갖는 경우 여러 개의 메시지가 동일한 메시지 키를 갖는다면 동일한 파티션에 저장되기 때문에 의도와 다른 파티션에 저장될 수 있으므로 주의해야 한다.\n\n메시지 키를 갖지 않는다면 메시지 키는 null로 처리되며 데이터는 파티션에 순서대로 분배된다.\n\n\n\n메시지에는 실질적인 데이터가 들어있다.\n\n이 데이터를 사용하기 위해서는 프로듀서가 데이터를 보낼 때 직렬화한 방식과 동일한 방식으로 컨슈머가 역직렬화 해야 한다.\n\n\n\n📖 데이터의 처리속도를 늘리는 방법\n\n\n\n\n  \n    컨슈머의 처리량을 늘린다\n\n    \n      컨슈머 애플리케이션을 내부적으로 멀티스레드로 동작하게 만들거나 컨슈머 애플리케이션이 실행되는 서버의 물리적인 사양을 스케일 업하거나, GC튜닝 등을 하는 방법이 있으나, 일반적으로 컨슈머 애플리케이션은 외부 시스템(S3, 하둡, DB 등)과 연동되어 있기 때문에 한계가 있다.\n    \n  \n\n\n\n\n\n  \n    파티션과 컨슈머의 개수를 늘려 병렬 처리한다\n\n    \n      한 개의 프로듀서가 초당 보내는 레코드가 1,000건이고 한개의 컨슈머가 초당 소모하는 레코드가 100건이라면 단순하게 파티션을 10개로 늘리고 10개의 컨슈머를 붙이면 최적의 성능이 나온다. 데이터의 양이 줄면 파티션과 컨슈머의 개수를 줄여 스케일 아웃하면 된다.\n    \n  \n\n\n\n\n✅ 빅데이터 처리 솔루션\n\n\n\n\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-05-17-kafka/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "자바 리터럴(literal) 표기법과 String",
      "date": "2021-05-19 20:46:00 +0000",
      "description": "자바에서 문자열을 담당하는String에 대한 탐구\n",
      "content": "\n  📕 리터럴(literal)    \n      💡 자바 프로그램의 모든 문자열 리터럴은 이 클래스의 인스턴스로 구현된다. | 문자열 객체는 불변하므로 공유할 수 있다.\n      💡 문자열은 리터럴로 생성된 뒤 값을 변경할 수 없다\n    \n  \n\n\n \n\n📕 리터럴(literal)\n\n\n\n\n  컴퓨터 과학 분야에서 리터럴(literal) 이란 소스 코드의 고정된 값을 대표하는 용어다. 거의 모든 프로그래밍 언어는 정수, 부동소수점, 숫자, 문자열, 불린 자료형과 같은 용어를 가지고 있다. 어떤 언어는 열거 타입이나, 배열, 자료형, 객체와 같은 용어도 있다. 리터럴과 대조적으로, 고정된 값을 가질 수 있는 변수나 변경되지 않는 상수가 있다. 다음의 예제와 같이, 리터럴은 변수 초기화에 종종 사용된다.\n\n\n \n\nint i = 1;\nString s = \"봄싹\";\n\n\n📜 출처 - 위치백과\n\n \n\n자바를 공부하다 보면 책에서, 강의에서, 주변 사람에 의해서\n\n리터럴, 리터럴 표기법이라는 용어를 종종 쓰곤 한다.\n\n자바의 인스턴스가 뭔지 알면 아주 쉽게 이해할 수 있는 내용이다.\n\n반대로 자바의 인스턴스가 뭔지 아직 모른다면 절대 제대로 이해할 수 없는 내용이기도 하다.\n\n \n\n자바에서 문자열을 담당하는 객체는 String이다.\n\n또한 String은 아주 대표적인 VO(Value Object)이다.\n\nVO가 뭔지 모른다면 DTO 와 VO의 차이를 참고하기 바란다.\n\nVO는 객체를 값으로 사용하기 때문에 불변성을 갖는다.\n\n \n\nVO의 이름은 100원인데 런타임에 이 값이 변경되어\n\n내부적으로 100원의 값이 50원으로 변경됐다고 가정해보자.\n\n그럼 이 VO를 사용하는 모든 로직에서 엉뚱한 결과들이 나올 것이다.\n\n100원은 어떤 상황이더라도 100원의 가치를 해야만 한다.\n\n따라서 VO는 불변해야한다.\n\n \n\nVO의 공통점은 수정자(Setter)가 없거나, final로 선언되어 있어\n\n아예 값을 수정하지 못하거나 값을 수정하려고 들면 에러가 발생한다는 것이다.\n\nString 객체를 선언하는 데는 여러 가지 방법이 있다.\n\n \n\nString str = \"abc\"; // 리터럴 표기법\n\nString str = new String(data); // 생성자 사용\n\nchar data[] = {'a', 'b', 'c'};\nString s = String.valueOf(data); // valueOf 사용(=생성자사용)\n\n\n \n\nvalueOf 메서드 또한 내부적으로 생성자를 이용한다.\n\n \n\npublic static String valueOf(char data[]) {\n    return new String(data);\n}\n\n\n \n\njava.lang.String을 찾아보면 최상단에 이런 문구가 있다.\n\n\n  The String class represents character strings. All string literals in Java programs, such as “abc”, are implemented as instances of this class. Strings are constant; their values cannot be changed after they are created. String buffers support mutable strings. Because String objects are immutable they can be shared.\n\n\n \n\n이곳에서도 리터럴이라는 용어가 나온다.\n\n여기서 공식문서는 몇 가지 아주 중요한 내용을 말하고 있다.\n\n\n  abc와 같은 자바 프로그램의 모든 문자열 리터럴은 이 클래스의 인스턴스로 구현된다.\n  문자열은 생성된 뒤 값을 변경할 수 없다\n  문자열 객체는 불변하므로 공유할 수 있다\n\n\n이게 무슨 말일까?\n\n \n\n💡 자바 프로그램의 모든 문자열 리터럴은 이 클래스의 인스턴스로 구현된다. | 문자열 객체는 불변하므로 공유할 수 있다.\n\n\n\n자바에서는 객체의 인스턴스를 생성하기 위해 생성자(new)를 이용하는데,\n\n이 리터럴 표기법을 사용할 수 있는 String 클래스는 예외가 된다. (이외에 몇 가지 더 있다)\n\n \n\nString s1 = \"123\";\nString s2 = \"123\";\n\nSystem.out.println(\"s1 == s2 ? \" + (s1 == s2));\n\n\n \n\nString은 Object이므로 equals 메서드로 비교하는 게 정석이다.\n\n하지만 이렇게 s1과 s2를 리터럴 표기법으로 선언하고 동일 비교 연산(==)을 수행하면 어떤 결과가 나올까?\n\n \n\ns1 == s2 // true\n\n\n \n\ntrue가 나오게 된다.\n\nObject끼리 동일 비교 연산을 했는데 true라는 결과가 나오는 것부터\n\n두 객체의 주소 값이 같다는 말과 일맥상통하나, 아직 잘 이해가 되지 않는다.\n\n직접 주소 값을 출력해보자.\n\n \n\nSystem.out.println(\"System.identityHashCode(s1) = \" + System.identityHashCode(s1));\nSystem.out.println(\"System.identityHashCode(s2) = \" + System.identityHashCode(s2));\n\n\nSystem.identityHashCode(s1) = 1626877848\nSystem.identityHashCode(s2) = 1626877848\n\n\n \n\n볼 것도 없이 같다.\n\n그렇다면 리터럴 표기법이 아닌 생성자를 사용한다면?\n\n \n\nString s1 = \"123\";\nString s2 = new String(\"123\");\n    \nSystem.out.println(\"s1 == s2 ? \" + (s1 == s2)); // false\n\n\n \n\n이와 같이 false가 출력된다.\n\n생성자로 생성하는 String 객체는 힙 메모리에 생성되기 때문에,\n\n리터럴 표기법으로 작성한 s1과 다른 객체가 된다.\n\n \n\nString str = \"abc\"; // 리터럴 표기법\n\n\n \n\n리터럴 표기법으로 선언한 경우 생성자를 사용하지 않고도 인스턴스가 생성되며 이 인스턴스는 싱글톤이 된다.\n\n따라서 한번 리터럴 표기법으로 생성한 객체는 단 한 번만 생성되며,\n\n여러 클래스에서 같이 정의하더라도 이 객체는 모두 동일한 인스턴스(싱글톤)이다.\n\n \n\npublic class Test1 {\n    \n    String s = \"abc\";\n}\n\npublic class Test2 {\n    \n    String s = \"abc\";\n}\n\n\npublic class StringTest {\n    \n    public static void main(String[] args) {\n        Test1 test1 = new Test1();\n        Test2 test2 = new Test2();\n    \n        System.out.println(test1.s == test2.s); // true\n    }\n    \n}\n\n\n \n\nString은 여타 Object와 크게 다를 게 없지만, 이 리터럴 표기법만큼은 굉장히 신기하게 동작한다.\n\nString을 호출하거나 리터럴 표기법으로 선언할 경우 String에 정의된 intern이 실행된다.\n\n \n\npublic native String intern();\n\n\n \n\n시그니처에 native라는 키워드가 들어가 있는데,\n\n나는 자바를 공부할 때 native 키워드에 대해\n\n자바 외의 언어로 작성된 코드를 자바에서 사용하고자 할 때 사용되는 키워드라고 배웠었다.\n\n추적해보니 C계열 언어로 뭔가 많이 적혀있었는데\n\n이쯤 되니 너무 멀리 나가는 것 같기도 하고, 능력 밖인 것 같기도 하여 일단 보류하고\n\nintern의 Docs를 첨부한다.\n\n \n\n\n  Returns a canonical representation for the string object. A pool of strings, initially empty, is maintained privately by the class String. When the intern method is invoked, if the pool already contains a string equal to this String object as determined by the equals(Object) method, then the string from the pool is returned. Otherwise, this String object is added to the pool and a reference to this String object is returned. It follows that for any two strings s and t, s.intern() == t.intern() is true if and only if s.equals(t) is true. All literal strings and string-valued constant expressions are interned. String literals are defined in section 3.10.5 of the The Java™ Language Specification.\n\n\n \n\n즉 리터럴 표기법으로 String을 선언하거나, String을 호출했을 때\n\nJVM 문자열 풀에 해당 문자열이 존재하면 해당 문자열을 바로 반환해주고,\n\n만약 문자열 풀에 해당 문자열이 없다면 문자열을 풀에 등록하고 등록된 문자열을 반환해준다고 한다.\n\n리터럴 표기법으로 String 객체를 선언하고 자바 역어셈블러를 이용해 코드를 뜯어봤다.\n\n \n\njavap -verbose StringTest\nWarning: Binary file StringTest contains DataStructure.StringTest\nClassfile /mnt/d/development/JavaPractice/out/production/JavaPractice/DataStructure/StringTest.class\n  Last modified May 19, 2021; size 527 bytes\n  MD5 checksum de12796c5d61a5bdd6c8e440e84fbb6e\n  Compiled from \"StringTest.java\"\npublic class DataStructure.StringTest\n  minor version: 0\n  major version: 55\n  flags: ACC_PUBLIC, ACC_SUPER\nConstant pool:\n   #1 = Methodref          #6.#22         // java/lang/Object.\"&lt;init&gt;\":()V\n   #2 = Class              #23            // java/lang/String\n   #3 = String             #24            // 안녕하세요\n   #4 = Methodref          #2.#25         // java/lang/String.\"&lt;init&gt;\":(Ljava/lang/String;)V\n   #5 = Class              #26            // DataStructure/StringTest\n   #6 = Class              #27            // java/lang/Object\n   #7 = Utf8               &lt;init&gt;\n   #8 = Utf8               ()V\n   #9 = Utf8               Code\n  #10 = Utf8               LineNumberTable\n  #11 = Utf8               LocalVariableTable\n  #12 = Utf8               this\n  #13 = Utf8               LDataStructure/StringTest;\n  #14 = Utf8               main\n  #15 = Utf8               ([Ljava/lang/String;)V\n  #16 = Utf8               args\n  #17 = Utf8               [Ljava/lang/String;\n  #18 = Utf8               s\n  #19 = Utf8               Ljava/lang/String;\n  #20 = Utf8               SourceFile\n  #21 = Utf8               StringTest.java\n  #22 = NameAndType        #7:#8          // \"&lt;init&gt;\":()V\n  #23 = Utf8               java/lang/String\n  #24 = Utf8               안녕하세요\n  #25 = NameAndType        #7:#28         // \"&lt;init&gt;\":(Ljava/lang/String;)V\n  #26 = Utf8               DataStructure/StringTest\n  #27 = Utf8               java/lang/Object\n  #28 = Utf8               (Ljava/lang/String;)V\n{\n  public DataStructure.StringTest();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=1, locals=1, args_size=1\n         0: aload_0\n         1: invokespecial #1                  // Method java/lang/Object.\"&lt;init&gt;\":()V\n         4: return\n      LineNumberTable:\n        line 3: 0\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       5     0  this   LDataStructure/StringTest;\n\n  public static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n      stack=3, locals=2, args_size=1\n         0: new           #2                  // class java/lang/String\n         3: dup\n         4: ldc           #3                  // String 안녕하세요\n         6: invokespecial #4                  // Method java/lang/String.\"&lt;init&gt;\":(Ljava/lang/String;)V\n         9: astore_1\n        10: return\n      LineNumberTable:\n        line 6: 0\n        line 9: 10\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      11     0  args   [Ljava/lang/String;\n           10       1     1     s   Ljava/lang/String;\n}\nSourceFile: \"StringTest.java\"\n\n\n \n\nJVM 상수풀로 보이는 Constant pool이라고 적혀있는 부분에\n\n내가 리터럴 표기법으로 선언한 모든 문자열이 들어있음을 확인할 수 있었다.\n\n즉 이 Constant pool에서 문자열을 검색하거나 등록하고 반환한다는 뜻으로 생각된다.\n\n \n\n💡 문자열은 리터럴로 생성된 뒤 값을 변경할 수 없다\n\n\n\nString은 불변 객체답게 역시나 수정자(Setter)가 없다.\n\n또한 내부적으로 작성된 코드를 보면\n\n \n\npublic final class String\n    implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence {\n\n    @Stable\n    private final byte[] value;\n    \n    ...\n    \n}\n\n\n \n\n이와 같이 final로 선언돼있음을 알 수 있다.\n\n즉 값을 바꾸고 싶어도 바꿀 수가 없다.\n\n값을 바꾸고 싶다면 아예 새로운 인스턴스를 만들어서 주소를 참조해야만 한다.\n\n \n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2021-05-19-string-literal/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "백오피스 튜닝기 1",
      "date": "2021-05-20 21:05:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n백오피스가 너무 느렸다.\n\n리팩토링은 꾸준히 진행하고 있지만, 보통 레거시가 아닌지라 해야 할게 너무 많다.\n\n뭐 하나 클릭하기만 하면 돌아가는 프로그레스바와 함께 내 속도 같이 타들어갔다.\n\n \n\n이 느림은 내게 이대로는 도저히 안되겠다는 생각을 갖게 만들었다.\n\n이 느림을 어떻게든 개선 해 보고야 말겠다는 다짐을 하게만들고, 이를 행동에 옮기게 만들었다.\n\n\n\n튜닝에 앞서 내 경험상 스프링으로 돌아가는 자바 애플리케이션은 항상 리소스가 여유롭게 남아도는 자원이었기 때문에 애플리케이션 속도에 결정적인 영향을 미치는 부분은 두 가지라고 생각했다.\n\n \n\n\n  \n    DB 처리속도\n  \n  \n    화면 렌더링\n  \n\n\n \n\n우선 APM에서 슬로우 쿼리를 집중적으로 살펴보는데, 백오피스에서 가장 많이 호출되는 쿼리중 하나가 유별나게 느린 걸 발견했다.\n\n처리속도는 매 쿼리당 4초 내외였다.\n\n바로 두 눈에 쌍심지를 켜고 이 쿼리를 찾아 들어가 보니 inner, cross, outer join만 10번 가까이 붙어있었다.\n\n심지어 단순히 where절 한 번만 쓰면 될 것을 자기 자신을 다시 inner join 하는 대참사가 벌어지고 있었다.\n\n \n\n이 프로젝트가 완성된 게 5년 전이었고, 당시에는 테이블에 데이터가 많지 않았으니 괜찮았겠다 싶으면서도, 왜 하필 내가 담당할 때 이런 문제가 발생하는지… 😭\n\n아무튼 우선 실행계획을 돌려봤는데\n\n \n\n\n\n \n\n당최 뭔 소린지 아예 모르겠는 것이다.\n\nFull Index Scan, Index Scan, Index Seek 등등\n\n뭔가 많이 쓰여있는데 이것들이 뭔지 아예 몰랐다.\n\n그래서 이것이 SQL 서버다 라는 책을 휴일 하루(석가탄신일) 동안 읽었다.\n\n다음날 다시 보니 이제 대충 이해가 가기 시작했다.\n\n위 쿼리에서 가장 문제가 되는 부분은 11,490,000건의 데이터를 Full Index Scan 하며 처리하는 부분이었다.\n\n이 부분의 쿼리를 수정하고 실행계획을 다시 돌려보니,\n\n \n\n\n\n \n\n11,490,000건을 Full Index Scan 하며 처리하던 쿼리는 이렇게 바뀌었다.\n\n시간복잡도로 치면 O(1)이 된건가?\n\n아무튼 증가한 쿼리의 효율성은 약 125배 정도였다. (4,271ms -&gt; 약 30~40ms)\n\n \n\n\n\n \n\n로컬, 개발서버에서 적절한 테스트를 마친 후\n\n운영서버에 배포를 해 보니 정말 만족스러운 체감속도의 차이가 느껴졌다.\n\n \n\n이에 탄력을 받아 이것저것 수정하기 시작했다.\n\n테이블에 인덱스를 새로 생성하여 처리속도가 약 10배가량 증가한다거나, 처리하는 데이터는 40KB인데 웹 폰트를 4MB 정도 다운로드하여 렌더링이 오래 걸린다거나 등등의 잡다한 문제들이 있었고, 이를 하루 내내 처리하고 보니 괄목할만한 속도의 변화가 느껴졌다.\n\n \n\n내가 맡은 백오피스와 내 실력은 아직도 갈길이 멀고 내가 이 회사에 언제까지 있을지도 잘 모르겠지만, 추후에 내가 퇴직하더라도 백오피스가 좋은 프로젝트로 남았으면 하는 바람이 크다.\n\n개발자 커리어에 처음으로 담당하게 된 녀석이라 유독 더 그런지도 모르겠다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-05-20-diary-18/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "countBy 보단 existsBy",
      "date": "2021-05-21 23:06:00 +0000",
      "description": "SQL Insert시 중복검사, countBy 보단 existsBy\n",
      "content": "\n \n\n오늘 아주 잘못된 개발 방식 하나를 고쳤다.\n\n나는 JPA로 Insert 작업을 할 때 중복검사를 해 값이 없을 때만 insert 해야 하는 경우에\n\ncountBy~를 사용해 count &gt; 1이라는 조건으로 개발을 하고 있었다.\n\n \n\nLong countByGuid(String guid);\nboolean existsByGuid(String guid);\n\n\n \n\nJPA문서들을 보다 보니\n\n그게 참 바보 같은 짓이었다는 걸 깨닫게 됐다.\n\n머리를 망치로 얻어맞은 듯하여 바로 실험을 해보니,\n\n \n\nSELECT\n        FEEDBOARD0_.FEED_BOARD_ID AS COL_0_0_ \n    FROM\n        FEED_BOARD FEEDBOARD0_ \n    WHERE\n        FEEDBOARD0_.TITLE='안녕하세요' LIMIT 1\n\n\n \n\nexistsBy~를 사용하면 select count(*)가 아닌, select ~ limit 1이라는 쿼리가 발생한다.\n\n \n\n즉, countBy와 비슷하지만 순회 검색 중 중복되는 게 단 하나라도 있는 경우\n\n그 즉시 쿼리를 종료하는 것이므로 모든 개수를 세는 count보다 압도적으로 좋은 성능을 보인다.\n\n \n\n아주 간단한 실험 결과 데이터가 얼마 없음에도 불구하고 2배 이상의 성능 차이를 보여줬다.\n\n실제 서비스의 운영환경에서는 정말로 유의미한 성능차이가 발생할거라 판단된다.\n\n \n\n이 외에도 DB의 유니크 제약조건과 @SQLInsert 같은 JPA 애노테이션을 활용하는 방법 등이 있었으나,\n\n나는 기본키 생성 전략이 IDENTITY이기 때문에 뜻대로 되질 않았다.\n\n다만 SEQUENCE로 할 경우 충분히 활용 가치가 있다는 생각이 들기에 기록해놓고 잘 외워둬야 하겠다.\n\n \n\n@SQLInsert(sql=\"INSERT IGNORE INTO EntityClass(id,name) VALUES(?,?)\")\nclass EntityClass{\n   ...\n}\n\n\n \n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-05-21-exists/"
    },{
      "image": "/assets/img/backend/mysql.png",
      "title": "MySQL 시작하기",
      "date": "2021-05-22 23:59:00 +0000",
      "description": "MySQL 초기 세팅에 대해 정리합니다\n",
      "content": "\n  1. 데이터베이스 생성\n  2. 사용자 계정 생성\n  3. 사용자에게 권한 부여\n\n\n \n\n새 사이드 프로젝트를 시작할 때 딱 한번 하고 마는 작업들이라 할 때마다 약간씩 헷갈려서 기록해둔다.\n\n우선 MySQL을 구축했다면 접속을 한다.\n\n터미널로 하든 workbench로 하든 Data Grip이든 상관없다.\n\n\n\n이후 순서는 크게 세개다.\n\n \n\n1. 데이터베이스 생성\n\n\n\nMySQL은 기본적으로 대소문자를 구분하므로 별다른 설정을 하지 않았다면 가급적 소문자로 SQL을 입력한다.\n\n데이터베이스를 생성하기 전 현재 데이터베이스 목록을 확인한다.\n\nshow databases;\n\n\n \n\n\n\n이후 생성하고자 하는 데이터베이스가 없다면 새로 생성해주자.\n\n \n\ncreate database {DB} default character set utf8mb4;\n\n\n이때 데이터베이스의 기본 인코딩을 지정해줘야 추후 한글이 깨지지 않는다.\n\n그리고 utf8과 utf8mb4가 있는데, 무슨 차이냐면 !\n\nutf8로 하면 한글은 제대로 나오지만 emoji가 제대로 나오지 않는다.😲\n\n따라서 가급적 utf8mb4로 설정해주자.\n\n \n\n2. 사용자 계정 생성\n\n\n\n역시 사용자를 생성하기 전 사용자 목록을 먼저 확인해준다.\n\nMYSQL 스키마를 선택한 후 유저 테이블을 뒤질 것이다.\n\nuse mysql;\nselect user, host from user;\n\n\n \n\n\n\n \n\n생성하고자 하는 사용자 계정과 겹치는 게 있는지 확인한 후 사용자를 생성하자.\n\ncreate user '{user}'@'%' identified by '{password}';\n\n\n여기서 사용자 이름 뒤의 % 는 외부에서의 접속을 허락한다는 뜻이다.\n\n만일 로컬에서만 사용하고자 한다면 %가 아닌 localhost나 127.0.0.1을 입력해주면 되겠다.\n\n혹은 특정 IP에서만 DB에 접속이 가능하게 하고싶다면 해당 IP주소를 입력하면 되겠다.\n\n뒤는 해당 사용자명으로 접속하고자 할 때 입력해야 할 패스워드를 지정해준다.\n\n \n\n3. 사용자에게 권한 부여\n\n\n\n마지막으로 사용자에게 권한을 줘야 하는데 생각해볼 점이 있다.\n\n해당 사용자가 DDL도 사용할 수 있게 할 것인지, DML만 사용하게 할 것인지\n\n만일 DML만 사용 가능하다면 어느 정도 선까지 허용할 것인지 등이다.\n\n개발을 하다 보면 의도치 않게 DB 테이블을 날려버린다거나 혹은 데이터를 날려버린다거나 하는 일이 자주 발생한다.\n\n이런 경우는 정말 대참사이고 생각보다 자주 발생하기 때문에(심지어 회사에서도 종종 목격할 수 있다) 애초에 애플리케이션용 사용자 계정을 새로 만들어 데이터를 삭제하지 못하게 권한을 부여하지 않는 식으로 작업을 한다.\n\n필자 같은 경우엔 보통 DML만 사용 가능하게 하고 DML 중에서도 select, insert, update만 사용가능하게 권한을 주는 걸 선호한다.\n\ndelete문을 제외하는 이유는 사용하여 데이터 자체를 삭제했다고 한다면, 나중에 이 데이터가 다시 필요해질 경우에 굉장히 곤란해지기 때문이다.\n\n또한, delete는 애초에 거의 사용하지 않고 테이블에 유효한 데이터인지를 표시하는 컬럼을 별도로 생성하여 데이터를 관리한다.\n\n그리고 delete 사용에 제약을 걸어 의도치 않게 row가 날아가는 일을 원천 차단하는 것이다.\n\ngrant select, insert, update on {DB}.* to '{user}'@'%';\n\n\n이 SQL은 선택한 DB에 존재하는 모든 테이블 (DB.\\*)에 한해 선택한 사용자가 select, insert, update만을 사용할 수 있게 권한을 부여한다는 의미이다.\n",
      "categories": ["backend","database"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/database/2021-05-22-mysql-start/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "백오피스 튜닝기 2",
      "date": "2021-05-24 20:59:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n최근 회사에서 백오피스 리팩토링에 전력을 기울이고 있다.\n\n(너무 느려서 -ㅅ-.. 여유도 많이 있어서..)\n\n당장 눈에보이는 문제들을 모두 걷어내고 보니\n\nAPM에서 영문을 모르게 병목이 생기는 구간들이 발견됐다.\n\n \n\n\n\n \n\n정말 단순한 로직이고 서버단에서 초스피드로 모든 처리가 끝났으나 HttpResponse가 안 날아가고 병목이 생기는 것이었다.\n\n정말 HttpResponse 문제인지 확인해보기 위해 한 가지를 더 점검해봤다.\n\n \n\n\n\n \n\nTTFB(Time to first byte)는 클라이언트가 서버에 요청(Request)을 보내고 응답(Response)을 받기까지 걸리는 시간을 말하는데, 서버 모니터링에서 병목이 생기는 부분과 딜레이가 아주 흡사했다.\n\n \n\n발견한 수상한 점들을 정리하자면\n\n \n\n\n  문제가 발생하는 요청을 처리할 때 서버의 CPU 사용량이 폭증하는 현상 발생\n  서버의 HttpResponse 처리 시간 폭증\n  클라이언트 TTFB 폭증\n  위의 문제들로 인해 사용자 입장(우리 회사 직원들과 나….😭)에서 잦은 빈도로 약 2~4초의 로딩 발생\n\n\n \n\n즉, 서버는 요청을 즉시 받아 모든 처리를 광속으로 끝냈으나, 모종의 이유로 클라이언트에 응답을 보내는데 많은 시간이 걸린다는 게 결론이었다.\n\n문제가 있다는 걸 몰랐으면 모르되, 알고도 넘길 수는 없다.\n\n \n\n이 문제를 해결하기 위해 하루 동안 모든 콜스택을 살펴보니 의심되는 조건이 세 가지 있었다.\n\n \n\n\n  RestController가 아닌 Controller에서 DispatcherServlet이 ViewResolver에 ModelAndView를 넘기고 받는 과정\n  Spring Boot + JSP의 조합으로 인한 호환성 문제\n  org.apache.catalina.webresources.JarWarResourceSet.getArchiveEntries()가 매우 자주 보임\n\n\n \n\n백오피스는 레거시라 Spring + JSP를 사용하고 있었는데, 최근 Spring에서 Spring-Boot으로 마이그레이션했다.\n\n오피셜에 따르면 Spring-Boot은 기본적으로 단일 실행파일(bootJar)로 빌드해 내장 톰캣을 사용하기 때문에 서블릿의 일종인 JSP와 궁합이 좋지 않아 JSP를 공식적으로 지원하지 않으며 가급적 Thymeleaf 나 Freemarker 등의 템플릿 엔진을 사용해 bootJar로 빌드한 후 내장 톰캣으로 구동하라고 권고하고 있다.\n\n \n\n하지만 JSP를 당장에 템플릿 엔진으로 바꾸자니 공수가 너무 많이 들어 우선 Spring-Boot과 JSP조합을 사용하였고, 이를 Spring-Boot이 공식적으로 지원하지 않아 bootJar로 패키징 하는데 애로사항이 있어 war로 패키징하여 내장 톰캣을 사용하고 있었다.\n\n \n\n\n\n \n\n아무튼 콜스택에서 의심스러운 org.apache.catalina.webresources.JarWarResourceSet.getArchiveEntries()에 대해 찾아보니 war 내부의 jar 파일들을 스캔하는 내장 톰캣의 일부 로직이었다.\n\n \n\n@Override\nprotected Map&lt;String,JarEntry&gt; getArchiveEntries(boolean single) {\n    synchronized (archiveLock) {\n        if (archiveEntries == null) {\n            JarFile warFile = null;\n            InputStream jarFileIs = null;\n            archiveEntries = new HashMap&lt;&gt;();\n            boolean multiRelease = false;\n            try {\n                warFile = openJarFile();\n                JarEntry jarFileInWar = warFile.getJarEntry(archivePath);\n                jarFileIs = warFile.getInputStream(jarFileInWar);\n\n                try (TomcatJarInputStream jarIs = new TomcatJarInputStream(jarFileIs)) {\n                    JarEntry entry = jarIs.getNextJarEntry();\n                    while (entry != null) {\n                        archiveEntries.put(entry.getName(), entry);\n                        entry = jarIs.getNextJarEntry();\n                    }\n                    Manifest m = jarIs.getManifest();\n                    setManifest(m);\n                    if (m != null &amp;&amp; JreCompat.isJre9Available()) {\n                        String value = m.getMainAttributes().getValue(\"Multi-Release\");\n                        if (value != null) {\n                            multiRelease = Boolean.parseBoolean(value);\n                        }\n                    }\n                        // Hack to work-around JarInputStream swallowing these\n                        // entries. TomcatJarInputStream is used above which\n                        // extends JarInputStream and the method that creates\n                        // the entries over-ridden so we can a) tell if the\n                        // entries are present and b) cache them so we can\n                        // access them here.\n                    entry = jarIs.getMetaInfEntry();\n                    if (entry != null) {\n                        archiveEntries.put(entry.getName(), entry);\n                    }\n                    entry = jarIs.getManifestEntry();\n                    if (entry != null) {\n                        archiveEntries.put(entry.getName(), entry);\n                    }\n                }\n                if (multiRelease) {\n                    processArchivesEntriesForMultiRelease();\n                }\n            } catch (IOException ioe) {\n                // Should never happen\n                archiveEntries = null;\n                throw new IllegalStateException(ioe);\n            } finally {\n                if (warFile != null) {\n                    closeJarFile();\n                }\n                if (jarFileIs != null) {\n                    try {\n                        jarFileIs.close();\n                    } catch (IOException e) {\n                        // Ignore\n                    }\n                }\n            }\n        }\n        return archiveEntries;\n    }\n}\n\n\n \n\n위의 모든 조건을 종합하고 상황을 보니 런타임에 JSP에 관련된 작업이 처리되기 시작하면 위의 로직이 호출되고 내장 톰캣은 war 내부의 jar를 풀스캔 때리기 시작하며 동시에 CPU 사용률이 폭증하는 현상이 발생한다는 가정이 나왔다.\n\n그리고 위의 가정을 키워드로 다시 검색을 시작했다.\n\n \n\n📜 Performance - Spring Boot - Server Response Time\n\n \n\n📜 Provide fat jar aware implementations of Tomcat’s Resource and ResourceSet to speed up resource loading from executable wars\n\n \n\nSpring-Boot repository issue를 살펴보니 비슷한 문제제기가 있었고, Spring-Boot의 대빵(?) 개발자인 Andy Wilkinson에 따르면 이 문제는 두 가지 정도의 해결방법이 있다고 하는 것 같았다.\n\n또한 회피책이 존재하므로 우선순위가 높지 않다고 판단해 해당 문제는 Spring-Boot 2.x.x대에 해결할 계획이 없다고 밝혔다.\n\n \n\n\n  JSP + WAR를 사용하지 말고 템플릿 엔진 + JAR를 사용할 것\n  JSP + WAR를 사용하겠다면 내장 톰캣을 사용하지 말고 외장 톰캣을 사용 할 것\n\n\n \n\n우선 이 정도까지 파악을 마쳤고, 당장에 템플릿 엔진으로 마이그레이션 할 수는 없는 상황이니 우선 외장 톰캣을 이용해 보기로 결정했다.\n\n일단 문제는 문제고 퇴근시간 됐으면 퇴근은 해야지… (여유가 없는 것도 아니고 😙)\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-05-24-diary-19/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "백오피스 튜닝기 3",
      "date": "2021-05-25 10:36:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n오늘 회사에 도착하자마자 어제 하던 일을 이어나갔다.\n\nSpring-Boot을 사용하기 시작한 이후로 외장 톰캣을 전혀 쓰지 않아 생각보다 약간 헤맸다.\n\n서버에 톰캣 9.0.54(최신 릴리즈 버전)를 설치한 후 백오피스를 war로 패키징 하기 위한 작업을 시작했다.\n\n \n\npublic class Application extends SpringBootServletInitializer {\n\n\t@Override\n\tprotected SpringApplicationBuilder configure(SpringApplicationBuilder application) {\n\t\treturn application.sources(Application.class);\n\t}\n\n\n \n\n외장 톰캣을 사용 할 것이므로 외장 톰캣의 web.xml에 애플리케이션 컨텍스트를 등록해줘야 한다.\n\n외장 톰캣은 Servlet Container가 구동될 때 WEB-INF/에 존재하는 web.xml을 읽어 웹 애플리케이션을 구성해주기 때문이다.\n\nServlet 3.0부터는 SpringMVC의 WebApplicationInitializer 인터페이스를 구현하면 web.xml을 대체할 수 있게 됐는데, Spring-Boot에서 WebApplicationInitializer 인터페이스를 구현해놓은 콘크리트 클래스가 SpringBootServletInitializer이기 때문에 이 클래스를 상속받은 후 configure 메서드를 Override 하여 \n컨텍스트에 Spring-Boot의 Main 클래스를 등록시켜준다.\n\n \n\n\n  Configure the application. Normally all you would need to do is to add sources (e.g. config classes) because other settings have sensible defaults. You might choose (for instance) to add default command line arguments, or set an active Spring profile.\n\n\n \n\nprotected SpringApplicationBuilder configure(SpringApplicationBuilder builder) {\n    return builder;\n}\n\n\n \n\n그리고 build.gradle을 수정해준다.\n\n \n\napply plugin: 'war'\nbootWar.enabled = false\nwar.enabled = true\n\n\ndependencies {\n\n\t...\n    \n    providedRuntime 'org.springframework.boot:spring-boot-starter-tomcat'\n    \n    ...\n}\n\n\n \n\n이후 단독 실행 가능한 bootWar가 아닌 war로 패키징하여 이를 서버 톰캣 디렉터리의 webapps에 올려주고 톰캣의 server.xml을 설정해준 후 service start를 해줬다.\n\n \n\n\n  \n    \n      \n    \n  \n  \n    \n      문제의 상황\n    \n  \n\n\n \n\n\n\n\n\n\n\n \n\n위는 개선 후의 이미지인데 문제가 됐던 URI들의 TTFB가 매우 큰 폭으로 개선됐다. (약 2~4초 -&gt; 0.1초 내외)\n\n \n\n실 체감속도도 크게 개선됐다.\n\n크게 개선된 수준이 아니고 약간의 버벅거림조차 없는 클-린한 상태가 돼버렸다…😅\n\n나도 버그를 고쳐야겠다는 생각만 했지 사실 이 정도까지 빨라질 거라고는 예상을 하지 못했기 때문에 매우 놀라웠다.\n\n \n\n사실 방향만 보자면 Spring-Boot + war가 아닌 bootJar를 사용해야 맞는 것인데, View가 JSP이다 보니 war로 할 수밖에 없고, bootJar로 하자니 JSP를 전체 다 마이그레이션 해야만 하는 상황이라 어쩔 수 없는 상태였다.\n\n고도화를 하기에는 너무 해야 할 작업이 많기 때문이다.\n\n이는 차근차근 꾸준히 해 나가야 할 과제라고 생각한다.\n\n \n\n어쨌든 당분간은 이상태로 쓰도록 하고 JSP와 JQuery는\n\n차근차근 Thymeleaf와 Vue.js로 마이그레이션 해나갈 계획이다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-05-25-diary-20/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "백오피스 튜닝기 4",
      "date": "2021-05-26 20:49:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n실무를 보면서 처음으로 알고리즘과 자료구조가 도움이 된다고 느꼈다.\n\n지원부서에서 특정 기능이 안된다고 연락이 와서 살펴보는데 안되는건 아니고 그냥 느렸다. 말도 안 될 정도로…😲\n\n \n\n의아한 마음에 최근 배포내역부터 살펴봤는데 해당 기능에 직간접적으로 영향을 줄만한 내역이 보이질 않았다.\n\n그래서 해당 기능의 IO와 DB 쿼리부터 차근차근 확인을 했는데 별로 부하가 걸릴 것도 없었다.\n\n \n\n“진짜 뭐지..?” 싶어서 코드를 까보니 맙소사…\n\n \n\n해당 테이블에서 가져오는 row가 약 12,000개 정도였는데\n\n이렇게 가져다가 시간복잡도 O(N^2)의 로직을 타고 있던 것이었다.\n\n총 연산은 약 144,000,000회였으며, 이를 통해 클라이언트에 내려주는 데이터는 1.2MB 정도였다.\n\n \n\n별다른 세팅도 안된 브라우저에서 싱글 스레드로 1.2MB를 통으로 렌더링하고 자빠졌으니 느릴 수밖에 없었던 셈.\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n…\n\n \n\n…\n\n \n\n…\n\n \n\n…\n\n \n\n…\n\n \n\n…\n\n \n\n…\n\n \n\n…\n\n \n\n…\n\n \n\n\n\n \n\n대체 이런 코드가 어떻게 이제 와서 문제가 된 건지 원인을 찾기 위해 Git History를 보니 2017년 이후로 수정된 적이 없는 코드였다.\n\n즉, 개발 당시에는 테이블에 row가 얼마 없었으니 아무런 문제가 되질 않다가 회사가 크게 성장하고 데이터가 쌓이기 시작하면서 파탄을 드러낸 셈이다.\n\n \n\n테이블의 row가 1,500개였던 시절엔 2,250,000회의 루프가 돌았을 것이다.\n\n테이블의 row가 3,000개였던 시절엔 9,000,000회의 루프가 돌았을 것이다.\n\n테이블의 row가 6,000개였던 시절엔 36,000,000회의 루프가 돌았을 것이다.\n\n현재는 12,000개이므로 144,000,000회의 루프가 돌고 있는 것이고… 🤢\n\n \n\nMartin Fowler의 저서인 Refactoring에는 이런 주제가 나온다.\n\n개발업계의 선구자로 불리는 사람들에겐 공통점이 있는데, 이 사람들은 항상 현재 자신이 맡은 임무의 완수만을 보는 게 아니고 그 이상의 미래를 생각한다는 것이다.\n\n1990년대 후반에 Roy Fielding은 HTTP를 HTTP/1.0으로 업데이트하며 하위 호환성 문제를 고심하고 고심하다 Restful이라는 개념을 정립했다.\n\nMartin Fowler는 미래의 동료와 자기 자신을 위해 좋은 설계와 깔끔한 코드에 항상 공을 들이고, 습관적으로 리팩토링을 할 것을 권고하며, 똑똑하고 스킬이 좋은 개발자도 좋은 개발자이지만, 좋은 습관을 아주 많이 들인 착실한 개발자도 아주 좋은 개발자라고 말한다.\n\n자기 자신을 후자의 개발자로 보기도 하고.\n\n \n\n“아… 나는 절대이런 식으로는개발하지 말아야겠다”\n\n \n\n그 코드를 보면서 그동안 봐왔던 많은 글들이 한 번에 가슴으로 이해되고 와닿는 순간이었다.\n\n(내가 개고생하니까 와닿더라…😥)\n\n \n\n어쨌든 배운건 배운 거고, 이 폭탄을 치워야 될 사람은 결국 나인 것을… 😭\n\n오늘 하루 내내 죽을둥살둥하며 이 코드를 고치고, 이 코드를 고침으로서 발생하는 사이드 이펙트까지 고치고…😨\n\n \n\n우선 SQL을 갈아엎었다. 쿼리와 인덱스를 조정하여 쿼리의 성능을 높였으며, 이후 JQuery와 Mybatis로 작성돼있던 코드들을 Vue.js와 JPA로 마이그레이션했다.\n\n그리고 재귀호출 로직을 변경했다. 굳이 재귀로 처리할 필요가 없는 로직이었기 때문이다.\n\n \n\n그 외의 public API들과 각종 Validation 등등..\n\n결국 모듈 하나를 통째로 고도화해버렸다.\n\n \n\n아무튼 고생은 많이 했지만 그래도 부쩍 좋아진 성능과 새로만든 UI/UX를 보고있노라면 지원부서에서 좋아할 것 같아 힘이 난다. 🤗\n\n큰 교훈을 얻은 하루였다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-05-26-diary-21/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "문자열 계산기",
      "date": "2021-05-27 21:19:00 +0000",
      "description": "자바로 만드는 문자열 계산기\n",
      "content": "\n  📕 요구사항\n\n\n \n\n📕 요구사항\n\n\n\n\n  사용자가 입력한 문자열 값에 따라 사칙연산을 수행할 수 있는 계산기를 구현해야 한다.\n  문자열 계산기는 사칙연산의 계산 우선순위가 아닌 입력 값에 따라 계산 순서가 결정된다. 즉, 수학에서는 곱셈, 나눗셈이 덧셈, 뺄셈 보다 먼저 계산해야 하지만 이를 무시한다.\n  예를 들어 2 + 3 \\* 4 / 2와 같은 문자열을 입력할 경우 2 + 3 \\* 4 / 2 실행 결과인 10을 출력해야 한다.\n\n\n \n\npublic class StringCalculator {\n    \n    private String[] values;\n    \n    private LinkedList&lt;Double&gt; operands;\n    private LinkedList&lt;String&gt; operators;\n    \n    private double result;\n    \n    public StringCalculator() {\n        this(new LinkedList&lt;&gt;(), new LinkedList&lt;&gt;());\n    }\n    \n    private StringCalculator(LinkedList&lt;Double&gt; operands, LinkedList&lt;String&gt; operators) {\n        this.operands = operands;\n        this.operators = operators;\n    }\n    \n    public double getResult() {\n        return result;\n    }\n    \n    public void calculate() {\n        result = operands.poll();\n        while(operands.size() != 0) {\n            Operator operator = Operator.of(operators.poll());\n            result = operator.calculate(result, operands.poll());\n        }\n    }\n    \n    public void enter(final String s) {\n        values = s.split(\" \");\n        if(values.length &lt; 3) {\n            throw new IllegalArgumentException(\"입력값이 올바르지 않습니다\");\n        }\n        for(int i = 0; i &lt; values.length; i++) {\n            validate(i, values[i]);\n            add(values[i]);\n        }\n    }\n    \n    private void validate(final int idx, final String value) {\n        if(idx % 2 == 0 &amp;&amp; !isNumeric(value)) {\n            throw new IllegalArgumentException(\"입력값이 올바르지 않습니다\");\n        }\n        if(idx % 2 == 1 &amp;&amp; isNumeric(value)) {\n            throw new IllegalArgumentException(\"입력값이 올바르지 않습니다\");\n        }\n    }\n    \n    private void add(final String value) {\n        if(isNumeric(value)) {\n            operands.add(valueOf(value));\n        }\n        if(!isNumeric(value)) {\n            operators.add(value);\n        }\n    }\n    \n    private static boolean isNumeric(final String s) {\n        if(\"\".equals(s)) {\n            return false;\n        }\n        return s.matches(\"-?\\\\d+(\\\\.\\\\d+)?\");\n    }\n    \n    private enum Operator {\n        PLUS(\"+\", (e1, e2)-&gt;e1 + e2),\n        MINUS(\"-\", (e1, e2)-&gt;e1 - e2),\n        DIVISION(\"/\", (e1, e2)-&gt;e1 / e2),\n        MULTI(\"*\", (e1, e2)-&gt;e1 * e2);\n        \n        private String operator;\n        private BinaryOperator&lt;Double&gt; operating;\n        \n        Operator(final String operator, final BinaryOperator&lt;Double&gt; operating) {\n            this.operator = operator;\n            this.operating = operating;\n        }\n        \n        private static Operator of(final String operator) {\n            return Arrays.stream(Operator.values())\n                         .filter(value-&gt;value.operator.equals(operator))\n                         .findFirst()\n                         .orElseThrow(()-&gt;new IllegalArgumentException(\"유효한 연산자 형식이 아닙니다.\"));\n        }\n        \n        private Double calculate(final Double e1, final Double e2) {\n            return operating.apply(e1, e2);\n        }\n    }\n    \n}\n\n\n \n\nclass StringCalculatorTest {\n    \n    StringCalculator calculator;\n    \n    @BeforeEach\n    void setUp() {\n        calculator = new StringCalculator();\n    }\n    \n    @DisplayName(\"입력_테스트\")\n    @ParameterizedTest\n    @ValueSource(strings = {\"\",\n                            \"++*/\",\n                            \"12345\",\n                            \"2 3 42\",\n                            \"2 + + * 4 / 2\",\n                            \"+ + + + + + /,\"})\n    void enter(String param) {\n        assertThatThrownBy(()-&gt;{\n            calculator.enter(param);\n        }).isInstanceOf(IllegalArgumentException.class)\n          .hasMessageContaining(\"입력값이 올바르지 않습니다\");\n    }\n    \n    @DisplayName(\"계산_테스트\")\n    @ParameterizedTest\n    @CsvSource(value = {\"1 + 2:3\",\n                        \"4 - 2:2\",\n                        \"6 * 2:12\",\n                        \"8 / 4:2\",\n                        \"2 * 3 / 3 / 2:1\",\n                        \"2 + 3 * 4 / 2:10\"}, delimiter = ':')\n    void calculate(String param, double expected) {\n        calculator.enter(param);\n        calculator.calculate();\n        assertThat(calculator.getResult()).isEqualTo(expected);\n    }\n    \n}\n\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-05-27-game-5/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "숫자 야구 게임",
      "date": "2021-05-27 21:22:00 +0000",
      "description": "자바로 만드는 숫자 야구 게임\n",
      "content": "\n  📕 요구 사항\n  📕 실행 결과\n  📕 프로그래밍 요구사항\n\n\n \n\n📕 요구 사항\n\n\n\n기본적으로 1부터 9까지 서로 다른 수로 이루어진 3자리의 수를 맞추는 게임이다.\n\n\n  같은 수가 같은 자리에 있으면 스트라이크, 다른 자리에 있으면 볼, 같은 수가 전혀 없으면 포볼 또는 낫싱이란 힌트를 얻고, 그 힌트를 이용해서 먼저 상대방(컴퓨터)의 수를 맞추면 승리한다.\n    \n      e.g. 상대방(컴퓨터)의 수가 425일 때, 123을 제시한 경우 : 1스트라이크, 456을 제시한 경우 : 1볼 1스트라이크, 789를 제시한 경우 : 낫싱\n    \n  \n  위 숫자 야구 게임에서 상대방의 역할을 컴퓨터가 한다. 컴퓨터는 1에서 9까지 서로 다른 임의의 수 3개를 선택한다. 게 임 플레이어는 컴퓨터가 생각하고 있는 3개의 숫자를 입력하고, 컴퓨터는 입력한 숫자에 대한 결과를 출력한다.\n  이 같은 과정을 반복해 컴퓨터가 선택한 3개의 숫자를 모두 맞히면 게임이 종료된다.\n  게임을 종료한 후 게임을 다시 시작하거나 완전히 종료할 수 있다.\n\n\n \n\n📕 실행 결과\n\n\n\n숫자를 입력해 주세요 : 123\n1볼 1스트라이크\n숫자를 입력해 주세요 : 145\n1볼\n숫자를 입력해 주세요 : 671\n2볼\n숫자를 입력해 주세요 : 216\n1스트라이크\n숫자를 입력해 주세요 : 713\n3스트라이크\n3개의 숫자를 모두 맞히셨습니다! 게임 종료\n게임을 새로 시작하려면 1, 종료하려면 2를 입력하세요.\n1\n숫자를 입력해 주세요 : 123\n1볼 1스트라이크\n…\n\n\n \n\n📕 프로그래밍 요구사항\n\n\n\n\n  자바 코드 컨벤션을 지키면서 프로그래밍한다.\n    \n      기본적으로Google Java Style Guide을 원칙으로 한다.\n      단, 들여쓰기는 ‘2 spaces’가 아닌 ‘4 spaces’로 한다.\n    \n  \n  indent(인덴트, 들여쓰기) depth를 2가 넘지 않도록 구현한다. 1까지만 허용한다.\n    \n      예를 들어 while문 안에 if문이 있으면 들여쓰기는 2이다.\n      힌트: indent(인덴트, 들여쓰기) depth를 줄이는 좋은 방법은 함수(또는 메소드)를 분리하면 된다.\n    \n  \n  else 예약어를 쓰지 않는다.\n    \n      힌트: if 조건절에서 값을 return하는 방식으로 구현하면 else를 사용하지 않아도 된다.\n      else를 쓰지 말라고 하니 switch/case로 구현하는 경우가 있는데 switch/case도 허용하지 않는다.\n    \n  \n  모든 로직에 단위 테스트를 구현한다. 단, UI(System.out, System.in) 로직은 제외\n    \n      핵심 로직을 구현하는 코드와 UI를 담당하는 로직을 구분한다.\n      UI 로직을 InputView, ResultView와 같은 클래스를 추가해 분리한다.\n    \n  \n  3항 연산자를 쓰지 않는다.\n  함수(또는 메소드)가 한 가지 일만 하도록 최대한 작게 만들어라.\n\n\n \n\npublic class BaseBall {\n    private static int strikeCount;\n    private static int ballCount;\n    \n    public void run() {\n        String generate = RandomNumberGenerator.generate();\n        while(strikeCount != 3) {\n            computed(Input.number(), generate);\n            Output.print();\n        }\n        restart();\n    }\n    \n    private void restart() {\n        int trigger = Input.restartQuestion();\n        if(trigger == 1) {\n            new BaseBall().run();\n        }\n        if(trigger == 0) {\n            System.out.println(\"게임을 종료합니다\");\n            System.exit(0);\n        }\n    }\n    \n    private void computed(String inputs, String generate) {\n        strikeCount = 0;\n        ballCount = 0;\n        \n        for(int i = 0; i &lt; inputs.length(); i++) {\n            isBall(inputs, generate, i);\n            isStrike(inputs, generate, i);\n        }\n    }\n    \n    private void isBall(String inputs, String generate, int idx) {\n        if(inputs.charAt(idx) != generate.charAt(idx) &amp;&amp; generate.contains(Character.toString(inputs.charAt(idx)))) {\n            ballCount++;\n        }\n    }\n    \n    private void isStrike(String inputs, String generate, int idx) {\n        if(inputs.charAt(idx) == generate.charAt(idx)) {\n            strikeCount++;\n        }\n    }\n    \n    private static class RandomNumberGenerator {\n        private static final int MIN = 1;\n        private static final int MAX = 9;\n        \n        private static String generate() {\n            Set&lt;Integer&gt; set = new HashSet&lt;&gt;();\n            Random random = new Random();\n            \n            while(set.size() &lt; 3) {\n                set.add(random.nextInt(MAX) + MIN);\n            }\n            \n            StringBuilder stringBuilder = new StringBuilder();\n            set.forEach(stringBuilder::append);\n            \n            return stringBuilder.toString();\n        }\n    }\n    \n    private static class Input {\n        private static String number() {\n            System.out.print(\"\\n숫자를 입력해 주세요 : \");\n            Scanner sc = new Scanner(System.in);\n            return sc.nextLine();\n        }\n        \n        private static int restartQuestion() {\n            System.out.println(\"게임을 새로 시작하려면 1, 종료하려면 2를 입력하세요\");\n            Scanner sc = new Scanner(System.in);\n            return sc.nextInt();\n        }\n    }\n    \n    private static class Output {\n        private static void print() {\n            if(ballCount != 0) {\n                System.out.print(ballCount + \"볼 \");\n            }\n            if(strikeCount != 0) {\n                System.out.print(strikeCount + \"스트라이크\");\n            }\n            if(strikeCount == 0 &amp;&amp; ballCount == 0) {\n                System.out.print(\"낫싱\");\n            }\n            if(strikeCount == 3) {\n                System.out.println(\"3개의 숫자를 모두 맞히셨습니다! 게임 종료\");\n            }\n        }\n    }\n}\n\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-05-27-game-6/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "쿼리 튜닝을 편하게! p6spy 개조하기",
      "date": "2021-05-28 22:06:00 +0000",
      "description": "p6spy를 커스텀하여 가독성 좋은 쿼리 콘솔을 만들어 봅시다\n",
      "content": "\n  🚫 주의!\n  ✅ 개발 환경\n  ✅ 필수 설정    \n      📕 p6spy 구조\n    \n  \n\n\n\n\n대략 이러한 결과를 얻을 수 있습니다.\n\n\n\n🚫 주의!\n\n\n\n\n  굉장히 비싼 자원을 사용하므로 운영 환경에선 절대 사용하지 말 것을 권장드립니다.\n\n\n\n\n✅ 개발 환경\n\n\n\n소스코드는 GitHub에 공개되어 있습니다.\n\n\n  Java 11\n  Gradle 6.8.3\n  Spring-Boot 2.5.0\n  Spring-Data-JPA\n  H2 Database\n  p6spy 1.7.1\n\n\n\n\n✅ 필수 설정\n\n\n\n// file: 'build.gradle'\nimplementation 'com.github.gavlyukovskiy:p6spy-spring-boot-starter:1.7.1'\n\n\n\n\n# file: 'application.yaml'\ndecorator:\n  datasource:\n    p6spy:\n      enable-logging: true\n\n\n\n\n명시하지 않아도 기본값은 true로 설정돼있지만, profile을 이용하여 개발/운영에서 명확하게 사용하기 위해 선언해주었다.\n\n운영환경은 운영환경 profile에 위의 enable-logging을 false로 지정해주면 된다.\n\n\n\nJPA를 쓰다 보면 예상 밖의 쿼리가 발생하는 경우가 굉장히 많다.\n\n스프링에는 쿼리를 파악하기 좋게 해주는 라이브러리로 p6spy가 있는데, 기본값으로 사용할 경우 단순히 파라미터 바인딩만 보여주는 수준으로 생각보다 가독성이 좋지 않다.\n\n더 큰 문제점은 쿼리가 한번 발생하면 파라미터가 바인딩되지 않은 원본 쿼리와 파라미터를 바인딩한 후의 쿼리, 총 두 개의 쿼리가 나란히 출력되는 것이다.\n\n\n\n이처럼 간단한 쿼리의 경우는 그럭저럭 괜찮을 수 있으나, 통계성 쿼리 같이 복잡하고 수십 줄 이상되는 빅 쿼리가 두 개 연달아 나오면 굉장히 혼란스럽다.\n\n심지어 두 개의 쿼리 중 한 개는 물음표가 가득할 것이다.\n\n이런 문제를 개선하기 위해 p6spy를 커스터마이징 했다.\n\n\n\n📕 p6spy 구조\n\n\n\n\n  \n    DataSource를 래핑하여 프록시를 만든다.\n  \n  \n    쿼리가 발생하여 JDBC가 ResultSet을 반환하면 이를 만들어둔 프록시로 가로챈다.\n  \n  \n    내부적으로 ResultSet의 정보를 분석하고 p6spy의 옵션을 적용해준다.\n  \n  \n    Slf4j를 사용해 로깅한다.\n  \n\n\n\n\n처음 p6spy가 초기화될 때 쿼리를 포매팅하는 객체가 MultiLineFormat이다.\n\n\n\npublic class P6SpyProperties {\n    private boolean enableLogging = true;\n    private boolean multiline = true;\n    private P6SpyLogging logging = P6SpyLogging.SLF4J;\n    private String logFile = \"spy.log\";\n    private String logFormat;\n}\n\n\n\n\nprivate boolean multiline = true이며\n\nprivate String logFormat = null이다.\n\n\n\nif (!initialP6SpyOptions.containsKey(\"logMessageFormat\")) {\n            if (p6spy.getLogFormat() != null) {\n                System.setProperty(\"p6spy.config.logMessageFormat\", \"com.p6spy.engine.spy.appender.CustomLineFormat\");\n                System.setProperty(\"p6spy.config.customLogMessageFormat\", p6spy.getLogFormat());\n            }\n            else if (p6spy.isMultiline()) {\n                System.setProperty(\"p6spy.config.logMessageFormat\", \"com.p6spy.engine.spy.appender.MultiLineFormat\");\n            }\n        }\n\n\n\n\n위 조건으로 인해 CustomLogMessageFormat이 아닌 MultiLineFormat으로 타고 들어간다.\n\n이후 MultiLineFormat의 포맷을 보면,\n\n\n\npublic class MultiLineFormat implements MessageFormattingStrategy {\n  @Override\n  public String formatMessage(final int connectionId, final String now, final long elapsed, final String category, final String prepared, final String sql, final String url) {\n    return \"#\" + now + \" | took \" + elapsed + \"ms | \" + category + \" | connection \" + connectionId + \"| url \" + url + \"\\n\" + prepared + \"\\n\" + sql +\";\";\n  }\n}\n\n\n\n\n코드를 보면 알겠지만, 원하는 포맷으로 확장하기 위해서 포매터를 직접 구현하여 지정해주면 된다.\n\n\n\n@Configuration\npublic class P6spyConfig {\n    @PostConstruct\n    public void setLogMessageFormat() {\n        P6SpyOptions.getActiveInstance().setLogMessageFormat(P6spyPrettySqlFormatter.class.getName());\n    }\n}\n\n\n\n\n설정 클래스를 생성하여 새로운 LogFormatter를 지정해준 후 구현에 들어간다.\n\n\n\npublic class P6spyPrettySqlFormatter implements MessageFormattingStrategy {\n    @Override\n    public String formatMessage(final int connectionId, final String now, final long elapsed, final String category, final String prepared, final String sql, final String url) {\n        return null;\n    }\n}\n\n\n\n\nMessageFormattingStrategy를 구현한다.\n\n이름 그대로 메시지 포매팅 전략이다.\n\n기본적으로 SingleLineFormat, CustomLineFormat, MultiLineFormat이 구현돼있다.\n\nCustomLineFormat은 이름 때문에 약간 헷갈리는데 사용자가 커스터마이징 할 포매터가 아니고, SingleLineFormat을 약간 더 손본 포매터다.\n\n그러므로 이 녀석을 쓰면 안 되고 직접구현해야 한다.\n\n아래는 CustomLineFormat의 전체 코드이다. 참고 바람.\n\n\n\npublic class CustomLineFormat implements MessageFormattingStrategy {\n\n  private static final MessageFormattingStrategy FALLBACK_FORMATTING_STRATEGY = new SingleLineFormat();\n\n  public static final String CONNECTION_ID = \"%(connectionId)\";\n  public static final String CURRENT_TIME = \"%(currentTime)\";\n  public static final String EXECUTION_TIME = \"%(executionTime)\";\n  public static final String CATEGORY = \"%(category)\";\n  public static final String EFFECTIVE_SQL = \"%(effectiveSql)\";\n  public static final String EFFECTIVE_SQL_SINGLELINE = \"%(effectiveSqlSingleLine)\";\n  public static final String SQL = \"%(sql)\";\n  public static final String SQL_SINGLE_LINE = \"%(sqlSingleLine)\";\n  public static final String URL = \"%(url)\";\n\n  /**\n   * Formats a log message for the logging module\n   *\n   * @param connectionId the id of the connection\n   * @param now          the current ime expressing in milliseconds\n   * @param elapsed      the time in milliseconds that the operation took to complete\n   * @param category     the category of the operation\n   * @param prepared     the SQL statement with all bind variables replaced with actual values\n   * @param sql          the sql statement executed\n   * @param url          the database url where the sql statement executed\n   * @return the formatted log message\n   */\n  @Override\n  public String formatMessage(final int connectionId, final String now, final long elapsed, final String category, final String prepared, final String sql, final String url) {\n\n    String customLogMessageFormat = P6SpyOptions.getActiveInstance().getCustomLogMessageFormat();\n\n    if (customLogMessageFormat == null) {\n      // Someone forgot to configure customLogMessageFormat: fall back to built-in\n      return FALLBACK_FORMATTING_STRATEGY.formatMessage(connectionId, now, elapsed, category, prepared, sql, url);\n    }\n\n    return customLogMessageFormat\n      .replaceAll(Pattern.quote(CONNECTION_ID), Integer.toString(connectionId))\n      .replaceAll(Pattern.quote(CURRENT_TIME), now)\n      .replaceAll(Pattern.quote(EXECUTION_TIME), Long.toString(elapsed))\n      .replaceAll(Pattern.quote(CATEGORY), category)\n      .replaceAll(Pattern.quote(EFFECTIVE_SQL), Matcher.quoteReplacement(prepared))\n      .replaceAll(Pattern.quote(EFFECTIVE_SQL_SINGLELINE), Matcher.quoteReplacement(P6Util.singleLine(prepared)))\n      .replaceAll(Pattern.quote(SQL), Matcher.quoteReplacement(sql))\n      .replaceAll(Pattern.quote(SQL_SINGLE_LINE), Matcher.quoteReplacement(P6Util.singleLine(sql)))\n      .replaceAll(Pattern.quote(URL), url);\n  }\n\n\n\n\n쿼리가 정확히 어떤 경로를 타고 발생했는지 추적하여 기록해줄 것이다.\n\n\n\nStackTraceElement[] stackTrace = new Throwable().getStackTrace();\nfor(int i = 0; i &lt; stackTrace.length; i++) {\n    System.out.println(stackTrace[i]);\n}\n\n\n\n\nThrowable을 호출하여 stack trace를 쭉 뽑아보면\n\n\n\nio.p6spy.formatter.P6spyPrettySqlFormatter.formatMessage(P6spyPrettySqlFormatter.java:15)\ncom.p6spy.engine.spy.appender.Slf4JLogger.logSQL(Slf4JLogger.java:50)\ncom.p6spy.engine.common.P6LogQuery.doLog(P6LogQuery.java:121)\ncom.p6spy.engine.common.P6LogQuery.doLogElapsed(P6LogQuery.java:91)\ncom.p6spy.engine.common.P6LogQuery.logElapsed(P6LogQuery.java:203)\ncom.p6spy.engine.logging.LoggingEventListener.logElapsed(LoggingEventListener.java:107)\ncom.p6spy.engine.logging.LoggingEventListener.onAfterCommit(LoggingEventListener.java:54)\ncom.p6spy.engine.event.CompoundJdbcEventListener.onAfterCommit(CompoundJdbcEventListener.java:285)\ncom.p6spy.engine.wrapper.ConnectionWrapper.commit(ConnectionWrapper.java:172)\norg.hibernate.resource.jdbc.internal.AbstractLogicalConnectionImplementor.commit(AbstractLogicalConnectionImplementor.java:86)\norg.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:282)\norg.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:101)\norg.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:562)\norg.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:743)\norg.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:711)\norg.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:654)\norg.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:407)\norg.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\norg.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\norg.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\norg.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)\norg.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\norg.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)\ncom.sun.proxy.$Proxy88.save(Unknown Source)\nio.p6spy.controller.MainController.run(MainController.java:35)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:566)\norg.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197)\norg.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141)\norg.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106)\norg.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894)\norg.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)\norg.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)\norg.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1063)\norg.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)\norg.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)\norg.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)\njavax.servlet.http.HttpServlet.service(HttpServlet.java:652)\norg.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)\njavax.servlet.http.HttpServlet.service(HttpServlet.java:733)\norg.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)\norg.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)\norg.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)\norg.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)\norg.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)\norg.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)\norg.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)\norg.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)\norg.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)\norg.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)\norg.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)\norg.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)\norg.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)\norg.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)\norg.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)\norg.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)\norg.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)\norg.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)\norg.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)\norg.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)\norg.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)\norg.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)\norg.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)\norg.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357)\norg.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374)\norg.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)\norg.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893)\norg.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1707)\norg.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\norg.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\njava.base/java.lang.Thread.run(Thread.java:834)\n2021-05-28 21:31:46.316  INFO 2820 --- [nio-8080-exec-2] p6spy                                    :\n\n\n\n\nThrowable이 호출된 시점까지의 모든 경로가 출력된다.\n\n여기서 필요한 부분만 추출하면 되는데, 원하는 trace에서 공통점을 찾을 수 있다.\n\n바로 문자열의 시작점이 main 패키지의 경로라는 것이다.\n\n따라서 아래와 같이 코드를 작성해주면 필터링이 된다.\n\n\n\nStackTraceElement[] stackTrace = new Throwable().getStackTrace();\nfor(int i = 0; i &lt; stackTrace.length; i++) {\n        if(stackTrace[i].toString().startsWith(\"io.p6spy\") &amp;&amp; !stackTrace[i].toString().contains(\"P6spyPrettySqlFormatter\")) {\n            System.out.println(stackTrace[i]);\n        }\n    }\n\n\n\n\n여기서 P6spyPrettySqlFormatter의 trace는 필요 없기 때문에 필터링해 준다.\n\n그리고 이 로그를 더 보기 편하게 역순으로 뒤집어줄 것이다.\n\nStack을 활용할 것인데, 추출되는 trace를 순서대로 Stack에 push 하고, 다시 pop 하면 역순으로 뒤집힐 것이다.\n\n\n\n@Override\npublic String formatMessage(final int connectionId, final String now, final long elapsed, final String category, final String prepared, final String sql, final String url) {\n    Stack&lt;String&gt; callStack = new Stack&lt;&gt;();\n    StackTraceElement[] stackTrace = new Throwable().getStackTrace();\n\n    for(int i = 0; i &lt; stackTrace.length; i++) {\n        String trace = stackTrace[i].toString();\n        if(trace.startsWith(\"io.p6spy\") &amp;&amp; !trace.contains(\"P6spyPrettySqlFormatter\")) {\n            callStack.push(trace);\n        }\n    }\n\n    StringBuilder callStackBuilder = new StringBuilder();\n    int order = 1;\n    while(callStack.size() != 0) {\n        callStackBuilder.append(\"\\n\\t\\t\" + (order++) + \". \" + callStack.pop());\n    }\n    return null;\n}\n\n\n\n\n\n\n\n\n쿼리가 발생한 지점과 클릭하면 즉시 이동할 수 있는 포탈(🤗)이 생성됐다.\n\n이제 SQL을 보기 좋게 포매팅할 것이다.\n\nformatMessage()에 이런저런 파라미터가 많이 들어오는데\n\n이에 대한 자세한 내용은 p6spy docs를 보면 하기와 같다.\n\n\n\nParams:\nconnectionId – the id of the connection\nnow – the current ime expressing in milliseconds\nelapsed – the time in milliseconds that the operation took to complete\ncategory – the category of the operation\nprepared – the SQL statement with all bind variables replaced with actual values\nsql – the sql statement executed\nurl – the database url where the sql statement executed\n\n\n\n\n이 파라미터들을 적당히 버무려 준다.\n\n\n\nimport com.p6spy.engine.logging.Category;\nimport com.p6spy.engine.spy.appender.MessageFormattingStrategy;\nimport org.hibernate.engine.jdbc.internal.FormatStyle;\n\nimport java.text.MessageFormat;\nimport java.util.Locale;\nimport java.util.Objects;\nimport java.util.Stack;\nimport java.util.function.Predicate;\n\nimport static java.util.Arrays.stream;\n\npublic class P6spyPrettySqlFormatter implements MessageFormattingStrategy {\n    private static final String NEW_LINE = System.lineSeparator();\n    private static final String P6SPY_FORMATTER = \"P6spyPrettySqlFormatter\";\n    private static final String PACKAGE = \"io.p6spy\";\n    private static final String CREATE = \"create\";\n    private static final String ALTER = \"alter\";\n    private static final String COMMENT = \"comment\";\n\n    @Override\n    public String formatMessage(final int connectionId, final String now, final long elapsed, final String category, final String prepared, final String sql, final String url) {\n        return sqlFormatToUpper(sql, category, getMessage(connectionId, elapsed, getStackBuilder()));\n    }\n\n    private String sqlFormatToUpper(final String sql, final String category, final String message) {\n        if (Objects.isNull(sql.trim()) || sql.trim().isEmpty()) {\n            return \"\";\n        }\n        return new StringBuilder()\n                .append(NEW_LINE)\n                .append(sqlFormatToUpper(sql, category))\n                .append(message)\n                .toString();\n    }\n\n    private String sqlFormatToUpper(final String sql, final String category) {\n        if (isStatementDDL(sql, category)) {\n            return FormatStyle.DDL\n                    .getFormatter()\n                    .format(sql)\n                    .toUpperCase(Locale.ROOT)\n                    .replace(\"+0900\", \"\");\n        }\n        return FormatStyle.BASIC\n                .getFormatter()\n                .format(sql)\n                .toUpperCase(Locale.ROOT)\n                .replace(\"+0900\", \"\");\n    }\n\n    private boolean isStatementDDL(final String sql, final String category) {\n        return isStatement(category) &amp;&amp; isDDL(sql.trim().toLowerCase(Locale.ROOT));\n    }\n\n    private boolean isStatement(final String category) {\n        return Category.STATEMENT.getName().equals(category);\n    }\n\n    private boolean isDDL(final String lowerSql) {\n        return lowerSql.startsWith(CREATE) || lowerSql.startsWith(ALTER) || lowerSql.startsWith(COMMENT);\n    }\n\n    private String getMessage(final int connectionId, final long elapsed, final StringBuilder callStackBuilder) {\n        return new StringBuilder()\n                .append(NEW_LINE)\n                .append(NEW_LINE)\n                .append(\"\\t\").append(String.format(\"Connection ID: %s\", connectionId))\n                .append(NEW_LINE)\n                .append(\"\\t\").append(String.format(\"Execution Time: %s ms\", elapsed))\n                .append(NEW_LINE)\n                .append(NEW_LINE)\n                .append(\"\\t\").append(String.format(\"Call Stack (number 1 is entry point): %s\", callStackBuilder))\n                .append(NEW_LINE)\n                .append(NEW_LINE)\n                .append(\"----------------------------------------------------------------------------------------------------\")\n                .toString();\n    }\n\n    private StringBuilder getStackBuilder() {\n        final Stack&lt;String&gt; callStack = new Stack&lt;&gt;();\n        stream(new Throwable().getStackTrace())\n                .map(StackTraceElement::toString)\n                .filter(isExcludeWords())\n                .forEach(callStack::push);\n\n        int order = 1;\n        final StringBuilder callStackBuilder = new StringBuilder();\n        while (!callStack.empty()) {\n            callStackBuilder.append(MessageFormat.format(\"{0}\\t\\t{1}. {2}\", NEW_LINE, order++, callStack.pop()));\n        }\n        return callStackBuilder;\n    }\n\n    private Predicate&lt;String&gt; isExcludeWords() {\n        return charSequence -&gt; charSequence.startsWith(PACKAGE) &amp;&amp; !charSequence.contains(P6SPY_FORMATTER);\n    }\n}\n\n\n\n\n\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-05-28-p6spy/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "엔티티 클래스 자동 생성하기",
      "date": "2021-05-31 13:55:00 +0000",
      "description": "JPA Entity 원터치로 자동 생성하기\n",
      "content": "\n  1. IntelliJ database tool 연동\n  2. Groovy script 적용\n  3. 엔티티 클래스 생성\n  4. serialVersionUID 생성\n\n\n \n\nJPA를 사용하다 보면 데이터베이스의 테이블 명세를 보면서 엔티티 클래스를 작성하는 일이 자주 생긴다.\n\n심지어 필드가 수십 개 정도 되면 엔티티 클래스를 만드는 일 자체가 무지막지한 노가다가 돼버리기 십상이다.\n\nintelliJ는 이 과정을 지원해준다.\n\n필요한 것은 오로지 groovy script뿐이다.\n\n \n\n1. IntelliJ database tool 연동\n\n\n\n\n\n \n\n자신이 사용하고 있는 데이터베이스를 연동해준다.\n\n \n\n\n\n \n\n접속 정보를 모두 알맞게 입력한 다음 Test Connection을 눌러 통과하면 OK를 눌러준다.\n\n \n\n2. Groovy script 적용\n\n\n\n\n\n \n\n테이블을 우클릭하여 위의 순서대로 클릭해준다.\n\n그러면 Generate POJOs.groovy 라는 파일이 열린다.\n\n \n\n\n\n \n\n기본적인 script가 작성돼있는데,\n\n해당 script를 그대로 사용하면 굉장히 이상한 엔티티 클래스가 만들어지므로\n\n이를 입맛에 맞게 커스터마이징 해야 한다.\n\n필자가 커스터마이징한 script는 MSSQL에 맞추긴 했는데 (회사가 MSSQL을 쓴다 😥)\n\n그래도 대부분의 DB에서도 사용할 수 있을 것이라 여겨진다. (아닐 수도 있다.)\n\n혹시라도 잘 맞지 않는다면 입맛대로 튜닝해서 사용하도록 하시라.\n\n기존의 script를 모두 제거하고 아래의 script를 통째로 붙여 넣고 저장한다(CTRL + S).\n\n \n\n// file: 'Generate POJOs.groovy'\nimport com.intellij.database.model.DasTable\nimport com.intellij.database.model.ObjectKind\nimport com.intellij.database.util.Case\nimport com.intellij.database.util.DasUtil\nimport com.intellij.psi.codeStyle.NameUtil\n\nimport javax.swing.*\n\n/**\n * @author shirohoo* @link https://github.com/shirohoo/create-automation-jpa-entity\n * @param pakageName , primaryKey\n *\n * &lt;pre&gt;\n *\n *     this script's default primary key strategy is @GeneratedValue(strategy = GenerationType.IDENTITY)\n *     and specialized in Microsoft SQL Server\n *     and finally implemented Serializable so recommend that create serial version UID\n *\n *     first. enter your project package name. for example:\n *     &gt;  com.intelliJ.psi\n *\n *     second. enter primary key column name of target database table.\n *     this script is convert input to camel case. for example 1:\n *     &gt;  table primary key column name = MEMBER_ID\n *     &gt;  enter primary key = memberId\n *\n *     example 2:\n *     &gt;  table primary key column name = ID\n *     &gt;  enter primary key = id\n *\n * &lt;/pre&gt;\n */\n\ncolumnType = [\n        (~/(?i)bigint/)            : \"Long\",\n        (~/(?i)int/)               : \"Integer\",\n        (~/(?i)bit/)               : \"Boolean\",\n        (~/(?i)decimal/)           : \"BigDecimal\",\n        (~/(?i)float|double|real/) : \"Double\",\n        (~/(?i)datetime|timestamp/): \"LocalDateTime\",\n        (~/(?i)time/)              : \"LocalTime\",\n        (~/(?i)date/)              : \"LocalDate\",\n        (~/(?i)nvarchar/)          : \"nvarchar\",\n        (~/(?i)varchar/)           : \"varchar\",\n        (~/(?i)char/)              : \"String\"\n]\n\ndef input = {\n    JFrame jframe = new JFrame()\n    String answer = JOptionPane.showInputDialog(jframe, it)\n    jframe.dispose()\n    answer\n}\n\npackageName = input(\"Enter your package name\")\nprimaryKey = input(\"Enter column name of primary key \")\n\nFILES.chooseDirectoryAndSave(\"Choose directory\", \"Choose where to store generated files\") { dir -&gt;\n    SELECTION.filter {\n        it instanceof DasTable &amp;&amp; it.getKind() == ObjectKind.TABLE\n    }.each {\n        generate(it, dir)\n    }\n}\n\ndef generate(table, dir) {\n    def tableName = table.getName()\n    def className = convertFieldName(tableName, true)\n    def fields = categorizeFields(table)\n    new File(dir, className + \".java\").withPrintWriter {\n        out -&gt; generate(out, tableName, className, fields)\n    }\n}\n\ndef generate(out, tableName, className, fields) {\n    out.println \"package $packageName;\"\n    out.println \"\"\n    out.println \"import javax.persistence.*;\"\n    out.println \"import java.io.Serializable;\"\n    out.println \"\"\n    out.println \"@Entity\"\n    out.println \"@ToString @Getter\"\n    out.println \"@NoArgsConstructor(access = AccessLevel.PROTECTED)\"\n    out.println \"@Table(name = \\\"$tableName\\\")\"\n    out.println \"public class $className extends BaseEntity {\"\n    out.println \"\"\n    fields.each() {\n        if (it.annos != \"\") {\n            out.println \" ${it.annos}\"\n        }\n        if (it.name == primaryKey) {\n            out.println \" @Id @GeneratedValue(strategy = GenerationType.IDENTITY)\"\n        }\n        if (it.type == 'nvarchar') {\n            out.println \" @Nationalized\"\n            out.println \" @Column(name = \\\"${it.colName}\\\")\"\n            out.println \" private String ${it.name};\"\n        } else if (it.type == 'varchar') {\n            out.println \" @Column(name = \\\"${it.colName}\\\")\"\n            out.println \" private String ${it.name};\"\n        } else {\n            out.println \" @Column(name = \\\"${it.colName}\\\")\"\n            out.println \" private ${it.type} ${it.name};\"\n        }\n        out.println \"\"\n    }\n    out.println \"}\"\n}\n\ndef categorizeFields(table) {\n    DasUtil.getColumns(table).reduce([]) { fields, col -&gt;\n        def spec = Case.LOWER.apply(col.getDataType().getSpecification())\n        def typeStr = columnType.find {\n            p, t -&gt; p.matcher(spec).find()\n        }.value\n        fields += [[\n                           colName: col.getName(),\n                           name   : convertFieldName(col.getName(), false),\n                           type   : typeStr,\n                           annos  : \"\"]]\n    }\n}\n\ndef convertFieldName(str, capitalize) {\n    def s = NameUtil.splitNameIntoWords(str)\n            .collect {\n                Case.LOWER.apply(it).capitalize()\n            }\n            .join(\"\")\n            .replaceAll(/[^\\p{javaJavaIdentifierPart}[_]]/, \"_\")\n    capitalize || s.length() == 1 ? s : Case.LOWER.apply(s[0]) + s[1..-1]\n}\n\n\n \n\n3. 엔티티 클래스 생성\n\n\n\n\n\n \n\n이제 엔티티 클래스를 생성하고자 하는 테이블을 우클릭하여 위의 순서대로 클릭해준다.\n\n그럼 입력창이 두 번 뜨고, 생성된 엔티티 클래스를 어떤 위치에 저장할 것인지 물을 것이다.\n\n처음은 자신의 프로젝트 패키지명을 입력해주고,\n\n두 번째는 테이블의 기본키 컬럼을 camel case로 변환한 이름을 입력해준다.\n\n일반적으로 데이터베이스의 컬럼명은 대문자나 소문자의 snake case를 이용하는 게 관례이므로,\n\n오로지 이 경우만 완벽하게 고려하여 작성하였다.\n\n만약 다른 방식으로 사용하고 있다면 script를 변경해야 할 수도 있다.\n\n \n\n// 예제1\n테이블명: MEMBER\n기본키 컬럼명: MEMBERID\n입력해야 할 값: memberId\n\n// 예제2\n테이블명: MEMBER\n기본키 컬럼명: ID\n입력해야 할 값: id\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n그러면 이처럼 엔티티 클래스가 생성된다.\n\n이 파일을 열어보면 아래와 같은 형식으로 작성돼있음을 확인할 수 있을 것이다.\n\n \n\n@Entity\n@Getter\n@Builder\n@ToString\n@AllArgsConstructor\n@NoArgsConstructor(access = AccessLevel.PROTECTED)\n@Table(name = \"requestlog\")\npublic class RequestLog implements Serializable {\n @Id @GeneratedValue(strategy = GenerationType.IDENTITY)\n @Column(name = \"id\")\n private Long id;\n\n @Column(name = \"moddate\")\n private LocalDateTime modDate;\n\n @Column(name = \"regdate\")\n private LocalDateTime regDate;\n\n @Column(name = \"clientip\")\n private String clientIp;\n\n @Column(name = \"httpmethod\")\n private String httpMethod;\n\n @Column(name = \"requesturi\")\n private String requestUri;\n}\n\n\n \n\n4. serialVersionUID 생성\n\n\n\nHibernate Docs에서는 모든 엔티티 클래스에 대해 Serializable 인터페이스를 구현하는 걸 권장하고 있다.\n\n대략 엔티티 매핑 방법에 따라 DB에 파라미터를 보낼 때 직렬화하여 보내야 하는 경우가 있기 때문이란다.\n\n이 권고사항을 지키지 않고 상황이 맞아떨어질 경우 간혹 Composite-id class must implement Serializable error 같은걸 만날 수 있긴 한데,\n\n솔직히 아주 가끔 나오는 상황이라 굳이 해당 인터페이스를 구현하지 않아도 된다고 생각하긴 한다.\n\n \n\n그래도 공식문서 권고사항이니 가급적 지키기 위해 goorvy script에 끼워넣어뒀다.\n\nIntelliJ는 직렬화시 필요한 serialVersionUID를 랜덤으로 생성해주는 기능이 있다.\n\n먼저 Shift를 두 번 연속 빠르게 입력한다.\n\n그러면 아래와 같은 창이 뜬다.\n\n \n\n\n\n \n\nSerializable class without 'se\n\n\n \n\n위의 문자열을 붙여 넣어 검색하면 위의 기능이 검색되는데\n\n저 기능을 ON으로 변경해주면 된다.\n\n그리고 엔티티 클래스 이름에 마우스를 갖다 대면…\n\n \n\n\n\n \n\n\n\n \n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-05-31-entity-automatic/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "OneToOne에 대해서",
      "date": "2021-05-31 13:55:00 +0000",
      "description": "JPA 사용 시 만악의 근원, @OneToOne에 대한 고찰\n",
      "content": "\n \n\nJPA를 사용하면서 @OneToOne에 대해 느낀바로는 만악의 근원에 가깝다는 것이다.\n\n여타 매핑과 차별되는 점은 (@ManyToOne, @ManyToMany, @OneToMany)\n\n이 녀석은 기본적으로 EAGER로 동작한다는 것이다.\n\n@ManyToOne도 기본적으로 EAGER로 동작하기는 하는데 내부적인 동작에 큰 차이가 있다.\n\n아래는 @OneToOne의 전체적인 명세이다.\n\n \n\n\n  Specifies a single-valued association to another entity that has one-to-one multiplicity. It is not normally necessary to specify the associated target entity explicitly since it can usually be inferred from the type of the object being referenced. If the relationship is bidirectional, the non-owning side must use the mappedBy element of the OneToOne annotation to specify the relationship field or property of the owning side. The OneToOne annotation may be used within an embeddable class to specify a relationship from the embeddable class to an entity class. If the relationship is bidirectional and the entity containing the embeddable class is on the owning side of the relationship, the non-owning side must use the mappedBy element of the OneToOne annotation to specify the relationship field or property of the embeddable class. The dot (“.”) notation syntax must be used in the mappedBy element to indicate the relationship attribute within the embedded attribute. The value of each identifier used with the dot notation is the name of the respective embedded field or property.\n\n\n \n\nExample 1: One-to-one association that maps a foreign key column\n  \n      // On Customer class:\n  \n      @OneToOne(optional=false)\n      @JoinColumn(\n      \tname=\"CUSTRECID\", unique=true, nullable=false, updatable=false)\n      public CustomerRecord getCustomerRecord() { return customerRecord; }\n  \n      // On CustomerRecord class:\n  \n      @OneToOne(optional=false, mappedBy=\"customerRecord\")\n      public Customer getCustomer() { return customer; }\n  \n  \n      Example 2: One-to-one association that assumes both the source and target share the same primary key values. \n  \n      // On Employee class:\n  \n      @Entity\n      public class Employee {\n      \t@Id Integer id;\n      \n      \t@OneToOne @MapsId\n      \tEmployeeInfo info;\n      \t...\n      }\n  \n      // On EmployeeInfo class:\n  \n      @Entity\n      public class EmployeeInfo {\n      \t@Id Integer id;\n      \t...\n      }\n  \n  \n      Example 3: One-to-one association from an embeddable class to another entity.\n  \n      @Entity\n      public class Employee {\n         @Id int id;\n         @Embedded LocationDetails location;\n         ...\n      }\n  \n      @Embeddable\n      public class LocationDetails {\n         int officeNumber;\n         @OneToOne ParkingSpot parkingSpot;\n         ...\n      }\n  \n      @Entity\n      public class ParkingSpot {\n         @Id int id;\n         String garage;\n         @OneToOne(mappedBy=\"location.parkingSpot\") Employee assignedTo;\n          ... \n      } \n\n\n \n\n@OneToOne인데 양방향 관계인 경우 관계의 주격이 아닌 측에서 mappedBy를 선언하라고 돼있다.\n\n여타 다른 매핑과 크게 다를 게 없어 보이는 설명과 예제들이다.\n\n \n\n@Target({METHOD, FIELD}) \n@Retention(RUNTIME)\n\npublic @interface OneToOne {\n\n    Class targetEntity() default void.class;\n\n    CascadeType[] cascade() default {};\n\n    FetchType fetch() default EAGER;\n\n    boolean optional() default true;\n\n    String mappedBy() default \"\";\n\n    boolean orphanRemoval() default false;\n}\n\n\npublic enum CascadeType { \n\n    / Cascade all operations */\n    ALL, \n\n    / Cascade persist operation */\n    PERSIST, \n\n    / Cascade merge operation */\n    MERGE, \n\n    / Cascade remove operation */\n    REMOVE,\n\n    / Cascade refresh operation */\n    REFRESH,\n\n    /\n     * Cascade detach operation\n     *\n     * @since 2.0\n     * \n     */   \n    DETACH\n}\n\n\n \n\n\n\n \n\nClass targetEntity() default void.class;\n\n(Optional) The entity class that is the target of the association.\nDefaults to the type of the field or property that stores the association\n\n\n \n\n기본값이 필드의 클래스이므로 굳이 적지 않아도 된다.\n\n많이 보이는데 정확히 뭐 하는 건지 몰랐었어서 헷갈렸는데 알고 보니 엔간하면 그냥 생략하는 게 좋은 것 같다.\n\n \n\n@OneToOne(targetEntity = Test.class)\n@JoinColumn(name = \"TESTSEQ\", referencedColumnName = \"TESTSEQ\")\nprivate Test test;\n\n\n@OneToOne\n@JoinColumn(name = \"TESTSEQ\")\nprivate Test test;\n\n\n \n\n위와 아래는 같은 코드이다.\n\n위의 코드는 이미 내부적으로 Default로 선언돼있는 코드를 굳이 또 선언하였다.\n\n아래 코드는 이미 선언돼있는 코드들을 생략하여 작성한 형태이다.\n\n \n\n\n\n \n\nCascadeType[] cascade() default {};\n\n(Optional) The operations that must be cascaded to the target of the association.\nBy default no operations are cascaded.\n\n\n \n\n관계가 맺어져 있는 엔티티에 변경사항이 생길 경우 같이 변경될지의 여부다.\n\n기본값은 사용하지 않음이며, 잘 사용하면 매우 편리한 기능이 될 수 있다.\n\n하지만 제대로 알지 못하고 사용하면 데이터가 통째로 꼬여버리거나,\n\n드랍되거나 하는 대참사가 발생할 수 있으므로 사전에 충분한 학습을 하고 사용해야 한다.\n\n \n\n\n\n \n\nString mappedBy() default \"\";\n\n(Optional) The field that owns the relationship.\nThis element is only specified on the inverse (non-owning) side of the association.\n\n\n \n\n양방향 매핑 시 연관관계의 주인을 명시적으로 선언해준다.\n\n이 옵션을 사용해 관계를 엮어 줄 경우 주격이 아니더라도 엔티티 그래프 탐색이 가능해진다.\n\n다만 CUD(Create, Update, Delete)에 대해서는 주격 엔티티에서만 정상 동작하므로 주의가 필요하다.\n\n주격이 아닌 엔티티에서 선언하면 된다.\n\n \n\n\n\n \n\nboolean orphanRemoval() default false;\n(Optional) Whether to apply the remove operation to entities that have been removed\nfrom the relationship and to cascade the remove operation to those entities.\n\n\n \n\n보통 1:N 관계 테이블 설정할 때 옵션을 추가해준다.\n\nPK(JoinColumn) 값이 null로 변한 자식은 고아 객체라고 한다.\n\n부모 객체와의 연결점을 잃어버렸다는 뜻이다.\n\norphanRemoval 옵션은 바로 이 고아 객체를 자동으로 삭제해주는 역할을 한다.\n\n보통 자식 엔티티의 변경이 있다면 insert &gt; update &gt; update &gt; delete 순으로 이어지는데\n\norphanRemoval 옵션을 적용하면 insert &gt; update &gt; delete 순으로 변경된다.\n\n변경된 자식을 먼저 insert 하고, 기존의 자식을 null로 update 한다.\n\n그리고 기존 null 처리된 자식을 delete 한다.\n\n \n\n\n\n \n\nFetchType fetch() default EAGER;\n\n(Optional) Whether the association should be lazily loaded or must be eagerly fetched. \nThe EAGER strategy is a requirement on the persistence provider runtime that the associated entity must be eagerly fetched. \nThe LAZY strategy is a hint to the persistence provider runtime.\n\n\n\nboolean optional() default true;\n\n(Optional) Whether the association is optional. \nIf set to false then a non-null relationship must always exist.\n\n\n \n\n@OneToOne 사용을 지양해야 하는 가장 큰 원인 두 가지다.\n\n \n\npublic class A {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    @OneToOne\n    @JoinColumn(name = \"bid\")\n    private B b;\n}\n\t\n\npublic class B {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    @OneToOne\n    @JoinColumn(name = \"cid\")\n    private C c;\n}\n\npublic class C {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n}\n\n\n \n\n일대일 단방향이다.\n\nA 엔티티를 findById를 통해 조회하면\n\nA+B가 날아가고, 이후 B+C가 날아간다.\n\n즉 EAGER로 동작하며 동시에 N+1문제가 발생한다.\n\n \n\n원인은 무엇이고 해결은 어떻게 해야 할까?\n\n \n\noptional은 기본적으로 true로 설정돼있다.\n\n이 말인즉슨, 관계를 맺은 엔티티가 nullable 하다는 것인데,\n\n이렇게 되면 하이버네이트는 매핑된 엔티티가 null이었을 경우의 수를 배제할 수 없기 때문에 프록시를 채워줄 수 없다.\n\n그래서 optional=true, @OneToOne 매핑이 돼있는 경우 (=모두 기본값인 경우)\n\n하이버네이트는 위의 가능성으로 인해 일단 쿼리를 날려보지 않고서는(EAGER) null을 채워줘야 할지,\n\n프록시를 채워줘야 할지(LAZY) 알 수 없기 때문에 무조건 쿼리를 한번 날려보게 되며,\n\n이러한 내부 동작 원리로 인해 무조건적으로 EAGER로 동작하고 N+1문제가 발생하는 것이다.\n\n \n\n내부적으로 이런 동작을 하고 세부적으로 파고들면 훨씬 더 복잡하다.\n\n더 파보려다가 머리가 지끈지끈거려서 관뒀다.\n\n아무튼 일반적으로 JPA를 사용하는 모든 개발자가 이런 내부 동작을 자세히 알기 어렵고\n\n이로 인해 N+1문제가 자주 발생하기 때문에 가급적 @OneToOne 사용을 자제해야 한다.\n\n \n\n해결방법은 간단하다.\n\noptional=false로 지정하여 not null. 즉, 엔티티가 무조건 있음을 보장해준다면\n\n하이버네이트는 null일 수도 있는 경우의 수를 완벽히 배제하여 프록시를 채워줄 수 있게 되기 때문에 LAZY설정이 동작하게 된다.\n\n이러면 즉시로딩이 아닌 지연로딩이 되므로 N+1문제 또한 해결할 수 있다.\n\n \n\n@OneToOne(fetch = FetchType.LAZY, optional = false) // Not Null\n\n\n \n\n하지만 모든 걸 다 떠나서 애초에 @OneToOne 관계를 맺는다는 것은 애시당초 DB설계를 잘못했을 가능성이 매우 높다.\n\n굳이 테이블을 분리하여 @OneToOne 관계를 맺어야만 하는 상황인지부터 다시 점검해봐야 한다.\n\n \n\n그래서 개인적으로 @ManyToOne 단방향 관계만 사용하는 것을 선호하며,\n\n그 이상의 복잡한 관계가 생길 경우 DB설계를 검토하거나, Querydsl을 사용하는 편이다.\n\n마지막으로 다른 매핑 방식은 이러한 문제가 발생하지 않는 이유가 뭔고 하니…\n\n \n\n@OneToOne을 제외한 다른 매핑 방식들은 null이건 아니건 Collection을 채워주면 되기 때문에\n\n이 경우 Collection Wrapper라는 것을 이용하게 되어 LAZY가 먹히는 것이며,\n\n@ManyToOne은 전통적인 RDB의 N:1 관계로 역시 값이 항상 존재하기 때문에 LAZY가 먹힌다.\n\n \n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-05-31-one-to-one/"
    },{
      "image": "/assets/img/backend/groovy.png",
      "title": "Hello Groovy!",
      "date": "2021-05-31 22:57:00 +0000",
      "description": "Gradle의 핵심! Groovy를 시작합니다\n",
      "content": "\n\n\n\n  Groovy Tutorial\n\n\n\n\n\n\n\n\n최근 빌드 툴에 대해 관심이 크게 생겨 본격적으로 Gradle 공부를 시작했다.\n\n근데 왜 Maven이 아니고 Gradle이냐?\n\nMaven은 XML 기반으로 돌아가는데 XML은 정적 데이터를 표현하기 위한 마크업 언어로\n\n진짜 무지막지하게 딱딱한 언어다. 애초에 프로그래밍 언어가 아니기도 하고.\n\n그래서 레거시 스프링에서 각종 설정 파일들(XML)을 만지다 보면 막말로 현타가 온다. 😒\n\n원하는 대로 할 수 있는 게 생각보다 많지 않다고 느껴졌었다.\n\nGradle은 기반 언어로 Groovy를 채택했고, 간단한 빌드 스크립트만 작성해준다면\n\n정말이지 별의별 짓거리를 다 할 수 있다. 그야말로 유연함의 끝판왕이라고 볼 수 있는 것 같다.\n\n개발의 전 과정은 언어를 막론하고 대동소이하다.\n\n\n\n\n  소스 코드를 작성한다\n  컴파일러를 이용해 컴파일한다 (한방에 다 컴파일하냐, 줄마다 하냐 차이가 있긴 하다)\n  컴파일된 코드를 테스트한다\n  테스트 결과나 커버리지 측정 결과를 출력한다\n  Javadoc과 같은 문서를 작성한다\n  빌드 - 클래스 파일과 리소스 파일을 패키징하여 압축한다\n  압축한 파일을 테스트 환경이나 스테이징 환경 혹은 운영 환경에 배포한다\n  압축 파일을 저장소에 등록한다\n\n\n\n\nGradle을 제대로 사용하면 여기서 과정 2~8을 모두 다 자동화해버릴 수 있다.\n\n그렇다 보니 점점 개발에 대해 알아갈수록 빌드 툴, 특히 Gradle이 가진 매력이 성큼 다가왔다.\n\n사실상 거의 전 과정에 Gradle이 매우 중요한 위치를 차지하고 있고,\n\n여기에 젠킨스, 카프카 등을 다루는 DevOps영역이 쉽게 연동될 수 있다.\n\n아무튼 Gradle을 입맛대로 써보려고 보니 Groovy와 GroovyDSL를 배워야겠더라.\n\n그래서 문법을 봤는데 자바, 스칼라랑 크게 다를 게 없어서 별거 아니네? 싶더라.\n\n아래는 그루비를 따로 설치하지 않아도 웹에서 사용해볼 수 있는 사이트이다.\n\n\n  https://www.tutorialspoint.com/execute_groovy_online.php\n\n\n\n\n그루비 튜토리얼의 개요를 보면 이렇게 설명하고 있다.\n\n\n  그루비는 정적 타이핑과 동적 타이핑을 모두 지원합니다\n  그루비는 연산자 오버 로딩을 지원합니다\n  그루비는 리스트와 연관 배열을 지원합니다\n  그루비는 정규표현식을 지원합니다\n  그루비는 XML과 HTML 같은 다양한 마크업 언어를 지원합니다\n  그루비의 문법은 자바와 매우 유사하므로 자바 엔지니어라면 쉽게 시작할 수 있습니다\n  그루비는 자바의 라이브러리를 쉽게 사용할 수 있습니다\n  그루비는 java.lang.Object를 상속합니다\n\n\n\n\n오케이! 대충 알겠고 가뿐한 마음으로 3.0.8을 설치하고 Hello Groovy 구현에 들어갔다.\n\n그리고 시작부터 무지막지한 삽질을 했다. 😂\n\n아무리 문법을 봐도 틀린 게 없는데 안되는 것이다.\n\n\n\n그루비 컴파일러에 내부적으로 문제가 있다는거 같은데 진짜 뭔소린가 싶었다.\n\n한참의 구글링 끝에 알고 보니 Groovy는 JDK8과 호환이 된다는 것…. JDK11로 하고 있어서 안됐다. 😭\n\n분명 설치란에는 JDK8+라고 돼있어서 11도 당연히 될 줄 알았는데\n\n이럴거면 대체 왜 튜토리얼 JDK8+라고 써놓은거냐 😡\n\n\n\n// file: 'HelloGroovy.groovy'\nclass Main {\n    static void main(String[] args) {\n        def s = 'Hello Groovy!'\n        println(s)\n    }\n}\n\n\n\n\n항상 Hello World에는 해당 언어의 정수가 들어가 있기 마련이다.\n\n대략 보이는것은 파이썬의 향기가 살짝 나는 듯 하고, (def, 세미콜론 생략)\n\n문법은 자바와 유사한 수준이 아니고 똑같은 수준이라고 봐도 무방할 것 같다.\n\n\n\n\n",
      "categories": ["backend","groovy"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/groovy/2021-05-31-groovy-1/"
    },{
      "image": "/assets/img/backend/groovy.png",
      "title": "Groovy가 Java와 다른 점",
      "date": "2021-05-31 22:57:00 +0000",
      "description": "Groovy와 Java의 차이에 대해 학습합니다\n",
      "content": "\n  1. Default imports\n  2. Multi-methods\n  3. Array initializers\n  4. Package scope visibility\n  5. ARM blocks\n  6. Inner classes    \n      6.1. Static inner classes\n      6.2. Anonymous Inner Classes\n      6.3. Creating Instances of Non-Static Inner Classes\n    \n  \n  7. Lambda expressions and the method reference operator\n  8. GStrings\n  9. String and Character literals\n  10. Primitives and wrappers\n  11. Behaviour of==\n  12. Conversions\n  13. Extra keywords\n\n\n \n\n\n  https://groovy-lang.org/differences.html\n\n\n\n\n1. Default imports\n\n아래의 패키지들은 그루비에서 기본적으로 포함되므로 명시적으로 import 할 필요가 없다.\n\n\n  java.io.*\n  java.lang.*\n  java.math.BigDecimal\n  java.math.BigInteger\n  java.net.*\n  java.util.*\n  groovy.lang.*\n  groovy.util.*\n\n\n\n\n2. Multi-methods\n\n그루비에서는 호출될 메서드가 런타임에 선택된다.\n\n이게 무슨 말이냐면 파라미터 유형에 따라 매번 다른 메서드가 실행될 수 있다는 것이다.\n\n이를 디스패치(Dispatch) 또는 다중 메서드(Multi-methods)라고 부른다.\n\n자바는 정적 타이핑을 하기 때문에 선언된 유형에 따라 실행되는 차이가 있다.\n\nint method(String arg) {\n    return 1;\n}\nint method(Object arg) {\n    return 2;\n}\nObject o = \"Object\";\nint result = method(o);\n\n// 자바\nassertEquals(2, result);.\n\n// 그루비\nassertEquals(1, result);\n\n\n메서드명이 같지만, 파라미터 유형이 다르다.\n\n위는 String이고 아래는 Object이다.\n\n자바는 위의 코드를 실행하면 타입 선언을 Object로 했기 때문에 실제 값이 String 이라도 Object로 선언된 메서드가 실행되어 2가 리턴되는데,\n\n그루비는 타입선언이 Object로 됐지만, 실제 값은 String이기 때문에 String으로 선언된 메서드가 실행되어 1이 리턴된다.\n\n\n\n3. Array initializers\n\n자바에서 배열 초기화는 다음 두 가지 방식을 사용한다.\n\nint[] array = {1, 2, 3};             // Java array initializer shorthand syntax\nint[] array2 = new int[] {4, 5, 6};  // Java array initializer long syntax\n\n\n하지만 그루비에서 대괄호({})는 클로저의 예약어이기 때문에 자바의 배열 리터럴을 사용할 수 없으며,\n\n대신 다음과 같이 그루비만의 배열 리터럴을 사용한다. (자바스크립트에서 자주 보던 건데…?🤣)\n\nint[] array = [1, 2, 3]\n\n\n또한, 그루비 3.0+ 부터는 아래와 같은 문법도 사용 가능하다.\n\n// Groovy 3.0+ supports the Java-style array initialization long syntax\ndef array2 = new int[] {1, 2, 3} \n\n\n\n\n4. Package scope visibility\n\n자바는 접근 제한자를 따로 작성하지 않으면 자바 컴파일러가 접근 제한자를 default, 즉 package-private으로 설정해준다.\n\n// In Java, package-private\nclass Person {\n    String name\n}\n\n\n하지만 그루비는 접근 제한자를 생략하면 public이 돼버리기 때문에\n\npackage-private로 설정하고 싶다면 @PackageScope라는 어노테이션을 달아줘야 한다고 한다.\n\npackage model\nclass Person {\n    @PackageScope String name = \"홍길동\"\n}\n\npackage main\nclass Main {\n    static void main(String[] args) {\n        def person = new Person()\n        println person.getName()\n    }\n}\n\n\n\n\npackage model\nclass Person {\n    String name = \"홍길동\"\n}\n\npackage main\nclass Main {\n    static void main(String[] args) {\n        def person = new Person()\n        println person.getName()\n    }\n}\n\n\n\n\n그루비는 더 간단한 문법을 지원하기 위해 JavaBeans와 유사한 GroovyBeans를 도입했다.\n\nGroovyBeans 내의 프로퍼티들은 public 필드와 유사하므로 getter와 setter를 명시적으로 정의할 필요가 없다.\n\n근데 왜 필드에 직접 접근하는 건 허용되는지 아직은 잘 모르겠다.\n\npackage model\nclass Person {\n    @PackageScope String name = \"홍길동\"\n}\n\npackage main\nclass Main {\n    static void main(String[] args) {\n        def person = new Person()\n        println person.name\n    }\n}\n\n\n\n\n\n\n5. ARM blocks\n\n이건 자바의 try-with-resource 문법을 말하는 것 같다.\n\nPath file = Paths.get(\"/path/to/file\");\nCharset charset = Charset.forName(\"UTF-8\");\ntry (BufferedReader reader = Files.newBufferedReader(file, charset)) {\n    String line;\n    while ((line = reader.readLine()) != null) {\n        System.out.println(line);\n    }\n\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\ntry절에 시스템 자원을 사용하는 코드를 파라미터로 던져주면\n\ntry블록이 끝나는 시점에 자원을 자동으로 반납한다. (단, AutoCloseable 인터페이스가 구현돼있어야 한다.)\n\n그루비는 3.0+부터 이 문법을 지원하며, 또한 클로저를 이용한 문법이 더 효율적일 것이라고 한다.\n\nnew File('/path/to/file').eachLine('UTF-8') {\n   println it\n}\n\n// 자바와 비슷한 문법을 원하는 경우\nnew File('/path/to/file').withReader('UTF-8') { reader -&gt;\n   reader.eachLine {\n       println it\n   }\n}\n\n\n뭔가 코드 추상화 수준이 자바랑 비교해서 말이 안 되는 것 같은데, 일단 그렇다고 하니 넘어간다.\n\n\n\n6. Inner classes\n\n\n  익명 내부 클래스와 중첩 클래스의 구현은 자바의 문법과 매우 유사하지만, 몇 가지 차이점이 있다.\n예를 들어 내부 클래스의 지역변수가 final일 필요는 없다. 왜냐하면 내부 클래스의 바이트 코드가 생성될 때 groovy.lang.Closure의 몇 가지 세부적인 구현 사항 위에 올려서 같이 보내기 때문이다.\n\n\n\n\n6.1. Static inner classes\n\n다음은 정적 내부 클래스의 예이다.\n\nclass A {\n    static class B {}\n}\n\nnew A.B()\n\n\n그루비는 정적 내부 클래스의 지원이 가장 잘 되기 때문에,\n\n내부 클래스를 이용해야 할 일이 생긴다면 가급적 정적 내부 클래스로 만들 것을 권장한다.\n\n\n\n6.2. Anonymous Inner Classes\n\nimport java.util.concurrent.CountDownLatch\nimport java.util.concurrent.TimeUnit\n\nCountDownLatch called = new CountDownLatch(1)\n\nTimer timer = new Timer()\ntimer.schedule(new TimerTask() {\n    void run() {\n        called.countDown()\n    }\n}, 0)\n\nassert called.await(10, TimeUnit.SECONDS)\n\n\n\n\n6.3. Creating Instances of Non-Static Inner Classes\n\n자바에서는 다음과 같은 코드를 수행할 수 있다.\n\npublic class Y {\n    public class X {}\n    public X foo() {\n        return new X();\n    }\n    public static X createX(Y y) {\n        return y.new X();\n    }\n}\n\n\n그루비는 3.0 이전 버전에서 y.new X()와 같은 문법을 지원하지 않기 때문에\n\n아래 new X(y)와 같은 문법을 사용해야 한다.\n\npublic class Y {\n    public class X {}\n    public X foo() {\n        return new X()\n    }\n    public static X createX(Y y) {\n        return new X(y)\n    }\n}\n\n\n하지만 그루비는 인수 없이 한 개의 파라미터로 메서드 호출을 지원하기 때문에, 이 경우 파라미터의 값은 null이 된다.\n\n기본적으로 생성자도 메서드이기 때문에 이 규칙이 적용되며,\n\n예를 들면 개발자가 new X(this) 대신 new X()를 작성할 위험이 있다.\n\n\n\n다만 이게 일반적으로 사용될 수 있는 방법이기도 해서\n\n아직 마땅한 해결책을 찾지 못했기 때문에, 유의해야 한다고 한다.\n\n그리고 그루비는 3.0+부터 비 정적 내부 클래스의 인스턴스를 생성하기 위한 자바식 문법을 지원한다.\n\n\n\n7. Lambda expressions and the method reference operator\n\n자바 8부터 람다 표현식과 메서드 참조를 지원한다.\n\n// Java\nRunnable run = () -&gt; System.out.println(\"Run\");  \nlist.forEach(System.out::println);\n\n\n그루비 3.0+부터 패럿 파서(Parrot parser)에서도 이를 지원한다.\n\n그루비 3.0 이전 버전이라면 클로저를 이용해야 한다고 한다.\n\n여기서 패럿 파서가 뭔지 아직 잘 모르겠다.\n\n이것도 일단 이런 게 있구나 하고 넘어가자.\n\n// Groovy \nRunnable run = { println 'run' }\nlist.each { println it } // or list.each(this.&amp;println)\n\n\n\n\n8. GStrings\n\n그루비는 JDK의 java.lang.String 타입과 GDK의 groovy.lang.GString이라는 두 가지 타입을 갖는다.\n\n홀따옴표로 선언한 문자열은 자바의 String 타입을 이용하며, 쌍따옴표로 선언한 문자열은 GString이 지원된다.\n\nGString은 자바의 String에 비해 기능이 더 많은 듯하다.\n\ndef jString = 'Welcom to Groovy'\nassert jString as java.lang.String\n\ndef language = \"Groovy\"\ndef gString = \"Welcome to $language\"\nassert gString == \"Welcome to Groovy\"\nassert gString as groovy.lang.GString\n\n\n\n\n9. String and Character literals\n\n그루비에서 홀따옴표로 작성된 리터럴은 String으로 사용되며,\n\n쌍따옴표로 작성된 리터럴은 문자열에 보간이 있는지 여부에 따라 String혹은 GString으로 사용된다.\n\n여기서 보간이라 함은 달러($) 표시를 의미하는 듯함.\n\nassert 'c'.getClass()==String\nassert \"c\".getClass()==String\nassert \"c${1}\".getClass() in GString\n\n\n그루비는 char타입 변수에 단일 문자 String을 할당할 때 char타입으로 자동형변환 한다.\n\n그래서 char타입을 인자로 받는 메서드를 호출할 때는 타입 체크를 해야 한다.\n\nchar a='a'\nassert Character.digit(a, 16)==10 : 'But Groovy does boxing'\nassert Character.digit((char) 'a', 16)==10\n\ntry {\n  assert Character.digit('a', 16)==10\n  assert false: 'Need explicit cast'\n} catch(MissingMethodException e) {\n}\n\n\n그루비는 두 가지 스타일의 형변환을 지원한다.\n\n자바에서는 'cx'; 가 말도 안 되는 소리인데\n\n그루비에서는 'cx';가 된다.\n\n왜냐하면 자바에서 홀따옴표는 char타입을 의미하고, 그루비에서 홀따옴표는 자바의 String 타입을 의미하기 때문\n\n그래서 아래와 같은 상황이 나오는 듯하다.\n\n// for single char strings, both are the same\nassert ((char) \"c\").class==Character // C-style\nassert (\"c\" as char).class==Character // Groovy Style\n\n// for multi char strings they are not\ntry {\n  ((char) 'cx') == 'c'\n  assert false: 'will fail - not castable'\n} catch(GroovyCastException e) {\n}\nassert ('cx' as char) == 'c'\nassert 'cx'.asType(char) == 'c'\n\n\nC-Style은 아래 try 블록처럼 쓰면 예외를 뱉지만,\n\n그루비 스타일은 관대하게 동작하여 예외를 뱉는 대신 첫 글자만 취해 char로 형변환 해준다.\n\n\n\n10. Primitives and wrappers\n\n그루비는 모든 것에 Object를 사용하기 때문에(동적 타이핑 때문인 듯),\n\n기본 타입에 대한 참조에도 오토 박싱을 사용한다.\n\n그래서 박싱보다 확장을 우선하는 자바와 다르게 동작한다.\n\n다음은 그 예이다.\n\nint i\nm(i)\n\nvoid m(long l) {           // java\n  println \"in m(long)\"\n}\n\nvoid m(Integer i) {        // groovy\n    println \"in m(Integer)\"\n}\n\n\n위 코드를 자바에서 작성하면 박싱보다 확장을 우선하기 때문에\n\nint 가 long으로 확장되어 void m(long l) 메서드가 호출되지만,\n\n그루비의 경우 박싱이 더 우선되므로 int가 Integer로 오토 박싱 되어 void m(Integer i) 메서드가 호출된다.\n\n\n\n11. Behaviour of==\n\n자바에서 ==는 인스턴스의 동일성을 의미한다.\n\n하지만 그루비에서 ==는 자바의 equals()와 같이 동작하기 때문에\n\n만약 자바의 ==를 그루비에서 사용하고 싶다면 is()나 ===를 사용하면 된다.\n\nclass CompareTest {\n    static void main(String[] args) {\n    \n        // 리터럴 표기법으로 선언할 경우 상수풀에 등록되므로 생성자 이용\n        String s1 = new String(\"안녕하세요\") \n        String s2 = new String(\"안녕하세요\") \n        \n        println(s1==s2) // true\n        println(s1===s2) // false\n        println(s1.is(s2)) // false\n    }\n}\n\n\n\n\n12. Conversions\n\n자바는 여러 가지 형변환을 지원한다.\n\n\n  Y : 묵시적 형변환 가능\n  C : 명시적 형변환 가능\n  T : 형변환이 가능하나 데이터의 손실이 발생하는 경우\n  N : 형변환 불가능\n\n\n\n\n그루비는 다음과 같은 형변환을 지원한다.\n\n\n  Y : 묵시적 형변환 가능\n  D : 동적이거나 명시적 형변환 가능\n  T : 형변환이 가능하나 데이터의 손실이 발생하는 경우\n  B : 박싱, 언박싱 가능\n  N : 형변환 불가능\n\n\n\n\n그루비는 형변환 중 발생하는 데이터의 손실을 판단하는 근거로 Groovy Truth를 이용한다.\n\n\n  Groovy Truth\n\n\n그루비는 숫자를 문자로 변환할 때 Number.intValue()에서 char로 변환하며,\n\nFloat이나 Double에서 변환할 경우 Number.doubleValue()를 사용하여 자바의 BigInteger나 BigDecimal을 생성한다.\n\n이게 아니라면 toString()을 이용하여 생성한다.\n\n다른 동작에 대해서는 java.lang.Number에 정의되어있다.\n\n\n\n13. Extra keywords\n\n그루비는 자바의 예약어 대부분을 예약어로 사용하며, 다음과 같은 예약어를 추가로 사용한다.\n\n\n  as\n  def\n  in\n  trait\n  it // 클로저의 파라미터를 지칭하는 기본 예약어\n\n\n그루비는 자바처럼 엄격하지 않아 다음과 같은 코드가 유효하다.\n\n// 이게 무슨 말도안되는 코드냐..... 이게 된다네요..\nvar var = [def: 1, as: 2, in: 3, trait: 4]\n\n\n따라서 위와 같은 문법이 문법상 허용은 되지만 큰 혼동을 일으킬 수 있으므로 사용을 자제하라고 한다.\n",
      "categories": ["backend","groovy"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/groovy/2021-05-31-groovy-2/"
    },{
      "image": "/assets/img/backend/groovy.png",
      "title": "Groovy 핵심 문법",
      "date": "2021-05-31 22:57:00 +0000",
      "description": "Groovy의 디테일한 핵심 문법에 대해 알아봅니다\n",
      "content": "\n  Groovy 핵심 문법    \n      1. 세미콜론을 생략할 수 있다\n      2. 소괄호를 생략할 수 있다\n      3. System.out을 생략할 수 있다\n      4. GString\n      5. package-private\n      6. Getter와 Setter 자동 작성(코틀린과 똑같다)\n      7. return 생략 가능\n      8. 연산자 오버로딩\n      9. 동일성, 동등성 검사\n      10. Assertions\n      11. Collections\n      12. Closures\n    \n  \n\n\n \n\nGroovy 핵심 문법\n\n그루비는 확실히 자바 엔지니어에게는 매우 쉬운 언어가 맞는 듯하다.\n\n그루비에 대해 공부하고 느낀 것은 그냥 자바라는 그림 위에 점을 하나 찍고 “저는 그루비에요~” 라고 하는 것과 같다.\n\n그래서 생각보다 다룰 내용이 얼마 없다.\n\n기본적인 그루비의 문법은 자바와 거의 같고, 자바의 모든 라이브러리도 사용할 수 있다.\n\n그러면서 동적 타이핑을 지원하기 때문에 자바에 비해 너그럽다.\n\n다만 이는 단점이 될 수도 있다. 컴파일 단계에서 코드의 에러를 잡아준다는 것은 굉장히 좋은 일이기 때문이다.\n\n마지막으로 자바의 대부분의 규칙과, 예약어를 공유하며 추가적인 예약어가 더 있다.\n\n아래의 표를 참고하시면 되겠다.\n\n \n\n\n\n \n\n자바 엔지니어라면 그루비를 공부하면서 고려해야 할 부분은 몇 개 없다.\n\n왜냐하면 진짜 모르겠으면 그냥 자바처럼 써도 어지간하면 다 돌아가기 때문이다.\n\n\n  동적 타이핑으로 인해 특정 부분에서 예상과 다르게 동작할 수 있다\n  연산자 오버로딩이 가능하다\n  클로저를 사용할 수 있다\n\n\n동적 타이핑으로 인한 문제는 내가 동적 타이핑을 좋아하지 않기 때문에 그루비로 코딩을 해도 정적 타이핑으로 작성해서 별 의미가 없었고, 연산자 오버로딩은 굉장히 쓸만한 기능이라고 느껴졌다.\n\n마지막으로 클로저가 그루비의 핵심인 듯하다.\n\n클로저는 변수에 정의한 함수 조각? 작은 함수? 라고 생각하면 될 것 같다.\n\n이는 함수형 프로그래밍에서 사용되는 개념으로 자바의 메서드를 일급시민으로 취급하여 메서드 자체를 파라미터로 넘기는 것과 비슷한 효과를 누린다.\n\n어떻게 보면 자바의 람다식과 크게 다를 게 없는것도 같다.\n\n\n\n1. 세미콜론을 생략할 수 있다\n\n// 세미콜론을 생략할 수 있다(파이썬을 생각하면 된다)\n// 하지만 여러줄의 코드를 한줄에 작성 할 경우엔 생략할 수 없다\nStringBuilder stringBuilder = new StringBuilder()\nString a; String b\n\n\n\n\n2. 소괄호를 생략할 수 있다\n\n// 소괄호를 생략할 수 있다\n// 하지만 추천하지 않는 방법으로 명시적으로 선언해주는게 좋다고 보는 분위기인 듯\n// if문의 구문이 한줄일 경우 중괄호를 생략하는 것과 비슷하다고 생각하면 될 듯\nprint 'a'\nprintln 'hello'.substring(0, 1)\ntestMethod \"hello\"\n\n\n\n\n3. System.out을 생략할 수 있다\n\n// System.out 은 기본적으로 import 돼있으므로 생략 가능\nSystem.out.println('') // java\nprintln('') // groovy\n\nSystem.out.printf('') // java\nprintf('') // groovy\n\nSystem.out.print('') // java\nprint('') // groovy\n\n\n\n\n4. GString\n\n// GString은 GDK에 추가된 여러 기능을 더 사용 할 수 있다\n// 대표적으로 보간기능이 있다 -&gt; \"hi, i\\'m $param\"\n// 쌍따옴표는 GDK GroovyGString\n// 홀따옴표는 JDK String\nString gdk = \"hello\"\nString jdk = 'hello'\n\n\n\n\n5. package-private\n\n/**\n * @PackageScope : 접근제한 package-private으로 설정. 생략하면 public (자바는 default임)\n */\nclass GroovyAccessModifier {\n    @PackageScope String name = \"홍길동\"\n}\n\n\n\n\n6. Getter와 Setter 자동 작성(코틀린과 똑같다)\n\n// Getter와 Setter는 그루비가 자동으로 작성해준다\nstatic class GroovyBeans {\n    String name;\n    int age;\n\n    GroovyBeans(String name, int age) {\n        this.name = name\n        this.age = age\n    }\n\n    // return은 생략해도 되며, return type을 def로 선언하면 동적타이핑이 된다\n    // 이 코드블록의 경우 쌍따옴표를 사용했으므로 GString을 반환 할 것이며, 보간사용 가능\n    def getInformation() {\n        \"name: $this.name | age: $this.age\"\n    }\n}\n    \n    \ndef beans = new GroovyBeans(\"groovy\", 10)\nprintln(beans.getInformation()) // name: groovy | age: 10\n\n\n\n\n7. return 생략 가능\n\nBucket plus(Bucket other) {\n    new Bucket(this.size + other.size) // return 생략 됨\n}\n\n\n\n\n8. 연산자 오버로딩\n\n\n  https://groovy-lang.org/operators.html#Operator-Overloading\n\n\n\n\npackage groovy\n\nclass GroovyOperatorOverloading {\n    static void main(String[] args) {\n        def a = new Bucket(1)\n        def b = new Bucket(2)\n\n        println((a + b).size) // 3\n        println((a - b).size) // -1\n        println((a / b).size) // 0.5\n        println((a * b).size) // 2\n        println((a % b).size) // 1\n    }\n}\n\nclass Bucket {\n    def size\n\n    Bucket(def size) {\n        this.size = size\n    }\n\n    // Operator Overloading\n    // https://groovy-lang.org/operators.html#Operator-Overloading\n    Bucket plus(Bucket other) {\n        new Bucket(this.size + other.size)\n    }\n\n    Bucket minus(Bucket other) {\n        new Bucket(this.size - other.size)\n    }\n\n    Bucket div(Bucket other) {\n        new Bucket(this.size / other.size)\n    }\n\n    Bucket multiply(Bucket other) {\n        new Bucket(this.size * other.size)\n    }\n\n    Bucket mod(Bucket other) {\n        new Bucket(this.size % other.size)\n    }\n}\n\n\n\n\n\n9. 동일성, 동등성 검사\n\n/**\n * 자바의 ==는 동일성비교, equlas()는 동등성 비교\n * 그루비는 ===혹은 is()가 동일성 비교, ==가 동등성 비교\n */\nclass GroovyCompare {\n    static void main(String[] args) {\n        String s1 = new String(\"안녕하세요\") // 생성자를 사용했으므로 서로 다른 인스턴스\n        String s2 = new String(\"안녕하세요\")\n        println(s1==s2) // true\n        println(s1===s2) // false\n        println(s1.is(s2)) // false\n    }\n}\n\n\n\n\n10. Assertions\n\n코드의 유효성을 검증하는 데 사용한다.\n\n그루비의 assertions는 매우 강력하다.\n\nclass GroovyAssertions {\n    static void main(String[] args) {\n        // GroovyAssertions\n        int i = 1\n        assert (i == 1) // int i = 1 이므로 true\n        assert ['a'] // List가 비어있지 않으므로 true\n        assert ['a': 1] // Map이 비어있지 않으므로 true\n        assert 'a' // String이 비어있지 않으므로 true\n    }\n}\n\n\n\n\n\n11. Collections\n\nclass GroovyCollections {\n\n    // 리터럴 표기법 사용 시 중괄호({})는 Groovy에서 클로저의 예약어이므로 대괄호([])사용\n    static void main(String[] args) {\n        //-------------------------------------- List --------------------------------------//\n        List&lt;Integer&gt; l1 = [1, 2, 3, 4] // Java Collection 사용 정적 타이핑\n        def l2 = [1, 2, 3, 4] // def 예약어를 사용한 동적 타이핑 + 리터럴 표기법\n        def l3 = ['Hi', 1, true, File] // 여러 타입의 요소를 같은 List에 포함시킬수도 있다\n\n        def list = []  // 빈 List 선언\n        list += [1, 2, 3] // List에 요소 추가\n        assert list == [1, 2, 3] &amp;&amp; list.size == 3 // 제대로 추가됐는지 검증\n\n        list &lt;&lt; 4 &lt;&lt; 5 // List에 다음과 같은 방법으로도 요소를 추가할 수 있다 (C와 유사하다)\n        assert list == [1, 2, 3, 4, 5]\n\n        list.add(6) // List에 다음과 같은 방법으로도 요소를 추가할 수 있다 (Java의 방식)\n        assert list == [1, 2, 3, 4, 5, 6]\n\n        assert list[0] == 1 // Java 원시 배열: 인덱스를 직접 입력하여 요소를 꺼내는 방법\n        assert list.get(0) == 1 // Java Collection: 인덱스를 직접 입력하여 요소를 꺼내는 방법\n        assert list.getAt(1) == 2 // Groovy Collection: 인덱스를 직접 입력하여 요소를 꺼내는 방법\n        assert list[-1] == 6 // 인덱스를 음수로 줄 경우 역순으로 검색한다. 이 경우 인덱스는 0이 아닌 1부터 시작\n        assert list[-3] == 4 // 인덱스를 음수로 줄 경우 역순으로 검색한다. 이 경우 인덱스는 0이 아닌 1부터 시작\n\n        list.putAt(1, 1) // 1번 인덱스(2)에 1을 덮어씌움\n        assert list == [1, 1, 3, 4, 5, 6]\n        assert list.set(1, 2) == 1 // 1번 인덱스(1)에 2를 덮어씌움. set메서드는 덮어씌워져 제거된 값을 리턴한다\n        assert list == [1, 2, 3, 4, 5, 6]\n\n        // Groovy는 stream 사용 시 별다른 이름을 지정하지 않으면 기본적으로 it을 사용한다\n        list.each {\n            // 모든 원소를 순차적으로 출력\n            println \"$it\"\n        }\n        list.eachWithIndex {\n                // 모든 원소와 인덱스를 출력\n            it, index -&gt; println \"item: $it, index: $index\"\n        }\n\n        list -= 1 // 원소를 제거. 일치하는 원소가 여러개 있을 경우 모두 제거된다\n        assert list == [2, 3, 4, 5, 6]\n        list = list.minus([2, 3, 4]) // 여러 원소를 제거\n        assert list == [5, 6]\n\n        //-------------------------------------- Map --------------------------------------//\n        def map = ['name': 'shirohoo', 'hobby': 'develop'] // Map 선언\n        assert map.size() == 2 // Map 사이즈 검증\n\n        map += ['skills': ['java', 'groovy']] // Map에 List를 원소로 추가\n        assert map == ['name': 'shirohoo', 'hobby': 'develop', 'skills': ['java', 'groovy']]\n\n        map['age'] = 28 // 배열에 key:age로 새로운 값 추가\n        assert map == ['name': 'shirohoo', 'hobby': 'develop', 'skills': ['java', 'groovy'], 'age': 28]\n\n        // 값을 확인하는 여러가지 방법들\n        assert map.name == 'shirohoo'\n        assert map['name'] == 'shirohoo'\n        assert map.get('name') == 'shirohoo'\n        assert map.getAt('name') == 'shirohoo'\n        assert map.skills[0] == 'java'\n\n        map.each {\n                // 모든 원소를 순차적으로 출력\n            it -&gt; println it.key + \":\" + it.value\n        }\n\n        map.eachWithIndex {\n                // 모든 원소와 인덱스를 출력\n            it, index -&gt; println \"item $index - \" + it.key + \":\" + it.value\n        }\n\n        //-------------------------------------- range --------------------------------------//\n        def range = 1..10 // 1~10까지 순차적으로 선언\n        assert range == [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n        range = 'a'..'c' // a~b까지 선언\n        assert range == ['a', 'b', 'c']\n\n        range = 1..&lt;8 // 1~7까지 선언\n        assert range == [1, 2, 3, 4, 5, 6, 7]\n\n        (1..5).each {\n            // 1~5까지 선언, 출력\n            println it\n        }\n\n        assert [*3..10] == [3, 4, 5, 6, 7, 8, 9, 10] // *이 앞에 추가되면 실제로 구현함\n        assert [5, 7, *2..4] == [5, 7, 2, 3, 4] // List [5,7]에 2~4까지를 순차적으로 추가함\n    }\n}\n\n\n\n\n12. Closures\n\n\n  http://www.groovy-lang.org/closures.html\n\n\n클로저는 함수에 함수를 넘기는 용도로 사용된다.\n\n자바 메서드의 상위호환 버전이라고 봐도 될 것 같다.\n\n함수에 넘겨진 클로저는 부모 함수의 상태를 가지고 동작할 수 있다.\n\n대부분의 함수형 언어에 있는 기능이기도 하다.\n\nclass GroovyClosure {\n\n    // 클로저 정의\n    def closure = { key, value -&gt;\n        {\n            println(key)\n            println(value)\n            [\"$key\" : \"$value\"]\n        }\n    }\n}\n\nclass Main {\n    static void main(String[] args) {\n        def groovyClosure = new GroovyClosure()\n\n        // 호출 방법 1: 클로저변수만 사용\n        println('방법 1')\n        println(groovyClosure.closure('groovy', 'closure'))\n\n        // 호출 방법 2: 클로저변수.call\n        println('방법 2')\n        println(groovyClosure.closure.call('groovy', 'closure'))\n    }\n}\n\n\n\n\n",
      "categories": ["backend","groovy"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/groovy/2021-05-31-groovy-3/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "Windows10 Powershell 테마 적용하기",
      "date": "2021-06-02 20:57:00 +0000",
      "description": "Windows10 Powershell\n",
      "content": "\n  📕 참고\n  💡 적용\n\n\n\n\n📕 참고\n\n\n\n\n  https://docs.microsoft.com/ko-kr/windows/terminal/tutorials/powerline-setup\n\n\n\n\n💡 적용\n\n\n\nMicrosoft Stroe -&gt; Windows Terminal 설치\n\n\n\n\n\n\n\nWindows Terminal을 관리자 권한으로 실행하여 Powershell을 연다.\n\n\n\n\n\n\n\n\n\n\n\n아래 명령어를 순서대로 입력하며,\n\n뭘 묻는 텍스트가 나타나면 Y를 입력 후 엔터를 친다.\n\n\n\nInstall-Module posh-git -Scope CurrentUser\nInstall-Module oh-my-posh -Scope CurrentUser\n\n\n\n\n\n\n\n\n아래 명령어를 입력해준다\n\n\n\nnotepad $profile\n\n\n\n\n\n\n\n\n예를 선택\n\n\n\n\n\n\n\n아래의 내용을 입력 후 저장하고 닫는다.\n\n\n\n$env:LC_ALL='C.UTF-8'\n\nImport-Module posh-git\nImport-Module oh-my-posh\nSet-PoshPrompt -Theme powerline\n\n\n\n\n새로운 Powershell을 연다.\n\n\n\n\n\n\n\n\n\n\n\n에러가 발생할 텐데, 아래의 명령어를 입력해주고 다시 새로운 Powershell을 연다.\n\n\n\nSet-ExecutionPolicy RemoteSigned\n\n\n\n\n\n\n\n\n\n\n\n\n테마가 폴더나, 브랜치 등의 이모티콘을 사용하는데\n\n대부분의 폰트가 이러한 이모티콘을 지원하지 않으므로\n\n특수한 폰트를 설치하고 설정해야 한다.\n\n\n\n\n  https://www.nerdfonts.com/font-downloads\n\n\n\n\n사이트에 접속하여 마음에 드는 폰트를 다운로드한 후 설치해준다.\n\n필자는 CaskaydiaCove Nerd를 다운로드하여서 설치했다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n만약 다른 테마를 적용하고 싶다면, 아래의 사이트에서 마음에 드는 테마를 고른다.\n\n\n\n\n  https://ohmyposh.dev/docs/themes/\n\n\n\n\n테마의 이름을 복사한 후\n\n\n\nnotepad $profile\n\n\n\n\n\n\n\n\n테마의 이름을 바꿔주면 된다.\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-06-02-windows-powershell/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "Windows10에서 리눅스 명령어 사용하기",
      "date": "2021-06-02 23:42:00 +0000",
      "description": "Windows10 Linux Command\n",
      "content": "\n  1. ll 사용하기\n  2. ls 사용하기\n\n\n\n\n1. ll 사용하기\n\n\n\nC:\\Windows\\System32에 진입한 후 ll.bat을 만들고, 내용에 dir/w를 입력하고 저장한다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. ls 사용하기\n\n\n\n아래의 명령어를 입력한다\n\ndoskey ls = dir\n\n\n\n\n\n\n\n\n\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-06-02-windows-linux-command/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "Windows Terminal 항상 관리자 권한으로 실행하기",
      "date": "2021-06-03 00:03:00 +0000",
      "description": "Windows10 Administrator\n",
      "content": "\n\n\n바탕화면에 바로가기 생성\n\n\n\n\n\n\n\n%LocalAppData%\\Microsoft\\WindowsApps\\wt.exe\n\n\n\n\n\n\n\n\n\n\n\n\n생성된 바로가기 우클릭 - 속성 - 고급 - 관리자 권한으로 실행\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-06-03-windows-admin/"
    },{
      "image": "/assets/img/frontend/vue/vue.png",
      "title": "Vue.js 톺아보기",
      "date": "2021-06-06 14:16:00 +0000",
      "description": "Vue.js에 대한 개념을 잡아봅시다\n",
      "content": "\n  📕 Vue.js, Vue-CLI    \n      😎 Reactivity\n      😎 Instance\n      😎 Component\n      😎 Component Communication\n      😎 Axios - HTTP Library\n      😎 Template syntax\n      😎 Vue-CLI\n      😎 Single file component\n    \n  \n\n\n📕 Vue.js, Vue-CLI\n\n\n  Reactivity\n  Instance\n  Component\n  Component Communication\n    \n      props\n      event-emit\n    \n  \n  Axios - HTTP Library\n  Template syntax\n    \n      data-binding\n      vue-directive\n    \n  \n  Vue-CLI\n  Single file component\n\n\n\n\n😎 Reactivity\n\nVue.js가 추구하는 핵심 가치이다.\n\nVue.js의 대부분의 기능이 이 가치를 위해 존재한다고 해도 과언이 아니다.\n\n데이터를 바인딩하고, 데이터의 변화를 감지하면 화면에 즉시 반영하는 기법을 말한다.\n\n\n\n😎 Instance\n\nVue.js를 사용하기 위해서는 Vue 인스턴스가 반드시 필요하며, 생성자를 사용한다.\n\n이 인스턴스에는 여러가지 메서드가 정의되어 있다.\n\nnew Vue({\n  el        : '#app',\n  data      : {},\n  components: {},\n  mounted   : {},\n  computed  : {},\n  methods   : {},\n  ...\n});\n\n\n\n\n😎 Component\n\n컴포넌트(Component)는 모던 프론트 프레임워크의 트렌드이다.\n\nHTML을 컴포넌트 단위로 작성하여 재사용성을 키워 최대한 경제적으로 화면을 구성하는 것이 목적이다.\n\n이때 전역 컴포넌트(Global Component)와 지역 컴포넌트(Local Component)로 나뉘며\n\n전역 컴포넌트는 말 그대로 scope가 global인 컴포넌트를 말하며,\n\n지역 컴포넌트는 각 컴포넌트의 Vue 인스턴스의 components 블록에 정의된 컴포넌트를 말한다.\n\n지역 컴포넌트는 지역 컴포넌트가 정의된 컴포넌트에서만 생명주기를 갖는다.\n\n일반적으로 대부분의 오픈소스 라이브러리가 전역 컴포넌트의 형태로 되어있고,\n\n일반적인 개발자가전역 컴포넌트를 직접 작성하는 경우는 드물며 지역 컴포넌트를 아주 많이 사용하게 된다.\n\n// 전역 컴포넌트\nVue.component('app-header', {\n  template: '&lt;h1&gt;Header Component&lt;/h1&gt;'\n});\n\n// 지역 컴포넌트\nlet appHeader = {\n  template: '&lt;h1&gt;Header Component&lt;/h1&gt;'\n}\n\nnew Vue({\n  components: {\n    'app-header': appHeader\n  }\n})\n\n\n\n\n😎 Component Communication\n\n\n\nComponent Communication은 데이터의 흐름을 조금이라도 더 쉽게 파악하기 위한 구조이다.\n\n기본적인 구조는 하기와 같다\n\n상위 컴포넌트에서 하위 컴포넌트로는 props(data)가 내려가며,\n\n하위 컴포넌트에서 상위 컴포넌트로는 event($emit)가 올라간다\n\n\n\n😎 Axios - HTTP Library\n\nAxios는 Vue.js의 공식적인 HTTP Library이다.\n\npromise기반으로 동작하며, CDN방식을 이용하여 라이브러리를 사용하거나 NPM으로 직접 설치하는 방법으로 나뉜다.\n\n// CDN 방식\n&lt;script src=\"https://unpkg.com/axios/dist/axios.min.js\"&gt;&lt;/script&gt;\n&lt;script&gt;\n  new Vue({\n   el: '#app',\n   methods: {\n     fetch: function() {\n          axios.get('https://jsonplaceholder.typicode.com/users/')\n               .then(function(response) {\n                 console.log(response); // then: 통신 성공시 실행 될 블록\n               })\n               .catch(function(error) {\n                 console.log(error); // catch: 통신 실패시 실행 될 블록\n               });\n        }\n    }\n  })\n&lt;/script&gt;\n\n\n// NPM 방식\ncd {vue-project-path}\n\nnpm i axios\n\n\nimport axios from 'axios';\nnew Vue({\n  el: '#app',\n  methods: {\n    fetch: function() {\n      axios.get('https://jsonplaceholder.typicode.com/users/')\n           .then(function(response) {\n             console.log(response); // then: 통신 성공시 실행 될 블록\n           })\n           .catch(function(error) {\n             console.log(error); // catch: 통신 실패시 실행 될 블록\n           });\n    }\n  }\n})\n\n\n\n\n😎 Template syntax\n\ndata-binding은 Vue 인스턴스의 데이터와 HTML을 동기화시키는 작업이다.\n\n아래의 코드를 보면 Vue 인스턴스와 &lt;div id='app'&gt; 가 연결돼있고,\n\nVue 인스턴스의 data - message가 `` 라는 문법으로 바인딩이 되어있다.\n\n이 상태에서 message의 값이 변경되면 HTML에 실시간으로 변경된 값이 표시되게 된다.\n\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"ko\"&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n      &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n        &lt;title&gt;Title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=\"app\"&gt;\n      \n    &lt;/div&gt;\n\n    &lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;\n    &lt;script&gt;\n      new Vue({\n      el        : '#app',\n      data      : {\n      message: 'hello'\n    },\n    });\n    &lt;/script&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\n\n\nvue-directive v-로 시작하는 Vue.js의 문법을 총칭한다.\n\n예를 들자면 v-on, v-if-else, v-bind,v-model,v-show 등을 말하며,\n\n위의 data-binding과 결합하여 강력한 Reactivity를 보여준다.\n\n\n\n😎 Vue-CLI\n\nCLI는 Command-line interface의 약자다.\n\nVue.js를 NPM과 Webpack을 사용하여 명령줄 한두줄만으로 쉽게 사용할 수 있게 해주는 고급기술이다.\n\n프로젝트를 자동으로 생성해주지만, 프로젝트의 구조가 정형화돼있으므로 이에 대한 학습이 필요하다.\n\n프로젝트를 생성하기 위해서는 Node.js와 NPM이 설치돼있어야 하며\n\n작성자는 아래와 같은 버전을 사용했다.\n\nnpm -v\n6.14.13\n\nnode -v\nv14.17.0\n\nvue --version\n@vue/cli 4.5.13\n\n\nNode.js와 NPM이 설치돼있다면 Vue-CLI를 설치하기 위해 아래의 명령어를 입력한다.\n\n-g는 OS에 Vue-CLI를 전역으로 설치하겠다는 의미이다.\n\nnpm install -g @vue/cli\n\n\n이후 Vue.js 프로젝트를 생성하기 위한 명령어는 하기와 같다.\n\ncd {project를 생성할 위치}\n\nvue create {project-name}\n\n\n프로젝트가 생성되면 터미널에 적혀있는 대로\n\ncd {project-name}\n\nnpm run serve\n\n\n를 순차적으로 입력하면 Vue.js 서버가 뜬다.\n\n생성되는 프로젝트의 구조는 하기와 같다.\n\nProject\n├─ README.md\n├─ .gitignore\n├─ babel.config.js\n├─ package.json\n├─ package-lock.json\n├─ public\n│  ├─ favicon.ico\n│  └─ index.html\n└─ src\n   ├─ App.vue\n   ├─ main.js\n   ├─ components\n   └─ assets\n      └─ logo.png\n\n\n\n\n😎 Single file component\n\nVue-CLI를 이용하여 만든 프로젝트에는 .vue확장자를 가진 파일들이 있다.\n\n이를 싱글파일 컴포넌트(Single file component)라 부르며,\n\n이 싱글파일 컴포넌트들을 Webpack이 잘 엮어내어 사용자들에게 화면을 보여주는 것이다.\n\n공부를 더 해봐야 겠지만 Webpack은 Gradle과 비슷한 역할을 한다고 생각되며\n\n바벨(babel)이라고 부르는 것은 javascript가 실행되는 다양한 환경에서\n\n각 시스템들의 호환성을 보장해주기 위한 indirection으로\n\nJava의 JVM과 비슷한 역할을 한다고 이해가 됐다.\n",
      "categories": ["frontend","vue"],
      "tags": [],
      
      "collection": "posts",
      "url": "/frontend/vue/2021-06-06-vue-01/"
    },{
      "image": "/assets/img/spring/spring-batch/spring-batch-logo.png",
      "title": "Spring Batch 개요",
      "date": "2021-06-14 21:19:00 +0000",
      "description": "Spring Batch에 대한 기본 개념\n",
      "content": "\n  🚀 Batch ?\n  🚀 Spring-Batch ?\n  🏁 Spring-Batch 설정    \n      🍔 build.gradle 설정\n      🍔 SpringBootApplication 설정\n      🍔 application.yaml 설정\n      🍔 Database 설정\n    \n  \n  🚀 Spring-Batch 구조    \n      🍀 Metadata\n      🍀 Job\n      🍀 Step\n    \n  \n  🚀 JobParameters\n  🚀 DataSharing\n  🚀 Bean Scope &amp; Lifecycle\n  🚀 Database Cursor &amp; Paging    \n      😎 Cursor\n      😎 Paging\n    \n  \n\n\n🚀 Batch ?\n\n  큰 단위의 작업을 일괄 처리, 현업에서는 이를 배치작업, 배치성 작업이라고 부른다\n    \n      대용량 데이터 계산에 주로 사용(ex&gt; 매출 집계 등)\n    \n  \n  비실시간성 작업이며 규칙적인 주기(스케쥴러, 크론 등을 활용)로 실행 됨\n  트래픽이 뜸한 새벽시간대에 많이 실행되므로 서버자원을 최대로 활용\n\n\n🚀 Spring-Batch ?\n\n\n\n\n  Batch 처리를 쉽게 하기 위한 Spring 생태계의 Framework\n  Spring Triangle (DI, AOP, PSA) 활용 가능\n  다양한 사용자를 고려해 설계되어 확장성과 사용성이 매우 좋다\n  Job과 Step으로 나뉘며 Step은 Tasklet과 Chunk로 나뉨\n  간단한 작업(Tasklet), 대규모 작업(Chunk)\n\n\n🏁 Spring-Batch 설정\n\n🍔 build.gradle 설정\nimplementation 'org.springframework.boot:spring-boot-starter-batch'\n\n\n🍔 SpringBootApplication 설정\n\n@EnableBatchProcessing // 필수: Spring-Batch의 기능을 활성화\n@SpringBootApplication\npublic class SpringBatchApplication {\n    \n    public static void main(String[] args) {\n        SpringApplication.run(SpringBatchApplication.class, args);\n    }\n    \n}\n\n\n\n🍔 application.yaml 설정\n\nspring:\n  batch:\n    job:\n      ## 실행옵션에 job name이 없을 경우 아무런 job도 실행하지 않음 (안전장치)\n      ## ex) --job.name=itemReaderJob\n      names: ${job.name:NONE}\n\n    ## always - Spring-Batch DDL이 DB에 항상 반영 // 개발환경 추천\n    ## embedded - Embedded DB인 경우에만 Spring-Batch DDL이 DB에 반영 // 개발환경 추천\n    ## never - Spring-Batch DDL이 DB에 절대 반영되지 않음 (직접 SQL을 관리) // 운영환경 추천\n    \n    initialize-schema: embedded (cf.default)\n\n\n🍔 Database 설정\n\n\n\nSpring-Batch는 DB에 Metadata table을 생성하여, 이 데이터들을 기반으로 동작하므로 BatchApplication과 연결된 DB에 Spring-Batch DDL을 적용해줘야 한다\n\n이 DDL은 Spring-Batch Core에 포함돼있으므로, 자신이 사용하는 DB에 맞는 sql파일을 적용하면 된다\n\npath: spring-batch-core/org.springframework/batch/core/*\n\n\n\n\n\n\n\n\n🚀 Spring-Batch 구조\n\n\n\n🍀 Metadata\n\n  BATCH_JOB_INSTANCE\n    \n      Job이 실행되며 생성되는 최상위 계층의 테이블\n      job_name과 job_key를 기준으로 하나의 row가 생성되며, 같은 job_name과 job_key가 저장될 수 없다 (Unique key)\n      job_key는 BATCH_JOB_EXECUTION_PARAMS에 저장되는 Parameter를 나열해 암호화해 저장한다\n    \n  \n  BATCH_JOB_EXECUTION\n    \n      Job이 실행되는 동안 시작/종료 시간, job 상태 등을 관리한다\n    \n  \n  BATCH_JOB_EXECUTION_PARAMS\n    \n      Job을 실행하기 위해 주입된 parameter 정보 저장한다\n    \n  \n  BATCH_JOB_EXECUTION_CONTEXT\n    \n      Job이 실행되며 공유해야할 데이터를  직렬화해 저장한다\n    \n  \n  BATCH_STEP_EXECUTION\n    \n      Step이 실행되는 동안 필요한 데이터 또는 실행된 결과 저장한다\n    \n  \n  BATCH_STEP_EXECUTION_CONTEXT\n    \n      Step이 실행되며 공유해야할 데이터를 직렬화해 저장한다\n    \n  \n\n\n\n\n🍀 Job\n\n  Job은 배치의 실행 단위(Application)를 의미함\n  jar 실행 시 Job Name을 실행옵션으로 주면 해당 Job만 실행 할 수 있다\n  Job은 JobLauncher에 의해 실행 됨\n  Job은 N개의 Step을 순차적으로 실행할 수 있고, 전체적인 흐름제어를 한다\n\n\n\n\n\n  JobInstance: BATCH_JOB_INSTANCE 테이블과 매핑\n    \n      새로운 JobInstance의 생성 기준은 JobParameters의 중복 여부이다\n      다른 JobParameters로 Job이 실행되면 새로운 JobInstance가 생성된다\n      같은 JobParameters Job이 실행되면, 이미 생성된 JobInstance 실행된다\n    \n  \n  JobExecution: BATCH_JOB_EXECUTION 테이블과 매핑\n    \n      JobExecution은 항상 새로 생성된다\n    \n  \n  JobParameters: BATCH_JOB_EXECUTION_PARAMS 테이블과 매핑\n  ExecutionContext: BATCH_JOB_EXECUTION_CONTEXT 테이블과 매핑\n  StepExecution: BATCH_STEP_EXECUTION 테이블과 매핑\n  ExecutionContext: BATCH_STEP_EXECUTION_CONTEXT 테이블과 매핑\n\n\n\n\n🍀 Step\n\n  Step은 Job의 세부 실행 단위이며, 하나의 Job에 여러개가 등록 될 수 있다\n  Step은 2가지 종류로 나눌 수 있다\n    \n      Tasklet: 하나의 작업을 그대로 진행(주로 소규모 작업)\n        \n          주로 소규모 작업에 사용하며, 이 경우Chunk보다 쉽게 사용할 수 있다\n          반대로 대량처리에 Chunk 대신 Tasklet을 사용한다면 매우 복잡해진다\n        \n      \n      Chunk: 하나의 작업을 여러번 쪼개서 진행(주로 대규모 작업), 3가지 작업을 거친다\n        \n          대규모 작업에 사용 할 경우 Tasklet보다 쉽게 구현 할 수 있다\n          예를 들면 DB 데이터 10,000개의 row를 처리해야 할 경우 1,000개씩 10번 나누어 처리한다\n          ItemReader: 배치 아이템을 읽는다. 더이상 읽을 아이템이 없다면 Job을 종료한다\n          ItemProcessor: 읽은 아이템에 특정한 가공을 거친다. optional이므로 생략가능하다\n          ItemWriter: 아이템을 최종 처리한다. 예를들면 DB에 DML을 commit하거나, 파일을 작성한다\n        \n      \n    \n  \n\n\n\n\n🚀 JobParameters\n\n\n  Spring-Batch가 배치작업에 필요한 데이터를 외부에서 주입받을 수 있는변수\n  즉, 배치 애플리케이션 외부와의 통로이다 (외부 &gt; 내부 단방향)\n  Spring-Expression-Language와 JobExecution 객체의 getJobParameters 메서드를 통해 접근할 수 있다\n\n\n// Spring-Expression-Language\n@Value(\"#{jobParameters[key]}\") \n\n// JobExecution.getJobParameters();\nString param = jobParameters.getString(key, value);\n\n\n\n\n🚀 DataSharing\n\n\n  Spring-Batch에는 Metadata 와 매핑되는 ExecutionContext 객체가 존재\n  ExecutionContext 객체를 상속받은 JobExecution, StepExecution 객체가 존재\n  JobExecution은 해당 Job의 모든 Step이 접근하여 데이터를 얻을 수 있다\n  StepExecution은 Step 하나에 종속적이다\n\n\n@Slf4j\n@Configuration\n@RequiredArgsConstructor\npublic class SharedJobConfiguration {\n    private final JobBuilderFactory jobBuilderFactory;\n    private final StepBuilderFactory stepBuilderFactory;\n    \n    /**\n     * &lt;pre&gt;\n     * 각 Step끼리는 데이터 공유가 되지 않으므로\n     * emptyStepKey이 출력되는게 정상\n     * StepExecution은 Step하나에 종속적이며,\n     * JobExecution은 Job전체에서 공유할 수 있다\n     *\n     * JobExecution = 전역\n     * StepExecution = 지역\n     * &lt;/pre&gt;\n     */\n    @Bean\n    public Job shareJob() {\n        return jobBuilderFactory.get(\"shareJob\")\n                                .incrementer(new RunIdIncrementer())\n                                .start(this.shareStep1())\n                                .next(this.shareStep2())\n                                .build();\n    }\n    \n    @Bean\n    public Step shareStep1() {\n        return stepBuilderFactory.get(\"shareStep1\")\n                                 .tasklet((contribution, chunkContext)-&gt;{\n                                     StepExecution stepExecution = contribution.getStepExecution();\n            \n                                     ExecutionContext stepExecutionContext = stepExecution.getExecutionContext();\n                                     stepExecutionContext.putString(\"stepKey\", \"step execution context\");\n            \n                                     JobExecution jobExecution = stepExecution.getJobExecution();\n                                     ExecutionContext jobExecutionContext = jobExecution.getExecutionContext();\n                                     jobExecutionContext.putString(\"jobKey\", \"job execution context\");\n            \n                                     JobParameters jobParameters = jobExecution.getJobParameters();\n                                     JobInstance jobInstance = jobExecution.getJobInstance();\n            \n                                     log.info(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; shareStep1\\njobName: {}\\nstepName: {}\\nparameter:{}\",\n                                              jobInstance.getJobName(),\n                                              stepExecution.getStepName(),\n                                              jobParameters.getLong(\"run.id\")\n                                             );\n            \n                                     return RepeatStatus.FINISHED;\n                                 }).build();\n    }\n    \n    @Bean\n    public Step shareStep2() {\n        return stepBuilderFactory.get(\"shareStep2\")\n                                 .tasklet((contribution, chunkContext)-&gt;{\n                                     StepExecution stepExecution = contribution.getStepExecution();\n            \n                                     ExecutionContext stepExecutionContext = stepExecution.getExecutionContext();\n            \n                                     JobExecution jobExecution = stepExecution.getJobExecution();\n                                     ExecutionContext jobExecutionContext = jobExecution.getExecutionContext();\n            \n                                     log.info(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; shareStep2\\njobKey: {}\\nstepKey: {}\",\n                                              jobExecutionContext.getString(\"jobKey\", \"emptyJobKey\"),\n                                              stepExecutionContext.getString(\"stepKey\", \"emptyStepKey\")\n                                             );\n            \n                                     return RepeatStatus.FINISHED;\n                                 }).build();\n    }\n}\n\n\n\n\n🚀 Bean Scope &amp; Lifecycle\n\n\n  @Scope는 어떤 시점에 bean을 생성/소멸시킬지를 설정할 수 있는 Spring의 애노테이션이다\n  Spring-Batch는 특이한 구조로 인해 더 세부적으로 설정한 애노테이션을 사용하며 두 예제는 같은 동작을 한다\n    \n      @JobScope == @Scope(\"job\")\n        \n          Job 실행 시점에 bean이 생성되며, Step에 선언한다\n        \n      \n      @StepScope == @Scope(\"step\")\n        \n          Step 실행 시점에 bean이 생성되며 Tasklet, Chunk에 선언한다\n        \n      \n    \n  \n  Job과 Step의 실행 시점에 의해 제어되기 때문에 Thread Safe하게 동작한다\n  특히 Spring-Expression-Language를 이용해 JobParameters를 유연하게 사용하기 위해서는 필수로 사용하는 애노테이션들이다\n\n\n\n\n🚀 Database Cursor &amp; Paging\n\n😎 Cursor\n\n\n  배치가 시작될 때 DB Connection이 연결된 후 배치 처리가 완료될 때 까지 Connection이 유지됨\n  DB Connection 빈도가 매우 낮아 성능이 좋지만, Connection 유지시간이 길다는 단점이 있다\n  한번의 Connection에서 작업이 처리되기 때문에 Thread Safe하지 않다\n  모든 결과를 메모리에 할당하기 때문에 리소스 사용량이 높다\n\n\n😎 Paging\n\n\n  페이징(SQL offset, limit) 단위로 DB Connection을 유지한다\n  Cursor기반 조회에 비해 상대적으로 DB Connection 빈도가 높아 성능이 낮다\n  페이징 단위로 메모리를 사용하기 때문에 Cursor기반 조회에 비해 리소스 사용량이 적다\n  페이징 단위로 매번 Connection을 하기 때문에 Thread Safe하며, 병렬처리를 시도할 수 있게된다\n  병렬처리시 Cursor기반 조회보다 성능이 더 좋을수도 있지만, 반대로 리소스 사용량이 더 커질수도 있다\n\n",
      "categories": ["spring","spring-batch"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-batch/2021-06-14-btach-introduction/"
    },{
      "image": "/assets/img/spring/spring-batch/spring-batch-logo.png",
      "title": "Spring Batch Chunk - CSV",
      "date": "2021-06-14 21:33:00 +0000",
      "description": "Spring Batch Chunk CSV 파일 처리 예제 코드\n",
      "content": "\n  📜 CSV 처리 예제\n\n\n \n\n📜 CSV 처리 예제\n\n\n\n \n\n@Slf4j\n@Configuration\n@RequiredArgsConstructor\npublic class CsvConfiguration {\n    private final JobBuilderFactory jobBuilderFactory;\n    private final StepBuilderFactory stepBuilderFactory;\n    \n    private static final String JOB_NAME = \"csvJob\";\n    private static final String STEP_ONE = \"csvStep\";\n    \n    private static final String ENCODING = \"UTF-8\";\n    private static final String CSV_ITEM_READER = \"csvItemReader\";\n    private static final String CSV_ITEM_WRITER = \"csvItemWriter\";\n    private static final String INPUT_PATH = \"csv/input/member.csv\";\n    private static final String OUTPUT_PATH = \"src/main/resources/csv/output/member.csv\";\n    \n    private static final String HEADER = \"id,name,age,address\";\n    private static final String FOOTER = \"-------------------\";\n\n    // append(true)일 경우 footer는 개행문자를 추가해야 다음줄에 추가됨\n    // private static final String FOOTER = \"-------------------\\n\";\n    \n    // Job\n    @Bean\n    public Job csvJob() throws Exception {\n        return jobBuilderFactory.get(JOB_NAME)\n                                // 같은 파라미터로 계속 배치를 실행할 수 있게 run.id를 증가\n                                .incrementer(new RunIdIncrementer()) \n                                .start(csvStep(null))\n                                .build();\n    }\n    \n    \n    // Step(Chunk)\n    @Bean\n    @JobScope // CLI 파라미터로 Chunk Size를 받음\n    public Step csvStep(@Value(\"#{jobParameters[chunkSize]}\") String value) throws Exception {\n        return stepBuilderFactory.get(STEP_ONE)\n                                 .&lt;Member, Member&gt;chunk(getChunkSize(value))\n                                 .reader(this.csvItemReader())\n                                 .writer(this.csvItemWriter())\n                                 .build();\n    }\n    \n    /**\n     * Batch-Application 실행 시 실행 파라미터로 chunk size 지정\n     * 입력 된 파라미터가 없으면 size=10으로 지정\n     * -chunkSize=20 --job.name=taskletProcessing\n     */\n    private int getChunkSize(String value) {\n        return StringUtils.isNotEmpty(value) ? parseInt(value) : 10;\n    }\n    \n    // csv를 읽어 row단위로 객체와 매핑해 반환\n    private FlatFileItemReader&lt;Member&gt; csvItemReader() throws Exception {\n        DefaultLineMapper&lt;Member&gt; mapper = new DefaultLineMapper&lt;&gt;();\n        DelimitedLineTokenizer tokenizer = new DelimitedLineTokenizer();\n        \n        tokenizer.setNames(\"id\", \"name\", \"age\", \"address\");\n        mapper.setLineTokenizer(tokenizer);\n        \n        mapper.setFieldSetMapper(fieldSet-&gt;{\n            int id = fieldSet.readInt(\"id\");\n            String name = fieldSet.readString(\"name\");\n            int age = fieldSet.readInt(\"age\");\n            String address = fieldSet.readString(\"address\");\n            return new Member(id, name, age, address);\n        });\n        \n        FlatFileItemReader&lt;Member&gt; itemReader = new FlatFileItemReaderBuilder&lt;Member&gt;()\n                .name(CSV_ITEM_READER)\n                .encoding(ENCODING)\n                .resource(new ClassPathResource(INPUT_PATH)) // ClassPathResource (Reader 사용할 때)\n                .linesToSkip(1) // csv파일의 첫 row는 컬럼 메타데이터이므로 스킵\n                .lineMapper(mapper)\n                .build();\n        \n        itemReader.afterPropertiesSet(); // itemReader 검증메서드\n        return itemReader;\n    }\n    \n    \n    // reader가 반환한 item이 Chunk Size만큼 writer로 넘어오면 쓰기 실행\n    private ItemWriter&lt;Member&gt; csvItemWriter() throws Exception {\n        BeanWrapperFieldExtractor&lt;Member&gt; fieldExtractor = new BeanWrapperFieldExtractor&lt;&gt;();\n        DelimitedLineAggregator&lt;Member&gt; aggregator = new DelimitedLineAggregator&lt;&gt;();\n        \n        // 각 column을 ,으로 구분\n        fieldExtractor.setNames(new String[] {\"id\", \"name\", \"age\", \"address\"});\n        aggregator.setDelimiter(\",\");\n        aggregator.setFieldExtractor(fieldExtractor);\n        \n        FlatFileItemWriter&lt;Member&gt; itemWriter = new FlatFileItemWriterBuilder&lt;Member&gt;()\n                .name(CSV_ITEM_WRITER)\n                .encoding(ENCODING)\n                .resource(new FileSystemResource(OUTPUT_PATH)) // FileSystemResource (Writer 사용할 때)\n                .lineAggregator(aggregator)\n                .headerCallback(writer-&gt;writer.write(HEADER)) // csv 최상단에 한줄 생성\n                .footerCallback(writer-&gt;writer.write(FOOTER)) // csv 최하단에 한줄 생성\n                .append(true) // 이 옵션을 주면 새로운 파일을 생성하는게 아닌, 기존 파일에 추가된 내용을 이어붙이도록 동작함\n                .build();\n        \n        itemWriter.afterPropertiesSet();\n        return itemWriter;\n    }\n}\n\n",
      "categories": ["spring","spring-batch"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-batch/2021-06-14-btach-chunk-csv/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "배치, 비동기, 오버엔지니어링, 도메인",
      "date": "2021-06-15 20:40:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n최근 백오피스가 굉장히 많이 안정화됐다.\n\n성능적인 면에서는 말할 것도 없고,\n\n로드밸런싱과 무중단 배포 구축으로 리스크 없이 CI/CD도 이루어지고 있다.\n\n \n\n최근에는 백오피스에서 잠시 손을 떼고\n\n배치 서버를 슬슬 담당하기 시작하며 스프링 배치를 알음알음 공부하고 있다.\n\n최근에는 우리 회사의 정보를 타 회사로 이관하는 일배치 개발 업무를 받았는데,\n\n기왕 만드는 거 성능 끝장나게 한번 만들어보자고\n\n멀티스레드와 비동기를 적극 활용해 배치 애플리케이션을 개발해서 돌려봤다.\n\n약 26만 건의 데이터를 타 회사의 서버로 이관하기 위한 요청이\n\n채 2분이 걸리지 않아 끝났으나, 429 폭탄 을 맞아버렸다. 😭\n\n \n\n그래서 수신 서버의 스펙을 다시 점검하고, 몇 번의 테스트를 거치면서 요청 속도를 줄여야만 했다.\n\n멀티스레드와 비동기는 싱글 스레드와 동기식으로 바뀌었고, Chunk size 또한 대폭 줄어들었다.\n\n이러고 걸리는 시간을 계산해보니, 26만 건의 데이터를 보내는데 약 5시간이 소요됨을 알고 좌절했다.\n\n(2분 -&gt; 5시간 😣)\n\n \n\n비동기가 업계에서 아직 활발하게 쓰이지 않는 이유를 약간 엿본듯했다.\n\n그리고 단독 애플리케이션이 아닌 여러 API와 연동되는 애플리케이션을 개발할 때는\n\n성능에 집착하는 습관성능충을 잠시 내려놔야겠다는 깨달음을 얻었다. 일 두 번 하더라…\n\n \n\n그리고 다른 일배치를 하나 더 만들게 됐는데, SFTP 서버에 접속해 데이터를 내려받는 배치였다.\n\n매우 간단하다고 생각이 들었는데 내려받아야 할 데이터를 보고 이해가 안 돼서 말문을 잃어버렸다.\n\n \n\nXML도 아니고 JSON도 아니고 난생처음 보는 데이터 형식이어서\n\n선배님들께 여쭤보니 이런 걸 전문이라고 부른다는 답변을 들었다.\n\n(중간에 그럼 이게 모스부호 같은 건가요?라고 반문했다가 웃음바다가 터졌다. 그래도 역시 비슷한 거 같긴 하다…)\n\n전문에 대한 설명을 좀 듣고 보니 그제야 문서가 이해되기 시작했다.\n\n \n\n참 이런 사례를 겪고 보니 현업에서 그렇게 강조하는 도메인 지식이 정말 중요하다는 게 이런 느낌이구나 싶었던 하루였다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-06-15-diary-23/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "JPA 기초 1 - ORM(Object Relational Mapping)",
      "date": "2021-06-18 20:06:00 +0000",
      "description": "ORM을 사용해야만 하는 이유\n",
      "content": "\n  📕 ORM(Object Relational Mapping)\n\n\n \n\n📕 ORM(Object Relational Mapping)\n\n\n\nORM이란 것은 RDBMS 인스턴스와 쉽게 상호작용해 쿼리작성의 부담을 줄이기 위한 목적의 프로그래밍 방식이다.\n\n그리고, 많이들 들어보았을 JPA는 자바진영의 ORM 표준 인터페이스이다.\n\n또한, 현 시점 가장 많이 사용되는 JPA 구현체는 하이버네이트(Hibernate)이다.\n\n이 기술들의 핵심 컨셉은 애플리케이션과 데이터베이스 사이에 가상의 데이터베이스(영속성 컨텍스트)라는 인디렉션(간접 참조계층)을 만드는 것이다.\n\n\n\nMybatis등의 다른 데이터 접근 기술을 사용하다 JPA를 배우는 개발자가 착각할 수 있는것은 반드시 JPA를 사용해야만 객체지향적인 코드를 작성할 수 있느냐는 것이다.\n\n이는 필자가 생각하기에 약간 잘못된 접근 방법이라고 생각하는데, 객체지향적으로 코드를 작성한다면 저장소가 파일시스템이든, RDBMS든, NoSQL이든 관계가 없어지기 때문에 JPA는 객체지향과는 큰 관계가 없다.\n\n오히려 필자는 JPA와 도메인 객체를 결합하게되면 도메인이 RDBMS에 오염된다고 생각하기 때문에 객체지향적으로 안티패턴 이라고까지 생각한다.\n\n\n\n그럼에도 불구하고 ORM, 그중 특히 하이버네이트를 사용하는 이유는 충분하다.\n\n\n\n\n  LGPL 메이저 오픈 소스\n    \n      상용으로 사용하더라도 코드를 공개하지 않아도 괜찮으며, 전 세계의 뛰어난 오픈 소스 개발자들이 두 눈에 불을 켜고 유지보수에 매달리고 있다.\n    \n  \n  좋은 성능\n    \n      하이버네이트는 내부적으로 캐시를 사용하기 때문에 성능이 좋다. 내부적으로 1차캐시와 2차캐시가 있는데, 1차캐시는 기본적으로 활성화돼있다.\n    \n  \n  직접 작성할 필요 없으며, 데이터베이스에 독립적인 SQL\n    \n      HQL(Hibernate Query Language)은 객체 지향 버전의 SQL로, 하이버네이트는 데이터베이스에 독립적인 쿼리를 만들어낸다. 심지어 이러한 쿼리를 개발자가 하나하나 직접 하드코딩하는 것이 아닌, 자바 코드 몇자면 자동으로 생성이 된다. 따라서 하이버네이트를 사용한다면 쿼리를 작성하는데 소요되는 시간이 0에 가깝게 줄어들며, 특정 데이터베이스에 종속적인 쿼리를 작성할 필요도 없어진다. 즉, 혹여나 프로젝트 중간에 데이터베이스가 변경되더라도 대규모의 쿼리수정을 할 필요가 없게 된다. 단, 이렇게 데이터베이스에 독립적인 애플리케이션을 개발하기 위해서는 하이버네이트에서 제공하는 네이티브 쿼리를 사용하지 않아야만 한다.\n    \n  \n  테이블 자동 생성 (ddl-auto 옵션)\n    \n      하이버네이트는 자동으로 테이블을 생성해준다. 개발 초기에 데이터베이스 테이블을 하나하나 직접 생성하지 않아도 되기 때문에 빠르게 개발을 시작할 수 있게 도와준다.\n    \n  \n  조인 단순화\n    \n      여러 테이블의 데이터를 함께 가져오는 조인 작업이 하이버네이트에서는 연관관계 매핑이라는 이름으로 지원이 되며, 이 매핑을 잘 해두면 조인작업이 매우 쉽게 처리된다.\n    \n  \n  데이터베이스 상태, 통계 제공\n    \n      하이버네이트는 쿼리와 데이터베이스의 상태에 대한 통계정보를 제공해준다. 따라서 개발 도중 쿼리의 성능을 간접적으로 계속해서 확인할 수 있다.\n    \n  \n\n\n\n\n필자가 JPA로 실무를 보며 느꼈던 중요한 부분들은 다음과 같다.\n\n\n  사용하지 않을 수 있다면, 네이티브 쿼리는 최후의 최후까지 사용하지 않아야 한다.\n  중요한 처리를 JPA의 연관관계 매핑을 통해 처리하려 들 경우 N+1, 동일성 불일치 등의 골치아픈 side-effect가 발생한다.\n  항상 트랜잭션과 영속성 컨텍스트를 머릿속에 그리고 있어야만 한다.\n  JPA Entity는 단순히 RDBMS의 테이블 구조를 따라갈 뿐이다.\n  도메인 모델(DM)과 영속성 모델(PM)을 분리하자.\n  데이터 중심적인 사고에 빠지지않고, 항상 객체지향적으로 생각하고 SOLID 원칙을 준수할 수 있도록 노력해야만 한다.\n\n\n\n\n\n  \n    \n      약어\n      개념\n    \n  \n  \n    \n      SRP\n      단일 책임 원칙 (Single responsibility principle) 한 클래스는 하나의 책임만 가져야 한다.\n    \n    \n      OCP\n      개방-폐쇄 원칙 (Open/closed principle) “소프트웨어 요소는 확장에는 열려 있으나 변경에는 닫혀 있어야 한다.”\n    \n    \n      LSP\n      리스코프 치환 원칙 (Liskov substitution principle)  “프로그램의 객체는 프로그램의 정확성을 깨뜨리지 않으면서 하위 타입의 인스턴스로 바꿀 수 있어야 한다.” 계약에 의한 설계를 참고하라.\n    \n    \n      ISP\n      인터페이스 분리 원칙 (Interface segregation principle)  “특정 클라이언트를 위한 인터페이스 여러 개가 범용 인터페이스 하나보다 낫다.”\n    \n    \n      DIP\n      의존관계 역전 원칙 (Dependency inversion principle)  프로그래머는 “추상화에 의존해야지, 구체화에 의존하면 안된다.” 의존성 주입은 이 원칙을 따르는 방법 중 하나다.\n    \n  \n\n\n\n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-06-18-jpa-1/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "JPA 기초 2 - JPA(Java Persistence API)",
      "date": "2021-06-19 21:16:00 +0000",
      "description": "JPA에 대한 기본 개념\n",
      "content": "\n  📕 JPA(Java Persistence API)    \n      🚀 About JPA\n      🚀 About Spring-Data-JPA\n      🚀 JPA 동작 원리\n      🚀 JPA 사용\n    \n  \n\n\n \n\n📕 JPA(Java Persistence API)\n\n\n\n🚀 About JPA\n\n\n\n\n\n\n\nJPA는 ORM을 Java 플랫폼에 호환되게 사용하기 위한 요구사항을 규격화한 표준 API이다.\n\n이 API는 javax.persistence 패키지에 정의돼있으며, 문자 그대로 대부분의 요구사항이 정의만 되어 있다.\n\n\n\n\n\n\n\n패키지를 까보면 대부분의 클래스가 interface임을 알 수 있다.\n\n여러 벤더에서 이 API를 구현하여 제공하고 있는데 구현체를 제공하는 벤더들은 Eclipse Link, Data Nucleus, OpenJPA, TopLink Essentials, Hibernate 등이 있으며, 2021년 현재 전 세계적으로 가장 많이 사용되는 벤더는 Hibernate이다.\n\n위키백과에 따르면 2019년부터 JPA는 Jakarta Persistence로 이름이 바뀌며 v3.0이 출시됐으며, 위 이미지는 Spring-Boot 최신 버전에서 캡처한 이미지로, jar이름도 jakarta.persistence임을 알 수 있다.\n\nJakarta Persistence v3.0의 요구사항을 만족하는 구현체를 제공하는 벤더는 총 3종류로 Data Nucleus v6.0, EclipseLink v3.0, Hibernate v5.5이다.\n\n\n\nJakarta Persistence 3.0\nRenaming of the JPA API to Jakarta Persistence happened in 2019, followed by the release of v3.0 in 2020.\n\nMain features included were:\n\nRename of all packages from javax.persistence to jakarta.persistence.\nRename of all properties prefix from javax.persistence to jakarta.persistence.\nVendors supporting Jakarta Persistence 3.0\n\nDataNucleus (from version 6.0)\nEclipseLink (from version 3.0)\nHibernate (from version 5.5)\n\n\n\n\n어떤 벤더를 사용하더라도 JPA라는 인터페이스가 강제돼있기 때문에 내부적으로 동작이 다를 순 있으나 실제 사용법에는 큰 차이가 없다.\n\n\n\n🚀 About Spring-Data-JPA\n\n\n\n\n\n\n\nJPA를 구현한 순수 구체 클래스를 그대로 사용할 경우 이런 저런 설정을 매번 따로 해줘야 하는 경우가 많은데, 이를 한단계 더 추상화하여 자주 사용하는 기능들을 편리하게 쓸 수 있게 만들어 둔 계층이다.\n\n개인적으로 가장 많이 사용하게 되는것은 org.springframework.data.jpa.repository 패키지의 SimpleJpaRepository이다.\n\n실제로 가장 많이 사용되는 save, saveAll, delete, deleteAll, findById, findBy~ 등의 API들이 SimpleJpaRepository에 정의돼있으며, 실제 구현부 코드는 JPA를 래핑한 수준의 아주 단순한 코드들이다.\n\n\n\n@Transactional\n@Override\npublic &lt;S extends T&gt; S save(S entity) {\n\n    Assert.notNull(entity, \"Entity must not be null.\");\n\n    if (entityInformation.isNew(entity)) {\n        em.persist(entity);\n        return entity;\n    } else {\n        return em.merge(entity);\n    }\n}\n\n@Transactional\n@Override\npublic &lt;S extends T&gt; List&lt;S&gt; saveAll(Iterable&lt;S&gt; entities) {\n    \n    Assert.notNull(entities, \"Entities must not be null!\");\n    \n    List&lt;S&gt; result = new ArrayList&lt;S&gt;();\n    \n    for (S entity : entities) {\n        result.add(save(entity));\n    }\n    return result;\n}\n\n@Override\n@Transactional\n@SuppressWarnings(\"unchecked\")\npublic void delete(T entity) {\n      \n    Assert.notNull(entity, \"Entity must not be null!\");\n    \n    if (entityInformation.isNew(entity)) {\n        return;\n    }\n    \n    Class&lt;?&gt; type = ProxyUtils.getUserClass(entity);\n    \n    T existing = (T) em.find(type, entityInformation.getId(entity));\n    \n    // if the entity to be deleted doesn't exist, delete is a NOOP\n    if (existing == null) {\n        return;\n    }\n    \n    em.remove(em.contains(entity) ? entity : em.merge(entity));\n}\n\n\n\n\nJPA를 처음 접하는 사람은 아직 잘 모르겠지만, JPA의 모든 동작은 transaction 위에서 진행되어야 작업이 반영되기 때문에, SimpleJpaRepository의 모든 public API에는 @Transactional이 작성돼있다.\n\n만약 JPA를 학습하고자 하는데 transaction이 뭔지 잘 모른다면 이 부분에 대한 선행학습이 필수적으로 요구된다고 볼 수 있겠다.\n\n\n\n🚀 JPA 동작 원리\n\n\n\n \n\n\n\n \n\n이미지가 잘 안보일 수 있는데, 몰라도 상관 없다. 그냥 이렇게 복잡하다는걸 보여주기 위한 이미지기 때문이다.\n\n아무튼 굉장히 복잡하게 구성돼있는데, 간단하게 핵심만 생각하자면 모든 작업이 EntityManager 위주로 돌아간다.\n\nEntityManager는 영속성 컨텍스트라는 이름의 가상 데이터베이스를 관리하는 객체이기 때문이다.\n\nDB 작업이 필요한 시점에 EntityManager를 생성해야 하는데, 이때 DataSource와 매핑된 Persistence에서 connection을 얻어와\n\nEntityManagerFactory가 EntityManager를 생성해주고, EntityManager는 connection을 Lazy 상태로 가진다.\n\n그리고 실제 작업이 시작되는 타이밍에 EntityManager는 EntityTransaction객체를 생성해 transaction을 시작하며 connection을 연결한다.\n\n이후 작업이 끝나면 EntityTransaction을 폐기하며 transaction을 종료하고 EntityManager또한 폐기한다.\n\nEntityManager까지 폐기하는 이유는 EntityManager가 Thread-Safe하지 않기 때문이며, EntityManager 인스턴스는 매 작업마다 새로 생성된다.\n\n \n\n\n\n \n\n이 과정이 대략 아래와 같은 코드로 나타난다.\n\n\n\nEntityManagerFactory emf = Persistence.createEntityManagerFactory(\"jpabook\"); //엔티티 매니저 팩토리 생성\nEntityManager em = emf.createEntityManager(); //엔티티 매니저 생성\nEntityTransaction tx = em.getTransaction(); //트랜잭션 획득\n\ntry {\n    tx.begin(); //트랜잭션 시작\n    logic(em);  //비즈니스 로직\n    tx.commit();//트랜잭션 커밋\n} catch (Exception e) {\n    tx.rollback(); //트랜잭션 롤백\n} finally {\n    em.close(); //엔티티 매니저 종료\n}\n\nemf.close(); //엔티티 매니저 팩토리 종료\n\n\n\n\nSpring-Data-JPA를 사용할 경우 위의 작업은 대부분 신경쓰지 않아도 되지만,\n\n만약 순수 JPA를 사용한다면 EntityManagerFactory는 싱글톤 등의 기법을 사용하여 애플리케이션 전체에서 재활용하는게 비용상 좋다.\n\n \n\n🚀 JPA 사용\n\n\n\n2021년 6월 기준 신규 프로젝트는 대부분 Spring-Boot으로 시작하기 때문에 xml기반의 설정을 제외하며,\n\nMaven보다는 Gradle이 아주 활발하게 사용되고 있으므로 Gradle 설정으로 대체한다.\n\n데이터베이스는 H2로 설정하고, boilerplate code를 작성하는 수고를 줄이기 위해 lombok을 추가한다.\n\n\n\n//build.gradle\n\ndependencies {\n    compileOnly 'org.projectlombok:lombok'\n    annotationProcessor 'org.projectlombok:lombok'\n    annotationProcessor 'org.springframework.boot:spring-boot-configuration-processor'\n    \n    implementation 'org.springframework.boot:spring-boot-starter-data-jpa'\n    runtimeOnly 'com.h2database:h2'\n}\n\n\n#application.yaml\nspring.datasource.url=jdbc:h2:tcp://localhost/~/learn-jpa\nspring.datasource.username=sa\nspring.datasource.password=\n\n\n@Entity // JPA 기능을 사용하기 위한 객체임을 명시 (테이블과 매핑되는 객체) \n@Getter\n@NoArgsConstructor(access = AccessLevel.PROTECTED)\npublic class Member implements Serializable {\n    private static final long serialVersionUID = 3990803224604257521L;\n    \n    @Id // 해당 필드가 DB의 PK임을 명시 \n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    // 기본키 생성전략을 auto_increment로 설정\n    // DB가 auto_increment를 지원하지 않으면 sequence로 설정된다\n    private Long id;\n    private String name;\n    private int age;\n    \n    @Builder\n    public Member(Long id, String name, int age) {\n        this.id = id;\n        this.name = name;\n        this.age = age;\n    }\n}\n\n\n\n\n@DataJpaTest\nclass MemberTest {\n    @PersistenceUnit\n    EntityManagerFactory emf; // EntityManagerFactory 생성\n    \n    EntityManager em;\n    EntityTransaction tx;\n    \n    @BeforeEach\n    void setUp() { // 테스트케이스가 시작되면 먼저 실행될 코드블럭\n        em = emf.createEntityManager(); // EntityManagerFactory에서 EntityManager 생성\n        tx = em.getTransaction(); // EntityManager에서 trasaction 획득\n    }\n    \n    @AfterEach\n    void tearDown() { // 테스트케이스가 종료되면 실행될 코드블럭\n        em.close();\n        emf.close();\n    }\n    \n    @Test\n    void memberTest() throws Exception {\n        tx.begin(); // transaction start\n        // given\n        Member member = Member.builder()\n                              .name(\"홍길동\")\n                              .age(30)\n                              .build(); // Member 인스턴스 생성\n        \n        // when\n        em.persist(member); // Member 인스턴스를 영속성 컨텍스트에 저장\n        em.flush(); // 영속성 컨텍스트의 변경사항을 DB에 반영\n        \n        Member findMember = em.find(Member.class, member.getId()); // 영속성 컨텍스트에서 ID로 Member를 조회\n        \n        \n        // then\n        assertThat(findMember).isSameAs(member); // 영속성 컨텍스트에 저장된 Member와 조회한 Member가 동일한지 \n        tx.commit(); // transaction 종료\n    }\n}\n\n\n\n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-06-19-jpa-2/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "Spring Data JPA - SimpleJpaRepository",
      "date": "2021-06-23 17:04:00 +0000",
      "description": "Spring Data JPA의 핵심 콘크리트 클래스인 SimpleJpaRepository에 대한 학습 테스트\n",
      "content": "\n  📕 SimpleJpaRepository\n\n\n \n\n📕 SimpleJpaRepository\n\n\n\nSpring Data JPA에는 CRUD를 정의한 CrudRepository 인터페이스가 존재하며 이를 상속하여 구현한 Spring Data JPA의 핵심적인 콘크리트 클래스가 SimpleJpaRepository이다.\n\n내부적으로 JPA의 persist, merge, flush, remove 등으로 구현돼있으며, @Transactional이 선언돼있다.\n\nSimpleJpaRepository의 대부분의 기능에 대한 학습 테스트코드를 작성하였다.\n\n전체 코드가 궁금하시다면 깃허브를 확인바랍니다.\n\n\n\n\n\n\n\n// file: 'MemberRepository.java'\n\npublic interface MemberRepository extends JpaRepository&lt;Member, Long&gt; {\n    // 수식어를 생략해도 findByNameIs, findByNameEquals 와 같이 동작함(==조건검색)\n    Member findByName(String name);\n\n    Member getByName(String name);\n\n    Member readByName(String name);\n\n    Member queryByName(String name);\n\n    Member searchByName(String name);\n\n    Member streamByName(String name);\n\n    Member findFirst1ByName(String name);\n\n    Member findTop1ByName(String name);\n\n    List&lt;Member&gt; findTop2ByName(String name);\n\n    Member findByNameAndAge(String name, int age);\n\n    List&lt;Member&gt; findByNameOrAge(String name, int age);\n\n    List&lt;Member&gt; findByIdAfter(Long id);\n\n    List&lt;Member&gt; findByIdBefore(Long id);\n\n    List&lt;Member&gt; findByIdIsLessThanEqual(Long id);\n\n    List&lt;Member&gt; findByIdGreaterThanEqual(Long id);\n\n    List&lt;Member&gt; findByAgeBetween(int age1, int age2);\n\n    List&lt;Member&gt; findByIdIsNotNull();\n\n    List&lt;Member&gt; findByAgeIn(List&lt;Integer&gt; ages);\n\n    List&lt;Member&gt; findByNameStartingWith(String name);\n\n    List&lt;Member&gt; findByNameEndingWith(String name);\n\n    List&lt;Member&gt; findByNameContaining(String name);\n\n    List&lt;Member&gt; findFirst2ByNameOrderByIdDesc(String name);\n\n    Page&lt;Member&gt; findByName(String name, Pageable pageable);\n}\n\n\n// file: 'SimpleRepositoryTest.java'\n\n@DataJpaTest\n@DirtiesContext(classMode = DirtiesContext.ClassMode.BEFORE_EACH_TEST_METHOD)\nclass SimpleRepositoryTest {\n    @Autowired\n    MemberRepository memberRepository;\n\n    @BeforeEach\n    void setUp() {\n        List&lt;Member&gt; members = List.of(Member.createMember(\"siro\", 29),\n                                       Member.createMember(\"sophia\", 32),\n                                       Member.createMember(\"dennis\", 25),\n                                       Member.createMember(\"james\", 41),\n                                       Member.createMember(\"michael\", 33));\n\n        memberRepository.saveAllAndFlush(members);\n    }\n\n    @AfterEach\n    void tearDown() {\n        memberRepository.deleteAll();\n    }\n\n    private Sort orderByIdDesc() {\n        return by(Order.desc(\"id\"));\n    }\n\n    @Test\n    @DisplayName(\"Member_1번을_조회\")\n    void findById() {\n        Member member = memberRepository.findById(1L)\n                                        .orElseThrow(NoSuchElementException::new);\n        assertThat(member.getName()).isEqualTo(\"siro\");\n        assertThat(member.getAge()).isEqualTo(29);\n    }\n\n    @Test\n    @DisplayName(\"Member_1번_3번을_조회\")\n    void findAllById() {\n        List&lt;Member&gt; members = memberRepository.findAllById(Lists.newArrayList(1L, 3L));\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 29),\n                                     tuple(\"dennis\", 25))\n                           .size().isEqualTo(2);\n    }\n\n    @Test\n    @DisplayName(\"Member_초기_데이터는_5명\")\n    void findAll() {\n        List&lt;Member&gt; members = memberRepository.findAll();\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 29),\n                                     tuple(\"sophia\", 32),\n                                     tuple(\"dennis\", 25),\n                                     tuple(\"james\", 41),\n                                     tuple(\"michael\", 33))\n                           .size().isEqualTo(5);\n    }\n\n    @Test\n    @DisplayName(\"Member_1번을_제거\")\n    void deleteById() {\n        memberRepository.deleteById(1L);\n        List&lt;Member&gt; members = memberRepository.findAll();\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"sophia\", 32),\n                                     tuple(\"dennis\", 25),\n                                     tuple(\"james\", 41),\n                                     tuple(\"michael\", 33))\n                           .size().isEqualTo(4);\n    }\n\n    @Test\n    @DisplayName(\"Member_1번_3번을_제거\")\n    void deleteAllById() {\n        memberRepository.deleteAllById(Lists.newArrayList(1L, 3L));\n        List&lt;Member&gt; members = memberRepository.findAll();\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"sophia\", 32),\n                                     tuple(\"james\", 41),\n                                     tuple(\"michael\", 33))\n                           .size().isEqualTo(3);\n    }\n\n    @Test\n    @DisplayName(\"Member_전체제거\")\n    void deleteAll() {\n        memberRepository.deleteAll();\n        List&lt;Member&gt; members = memberRepository.findAll();\n\n        assertThat(members).isEmpty();\n    }\n\n    @Test\n    @DisplayName(\"Member_Batch_1번_3번을_제거\")\n    void deleteAllByIdInBatch() {\n        memberRepository.deleteAllByIdInBatch(Lists.newArrayList(1L, 3L));\n        List&lt;Member&gt; members = memberRepository.findAll();\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"sophia\", 32),\n                                     tuple(\"james\", 41),\n                                     tuple(\"michael\", 33))\n                           .size().isEqualTo(3);\n    }\n\n    @Test\n    @DisplayName(\"Member_Batch_전체제거\")\n    void deleteAllInBatch() {\n        memberRepository.deleteAllInBatch();\n        List&lt;Member&gt; members = memberRepository.findAll();\n        assertThat(members).isEmpty();\n    }\n\n    @Test\n    @DisplayName(\"Member_1번이_존재하는지_확인\")\n    void existsById() {\n        boolean exists = memberRepository.existsById(1L);\n        assertThat(exists).isTrue();\n    }\n\n    @Test\n    @DisplayName(\"Member_전체수를_조회\")\n    void count() {\n        long count = memberRepository.count();\n        assertThat(count).isEqualTo(5);\n    }\n\n    /**\n     * JPA Page는 0부터 시작한다 &lt;br/&gt;\n     * &lt;br/&gt;\n     * Creates a new unsorted {@link PageRequest}. &lt;br/&gt;\n     * page zero-based page index, must not be negative. &lt;br/&gt;\n     * the size of the page to be returned, must be greater than 0. &lt;br/&gt;\n     * &lt;br/&gt;\n     * 참고자료 경로 &lt;br/&gt;\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-0.png\"\n     */\n    @Test\n    @DisplayName(\"Page_API\")\n    void pageV1() {\n        Page&lt;Member&gt; members = memberRepository.findAll(PageRequest.of(1, 3));\n        Pageable pageable = members.getPageable();\n\n        Sort sort = members.getSort();\n        int pageNumber = pageable.getPageNumber();\n        int totalPages = members.getTotalPages();\n        long totalElements = members.getTotalElements();\n        int numberOfElements = members.getNumberOfElements();\n        int size = members.getSize();\n\n        assertThat(sort.isUnsorted()).isTrue();\n        assertThat(pageNumber).isEqualTo(1);\n        assertThat(totalPages).isEqualTo(2);\n        assertThat(totalElements).isEqualTo(5);\n        assertThat(numberOfElements).isEqualTo(2);\n        assertThat(size).isEqualTo(3);\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"james\", 41),\n                                     tuple(\"michael\", 33))\n                           .size().isEqualTo(2);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-0.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_Pageable_조회\")\n    void pageV2() {\n        List&lt;Member&gt; createMembers = new ArrayList&lt;&gt;();\n        createMembers.add(Member.createMember(\"siro\", 11));\n        createMembers.add(Member.createMember(\"siro\", 22));\n        createMembers.add(Member.createMember(\"siro\", 33));\n        createMembers.add(Member.createMember(\"siro\", 44));\n        memberRepository.saveAllAndFlush(createMembers);\n\n        Page&lt;Member&gt; members = memberRepository.findByName(\"siro\", PageRequest.of(0, 3, orderByIdDesc()));\n        Pageable pageable = members.getPageable();\n\n        Sort sort = members.getSort();\n        int pageNumber = pageable.getPageNumber();\n        int totalPages = members.getTotalPages();\n        long totalElements = members.getTotalElements();\n        int numberOfElements = members.getNumberOfElements();\n        int size = members.getSize();\n\n        assertThat(sort.isSorted()).isTrue();\n        assertThat(pageNumber).isEqualTo(0);\n        assertThat(totalPages).isEqualTo(2);\n        assertThat(totalElements).isEqualTo(5);\n        assertThat(numberOfElements).isEqualTo(3);\n        assertThat(size).isEqualTo(3);\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 44),\n                                     tuple(\"siro\", 33),\n                                     tuple(\"siro\", 22))\n                           .size().isEqualTo(3);\n\n        members = memberRepository.findByName(\"siro\", PageRequest.of(1, 3, orderByIdDesc()));\n        pageable = members.getPageable();\n\n        sort = members.getSort();\n        pageNumber = pageable.getPageNumber();\n        totalPages = members.getTotalPages();\n        totalElements = members.getTotalElements();\n        numberOfElements = members.getNumberOfElements();\n        size = members.getSize();\n\n        assertThat(sort.isSorted()).isTrue();\n        assertThat(pageNumber).isEqualTo(1);\n        assertThat(totalPages).isEqualTo(2);\n        assertThat(totalElements).isEqualTo(5);\n        assertThat(numberOfElements).isEqualTo(2);\n        assertThat(size).isEqualTo(3);\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 11),\n                                     tuple(\"siro\", 29))\n                           .size().isEqualTo(2);\n    }\n\n    @Test\n    @DisplayName(\"Example_API\")\n    void exampleFindAll() {\n        ExampleMatcher matcher = matching()\n                .withIgnorePaths(\"age\") // age 는 무시하고 검색한다\n                .withMatcher(\"name\", GenericPropertyMatchers.contains()); // name 을 검색조건에 포함시킨다 - like 검색\n\n        /*-----------------------------------------\n         조건 검색을 위한 Member proxy 를 생성한다\n         name 에 i가 들어가는 멤버를 조회한다\n         age 는 무시되므로 값이 몇이든 의미없다\n         -----------------------------------------*/\n        Example&lt;Member&gt; example = Example.of(Member.createMember(\"i\", 0), matcher);\n\n        List&lt;Member&gt; members = memberRepository.findAll(example);\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 29),\n                                     tuple(\"sophia\", 32),\n                                     tuple(\"dennis\", 25),\n                                     tuple(\"michael\", 33))\n                           .size().isEqualTo(4);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-1.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_조회_접두사\")\n    void queryMethodsV1() {\n        Member member = Member.createMember(\"tester\", 77);\n        Member tester = memberRepository.save(member);\n\n        assertThat(tester).usingRecursiveComparison().isEqualTo(memberRepository.findByName(\"tester\"));\n        assertThat(tester).usingRecursiveComparison().isEqualTo(memberRepository.getByName(\"tester\"));\n        assertThat(tester).usingRecursiveComparison().isEqualTo(memberRepository.readByName(\"tester\"));\n        assertThat(tester).usingRecursiveComparison().isEqualTo(memberRepository.queryByName(\"tester\"));\n        assertThat(tester).usingRecursiveComparison().isEqualTo(memberRepository.searchByName(\"tester\"));\n        assertThat(tester).usingRecursiveComparison().isEqualTo(memberRepository.streamByName(\"tester\"));\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-1.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_Top_조회\")\n    void queryMethodsV2() {\n        /*-----------------------------------------\n         id=1 siro 와 id=6 siro 가 존재하는 상황에서\n        limit query 를 사용하여 id 우선순위가 더 높은 데이터를 조회한다\n         -----------------------------------------*/\n        Member member = Member.createMember(\"siro\", 77);\n        memberRepository.saveAndFlush(member); // id=6 siro save\n\n        Member siro = memberRepository.findById(1L).get(); // id=1 siro select\n        assertThat(siro).usingRecursiveComparison().isEqualTo(memberRepository.findTop1ByName(\"siro\"));\n        assertThat(siro).usingRecursiveComparison().isEqualTo(memberRepository.findFirst1ByName(\"siro\"));\n\n        List&lt;Member&gt; members = memberRepository.findTop2ByName(\"siro\"); //  limit = 2 select\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 29),\n                                     tuple(\"siro\", 77))\n                           .size().isEqualTo(2);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_And_조회\")\n    void queryMethodsV3() {\n        Member member = Member.createMember(\"siro\", 77);\n        memberRepository.saveAndFlush(member); // id=6 siro save\n\n        Member siro = memberRepository.findByNameAndAge(\"siro\", 77);\n        assertThat(siro).extracting(\"name\", \"age\")\n                        .containsExactly(\"siro\", 77);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_Or_조회\")\n    void queryMethodsV4() {\n        Member member = Member.createMember(\"siro\", 25);\n        memberRepository.saveAndFlush(member); // id=6 siro save\n\n        List&lt;Member&gt; members = memberRepository.findByNameOrAge(\"siro\", 25);\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 29),\n                                     tuple(\"dennis\", 25),\n                                     tuple(\"siro\", 25))\n                           .size().isEqualTo(3);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_After_조회(초과)\")\n    void queryMethodsV5() {\n        List&lt;Member&gt; members = memberRepository.findByIdAfter(1L);\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"sophia\", 32),\n                                     tuple(\"dennis\", 25),\n                                     tuple(\"james\", 41),\n                                     tuple(\"michael\", 33))\n                           .size().isEqualTo(4);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_After_조회(이상)\")\n    void queryMethodsV6() {\n        List&lt;Member&gt; members = memberRepository.findByIdGreaterThanEqual(1L);\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 29),\n                                     tuple(\"sophia\", 32),\n                                     tuple(\"dennis\", 25),\n                                     tuple(\"james\", 41),\n                                     tuple(\"michael\", 33))\n                           .size().isEqualTo(5);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_Before_조회(미만)\")\n    void queryMethodsV7() {\n        List&lt;Member&gt; members = memberRepository.findByIdBefore(5L);\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 29),\n                                     tuple(\"sophia\", 32),\n                                     tuple(\"dennis\", 25),\n                                     tuple(\"james\", 41))\n                           .size().isEqualTo(4);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_Before_조회(이하)\")\n    void queryMethodsV8() {\n        List&lt;Member&gt; members = memberRepository.findByIdIsLessThanEqual(5L);\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 29),\n                                     tuple(\"sophia\", 32),\n                                     tuple(\"dennis\", 25),\n                                     tuple(\"james\", 41),\n                                     tuple(\"michael\", 33))\n                           .size().isEqualTo(5);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_Between_조회\")\n    void queryMethodsV9() {\n        List&lt;Member&gt; members = memberRepository.findByAgeBetween(20, 30);\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 29),\n                                     tuple(\"dennis\", 25))\n                           .size().isEqualTo(2);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_NotNull_조회\")\n    void queryMethodsV10() {\n        List&lt;Member&gt; members = memberRepository.findByIdIsNotNull();\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 29),\n                                     tuple(\"sophia\", 32),\n                                     tuple(\"dennis\", 25),\n                                     tuple(\"james\", 41),\n                                     tuple(\"michael\", 33))\n                           .size().isEqualTo(5);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_In_조회(Batch)\")\n    void queryMethodsV11() {\n        List&lt;Member&gt; members = memberRepository.findByAgeIn(Lists.newArrayList(29, 32, 25));\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 29),\n                                     tuple(\"sophia\", 32),\n                                     tuple(\"dennis\", 25))\n                           .size().isEqualTo(3);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_Starting_조회\")\n    void queryMethodsV12() {\n        Member siro = memberRepository.findByNameStartingWith(\"si\").get(0);\n        assertThat(siro).extracting(\"name\", \"age\")\n                        .containsExactly(\"siro\", 29);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_Ending_조회\")\n    void queryMethodsV13() {\n        Member siro = memberRepository.findByNameEndingWith(\"ro\").get(0);\n        assertThat(siro).extracting(\"name\", \"age\")\n                        .containsExactly(\"siro\", 29);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-2.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_Containing_조회\")\n    void queryMethodsV14() {\n        Member siro = memberRepository.findByNameContaining(\"ir\").get(0);\n        assertThat(siro).extracting(\"name\", \"age\")\n                        .containsExactly(\"siro\", 29);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-3.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_First_OrderBy_조회\")\n    void queryMethodsV15() {\n        Member member = Member.createMember(\"siro\", 77);\n        memberRepository.saveAndFlush(member);\n\n        List&lt;Member&gt; members = memberRepository.findFirst2ByNameOrderByIdDesc(\"siro\");\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"siro\", 77),\n                                     tuple(\"siro\", 29))\n                           .size().isEqualTo(2);\n    }\n\n    /**\n     * 참고자료 경로\n     *\n     * @see \"Han-Changhun/src/test/resources/images/query-method-3.png\"\n     */\n    @Test\n    @DisplayName(\"Query_Methods_Sort_조회\")\n    void queryMethodsV16() {\n        List&lt;Member&gt; members = memberRepository.findAll(orderByIdDesc());\n        assertThat(members).extracting(\"name\", \"age\")\n                           .contains(tuple(\"michael\", 33),\n                                     tuple(\"james\", 41),\n                                     tuple(\"dennis\", 25),\n                                     tuple(\"sophia\", 32),\n                                     tuple(\"siro\", 29))\n                           .size().isEqualTo(5);\n    }\n}\n\n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-06-23-simple-repository/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "JPA 기초 3 - 영속성 컨텍스트(Persistence Context)",
      "date": "2021-06-23 22:23:00 +0000",
      "description": "영속성 컨텍스트(Persistence Context)에 대한 기본 개념\n",
      "content": "\n  📕 Persistence Context    \n      🚀 About Persistence Context\n      🚀 1차 캐시\n      🚀 동일성 보장\n      🚀 쓰기 지연, 지연 로딩, 변경 감지\n      🚀 검증\n    \n  \n\n\n \n\n📕 Persistence Context\n\n\n\n🚀 About Persistence Context\n\n\n\n \n\n\n\n \n\n영속성 컨텍스트(Persistence Context)는 간단하게 설명하자면 애플리케이션과 데이터베이스 사이에 위치한 가상의 데이터베이스이다.\n\n내부 데이터는 HashMap으로 구성돼있으며, key=value : id=Entity 로 돌아간다.\n\n그리고 이 가상 데이터베이스를 관리하는 객체가 EntityManager이다.\n\nEntityManager는 Thraed-Safe하지 않고, 각자 고유한 Scope를 갖기 때문에 보통 한 스레드에서 하나만 생성하며 Transaction위에서만 제대로 동작하므로 Transaction 설정이 매우 중요하다.\n\nEntityManager를 생성하기 위해서는 EntityManagerFactory가 필요하며 EntityManagerFactory는 DBCP와 매핑되어있다.\n\nHibernate에서 EntityManagerFactory를 구현한 콘크리트 클래스는 SessionFactoryImpl이며 아래와 같은 시그니처를 갖는다.\n\npublic interface SessionFactory extends EntityManagerFactory{}\n\npublic interface SessionFactoryImplementor extends SessionFactory{}\n\npublic class SessionFactoryImpl implements SessionFactoryImplementor{}\n\n\n\n\nSessionFactoryImpl에 대해서 공식문서에서는 하기와 같이 설명하고 있다.\n\n \n\n\n  SessionFactoryImpl는 SessionFactory interface를 구현한 콘크리트 클래스이며, 다음과 같은 책임을 갖는다\n\n  \n    캐시 구성을 설정한다 (불변성을 갖는다)\n    Entity-테이블 매핑, Entity 연관관계 매핑 같은 컴파일성 매핑을 캐시한다\n    메모리를 인식하여 쿼리를 캐시한다\n    PreparedStatements를 관리한다\n    ConnectionProvider에게 JDBC 관리를 위임한다\n    SessionImpl를 생성해낸다\n  \n\n  또한, 다음과 같은 특징 및 주의사항이 있다.\n\n  이 클래스는 클라이언트에게 반드시 불변 객체로 보여야 하며, 이는 모든 종류의 캐싱 혹은 풀링을 수행할 경우에도 마찬가지로 적용된다.\nSessionFactoryImpl는 Thread-Safe 하기 때문에 동시적으로 사용되는 것이 매우 효율적이다. 또한 동기화를 사용할 경우 매우 드물게 사용되어야 한다.\n\n\n \n\n즉, EntityManagerFactory는 불변 객체이기 때문에 Thread-Safe 하며 이 말인즉슨, 싱글톤 패턴을 이용하여 계속해서 재활용할 수 있음도 의미한다고 볼 수 있다.\n\n다음은 싱글톤과 정적 팩토리를 활용하여 EntityManagerFactory와 EntityManager를 사용하는 예제이다.\n\n \n\npublic class PersistenceFactory {\n    private static final EntityManagerFactory emf = Persistence.createEntityManagerFactory(\"persistenceUnitName\");\n\n    private PersistenceFactory() {\n    }\n\n    public static EntityManager getEntityManager() {\n        return emf.createEntityManager();\n    }\n}\n\n@SpringBootTest\nclass JpaTest {\n    @Test\n    @DisplayName(\"순수_JPA_테스트_샘플\")\n    void jpaTest() throws Exception {\n        EntityManager em = PersistenceFactory.getEntityManager(); // get Singleton instance\n        EntityTransaction tx = em.getTransaction();\n        tx.begin();\n        // given\n        Member member = Member.builder()\n                              .name(\"홍길동\")\n                              .age(30)\n                              .build();\n\n        // when\n        try {\n            em.persist(member);\n            em.flush();\n\n            Member findMember = em.find(Member.class, member.getId());\n\n            // then\n            assertThat(findMember).isSameAs(member);\n            tx.commit();\n        }\n        catch(Exception e) {\n            tx.rollback();\n        }\n        finally {\n            em.close();\n        }\n    }\n}\n\n\n영속성 컨텍스트(Persistence Context)를 사용하기 위해서는 EntityManager가 필요하고, EntityManager를 사용하기 위해서는 EntityManagerFactory가 필요함을 알았으며, EntityManagerFactory에 대해 대충이나마 알아보았다.\n\n \n\n다음으로 EntityManager에 대해 알아보자.\n\n \n\n우선 EntityManager는 특이한 성질을 하나 갖는다. DB Connection을 LAZY 상태로 가져간다는 것이다.\n\n이게 무슨 말이냐면, EntityManager가 생성되며 DBCP와 매핑된 EntityManagerFacotry에서 자연스럽게 Connection을 얻지만 이 Connection이 꼭 필요한 상황, 즉 후술 할 flush 메서드가 호출되는 시점에서야 Connection을 사용한다는 점이다.\n\n이는 Connection이 과도하게 남용되어 Connection이 부족해질 상황을 대비하기 위한 설계 의도로 보인다.\n\n이러한 속성이 있음을 우선 인지하자.\n\n \n\nEntityManager는 애플리케이션과 데이터베이스 사이에 위치한 가상의 데이터베이스라고 하였었다.\n\n일단 공식문서를 먼저 참고한다.\n\n \n\n\n  EntityManager 인스턴스는 영속성 컨텍스트(PersistenceContext)와 연결되며, 영속성 컨텍스트는 단순히 Entity의 집합이다.\n\n  영속성 컨텍스트 내에서 모든 Entity 인스턴스의 생명주기가 관리되며, EntityManager의 모든 Public API들은 이 생명주기를 관리하는 데 사용된다.\n\n\n우선 이를 이미지로 보면 다음과 같다.\n\n \n\n\n\n \n\n위 이미지에서 영속성 컨텍스트라고 적혀있는 표는 영속성 컨텍스트(PersistenceContext)가 HashMap으로 가지고 있는 Entity들을 의미한다.\n\n또한 findById, flush 등의 API들은 이 영속성 컨텍스트(PersistenceContext)를 관리하는 EntityManager의 API라고 볼 수 있겠다.\n\n \n\n일반적으로 HashMap Key에 데이터베이스의 PK값이 들어가게 되며, Entity 객체와 데이터베이스 테이블을 매핑하고 (연관관계 매핑) 발생하는 데이터들을 데이터베이스와 직접 통신하는 것이 아닌, 내부적으로 존재하는 HashMap을 사용해 EntityManager가 가상의 데이터베이스 (=영속성 컨텍스트) 를 제어하며 처리하는 것이다.\n\n이렇게 함으로써 DB Connection을 최소화하여 데이터베이스 부하를 줄일 수 있게 된다.\n\n이후 작업이 끝나거나 작업 중에 flush가 호출되면 영속성 컨텍스트(PersistenceContext)의 데이터를 모두 한꺼번에 데이터베이스에 반영한다.\n\n \n\n대략 이러한 구조로 돌아가며, 이 정도의 설명으로는 아직 감이 잡히지 않을 수 있다.\n\n괜찮다. JPA에서 가장 이해하기 힘든 부분중 하나라고 생각하기 때문이다.\n\n잘 모르겠더라도 대략적인 감이나마 잡고 이후 많은 자료를 보며 사용하다 보면 이해하는 순간이 반드시 올 것이다.\n\n \n\n우선 영속성 컨텍스트(PersistenceContext)에 속하고 EntityManager가 처리하는 데이터들에는 생명주기(Life Cycle)라고 부르는 4가지의 상태가 존재한다.\n\n이를 Entity 생명주기(Life Cycle)라고 부른다.\n\n설명하기 전에 우선 위의 코드를 다시 첨부한다.\n\n\n\n@SpringBootTest\nclass JpaTest {\n    @Test\n    @DisplayName(\"순수_JPA_테스트_샘플\")\n    void jpaTest() throws Exception {\n        EntityManager em = PersistenceFactory.getEntityManager(); // get Singleton instance\n        EntityTransaction tx = em.getTransaction();\n        tx.begin();\n        // given\n        Member member = Member.builder()\n                              .name(\"홍길동\")\n                              .age(30)\n                              .build();\n\n        // when\n        try {\n            em.persist(member);\n            em.flush();\n\n            Member findMember = em.find(Member.class, member.getId());\n\n            // then\n            assertThat(findMember).isSameAs(member);\n            tx.commit();\n        }\n        catch(Exception e) {\n            tx.rollback();\n        }\n        finally {\n            em.close();\n        }\n    }\n}\n\n\n영속성 컨텍스트(PersistenceContext)에 속한 Entity객체는 다음과 같은 4가지 생명주기(Life Cycle)를 갖는다.\n\n \n\n\n\n \n\n\n  비영속(transient)\n\n  \n    Entity가 방금 인스턴스화 되었으며 아직 영속성 컨텍스트와 연관되지 않은 상태\n    데이터베이스와 동기화되지 않았으며 일반적으로 할당된 식별자 값이 사용되지 않았거나 식별자 값이 할당되지 않은 상태를 의미\n  \n\n\nMember member = Member.builder()\n                      .name(\"홍길동\")\n                      .age(30)\n                      .build();\n\n\n보다시피 Entity 객체가 막 생성됐다.\n\n이 객체에는 id가 없기 때문에 EntityManager는 이 객체와 영속성 컨텍스트(PersistenceContext)를 비교하여 비영속 상태로 간주하게 된다.\n\n \n\n\n\n \n\n\n  영속(managed or persistent)\n\n  \n    Entity에 연관된 식별자가 있으며 영속성 컨텍스트와 연관된 상태\n    데이터베이스와 논리적으로 동기화되어 있으나 물리적으로는 존재하지 않을 수도 있는 상태\n  \n\n\nem.persist(member);\n\n\n비영속 상태인 Entity의 데이터가 영속성 컨텍스트(PersistenceContext)에 등록되었으며, 내부적으로 HashMap으로 Entity를 관리하기 때문에 Key값이 반드시 필요하다.\n\n하지만 방금 등록된 Entity는 비영속 상태이므로 Key값으로 써야 할 id가 null이기 때문에 Entity 객체에 선언된 @GeneratedValue를 참조하여 id를 생성해낸다. 아무것도 설정하지 않을 경우 AUTO로 동작하며, AUTO는 DBCP와 연결된 데이터베이스의 기본 동작을 따라간다.\n\n일반적으로 국내 업계에서 가장 많이 사용하는 상용 데이터베이스는 MySQL 혹은 MariaDB인데 (무료여서), 이 데이터베이스들의 경우 auto_increment를 지원하므로 이 경우 IDENTITY전략을 통해 사용하게 된다.\n\n@Id @GeneratedValue(strategy = GenerationType.IDENTITY)\nprivate Long id;\n\n\n \n\n\n\n \n\n\n  준영속(detached)\n\n  \n    Entity에 연관된 식별자가 있지만 더 이상 영속성 컨텍스트와 연관되지 않은 상태(분리된 상태)\n    일반적으로 영속성 컨텍스트가 close 되었거나 인스턴스가 영속성 컨텍스트에서 제거된 상태를 의미\n  \n\n\nem.detach(member);\n\n\n이 준영속 상태가 처음에 많이 헷갈린다.\n\n하지만 다행스럽게도 준영속 상태와 비영속 상태는 결정적인 차이가 딱 하나 존재한다.\n\n비영속 상태는 식별자가 있을 수도 있고, 없을 수도 있다. 이게 무슨 말이냐면,\n\n상기 비영속 상태 예제는 개발자가 Entity 객체 생성 시 id를 초기화하지 않았으므로 식별자가 존재하지 않는다. (Wrapper인 Long이므로 Nullable 하다)\n\n하지만 준영속 상태의 경우 식별자가 반드시 존재한다.\n\n \n\n준영속 상태는 객체가 영속성 컨텍스트(PersistenceContext)에 한번 속했다가 떨어져 나온 객체. 즉 영속성 컨텍스트(PersistenceContext) 내부 HashMap에서 Entity가 삭제된 상태를 의미하는데,\n\n비영속 상태의 객체를 EntityManager를 통해 영속성 컨텍스트(PersistenceContext)에 등록하게 되면 id를 어떻게든 생성해내고, 반대로 데이터베이스에서 데이터를 읽어왔다면 데이터베이스 테이블에 기본 키가 없을수가 없기때문에 (무결성 제약조건) 영속성 컨텍스트(PersistenceContext)에도 id가 반드시 존재하기 때문이다.\n\n \n\n여기서 재미있는 현상이 하나 생기는데, 그렇다면 개발자가 처음 Entity 객체를 생성해낼 때 id를 초기화해서 생성한다면 어떻게 될까?\n\n정답은 EntityManager가 id가 존재하는 비영속 상태의 Entity객체를 비영속 상태가 아닌 준영속 상태로 간주한다.\n\n \n\nEntityManager입장에서 준영속 상태라는 것은 영속성 컨텍스트(PersistenceContext) 내부 HashMap에 같은 식별자를 갖는 Entity가 존재하지 않는데, Entity에는 식별자가 있는 모든 경우를 의미하기 때문이다.\n\n그래서 이런 경우 persist 뿐만 아니라 merge 메서드도 먹힌다. 비영속 상태임에도 불구하고 말이다.\n\n \n\n\n\n \n\n\n  삭제(removed)\n\n  \n    Entity에는 연관된 식별자가 있고 영속성 컨텍스트와 연관되어 있지만 데이터베이스에서 삭제되도록 예약된 상태\n    최종적으로 영속성 컨텍스트와 데이터베이스에서 모두 삭제된다\n  \n\n\nem.remove(member);\n\n\n이 메서드가 호출되면 해당 Entity객체는 EntityManager를 통해 영속성 컨텍스트(PersistenceContext)에서 삭제가 예약 되며,\n\n이후 flush가 호출되면 영속성 컨텍스트(PersistenceContext)에서 삭제됨과 동시에 데이터베이스를 향해 delete쿼리가 발생한다.\n\n🚀 1차 캐시\n\n\n\n \n\n영속(persistent) 상태의 Entity는 모두 이곳에 HashMap(key(@Id) = value(Entity))으로 저장된다.\n\n따라서 식별자(@Id)가 없다면 제대로 동작하지 못하며 예외를 발생시킨다.\n\n// Entity - 비영속(transient)\nMember member = new Member();\nmember.setId(\"member1\");\nmember.setUsername(\"member\");\n\n\n// Entity - 영속(persistent)\nem.persist(member);\n\n\n// 1차 캐시 조회\nem.find(Member.class, \"member1\");\n\n\nJPA는 어떠한 명령에 대해 데이터베이스에 접근하기 전에 항상 이 1차 캐시에서 먼저 작업을 진행한다.\n\n이렇게 동작하는 이유는 데이터베이스 접속을 최소화하여 리소스를 효율적으로 사용할 수 있기 때문이다.\n\n따라서 위 코드에서 em.find()가 실행될 시점에 실제 데이터베이스에 접근해서 값을 가져오는 게 아니고\n\n1차 캐시에 저장되어 있는 (하지만 데이터베이스에는 아직 반영되지 않은) member 객체를 가져온다.\n\n@Test\npublic void cashTest() {\n    try {\n\n        System.out.println(\"=================== new Member ===================\");\n        Member member = Member.builder()\n                              .name(\"강동원\")\n                              .age(30)\n                              .build();\n        System.out.println(\"=================== em.persist ===================\");\n        em.persist(member);\n        System.out.println(\"==================================================\");\n\n        System.out.println(\"=================== em.find ===================\");\n        Member findMember = em.find(Member.class, member.getId());\n        System.out.println(\"member = \" + findMember);\n\n        tx.commit();\n    }\n    catch(Exception e) {\n        tx.rollback();\n    }\n}\n\n\n=================== new Member ===================\n=================== em.persist ===================\nHibernate: \n    call next value for hibernate_sequence\n==================================================\n=================== em.find ===================\nmember = Member(id=1, name=강동원, age=30)\nHibernate: \n    /* insert board.Member\n        */ insert \n        into\n            MEMBER\n            (age, name, id) \n        values\n            (?, ?, ?)\n\n\n \n\n쿼리 순서를 보자.\n\nem.find()가 실행된 후에야 insert쿼리가 나가고 select쿼리는 그 어디에도 보이지 않는다.\n\n왜 이런 현상이 발생하냐면, em.persist()가 실행될 때 데이터베이스에 저장된 게 아니고\n\n영속성 컨텍스트의 1차 캐시에 먼저 저장되어있는 상태에서 em.find()가 실행됐기 때문이다.\n\nEntityManager는 정해진 규칙대로 데이터베이스에 접근하기 전 1차 캐시를 먼저 뒤졌고, 1차 캐시에서 식별자를 통해 알맞은 객체를 찾아 가져온 것이다.\n\n따라서 select쿼리를 데이터베이스에 날릴 필요가 없게 된 것이다.\n\n그 후 tx.commit()이 실행되는 시점에서야 flush가 호출되며 데이터베이스에 insert쿼리를 날린 것이다.\n\nEntityTransaction 객체의 commit() 메서드를 살펴보면 실제로 내부에 flush 메서드가 포함되어 있음을 알 수 있다.\n\n@Override\npublic void commit() {\n    errorIfInvalid();\n    getTransactionCoordinatorOwner().flushBeforeTransactionCompletion(); // flush\n\n    // we don't have to perform any before/after completion processing here.  We leave that for\n    // the Synchronization callbacks\n    jtaTransactionAdapter.commit();\n}\n\n\n \n\n다른 예제를 보겠다.\n\n \n\n@Test\npublic void cashTest() {\n    try {\n\n        System.out.println(\"=================== new Member ===================\");\n        Member member = Member.builder()\n                              .name(\"강동원\")\n                              .age(30)\n                              .build();\n        System.out.println(\"=================== em.persist ===================\");\n        em.persist(member);\n        System.out.println(\"==================================================\");\n\n        em.flush();\n        em.clear();\n\n        System.out.println(\"=================== em.find ===================\");\n        Member findMember = em.find(Member.class, member.getId());\n        System.out.println(\"member = \" + findMember);\n\n        tx.commit();\n    }\n    catch(Exception e) {\n        tx.rollback();\n    }\n}\n\n\n=================== new Member ===================\n=================== em.persist ===================\nHibernate: \n    call next value for hibernate_sequence\n==================================================\nHibernate: \n    /* insert board.Member\n        */ insert \n        into\n            MEMBER\n            (age, name, id) \n        values\n            (?, ?, ?)\n=================== em.find ===================\nHibernate: \n    select\n        member0_.id as id1_1_0_,\n        member0_.age as age2_1_0_,\n        member0_.name as name3_1_0_ \n    from\n        MEMBER member0_ \n    where\n        member0_.id=?\nmember = Member(id=1, name=강동원, age=30)\n\n\n \n\n이번엔 중간에 EntityManger를 통해 영속성 컨텍스트(Persistence Context)를 강제로 flush → clear 했다.\n\n이는 영속성 컨텍스트에 저장돼있는 Entity를 모두 데이터베이스에 동기화(flush)하고,\n\n영속성 컨텍스트의 모든 Entity를 제거(clear)했음을 의미한다.\n\n실제 쿼리가 나가는 순서를 보면 flush → clear 할 때 insert쿼리가 실행됐고,\n\n그 후 em.find() 메서드가 실행되며 1차 캐시를 뒤졌지만\n\n알맞은 Entity정보를 찾지 못해 그제야 데이터베이스에 접근하며 select쿼리가 나감을 확인할 수 있다.\n\n \n\n🚀 동일성 보장\n\n\n\n1차 캐시와 연관된 내용이다.\n\n그냥 간단하게 1차 캐시를 통해 모든 작업을 처리하기 때문에 객체의 동일성 (메모리 주소가 같음을 의미한다) 이 보장된다는 이야기다.\n\n간단하게 코드로 보자.\n\n@Test\npublic void cashTest() {\n    try {\n\n        System.out.println(\"=================== new Member ===================\");\n        Member member = Member.builder()\n                              .name(\"강동원\")\n                              .age(30)\n                              .build();\n        System.out.println(\"=================== em.persist ===================\");\n        em.persist(member);\n\n        System.out.println(\"=================== em.find ===================\");\n        Member findMember1 = em.find(Member.class, member.getId());\n        Member findMember2 = em.find(Member.class, member.getId());\n        System.out.println(\"compare = \" + (findMember1 == findMember2));\n\n        tx.commit();\n    }\n    catch(Exception e) {\n        tx.rollback();\n    }\n}\n\n\n=================== new Member ===================\n=================== em.persist ===================\nHibernate: \n    call next value for hibernate_sequence\n=================== em.find ===================\ncompare = true\nHibernate: \n    /* insert board.Member\n        */ insert \n        into\n            MEMBER\n            (age, name, id) \n        values\n            (?, ?, ?)\n\n\nem.persist(member)가 실행되며 1차 캐시에 member Entity의 정보가 저장되었고 (영속 상태),\n\nMember findMember1 = em.find(Member.class, member.getId());\nMember findMember2 = em.find(Member.class, member.getId());\n\n\n \n\n를 통해 1차 캐시에서 같은 Entity객체를 두 번 가져와 각각 다른 레퍼런스 변수에 주소를 할당했다.\n\n따라서 두 객체는 같은 주소를 가지므로 완벽하게 동일하기 때문에\n\n\n  compare = true\n\n\n라는 결과가 나온다.\n\n마지막으로 tx.commit() 메서드가 실행되며 insert쿼리가 나간다.\n\n1차 캐시를 제대로 이해했다면 너무나 당연한 이야기다.\n\n \n\n🚀 쓰기 지연, 지연 로딩, 변경 감지\n\n\n\n역시 모두 1차 캐시와 관련된 내용이다.\n\n쓰기 지연은 위 코드와 같이 insert쿼리가 flush가 호출되는 시점에 발생하는 것을 의미하며,\n\n지연 로딩 또한 마찬가지로 위 코드와 같이 실제 작업이 실행되는 순간에 select쿼리가 나가는 현상을 말한다.\n\n각 작업들을 1차 캐시에 저장해 두고 이를 한 번에 작업해서 효율을 올리겠다는 설계 의도로 보인다.\n\n변경 감지의 경우 JPA에는 update 관련 API가 따로 존재하지 않는데 이에 대한 내용이다.\n\nEntityManager가 영속성 컨텍스트(Persistence Context)를 통해 관리하는 Entity는 객체의 정보가 변경될 경우 EntityManager가 이를 감지하고\n\nupdate쿼리를 자동으로 날려준다.\n\n이는 영속성 컨텍스트(Persistence Context) 내부에 각 Entity 객체에 대한 스냅샷(Snap-Shot)이 존재하기 때문에 가능한 일이다.\n\n역시 코드를 보자.\n\n@Test\npublic void cashTest() {\n    try {\n        System.out.println(\"=================== new Member ===================\");\n        Member member = Member.builder()\n                              .name(\"강동원\")\n                              .age(30)\n                              .build();\n        System.out.println(\"=================== em.persist ===================\");\n        em.persist(member);\n\n        System.out.println(\"=================== em.find ===================\");\n        Member findMember = em.find(Member.class, member.getId());\n\n        System.out.println(\"=================== em.update ===================\");\n        findMember.setName(\"강동원아님\");\n\n        tx.commit();\n    }\n    catch(Exception e) {\n        tx.rollback();\n    }\n}\n\n\n=================== new Member ===================\n=================== em.persist ===================\nHibernate: \n    call next value for hibernate_sequence\n=================== em.find ===================\n=================== em.update ===================\nHibernate: \n    /* insert board.Member\n        */ insert \n        into\n            MEMBER\n            (age, name, id) \n        values\n            (?, ?, ?)\nHibernate: \n    /* update\n        board.Member */ update\n            MEMBER \n        set\n            age=?,\n            name=? \n        where\n            id=?\n\n\n \n\n두 눈을 씻고 다시 봐도 위 코드 어디에도 em.update(member) 같은 코드는 보이지 않는다\n\n그럼에도 불구하고 실제로 update쿼리가 날아갔다.\n\n하지만 가만 보면 살짝 이상한 부분이 보인다.\n\ninsert쿼리가 먼저 한번 나간 후 update쿼리가 나간다.\n\n이는 JPA가 동작하는 내부적인 방식으로 인한 현상인데.\n\nem.persist(member)가 실행될 때 영속성 컨텍스트(Persistence Context)에 member객체가 저장되며\n\n이때의 상태(최초 상태)를 따로 저장하는데 이를 바로 스냅샷(Snap-Shot)이라 한다.\n\n그리고 EntityManager는 트랜잭션이 commit 되는 시점에 현재 영속성 컨텍스트(Persistence Context)의 정보와 스냅샷(Snap-Shot)의 정보를 비교하여 update 쿼리를 작성하기 때문에 최초에 insert 쿼리가 한 번 날아간 후 비교를 통해 작성된 update쿼리가 한번 더 날아가는 것이다.\n\n \n\n🚀 검증\n\n\n\n아래의 예제는 @GeneratedValue(strategy = GenerationType.IDENTITY)가 아닌, @GeneratedValue(strategy = GenerationType.SEQUENCE)로 진행하였다.\n\n@Test\npublic void persistenceContextTest() throws Exception {\n    try {\n        Member member = Member.builder()\n                              .name(\"홍길동\")\n                              .age(30)\n                              .build();\n\n        System.out.println(\"=============== persist() ===============\");\n        em.persist(member);\n\n        System.out.println(\"=============== detach() ===============\");\n        em.detach(member);\n\n        System.out.println(\"=============== commit() ===============\");\n        tx.commit();\n\n    }\n    catch(Exception e) {\n        System.out.println(\"EXCEPTION -&gt; \" + e.getMessage());\n        tx.rollback();\n    }\n}\n\n\n \n\n\n\n \n\nem.persist()가 실행되는 시점에 쓰기 지연 저장소에 insert쿼리를 작성하기 위해\n\nhibernate_sequence에 채번을 요청했음을 알 수 있다.\n\n\n  Hibernate: call next value for hibernate_sequence\n\n\n \n\n해당 시점에 1차 캐시에는 hibernate_sequence에서 얻어온 식별자 값으로\n\nmember의 정보와 member의 insert쿼리가 들어있는 상태이다.\n\n직후 member는 detach 메서드로 인해 준영속 상태가 되었으므로\n\n1차적으로 1차 캐시에서 member의 정보가 삭제되고,\n\n2차적으로 쓰기 지연 SQL 저장소에 저장되어있던 insert쿼리도 삭제되었다.\n\n따라서 커밋 시점엔 아무런 쿼리도 나가지 않았다.\n\n \n\n\n\n \n\n@Test\npublic void persistenceContextTest() throws Exception {\n    try {\n        Member member = Member.builder()\n                              .name(\"홍길동\")\n                              .age(30)\n                              .build();\n\n        System.out.println(\"=============== persist() ===============\");\n        em.persist(member);\n\n        System.out.println(\"=============== flush() ===============\");\n        em.flush();\n\n        System.out.println(\"=============== detach() ===============\");\n        em.detach(member);\n\n        System.out.println(\"=============== merge() -&gt; update ===============\");\n        Member mergeMember = em.merge(member);\n        System.out.println(\"병합 시점의 이름은 = \" + mergeMember.getName());\n        mergeMember.setName(\"홍길동 아니다\");\n        System.out.println(\"수정 후 이름은 = \" + mergeMember.getName());\n\n        System.out.println(\"=============== commit() ===============\");\n        tx.commit();\n\n    }\n    catch(Exception e) {\n        System.out.println(\"EXCEPTION -&gt; \" + e.getMessage());\n        tx.rollback();\n    }\n}\n\n\n \n\n\n\n \n\n준영속 상태와 비영속 상태가 다른 점은 식별자의 유무라고 했었다.\n\n비영속 상태는 식별자가 있을 수도 있고 없을 수도 있다.\n\n준영속 상태는 비영속 상태와 거의 동일하지만 한번 영속 상태였다가 영속 상태가 아니게 된 경우이므로\n\n준영속 상태는 반드시 식별자 값을 가지고 있다.\n\n \n\n위 코드의 실행 흐름을 보면 처음 member 객체는\n\n홍길동이라는 이름으로 비영속 상태가 되었고 persist 되어 영속 상태가 되었다.\n\n그리고 flush가 호출되며 해당 정보는 데이터베이스에 반영되며 insert쿼리가 나갔다.\n\n직후 detach 실행 후 준영속 상태로 변경되며 영속성 컨텍스트에서 해당 객체가 삭제된 상태에서\n\n다시 바로 merge가 호출됐고, 데이터베이스와의 동기화를 위해 객체가 들고 있는 식별자로 select쿼리를 날리는 걸 확인할 수 있다.\n\n \n\n병합 시점의 이름은 = 홍길동\n수정 후 이름은 = 홍길동 아니다\n\n\n \n\n그래서 위와 같은 메시지가 콘솔에 출력되었고\n\n이후 영속성 컨텍스트(Persistence Context)가 변경 감지를 통해 update쿼리를 발생시킨다.\n\n \n\n\n\n \n\n@Test\npublic void persistenceContextTest() throws Exception {\n    try {\n        System.out.println(\"=============== member 인스턴스 생성 ===============\");\n        Member member = Member.builder()\n                              .name(\"홍길동\")\n                              .age(30)\n                              .build();\n        System.out.println(\"em.contains(member) = \" + em.contains(member));\n\n        System.out.println(\"=============== persist ===============\");\n        em.persist(member);\n        System.out.println(\"em.contains(member) = \" + em.contains(member));\n\n        System.out.println(\"=============== detach ===============\");\n        em.detach(member);\n        System.out.println(\"em.contains(member) = \" + em.contains(member));\n\n        System.out.println(\"=============== commit ===============\");\n        tx.commit();\n    }\n    catch(Exception e) {\n        System.out.println(\"EXCEPTION -&gt; \" + e.getMessage());\n        tx.rollback();\n    }\n}\n\n\n \n\n\n\n \n\nem.contains 메서드는 해당 Entity가 영속성 컨텍스트(Persistence Context)에 존재하는 객체인지 아닌지를 boolean 값으로 출력해주는 메서드다.\n\nmember 객체가 처음 생성될 때(비영속 상태) contains는 false를 반환한다.\n\n이후 persist 되어 영속 상태가 된 시점에는 true를 반환한다.\n\n다시 detach 되어 준영속 상태가 된 시점에는 false를 반환하는 것을 확인할 수 있다.\n\n \n\n\n\n \n\n@Test\npublic void persistenceContextTest() throws Exception {\n    try {\n        System.out.println(\"=============== member 인스턴스 생성 ===============\");\n        Member member = Member.builder()\n                              .id(1L)\n                              .name(\"홍길동\")\n                              .age(30)\n                              .build();\n        System.out.println(\"em.contains(member) = \" + em.contains(member));\n\n        System.out.println(\"=============== merge ===============\");\n        Member mergeMember = em.merge(member);\n        System.out.println(\"em.contains(member) = \" + em.contains(member));\n        System.out.println(\"em.contains(mergeMember) = \" + em.contains(mergeMember));\n\n        System.out.println(\"=============== commit ===============\");\n        tx.commit();\n    }\n    catch(Exception e) {\n        System.out.println(\"EXCEPTION -&gt; \" + e.getMessage());\n        tx.rollback();\n    }\n}\n\n\n \n\nmember 객체는 비영속 상태이지만 식별자 값을 갖고 있기 때문 에\n\nem.merge(member)가 먹히며 영속성 컨텍스트(Persistence Context)는 member 객체가 merge 되는 시점에\n\n데이터베이스와의 동기화를 위해 member 객체가 가지고 있는 식별자 값으로 select쿼리를 날렸고,\n\n데이터베이스에는 id=1에 해당하는 정보가 없기 때문에\n\n영속성 컨텍스트에 등록하기 위해 채번을 요청하였음을 확인할 수 있다.\n\n \n\nHibernate: \n    call next value for hibernate_sequence\n\n\n \n\n그리고 한 가지 더 흥미로운 점이 있다.\n\n \n\n\n\n \n\nmerge는 준영속 객체 자체를 바로 영속성 컨텍스트(Persistence Context)에 올리는 것이 아니고\n\n새로운 객체를 만들어서 영속성 컨텍스트에 올린다는 것을 위의 로그로 확인할 수 있다.\n\n그리고 영속성 컨텍스트에는 정보가 있지만 데이터베이스에는 정보가 없으므로 이 또한 동기화를 위해\n\n커밋되는 시점에 merge 된 member 객체의 정보를\n\n데이터베이스에 insert쿼리를 통해 등록하는 모습을 확인할 수 있다.\n\n그러므로 merge는 실제로 CRUD 상에서\n\nCreate 또는 Update 기능을 동시에 수행할 수 있다고 볼 수 있겠다.\n\n \n\n\n\n \n\n이런 간단한 검증실험을 통해 알 수 있는 것은\n\n영속성 컨텍스트(Persistence Context)는 애플리케이션과 데이터베이스 사이에서 가상의 데이터베이스 역할을 수행한다는 것이다.\n\n그래서 트랜잭션이 commit 되거나 flush가 직접 호출되는 되는 시점에\n\n모든 식별자 값을 통해 영속성 컨텍스트의 내용을 실제 데이터베이스의 내용과 동기화시킨다는 점이다.\n\n@Test\npublic void persistenceContextTest() throws Exception {\n    try {\n        System.out.println(\"=============== findById ===============\");\n        Member member1 = em.find(Member.class, 1L);\n        Member member2 = em.find(Member.class, 2L);\n        Member member3 = em.find(Member.class, 3L);\n\n        System.out.println(\"=============== member1 update ===============\");\n        member1.setName(\"나 홍길동 아니다\");\n        member1.setAge(1);\n\n        System.out.println(\"=============== member2 update ===============\");\n        member2.setName(\"동방삭\");\n        member2.setAge(9999);\n\n        System.out.println(\"=============== commit ===============\");\n        tx.commit();\n    }\n    catch(Exception e) {\n        System.out.println(\"EXCEPTION -&gt; \" + e.getMessage());\n        tx.rollback();\n    }\n}\n\n\n \n\n\n\n \n\nem.find()를 통해 3가지 객체에 대한 정보를 가져오므로 3번의 select쿼리가 발생하고\n\n그중 2가지 객체의 정보를 변경하였으므로 2번의 update쿼리가 발생한다.\n\n이를 이미지를 통해 보면 아래와 같다.\n\n \n\n\n\n \n\n\n\n \n\nJPA를 사용할 때 가장 중요하게 생각해야 할 점은 영속성 컨텍스트(Persistence Context)에 대한 이해이다.\n\n영속성 컨텍스트(Persistence Context)는 애플리케이션과 데이터베이스의 사이에 존재하는 가상의 데이터베이스 이다.\n\n이러한 개념에 대한 이해가 제대로 되지 않은 상태에서 JPA를 사용한다면\n\n예상과 다른 쿼리가 발생하거나, 쿼리가 지나치게 많이 발생하거나 하는 문제들이 자주 발생하며,\n\n이러한 문제들로 인해 심각한 성능저하가 발생되어도 그러한 문제를 해결하지 못할 가능성이 높다.\n\n \n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-06-23-jpa-3/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "JPA 기초 4 - 엔티티 매핑(Entity Mapping)",
      "date": "2021-06-27 23:43:00 +0000",
      "description": "엔티티 매핑에 대한 기본 개념\n",
      "content": "\n  📕 Entity Mapping    \n      💨 Naming Strategy..\n    \n  \n  🚀 @Entity    \n      @Entity 제약사항\n    \n  \n  🚀 @Table    \n      💥 DDL 옵션은 항상 신중하게 확인해야 한다 💥\n    \n  \n  🚀 @Id, @GeneratedValue\n  🚀 @Column\n  🚀 @Enumerated\n  🚀 @Temporal\n  🚀 @Lob\n  🚀 @Transient\n  🚀 @Access\n\n\n \n\n📕 Entity Mapping\n\n\n\n\n\n\n\nJPA를 사용하는 데 가장 중요한 일은 Entity와 Table을 정확하게 매핑하는 것이다.\n\nJPA의 매핑 어노테이션은 크게 4가지로 분류할 수 있다.\n\n\n\n\n  객체(Entity) ↔ 테이블(Table): @Entity, @Table\n  기본 키(PK, Primary Key): @Id\n  필드(Field) ↔ 컬럼(Column): @Column\n  연관관계(FK, Foreign Key): @ManyToOne, @ManyToMany, @OneToMany, @OneToOne, @JoinColumn\n\n\n\n\n💨 Naming Strategy..\n\n\n\nSpring Data Jpa 사용시 hibernate가 기본 구현체로 채택돼있고, hibernate 매핑시 ImprovedNamingStrategy를 기본 클래스로 사용하고 있는걸로 판단된다.\n\n같은 NamingStrategy 인터페이스를 구현한 DefaultNamingStrategy도 존재하는데, 이름만 보면 이녀석이 디폴트가 맞는 것 같은데…\n\n정확한 동작과 내부 구현에 대해서는 추후 심도깊게 파봐야겠다.\n\n일단 ImprovedNamingStrategy는 간단하게\n\n\n\n\n  소문자 -&gt; 소문자\n  대문자 -&gt; 대문자\n  카멜 케이스 -&gt; 스네이크 케이스\n\n\n\n\n로 변환하여 매핑해주는 걸로 보인다.\n\n\n\n🚀 @Entity\n\n\n\n이 어노테이션이 붙은 클래스는 JPA에서 관리하게 된다.\n\n따라서 JPA의 모든 기능을 이용하고자 한다면 필수적으로 사용하게 되는 어노테이션이다.\n\n\n\n\n\n\n\n\n  \n    \n      속성\n      기능\n      기본값\n    \n  \n  \n    \n      name\n      JPA에서 사용할 엔티티 이름을 지정한다. 이후 JPQL등에서 이 이름을 사용한다. 프로젝트 전체에서 고유한 이름을 설정해야만 충돌로 인한 문제가 발생하지 않는다.\n      클래스 이름을 그대로 사용한다.\n    \n  \n\n\n\n\n@Entity 제약사항\n\n\n\n\n  접근제한자가 public또는 protected인 기본 생성자가 반드시 필요하다.\n  final, enum, interface, inner 클래스에서는 사용할 수 없다.\n  저장할 필드에 final을 사용할 수 없다.\n\n\n\n\n엔티티 객체는 내부적으로 Class.getDeclaredConstructor().newInstance() 라는 자바 리플렉션을 사용하여 동작하는데 이 API는 생성자의 인수를 읽을 수 없기 때문에 인수가 존재하지 않는 기본 생성자가 반드시 필요하다.\n\nJPA 구현체로 Hibernate 벤더를 사용하는 경우 Hibernate 내부적으로 바이트코드를 조작하는 라이브러리를 도입하여 이러한 이슈를 어느정도 보완해준다고 하나 역시 완벽한 해결책이 아니며 기본 생성자 없이 동작할 수도 있지만, 오히려 동작하지 않기도 하는 경우가 발생하여 오히려 더 안 좋은 상황을 야기할 수 있으므로, 기본 생성자 만큼은 반드시 생성하는걸 권고하고 있다.\n\n기본적으로 자바 컴파일러는 클래스에 아무 생성자도 없으면 인수가 존재하지 않는 생성자, 즉 기본 생성자를 알아서 만들어 주지만 임의의 생성자를 한개 이상 작성하였다면 이때 자바 컴파일러는 기본 생성자를 생성해주지 않기 때문에 에러가 발생한다.\n\n따라서 임의의 생성자를 작성하였을 경우 기본 생성자를 반드시 직접 작성 해 주어야 하며, 실무에서는 특별한 이유가 존재하지 않고서야 기본 생성자를 열어두지 않는 방향, 즉 제약적으로 개발하는게 일반적이기 때문에 package-private 또는 private으로 많이 작성하게 되나, 엔티티의 경우 반드시 protected 이상의 접근제한자가 허용되어 있어야 하기 때문에 일반적으론 protected로 많이 생성하게 된다.\n\n\n\n@Entity\npublic class Memeber{\n    @Id\n    private Long id;\n    private String name;\n\n    protected Member() {\n    }\n    // omitted for brevity\n}\n\n@Entity\n@NoArgsConstructor(access = AccessLevel.PROTECTED) // use lombok\npublic class Memeber{\n    @Id\n    private Long id;\n    private String name;\n    // omitted for brevity\n} \n\n\n\n\n🚀 @Table\n\n\n\n엔티티와 매핑할 데이터베이스 테이블을 지정한다.\n\n생략하면 엔티티 이름을 기본값으로 사용한다고 하는데, 여기서 말하는 엔티티 이름이 @Entity(name = \"\")인지, 엔티티 클래스의 이름인지는 명확하지 않다.\n\n추후 따로 테스트를 통해 알아봐야겠다.\n\n\n\n\n\n \n\n\n  \n    \n      속성\n      기능\n      기본값\n    \n  \n  \n    \n      name\n      JPA에서 사용할 엔티티 이름을 지정한다. 이후 JPQL등에서 이 이름을 사용한다. 프로젝트 전체에서 고유한 이름을 설정해야만 충돌로 인한 문제가 발생하지 않는다.\n      클래스 이름을 그대로 사용한다.\n    \n    \n      catalog\n      catalog 기능이 있는 DB에서 catalog를 매핑한다.\n      -\n    \n    \n      schema\n      schema 기능이 있는 DB에서 scheme를 매핑한다\n      -\n    \n    \n      uniqueConstraints\n      DDL 생성 시 복합 유니크 인덱스를 생성한다.  단일 유니크 인덱스도 만들 수 있으나, 후술할 @Column에 더 좋은 기능이 존재하므로 잘 사용하지 않는다. 이 기능은 설정파일의 DDL 옵션에 따라 동작한다.\n      -\n    \n  \n\n\n\n\n\n  DDL 옵션\n\n  create: 애플리케이션 시작 시 모든 스키마를 드랍 후 새로 생성\n\n  create-drop: 애플리케이션 시작 시 모든 스키마 드랍 후 생성, 애플리케이션 종료 시 모든 스키마 드랍\n\n  update: 애플리케이션 시작 시 기존 스키마에서 변경된 내역을 적용\n\n  validate: 애플리케이션 시작 시 스키마가 제대로 매핑되는지 유효성 검사만 진행. 실패하면 애플리케이션을 종료\n\n  none: JPA DDL 옵션을 사용하지 않음\n\n  #application.yaml\nspring:\n  jpa:\n    hibernate:\n      ddl-auto: create-drop\n  \n\n\n\n\n💥 DDL 옵션은 항상 신중하게 확인해야 한다 💥\n\n\n\n실무에서 이 옵션으로 인해 중요한 테이블이 통째로 드랍되거나, 중요한 데이터가 삭제되는 등의 많은 사고가 발생한다.\n\n실제로 필자도 토이 프로젝트에서 테이블을 날려먹어본 경험이 있으며, 이 때 백업을 해놓지 않아 굉장한 고생을 했었다.\n\n이러한 현상은 주니어 시니어를 가리지 않고 JPA를 처음 접한 대부분의 개발자라면 마치 당연하게 겪는 성장통처럼 느껴질 정도다.\n\n다만 실무에서 만큼은 이러한 사고를 치지 않도록 항상 스스로 주의해야 할 것이다.\n\n\n\n💥 재난급 서버 장애내고 개발자 인생 끝날뻔 한 썰 - 납량특집! DB에 테이블이 어디로 갔지?\n\n\n\n\n  출처: 개발바닥 유튜브\n\n\n\n\n🚀 @Id, @GeneratedValue\n\n\n\n\n\n\n\n일반적으로 @Id를 붙인 필드는 테이블의 기본키(PK)와 매핑된다.\n\n다만 오해하지 않아야 할 것은 반드시 물리적인 기본키와 매핑될 필요는 없다는 것이다.\n\n물리적인 기본키가 무슨 말이냐면, 데이터베이스에 설정되어있는 기본키를 말함이다.\n\nHibernate 공식 문서에서는 @Id가 무조건 PK와 매핑될 필요가 없으며, 다만 식별할 수 있는 값이기만 하면 된다고 하고 있다.\n\n이는 영속성 컨텍스트(Persistence Context)에 저장되는 엔티티들이 @Id를 key로 하여 HashMap으로 저장되는 특징 때문인 것으로 보인다.\n\n하지만 대부분의 상황이 관례적인 방법으로 모두 해결이 가능하기 때문에 일반적으로 데이터베이스의 기본키와 매핑하여 사용되고 있으며 이러한 방법으로 해결할 수 없는 특별한 상황에 대해서는 다른 방법을 강구해야 할 테니, 이런 내용에 대해서는 알아두면 좋겠다 싶었다.\n\n \n\nHibernate 공식 문서에는 @Id에 다음과 같은 타입을 지원한다고 적혀있다.\n\n\n\n\n  자바 기본타입(primitive type): int, long, float, double 등등\n  자바 래퍼타입(wrapper type): Integer, Long 등\n  String\n  java.util.Date\n  java.sql.Date\n  java.math.BigDecimal\n  java.math.BigInteger\n\n\n\n\n기본키를 사용하는 많은 방법이 존재하지만 실무에서는 일반적으로 primitive type은 사용하지 않는다.\n\n왜냐하면 기본타입(primitive type)인 int를 id로 사용한다고 하면, 값을 할당하지 않을 경우 0으로 초기화가 되는데 이럴 경우 id가 0인 데이터에 대해서 id를 할당하지 않았기 때문에 0인 것인지, 아니면 어떠한 의도를 갖고 id를 0으로 할당한 것인지 알 수 없다.\n\n\n\n하지만 오브젝트 타입(Object type)의 경우 nullable하기 때문에 값을 초기화하지 않는다면 null로 초기화가 되며, 만약 이러한 상황에서 id 값이 0인 데이터를 발견했다면 이는 어떠한 의도가 있기 때문에 id가 0이라는 것을 보장해줄 수 있게 된다.\n\n\n\n따라서 위의 이유로 대부분 id 필드로 Long을 가장 많이 사용하며, 간혹 String(UUID), Integer, BigDecimal 등을 사용하는 모습도 볼 수 있다.\n\n만약 본인이 기본타입을 id 필드로 사용하고 있었다면 앞으로는 혹시 모를 곤혹스런 상황이 발생할 것에 미리 대비하며 오브젝트 타입을 사용하는 습관을 들이자.\n\n \n\n기본키가 아닌 필드에 대해서는 약간 다르다.\n\n\n\n하이버네이트는 기본적으로 일반적인 필드도 오브젝트 타입을 사용하는걸 권장하고 있긴한데, 데이터베이스 컬럼에 not null 제약조건이 걸려있는 경우라면 약간 다르다.\n\n비교적 최근에 하이버네이트는 필드가 기본타입일 경우 not null 제약 조건을 자동으로 적용하게끔 변경되었으므로, 이 경우 엔티티 클래스에서 오브젝트 타입을 사용하고 @Column(nullable = false)를 붙이기 보다는 기본타입을 사용하는걸 고려하라고 한다.\n\n그리고 코드 레벨에서 유효성 검사(Validation)가 필요하다면 Spring Validation의 @NotNull 혹은 Lombok의 @NonNull을 사용하면 된다.\n\n \n\n실제로 테스트해본 결과 위 글대로 제대로 동작함을 확인했다.\n\n \n\n// file: 'for example'\n@Entity\npublic class Member{\n    @Id\n    private Long id;\n    \n    private String name; // nullable\n    \n    @NonNull // &lt;- 둘중하나\n    @NotNull // &lt;- 둘중하나\n    private int age; // not null\n}\n\n\n \n\n📜 하이버네이트 공식 문서\n\n  We recommend that you declare consistently-named identifier attributes\n\n  on persistent classes and that you use a nullable (i.e., non-primitive) type.\n\n\n \n\n@Entity\n@Table(name = \"request_log\")\npublic class RequestLog{\n    @Id @GeneratedValue // 아무것도 작성하지 않으면 AUTO\n    @Column(name = \"request_log_id\")\n    Long id;\n}\n\n\n\n\n\n\n\n\n각 DB 벤더는 기본키 자동생성 전략이 있는데, 업계에서 가장 많이 사용되는 벤더인 Oracle, MySQL 은 다음과 같은 기본키 생성전략을 사용한다.\n\n \n\n\n  Oracle -&gt; sequence\n  MySQL -&gt; auto_increment\n\n\n \n\n이러한 전략들을 JPA에서 사용하기 위해 @GeneratedValue를 사용하며, @GeneratedValue를 생략 할 경우 기본키 생성전략을 사용하지 않고 개발자가 직접 기본키를 할당해줘야 하기 때문에 @GeneratedValue는 필수가 아니지만 필수적으로 사용하게 된다.\n\n\n\n@GeneratedValue를 사용하지 않을 경우 하기와 같은 방식으로 기본키를 직접 할당해줘야 한다.\n\n\n\nMember member = new Member();\nmember.setId(1L)\nem.persist(member); // 혹은 memberRepository.save(member);\n\n\n\n\n@GeneratedValue를 사용 할 경우는 하기와 같다.\n\n\n\nMember member = new Member();\n\n// 저장되며 id 자동 생성\nem.persist(member); // 혹은 memberRepository.save(member);\n\n\n\n\n왜 사용하느냐면, 만약 기본키를 직접 할당해야 할 경우 새로 할당하려는 값이 이미 DB에 저장되어 있다면 기본키 무결성 제약조건을 위반하여 SQL Exception이 떨어지게 된다.\n\n하지만 이를 시스템에서 자동 생성하게 한다면 시스템이 알아서 새로 사용 할 수 있는 안전한 값을 찾아내어 생성하기 때문에 이러한 문제가 발생하지 않게 된다.\n\n@GeneratedValue의 기본키 생성전략은 아래와 같다.\n\n\n\n@GeneratedValue(strategy = GenerationType.TABLE)\n\n@GeneratedValue(strategy = GenerationType.SEQUENCE)\n\n@GeneratedValue(strategy = GenerationType.IDENTITY)\n\n@GeneratedValue(strategy = GenerationType.AUTO)\n\n\n\n\n\n\n\n\nTable 생성 전략은 실무에서 거의 사용하지 않으며,MySQL 혹은 MariaDB 같은것을 사용한다면 IDENTITY를 일반적으로 사용하고Oracle을 쓴다면 SEQUENCE를 사용한다.\n\n외에 토이 프로젝트나 사이드 프로젝트의 경우는 기술전환이 자유롭게 행해지기 때문에 AUTO도 많이 사용되는 걸로 보인다.\n\n이러한 기본키 생성 전략은 사실 JPA의 영역이라기 보다 DB의 영역이기 때문에 이러한 내용에 대해 잘 모르겠다면 JPA가 아닌 DB에 대한 선행 학습이 필요하다고 사료된다.\n\n\n\nIDENTITY의 경우 한가지 중요한 내용이 있다.\n\nDB의 auto_increment 기능을 사용 하고 JPA에서 @GeneratedValue(strategy = GenerationType.IDENTITY)를 사용하는 경우 트랜잭션 작업이 들어가야지만 할당해야 할 id값을 알 수 있기 때문에 insert 쿼리에 대해 쓰기지연 기능이 제대로 동작하지 않고 즉시 insert 쿼리가 발생한다.\n\n\n\n같은 원리로 batch insert도 제대로 동작하지 않기 때문에 이 경우 JdbcTemplate나 Mybatis 등의 사용을 고려하게 된다.\n\n\n\n🚀 @Column\n\n\n\n\n\n\n\n엔티티 필드와 테이블 컬럼을 매핑하는데 사용한다.\n\n기본값은 위와 같으며, 주로 사용되는 옵션은 name정도다.\n\n나머지는 DDL 옵션과 관계가 있는데 실무에서는 보통 DB구축이 이미 돼있는 상황에 매핑을 하기만 하는 경우가 일반적이고, 혹시 모를 사고를 대비하기 위해 DDL 옵션을 끄거나(none), 유효성 검사(validate)정도만 사용하는 경우가 대부분이기 때문에\n\n나머지 DDL 관련 옵션들은 적용되지 않는다.\n\n\n\n\n  \n    \n      속성\n      기능\n      기본값\n    \n  \n  \n    \n      name\n      필드와 매핑할 테이블의 컬럼명\n      객체의 필드명\n    \n    \n      insertable\n      엔티티 저장 시 이 필드도 같이 저장  false로 설정하면 이 필드는 데이터베이스에 저장하지 않음\n      true\n    \n    \n      updatable\n      엔티티 수정 시 이 필드도 같이 수정  false로 설정하면 이 필드는 데이터베이스에 수정하지 않음\n      true\n    \n    \n      table\n      하나의 엔티티를 두 개 이상의 테이블에 매핑할 때 사용. \n      현재 클래스가 매핑 된 테이블\n    \n    \n      nullable\n      null 허용 여부로, false로 설정하면 DDL 옵션으로 인한 DDL 생성 시 컬럼에 not null 제약조건이 붙는다\n      true\n    \n    \n      unique\n      @Table의 uniqueConstraints는 복합 유니크 인덱스를 생성할 때 사용하며,  이 기능은 단일 유니크 인덱스를 생성할 때 사용\n      -\n    \n    \n      columnDefinition\n      데이터 베이스 컬럼 정보를 직접 입력한다(Native)\n      -\n    \n    \n      length\n      문자 길이 제약 조건, String 에만 사용\n      255\n    \n    \n      precision\n      BigDecimal, BigInteger 타입 사용시 사용한다. 정밀도를 의미하는데, 전체 자릿수를 의미한다\n      0\n    \n    \n      scale\n      BigDecimal, BigInteger 타입 사용시 사용한다. 스케일은 소수점 이하 자리수를 의미한다\n      0\n    \n  \n\n\n\n\n🚀 @Enumerated\n\n\n\n\n\n\n\n\n\n\n\n보통 어떤 상태값을 표현하는데 많이들 사용한다.\n\n예로 들만한 대표적인 enum 클래스는 spring-web의 org.springframework.http.HttpStatus 라고 볼 수 있겠다.\n\n\n\n\n\n\n\n엔티티에서는 보통 어떤 상태값에 대해 enum 클래스를 작성하고, 이에 부수적인 기능들을 추가하여 엔티티 필드에 매핑해 사용하는데\n\n이때 Ordinal, String 을 선택한다. 이것에 대해서는 공식이라고 생각해도 좋겠다. 무조껀 String을 사용하자.\n\nOrdinal은 enum 클래스의 상수 필드 순서를 Integer 타입으로 사용하게 되는데, enum 클래스에 변경사항이 생겨\n\n상수 필드의 순서가 바뀐다면 관련된 모든 코드에 에러가 발생하게 된다. (OCP 위반)\n\nString은 enum 클래스의 상수 필드명 자체를 사용하기 때문에 enum 클래스에 변경사항이 생겨도 다른 코드에 영향을 주지 않는다.\n\nOrdinal이 String에 비해 좋은 점도 분명히 있긴 한데, 실무에서는 사소한 성능상의 이점보다 휴먼에러를 줄이는 것이 더 중요한 과제이기 때문에\n\n성능상 손해를 좀 보더라도 안전한 코드를 작성하는게 더 좋다고 생각한다.\n\n\n\n🚀 @Temporal\n\n\n\n\n\n\n\nDate와 Calendar관련 어노테이션인데, 이 두 클래스는 현 시점에서 자바 플랫폼 라이브러리에서 실패한 클래스이므로 따로 작성하지 않는다.\n\n이 객체들은 별다른 노하우가 없던 자바 초창기에 불변 객체로 만들어지지 못했었고, 이로 인한 많은 문제가 발생하고 있다.\n\n자바 8이 주류로 자리잡고 Date와 Calendar의 대부분 Public API가 Deprecated 됐으며\n\nLocalDate, LocalDateTime이 주류로 사용되고 있는 현 시점에서\n\nDate와 Calendar를 사용한다는 것은 시대를 역행하는 것이라고 생각하기 때문에\n\n이에 관해 궁금하신 분은 다른 자료가 많으니 직접 찾아보는 것을 추천드린다.\n\n \n\n일단 알아야 할 것은 만약 Hibernate를 사용하는데 Date나 Calendar를 사용한다면 @Temporal을 반드시 사용해야 하며,\n\nLocalDate나 LocalDateTime을 사용한다면 별다른 어노테이션을 작성하지 않아도 된다.\n\n자바 초창기에 Hibernate에서 자바의 Date를 지원하기 위해 작성된 기능이므로 현 시점에서는 거의 사용되지 않는다.\n\n\n\n🚀 @Lob\n\n\n\n\n\n\n\n데이터베이스의 BLOB, CLOB 타입과 매핑한다.\n\n중요하지 않다고 생각되어 자세한 내용은 작성하지 않는다.\n\n\n\n🚀 @Transient\n\n\n\n\n\n\n\n데이터베이스와 무관한 필드임을 명시하는 어노테이션이다.\n\n주로 엔티티에서 데이터베이스 테이블과 관련되지 않는 데이터를 작업하거나 할 때 사용한다.\n\n생각보다 종종 사용할 일이 있었다.\n\n\n\n🚀 @Access\n\n\n\n\n\n\n\n\n\n\n\nJPA가 엔티티에 접근하는 방식을 지정한다\n\n필드 접근과 프로퍼티 접근의 투트랙이 존재한다.\n\n이 어노테이션을 생략하면 @Id의 위치에 따라 결정된다.\n\n우선순위는 @Access를 명시하는 것이 더 높다.\n\n\n\n@Entity\n@Access(AccessType.FIELD) // 생략해도 무방\npublic class User{\n    @Id // 필드에 위치\n    private Long id;\n\n    // omitted for brevity\n}\n\n@Entity\n@Access(AccessType.PROPERTY) // 생략해도 무방\npublic class User{\n    private Long id;\n\n    @Id // 접근자에 위치\n    public Long getId() {\n        return id;\n    }\n\n    // omitted for brevity\n}\n\n\n\n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-06-27-jpa-4/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "모의 해킹? 취약점 검사?",
      "date": "2021-06-30 19:38:00 +0000",
      "description": "개발일기\n",
      "content": "\n \n\n회사에서 내 프로젝트를 모의해킹이란 걸 외주로 맡겼다.\n\n그러고 나서 XSS에 취약점이 있다고 리포트를 받았는데\n\n사실 스프링 시큐리티에서 CSRF Filter를 Disable 해놓긴 했다.\n\n개발할 때 너무 번거로워서….😣\n\n \n\n그리고 귀찮은걸 떠나서 두 가지 근거가 있긴 했다.\n\n \n\n\n  \n    완전 내부망이었다.\n  \n  \n    로그인 페이지를 제외한 어떤 페이지도 외부로 노출되지 않았다.\n  \n\n\n \n\n암튼 그래서 CSRF Filter를 Disable 해뒀는데 모의해킹을 하니까 XSS 공격에 취약하다고 온 셈이다.\n\n리포트를 면밀히 보니까 심지어 슈퍼계정으로 XSS 공격을 했더라…😭\n\n \n\n\n\n \n\n아무튼 고쳐야 된다고 하니 울며 겨자 먹기로 작업에 들어갔다.\n\n곰곰이 내가 이 취약점을 보완하기 위해 해야 할 작업은 크게 세 가지였다.\n\n \n\n\n  \n    CSRF Filter를 적용한다.\n  \n  \n    모든 View에서 CSRF Token을 같이 보내게 한다.\n  \n  \n    XSS Filter를 적용해서 스크립트 공격을 막는다.\n  \n\n\n \n\nCSRF Filter는 스프링 시큐리티에서 코드 한 줄만 제거하면 끝났다.\n\n \n\nhttp.csrf().disable()\n\n\n \n\nView에서 CSRF Token을 사용하는 것은 공통 헤더 파일에 코드 두줄을 삽입해서 끝냈다.\n\n \n\n마지막으로 XSS Filter가 문제였는데\n\n스프링 시큐리티에 XSS Filter가 당연히! 있을 줄 알았는데 없더라…? 🤷‍♂️\n\n“응? 이게 대체 왜 없지?” 싶어서 직접 만들어야 하나 고민하면서 한참 서칭을 하는데\n\n네이버 형님들이 XSS Filter를 하나 만드셔서 오픈소스로 뿌려주셨더라 (정말 감사합니다 센빠이… 😭)\n\n \n\n\n\n \n\nlucy-xss-servlet-filter라는 물건인데.\n\nXSS 공격에 사용되는 &lt;, &gt; 같은 문자들을\n\nHttp Request Body에서 필터링하여 &amp;lt;, &amp;gt; 등으로 바꿔주는 필터다.\n\n \n\n📜 lucy-xss-servlet-filter GitHub\n\n \n\n문서도 깔끔하게 잘 적혀있어서(심지어 한글이다..!) 쉽게 쉽게 금방 적용해봤다.\n\n그리고 테스트를 해보는데 잘 적용된 듯싶다가 좀 이상한 부분이 있었다.\n\nRestController 쪽에서는 제대로 동작하지 않는 것처럼 보여 관련 글들을 또 서칭 해봤다.\n\n \n\n📜 Spring에서 JSON에 XSS 방지 처리 하기\n\n \n\n위 글을 보면서 적용해보니 해당 문제도 해결된 듯했다.\n\n내일부터는 본격적으로 모든 기능에 대해 통합 테스트를 해볼 예정인데\n\n처음으로 모의해킹이란 걸 겪어보면서 참 신기했다.\n\n \n\n스프링 시큐리티를 나름 열심히 공부해서 적용하고 사용하고 있지만\n\n사실 보안이라는 것에 대해 깊게 생각해본 적은 없었던 것 같다.\n\n“어지간한 건 스프링 시큐리티가 알아서 막아주겠지~?” 라는 마인드였달까?\n\n(변명이란 걸 해보자면 스프링 시큐리티 공식문서에 실제로 그렇게 쓰여있다…)\n\n아무튼 이래저래 생각이 많은 날이었던 것 같다.\n\n \n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-06-30-diary-24/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "JPA 기초 5 - 연관관계 매핑 기초",
      "date": "2021-06-30 21:32:00 +0000",
      "description": "연관관계 매핑 기초를 학습합니다\n",
      "content": "\n  📕 연관관계 매핑 기초\n  📜 @OneToOne\n  📜 @OneToMany\n  📜 @ManyToOne\n  📜 @ManyToMany\n\n\n \n\n📕 연관관계 매핑 기초\n\n\n\nERD 에는 총 4가지 관계가 있다.\n\n이를 JPA의 연관관계 매핑으로 매치시키면 하기와 같다.\n\n\n\n\n  일대일(1:1) - @OneToOne\n  일대다(1:N) - @OneToMany\n  다대일(N:1) - @ManyToOne\n  다대다(N:N) - @ManyToMany\n\n\n\n\n📜 @OneToOne\n\n\n\n\n\n\n\n\n  \n    \n      속성\n      기능\n      기본값\n    \n  \n  \n    \n      targetEntity\n      연관관계 매핑의 대상이 되는 타겟을 설정한다.\n      field의 class명\n    \n    \n      cascade\n      database의 cascade와 동일하다.\n      -\n    \n    \n      fetch\n      로딩 전략. EAGER가 기본값이며, EAGER일 경우 즉시로딩을 의미한다.  LAZY는 지연로딩을 의미한다.\n      EAGER\n    \n    \n      optional\n      null인지 아닌지를 설정한다. 기본값은 true이며 nullable함을 의미한다.\n      true\n    \n    \n      mappedBy\n      연관관계의 주인을 설정한다. 주인이 아닌 곳에서 선언한다.\n      -\n    \n    \n      orphanRemoval\n      고아 객체 처리를 어떻게 할지에 대한 설정이다.\n      false\n    \n  \n\n\n\n\n일반적으로 선수는 캐비넷을 하나씩 갖는다.\n\n이를 일대일관계라고 부르며 이 경우 부모는 선수, 자식은 캐비넷이라고 볼 수 있을 것이다.\n\n이때, 선수가 캐비넷이 필요없다고 하면 없을수도 있다(nullable).\n\n이를 JPA의 @OneToOne으로 풀어낸다면\n\n\n\n@Entity\npublic class Member {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    @NonNull\n    private String name;\n\n    @NonNull\n    private int age;\n\n    @OneToOne\n    private Cabinet cabinet;\n\n    // omitted for brevity\n}\n\n\n\n\n@Entity\npublic class Cabinet {\n    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    @NonNull\n    private Integer number;\n    \n    // omitted for brevity\n}\n\n\n\n\n이런 식으로 사용할 수 있을 것 같다.\n\n@OneToOne의 경우 실무에서 여러가지 문제를 발생시키는 JPA의 만악의 근원중 하나다.\n\n우선 @OneToOne의 경우 지연로딩전략이 잘 먹히지 않으며, 지연로딩을 하기 위해서는 다음과 같은 조건을 만족해야 한다.\n\n\n\n\n  not null이어야 한다. 즉, optional=false여야만 한다.\n  반드시 단방향 일대일 관계여야만 한다.\n  반드시 PK(Primary Key)로 조인하여야만 한다.\n\n\n\n\nLAZY의 경우 프록시를 활용하여 동작하게 되는데, 값이 null인 경우에는 프록시로 대체할수가 없다.\n\n매핑되는 객체가 Collection 타입일 경우 실제 내부 엘리먼트가 null이건 아니건 상관없이 Collection 자체를 프록시로 대체할 수 있기 때문에 이 경우 Collection Wrapper라는 것을 이용하게 되어 지연로딩이 매우 잘 먹히는데 반해@OneToOne의 경우 Collection으로 매핑하지 않고 단일 객체로 매핑하기 때문에 JPA에서 값이 null인 경우를 배제할 수 없게 된다.\n\n\n\n그래서 JPA는 이 경우 프록시를 채울 수 없게되고, 반드시 쿼리를 한번 발생시켜 값이 있는지 없는지를 검사해야만 null을 채울지 프록시를 채워줄지를 알 수 있다. 이러한 원리로 인해 반드시 EAGER로 동작하게 되며 N+1문제가 빈번히 발생한다.\n\n\n\n따라서 개발자가 해당 객체는 not null임을 명시해준다면(optional=false) JPA는 값이 null일 경우를 배제할 수 있게되어 프록시를 채워주게 되고, 이는 곧 지연로딩으로 동작할 수 있음을 의미하게 된다.\n\n \n\n보통 일대일 관계를 반드시 사용해야만 하는 경우가 드문데,\n\n만약 JPA를 사용하는 중 반드시 일대일 관계를 사용해야만 하는 상황일 경우에는 꼭 부모테이블에 FK를 두도록 하고\n\n일대일 관계가 아니게 될 수 있다면 애초에 처음부터 일대다나 다대일관계로 만드는 것이 추후 사고를 예방하는 길이 되겠다.\n\n\n\n📜 @OneToMany\n\n\n\n\n\n\n\n\n  \n    \n      속성\n      기능\n      기본값\n    \n  \n  \n    \n      targetEntity\n      연관관계 매핑의 대상이 되는 타겟을 설정한다.\n      field의 class명\n    \n    \n      cascade\n      database의 cascade와 동일하다.\n      -\n    \n    \n      fetch\n      로딩 전략. LAZY가 기본값이며, LAZY일 경우 지연로딩을 의미한다.  EAGER는 지연로딩을 의미한다.\n      LAZY\n    \n    \n      mappedBy\n      연관관계의 주인을 설정한다. 주인이 아닌 곳에서 선언한다.\n      -\n    \n    \n      orphanRemoval\n      고아 객체 처리를 어떻게 할지에 대한 설정이다.\n      false\n    \n  \n\n\n\n\n필자는 @OneToMany도 역시 잘 사용하지 않는다.\n\n우선 전통적인 RDB방식에 어긋나는 방식이다.\n\n일반적으로 RDB에서는 자식 테이블이 부모 테이블의 기본키를 외래키(FK)로 갖고있기 때문이다.\n\n실무에서는 일반적으로 양방향 관계를 설정할 경우에 종종 사용하는데, 필자는 가급적 양방향 관계를 걸지 않으려고 하기 때문에 많이 써본 적은 없는 것 같다.\n\n굳이 사용 예를 들자면 보통 한 팀에는 여러명의 선수가 소속되므로 팀 입장에서 선수와 일대다 관계이다.\n\n\n\n@Entity\npublic class Team {\n    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    @NonNull\n    private String name;\n\n    @OneToMany\n    private List&lt;Member&gt; members;\n}\n\n\n\n\n양방향 관계에서 연관관계의 주인이 아님을 명시하여 사용하는 예이다.\n\n이런 코드는 생각보다 많이 볼 수 있다.\n\n\n\n@Entity\npublic class Team {\n    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    @NonNull\n    private String name;\n\n    @OneToMany(mappedBy = \"team\")\n    private List&lt;Member&gt; members;\n}\n\n\n\n\n📜 @ManyToOne\n\n\n\n\n\n\n\n\n  \n    \n      속성\n      기능\n      기본값\n    \n  \n  \n    \n      targetEntity\n      연관관계 매핑의 대상이 되는 타겟을 설정한다.\n      field의 class명\n    \n    \n      cascade\n      database의 cascade와 동일하다.\n      -\n    \n    \n      fetch\n      로딩 전략. EAGER가 기본값이며, EAGER일 경우 즉시로딩을 의미한다.  LAZY는 지연로딩을 의미한다.\n      EAGER\n    \n    \n      optional\n      null인지 아닌지를 설정한다. 기본값은 true이며 nullable함을 의미한다.\n      true\n    \n  \n\n\n\n\nJPA를 사용하면서 가장 많이 사용하게 될 어노테이션이고, 가장 많이보게 될 어노테이션이다.\n\n절대다수의 RDB 설계상 자식 테이블이 부모 테이블의 기본키를 외래키(FK)로 갖고 있으며, 보통 DB 설계를 먼저 해놓고 JPA가 따라가며 매핑하는 방식으로 일을하게 되기 때문에 이 어노테이션을 많이 사용하게 된다.\n\n\n\n@ManyToOne에도 optional이 있는데 이 경우에는 부모 테이블이 확실하게 존재하기 때문에 부모객체가 null일 확률을 배제할 수 있다. 따라서 별다른 문제 없이 지연로딩 전략이 잘 적용된다.\n\n\n\nN+1 문제를 회피하기 위해 fetch옵션을 항상 LAZY로 설정하여 지연로딩 전략으로 사용한다.\n\n사용 예를 들자면 보통 한 팀에는 여러명의 선수가 소속되므로 선수 입장에서 팀과 다대일 관계이다.\n\n\n\n이를 코드로 표현하면 하기와 같다.\n\n\n\n@Entity\npublic class Member {\n    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    @NonNull\n    private String name;\n\n    @NonNull\n    private int age;\n\n    @ManyToOne(fetch = FetchType.LAZY)\n    private Team team;\n}\n\n\n\n\n📜 @ManyToMany\n\n\n\n\n\n\n\n\n  \n    \n      속성\n      기능\n      기본값\n    \n  \n  \n    \n      targetEntity\n      연관관계 매핑의 대상이 되는 타겟을 설정한다.\n      field의 class명\n    \n    \n      cascade\n      database의 cascade와 동일하다.\n      -\n    \n    \n      fetch\n      로딩 전략. LAZY가 기본값이며, LAZY일 경우 지연로딩을 의미한다.  EAGER는 지연로딩을 의미한다.\n      LAZY\n    \n    \n      mappedBy\n      연관관계의 주인을 설정한다. 주인이 아닌 곳에서 선언한다.\n      -\n    \n  \n\n\n\n\n다대다 관계인데, RDB에서는 이를 보통 매핑 테이블로 뽑아내서 사용한다.\n\nJPA에서도 역시 이 어노테이션을 쓰기보다 매핑 테이블과 일대다, 다대일관계로 많이 사용하게 된다.\n\n이유로는 @ManyToMany를 사용하면 관련 코드가 매우 복잡해져서 한눈에 잘 안들어오며 확장성이 매우 떨어진다.\n\n또한 안 그래도 복잡한 JPA인데 이정도로 추상화를 해버리면 팀 동료가 힘들어지는 경우가 생길 수 있다.\n\n필자는 아예 사용자체를 안해서 잘 모르기도 하거니와 앞으로도 쓸 이유가 없을 것 같아 따로 더 서술하진 않겠다.\n\n다만 굳이 이 어노테이션을 사용해야겠다면 가급적 List보다는 Set을 사용하는게 좋을 것 같다.\n\n\n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-06-30-jpa-5/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Github Pages 배포 에러",
      "date": "2021-07-04 20:32:00 +0000",
      "description": "Github Pages를 구축하던 중 발생한 이해 안되는 에러\n",
      "content": "\n \n\n티스토리는 분명 좋은 블로그다.\n\n하지만 티스토리 블로그에 100여개의 글을 작성하며 항상 불편한 점이 한가지 있었다.\n\n바로 마크다운(Markdown)에 친화적이지 않다는 것.\n\n그래서 이참에 조금 더 개발자스럽게(?) Github Pages로 블로그를 만들어보려는 시도를 했다.\n\n주말 2일 동안 Github Pages에 대한 문서를 보면서 작업을 진행했다.\n\n\n\n하지만 누가 그랬을까?\n\n배포에 성공하기 전까진 성공한게 아니라고 😂\n\n수많은 에러를 해결하면서 모든 작업을 끝내고 마침내 블로그를 배포하려니 또 요상한 에러가 발생했다. (마지막 관문)\n\nGithub Actions Build는 성공했는데 Page Build는 실패했다는 이상한 에러였다.\n\n처음에 아예 이해가 안된게, 빌드가 됐다는 것은 정적파일들이 정상적으로 생성됐다는 뜻과 일맥상통하는데\n\n생성된 정적파일들을 뿌려주기만 하면 되는데 이게 안된다? 말이 안된다는 생각이 먼저 들었다.\n\n\n\n\n\n메일로 날아온 빌드 알람은 하기와 같았다.\n\nThe page build failed for the `main` branch with the following error:\n\nA file was included in `/_layouts/post.html` that is a symlink or does not exist in your `_includes` directory. For more information,\n \nsee https://docs.github.com/github/working-with-github-pages/troubleshooting-jekyll-build-errors-for-github-pages-sites#file-is-a-symlink.\n\n\n/_layouts/post.html에서 _includes에 존재하지 않는 파일을 참조하고 있거나\n\n심볼릭 링크를 사용하고 있다는 에러 메세지와\n\n해당 메세지에 대한 Github Document 주소였다.\n\n하지만 이 메세지는 무시했다.\n\n왜냐하면 이미 로컬에서 빌드가 성공했었기 때문.\n\n굉장히 이해가 안되는 상황이라 이 문제에 대해 한참동안 구글링을 했다.\n\n\n\n한참의 구글링 끝에 Github Pages는 페이지를 보여주는 브랜치를 독립적으로 설정해야 한다는 내용을 찾았다.\n\n문제의 원인은 간단했다.\n\n전체적인 플로우는 하기와 같다.\n\n\n\nGithub에서 사용을 금지한 jekyll plugin들을 우회사용하기 위해\n\nGithub Actions와 Github Workflows를 사용했고\n\nmain 브랜치에 push가 발생하면 Github Workflows가\n\nmain 브랜치의 소스를 빌드하여 생성되는 정적파일들을 ph-pages 브랜치로 생성되게 만들었다.\n\n여기서 ph-pages는 사용자들에게 보여줄 페이지를 담당하는 브랜치라는 문서상의 내용을 보고 이렇게 작업을 한 것인데,\n\n자동으로 되는 줄 알고있다가 알고보니 추가 작업이 더 필요했던 것.\n\n\n\nRepository - Settings - Pages로 진입하여\n\nSource를 gh-pages 브랜치로 설정해주니 잘 동작하였다.\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-07-04-debugging-10/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "JPA 기초 6 - 프록시",
      "date": "2021-07-11 00:00:00 +0000",
      "description": "지연로딩의 핵심인 프록시에 대해 학습합니다\n",
      "content": "\n  📕 프록시(Proxy)    \n      🤔 프록시를 사용하는 이유 ?        \n          💡 흐름제어\n          💡 캐싱\n          💡 지연연산\n        \n      \n      🤔 JPA에서의 프록시 ?\n      🤔 로딩 전략은 어떻게 ?\n      💥 컬렉션 로딩 전략 주의점\n    \n  \n\n\n \n\n📕 프록시(Proxy)\n\n\n\n프록시는 한글로 대리자, 대리인이라는 뜻을 갖는다.\n\n프로그래밍에는 인디렉션(Indirection)이라는 개념이 있다.\n\n \n\n\n  📜 Dennis DeBruler\n  \n    컴퓨터 과학은 인디렉션 계층을 한 단계 더 만들면 모든 문제를 풀 수 있다고 믿는 학문이다.\n  \n\n\n \n\n위키백과등에서 인디렉션에 대한 내용을 참고해보면 두 계층사이에 어떤 문제가 발생했을 때 두 계층 사이에 별도의 계층을 하나 추가하면 해당 문제가 깔끔하게 해결되는 경우가 많다는 것이다.\n\n \n\n이를 프로그래밍 용어로 간접참조 혹은 추상화로 요약할 수 있을 것 같다.\n\n \n\n프록시는 이 인디렉션과 궤를 같이하며 프록시 패턴은 SOLID중 개방폐쇄원칙(OCP)과 의존역전원칙(DIP)을 충실히 따른다.\n\n \n\n그렇다면 프록시가 뭘까?\n\n \n\n프록시는 특정 개체의 사이에 위치한 진짜인 척을 하는 가짜 개체다.\n\n여기서 프록시가 목표로 하는 것은 본연의 로직에는 전혀 영향을 주지 않으면서 흐름을 제어 하는 것이다.\n\n그래서 두 개체는 사이에 프록시라는 가짜 개체가 있는지 전혀 모르며 서로를 진짜라고 신뢰하고 통신을 진행하게 된다.\n\n코드를 통해 보자.\n\n \n\n\n\n \n\n통상적인 프록시 패턴의 클래스 다이어그램이다.\n\n이를 코드로 풀어내면 다음과 같다.\n\n \n\n// file: 'Client.java'\npublic class Client {\n    Interface anInterface;\n\n    public Client(Interface anInterface) {\n        this.anInterface = anInterface;\n    }\n\n    public void callOperation(){\n        anInterface.operation();\n    }\n}\n\n\n \n\n// file: 'Interface.java'\npublic interface Interface {\n    void operation();\n}\n\n\n \n\n// file: 'Real.java'\npublic class Real implements Interface{\n    @Override public void operation() {\n        System.out.println(\"Real Operation\");\n    }\n}\n\n\n \n\n// file: 'Proxy.java'\npublic class Proxy implements Interface {\n    Interface real = new Real();\n\n    @Override public void operation() {\n        System.out.println(\"Proxy Operation\");\n        real.operation();\n    }\n}\n\n\n \n\n// file: 'ClientTest.java'\nclass ClientTest {\n    @Test\n    void proxy() {\n        Client client = new Client(new Proxy());\n\n        client.callOperation();\n    }\n}\n\n/*------------출력------------\n        Proxy Operation\n        Real Operation\n ----------------------------*/\n\n\n \n\n중간에 Proxy의 로직이 추가될 수 있으면서\n\n실제 결과는 Real의 연산결과가 나옴을 볼 수 있다.\n\n \n\n🤔 프록시를 사용하는 이유 ?\n\n\n\n프록시가 대충 뭔지 알았다면 프록시를 사용하는 이유에 대한 납득이 필요하다.\n\n프록시는 대표적으로 다음과 같은 역할들을 수행할 수 있다.\n\n \n\n\n  흐름제어\n  캐싱\n  지연연산\n\n\n \n\n💡 흐름제어\n\n\n\n서문의 예시코드와 같다.\n\n예시코드에서는 단순히\n\n \n\nSystem.out.println(\"Proxy Operation\");\n\n\n \n\n한줄만을 추가했지만, 이곳에 개발자가 임의의 코드를 추가할 수도 있다.\n\n보통 조건문을 사용하여 흐름을 제어하게 된다.\n\n이를 극대화시켜서 사용하는 예로 포워드 프록시, 리버스 프록시 등이 있다.\n\n스프링에서는 이를 활용해 AOP 기술을 구현하고 있으며 AOP 기술을 통해 구현되는 대표적인 기술로 @Transactional이 있다.\n\n \n\n💡 캐싱\n\n\n\n\n  📜 시나리오\n\n  특정한 텍스트를 읽어 복호화하여 반환해주는 기능이 있다.\n\n  매번 새로운 텍스트를 반환하니 리소스의 낭비가 심해 이를 캐시하고자 한다.\n\n\n \n\n// file: 'TextFileReader.java'\npublic interface TextFileReader {\n    SecretText read();\n}\n\n\n \n\n// file: 'RealTextFileReader.java'\npublic class RealTextFileReader implements TextFileReader {\n    private String plainText;\n\n    public RealTextFileReader(String plainText) {\n        this.plainText = SecretUtil.decode(plainText);\n    }\n\n    @Override\n    public SecretText read() {\n        System.out.println(\"RealTextFileReader reading text from : \" + plainText);\n        return new SecretText(plainText);\n    }\n}\n\n\n \n\n// file: 'TextFileReaderTest.java'\nclass TextFileReaderTest {\n    @Test\n    void noCache() {\n        TextFileReader reader = new RealTextFileReader(\"text\");\n        reader.read();\n        reader.read();\n        reader.read();\n        reader.read();\n        reader.read();\n    }\n}\n\n\n \n\n출력은 다음과 같다.\n\n \n\nRealTextFileReader reading text from : text\nRealTextFileReader reading text from : text\nRealTextFileReader reading text from : text\nRealTextFileReader reading text from : text\nRealTextFileReader reading text from : text\n\n\n \n\n이를 프록시 패턴을 활용해 캐시해보자\n\n \n\n// file: 'ProxyTextFileReader.java'\npublic class ProxyTextFileReader implements TextFileReader {\n    private String plainText;\n    private SecretText secretText;\n\n    public ProxyTextFileReader(String plainText) {\n        this.plainText = SecretUtil.decode(plainText);\n    }\n\n    @Override\n    public SecretText read() {\n        // 가지고 있는 파일이 없거나, 가지고 있는 파일과 요청받은 파일이 다른 경우 새로운 파일을 생성하여 캐시\n        if(secretText == null || !secretText.getPlainText().equals(plainText)) {\n            System.out.println(\"RealTextFileReader reading text from : \" + plainText);\n            this.secretText = new SecretText(plainText);\n            return this.secretText;\n        }\n\n        System.out.println(\"RealTextFileReader use cache\");\n        return new SecretText(plainText);\n    }\n}\n\n\n \n\n생성자를 통해 ProxyTextFileReader가 초기화되면 내부에 복호화 한 파일을 캐시해두고 이후 호출되면 캐시해둔 파일을 즉시 리턴하는 로직이다.\n\n \n\n// file: 'TextFileReaderTest.java'\nclass TextFileReaderTest {\n    @Test\n    void useCache() {\n        TextFileReader reader = new ProxyTextFileReader(\"text\");\n        reader.read();\n        reader.read();\n        reader.read();\n        reader.read();\n        reader.read();\n    }\n}\n\n\n \n\nRealTextFileReader reading text from : text\nRealTextFileReader use cache\nRealTextFileReader use cache\nRealTextFileReader use cache\nRealTextFileReader use cache\n\n\n \n\n이처럼 프록시를 사용하여 기존의 아키텍처에 영향을 주지 않는 선에서 캐시 기능을 간단하게 추가할 수 있다.\n\n \n\n💡 지연연산\n\n\n\n지연연산이라는 것은 어떤 연산이 정말로 실행되어야 하기 전까지 해당 연산의 실행을 유예하는 것이다.\n\n이렇게 함으로써 필요하지 않은 연산을 최소화하여 성능을 극대화시킬 수 있다.\n\n \n\n구현은 간단하다.\n\n진짜 객체를 프록시로 한번 래핑하면 된다.\n\n \n\n// file: 'LazyTextFileReader.java'\npublic class LazyTextFileReader implements TextFileReader{\n    private String plainText;\n    private TextFileReader reader;\n\n    public LazyTextFileReader(String plainText) {\n        this.plainText = plainText;\n    }\n\n    @Override\n    public SecretText read() {\n        if(reader == null){\n            reader = new RealTextFileReader(plainText);\n        }\n        System.out.println(\"lazy initialisation\");\n        return reader.read();\n    }\n}\n\n\n \n\n// file: 'TextFileReaderTest.java'\nclass TextFileReaderTest {\n    @Test\n    void lazy() {\n        TextFileReader reader = new LazyTextFileReader(\"text\");\n        reader.read();\n        reader.read();\n        reader.read();\n        reader.read();\n        reader.read();\n    }\n}\n\n\n \n\nlazy initialisation\nRealTextFileReader reading text from : text\nlazy initialisation\nRealTextFileReader reading text from : text\nlazy initialisation\nRealTextFileReader reading text from : text\nlazy initialisation\nRealTextFileReader reading text from : text\nlazy initialisation\nRealTextFileReader reading text from : text\n\n\n \n\n이렇게 하면 read()가 정말로 실행되야 할 순간이 오면 그제야 진짜 객체를 호출하여 연산을 시작한다.\n\n \n\n🤔 JPA에서의 프록시 ?\n\n\n\nJPA에는 연관관계 매핑 혹은 엔티티 매핑이라고 부르는 기법이 있다.\n\n데이터베이스의 테이블과 자바의 클래스를 매핑하여 쿼리 작성의 부담을 줄이기 위한 목적을 갖는다.\n\n즉, 이 방법을 사용하게 되면 데이터베이스의 외래키를 자바 코드로 구현할 때 자바의 객체 그래프 형식으로 변환된다. (참조, 참조, 참조)\n\n \n\n// file: 'Member.java'\n@Entity\npublic class Member {\n    @Id\n    private Long id;\n    \n    private String name;\n    \n    @ManyToOne\n    private Team team;\n    \n    public Team getTeam(){\n        return this.team;\n    }\n    \n    public String getName(){\n        return this.name;\n    }\n}\n\n\n \n\n// file: 'Team.java'\n@Entity\npublic class Team {\n    @Id\n    private Long id;\n    \n    private String name;\n    \n    public String getName(){\n        return this.name;\n    }\n}\n\n\n \n\npublic void printMemberAndTeam(String memberId){\n    Member member = memberRepository.findById(memberId); // left outer join 발생\n    System.out.println(\"회원 이름 : \" + member.getName());\n    System.out.println(\"소속 팀 이름 : \" + member.getTeam().getName());\n}\n\n\n \n\n이런 코드가 있다.\n\n데이터베이스에서 Member를 가져오면 @ManyToOne으로 인해 Team도 같이 가져와진다.\n\n이때 발생하는 쿼리는 다음과 같다.\n\n \n\nselect\n        member0_.id as id1_1_0_,\n        member0_.name as name2_1_0_,\n        member0_.team_id as team_id3_1_0_,\n        team1_.id as id1_2_1_,\n        team1_.name as name2_2_1_ \n    from\n        Member member0_ \n    left outer join\n        Team team1_ \n            on member0_.team_id=team1_.id \n    where\n        member0_.id=?\n\n\n \n\n그리고 Member와 Team의 데이터를 모두 출력(사용)하고 있으므로 이 경우에는 별다른 문제가 없다.\n\n \n\n하지만 다음과 같은 경우엔 어떨까?\n\n \n\npublic void printMemberAndTeam(String memberId){\n    Member member = memberRepository.findById(memberId);\n    System.out.println(\"회원 이름 : \" + member.getName());\n}\n\n\n \n\nMember와 Team의 데이터를 join하여 모두 가져온게 분명하지만 실제로는 Member의 데이터만을 사용하고 있다.\n\n이럴 경우에는 Team을 굳이 가져올 필요가 없으며, 오히려 가져오는 것이 리소스의 낭비이다.\n\n이럴 때 프록시를 활용한 지연로딩을 사용하게 된다.\n\n \n\n// file: 'Member.java'\n@ManyToOne(fetch = FetchType.LAZY)\nprivate Team team;\n\n\n \n\n이렇게 연관관계 매핑에 지연로딩(LAZY)를 사용하겠다고 선언하면 실제 쿼리의 발생순서는 다음과 같다.\n\n \n\npublic void printMemberAndTeam(String memberId){\n    Member member = memberRepository.findById(memberId); // Select Member 쿼리 발생, 다만 Member를 가져오되 Team은 프록시로 가져옴\n    System.out.println(\"회원 이름 : \" + member.getName()); // 쿼리 발생하지 않음\n    System.out.println(\"소속 팀 이름 : \" + member.getTeam().getName()); // Team이 실제로 사용되므로 Select Team 쿼리가 발생\n}\n\n\n \n\n위의 예시가 바로 지연로딩(fetch = LAZY)의 전부다.\n\n이 지연로딩을 사용하는 이유는 위 프록시의 지연연산 예시와 같이\n\n꼭 필요한 연산만 행해서 성능의 극대화를 꾀한다.\n\n라고 볼 수 있다.\n\n \n\n그리고 JPA를 더 공부하면 알게될 N+1 문제를 바로 이 지연로딩을 통해 회피한다.\n\n \n\n그렇다면 항상 지연로딩이 옳은것일까?\n\n \n\n그건 또 아니다.\n\n \n\n바로 위의 예시에서 보다시피,Member와 Team을 모두 사용하기 위한 목적으로 Member를 조회해왔음에도 지연로딩으로 인해 select 쿼리가 두번 발생했다.\n\n애초에 이를 join을 사용해 select 쿼리했다면 한번의 select 쿼리로 해결할 수 있었을 것이다.\n\n \n\n이를 즉시로딩(fetch = EAGER)이라고 하며 이처럼 즉시로딩이 더 효율적인 경우도 매우 많다.\n\nJPA를 더 공부하게 되면 나중에 fetch join이라는 것을 배우게 될 것인데, 이것이 바로 즉시로딩을 활용한 예라고 볼 수 있다.\n\n \n\n🤔 로딩 전략은 어떻게 ?\n\n\n\nfetch의 기본 설정은 다음과 같다.\n\n \n\n\n  💡 @~ToOne (@OneToOne, @OneToMany) - 즉시로딩(FetchType.EAGER)\n\n  💡 @~ToMany (@ManyToOne, @ManyToMany) - 지연로딩(FetchType.LAZY)\n\n\n \n\nJPA의 기본 로딩 전략은 연관된 엔티티가 한개(~ToOne)면 즉시 로딩을,컬렉션(~ToMany)이면 지연 로딩을 사용한다.\n\n컬렉션을 로딩하는 것은 비용이 많이 들고 잘못하면 너무 많은 데이터를 메모리에 퍼올릴 수 있기 때문이다.\n\n예를 들어 특정 회원이 연관된 컬렉션에 데이터를 수천만건 등록했는데 이를 즉시 로딩으로 설정해둔 경우 해당 회원을 로딩하는 순간 메모리에 수천만건의 데이터도 함께 퍼올려진다.\n\n만약에 멀티스레드 환경에서 이런 일이 발생한다면 애플리케이션은 그 즉시 OutOfMemory를 띄우며 뻗어버릴것이다.\n\n \n\n권장하는 방법은 모든 상황에 대해 지연 로딩을 사용하고, 상황을 보면서 필요한 부분에 즉시로딩(fetch join)을 사용하여 최적화하는 것이다.\n\n \n\n💥 컬렉션 로딩 전략 주의점\n\n\n\n컬렉션에 FetchType.EAGER를 사용할 경우 주의점은 다음과 같다.\n\n \n\n\n  컬렉션을 하나 이상 즉시 로딩하는 것은 권장하지 않는다\n\n\n컬렉션과 조인한다는 것(~ToMany)은 데이터베이스 테이블로 보면 일대다 조인이다.\n\n일대다 조인은 결과 데이터가 다쪽에 있는 수만큼 증가하게 된다.\n\n문제는 서로 다른 컬렉션을 두개이상 조인할 때 발생하는데, 이를 SQL용어로 카티션 곱이라고 한다.\n\n \n\n여러개의 테이블을 조인했을 때 발생 가능한 모든 경우의 수가 출력되는 상황을 말하며,\n\nN개의 행을 가진 테이블과 M개의 행을 가진 테이블을 조인했을 경우 NM의 결과가 출력된다.\n\n \n\n이 문제가 발생하게 되면 시스템에 막대한 부하를 발생시키므로 반드시 피해야 하는 문제이다.\n\n \n\n\n\n \n\n\n  컬렉션 즉시 로딩은 항상 외부조인(OUTER JOIN)을 사용한다\n\n\n예를 들어 다대일 관계인 회원 테이블과 팀 테이블을 조인할 때 회원 테이블의 외래키에\n\nnot null 제약조건을 걸어두면 모든 회원은 반드시 어떤 팀에 소속되야 하므로\n\n이 경우 내부조인(INNER JOIN)을 사용해도 올바른 데이터가 출력된다.\n\n \n\n반대로 양방향 매핑을 걸어 팀 테이블에서 회원 테이블로 일대다 조인을 시도할 때\n\n회원이 한명도 없는 팀을 내부 조인하면 팀까지 조회되지 않는 상황이 발생한다.\n\n데이터베이스 시스템으로는 이런 상황을 미연에 방지할 수 없으므로\n\n애초에 양방향 매핑을 사용하지 않거나, 반드시 외부조인(OUTER JOIN)을 사용해야 한다.\n\n \n\nFetchType.EAGER 설정과 조인 전략은 다음과 같다.\n\n \n\n\n  @ManyToOne, @OneToOne\n    \n      (optional = false): 내부조인\n      (optional = true): 외부조인\n    \n  \n\n\n \n\n\n  @OneToMany, @ManyToMany\n    \n      (optional = false): 외부조인\n      (optional = true): 외부조인\n    \n  \n\n\n \n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-07-11-jpa-6/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "JPA 기초 7 - 값 타입",
      "date": "2021-07-12 00:00:00 +0000",
      "description": "객체지향적 기법인 값 타입에 대해 학습합니다\n",
      "content": "\n  📕 값 타입    \n      💥 주의점\n    \n  \n\n\n \n\n📕 값 타입\n\n\n\n값 타입은 엔티티 클래스의 필드를 추상화하는 기법이다.\n\n먼저 값 타입에 대해 알아보기 전에 값 타입을 쓰는 이유를 먼저 알아보자.\n\n정보처리기사 데이터베이스 과목에서 정규화는 굉장히 비중있게 나오는 내용이지만, 실제 현업에서는 일반적으로 정규화를 잘 하지 않는 것 같다.\n\n \n\n이유가 뭘까?\n\n \n\n정규화를 하는 가장 목적은 이상현상을 최소화하는 것일 것이다.\n\n쉽게 말하면 중복 데이터를 최대한 줄여서 데이터가 꼬이지 않게, 데이터 일관성을 유지하고자 하는 일련의 작업이다.\n\n그리고 부가적인 장점으로 중복 데이터가 줄어들게 되어 데이터의 저장용량이 최적화된다는 점이 있다.\n\n \n\n🤔 … 조금 더 쉽게 이해할 수 있게 예를 들어보자. (예시가 어거지일 수 있습니다. 양해바랍니다.)\n\n학교에 대한 모델링을 한다고 했을 때 학생에 대한 테이블을 만들어야 할 것이다.\n\n학생 테이블에는 학번, 이름, 나이, 전공 컬럼을 만들었다고 가정하자.\n\n \n\n\n  \n    \n      학번\n      이름\n      나이\n      전공\n    \n  \n  \n    \n      20131212\n      홍길동\n      20\n      컴퓨터과학\n    \n    \n      20131213\n      아무개\n      20\n      컴퓨터과학\n    \n  \n\n\n \n\n그렇게 서비스를 잘 운영하던 중 갑자기 휴학생 테이블이 필요해졌고, 즉시 테이블을 만들었다고 가정하자.\n\n \n\n\n  \n    \n      학번\n      이름\n      나이\n      전공\n      사유\n      기간\n    \n  \n  \n    \n      20131212\n      홍길동\n      20\n      컴퓨터과학\n      군대\n      20151212\n    \n  \n\n\n \n\n이렇게 홍길동의 데이터는 두개의 테이블에 각각 나누어 입력돼버렸다.\n\n두 테이블에 중복되는 데이터는 학번, 이름, 나이, 전공인 상태이다.\n\n \n\n이 상태에서 만약 둘 중 하나의 테이블에서 홍길동의 데이터가 업데이트 된다면, 데이터의 무결성을 보장해주기 위해 반대쪽 테이블에도 똑같이 업데이트를 쳐줘야만 할 것이다.\n\n이런 작업들이 이어지다보면 반드시 휴먼에러로 인한 실수가 발생할 것이고, 이는 데이터가 꼬여버리는 결과를 만들게 될 것이다.\n\n \n\n따라서 이렇게 중복되는 데이터들을 추출하여 별도의 테이블로 만들고, 재사용하게 만들면 이러한 번거로운 작업들을 피할 수 있게 되며, 데이터를 안전하게 핸들링할 수 있을 것이다.\n\n \n\n정규화가 마냥 장점만 있을 것 같지만, 웹 개발 분야에서는 정규화를 하게되면 생기는 단점이 생각보다 만만찮다.\n\n \n\n알고리즘과 자료구조에 대한 공부를 하다보면 시간복잡도와 공간복잡도라는 개념이 나온다.\n\n시간복잡도와 공간복잡도는 반비례한다.\n\n메모리를 많이 사용할수록 더욱 더 효율적인 연산을 할 수 있게 되기 때문이다.\n\n하지만 현대에 들어 하드웨어의 엄청난 발달과 함께 공간복잡도의 중요성이 미미해진 반면, 시간복잡도의 중요성은 여전하다.\n\n왜냐하면 이제는 메모리의 부족을 느낄 상황 자체가 매우 희박하기 때문이다.\n\n또한 시간은 우주적인 관점에서 봐도 절대적인 가치로, 시간은 그 어떤것을 주고도 살 수 없지만, 메모리는 돈주고 사서 증설할 수 있다. 한마디로 시간은 대체불가의 자원이지만, 메모리는 값싼 자원이다.\n\n \n\n인터넷 사용자들의 행위를 분석하여 통계를 내보니, 읽기(read)와 쓰기(write)의 비율이 약 8:2 혹은 7:3 정도로 읽기의 비율이 훨씬 더 높았다고 한다.\n\n그리고, 방문자 행동 분석시 사용자가 페이지 로딩에 과도한 시간을 기다릴 경우 페이지 이탈율이 급속도로 증가한다는 연구결과도 있다.\n\n즉, 사용자를 웹 사이트에 오래 머무르게 하는 것이 회사의 매출에 직접적인 영향을 끼친다는 뜻이다.\n\n그러니까 웹 개발에서는 읽기가 쓰기보다 더 중요한 위치를 갖는다고 볼 수 있을 것 같다.\n\n \n\n문제는 정규화를 해서 테이블이 잘게 쪼개지는 만큼 조인(join)을 해야하며, 많아지는 조인은 데이터베이스에 부하를 발생시킨다.\n\n또한, 조인으로 인해 트랜잭션의 로킹 단위가 커지게 되고, 이는 데이터베이스의 공유도를 감소시켜 동시성 성능이 떨어지게 만든다.\n\n결과적으로 이는 질의(query)에 대한 응답속도가 느려짐을 뜻하며, 고객이 느끼는 응답시간이 늘어남을 뜻하기도 한다.\n\n \n\n정리하자면, 정규화를 시행했을 때 기대되는 이득은 중복 데이터 제거, 저장용량의 최적화, 이상현상의 최소화라고 볼 수 있고, 이러한 이득을 얻기 위해 동시성을 포기해야만 한다. 이는 곧 시간적인 손실(=성능)이다.\n\n문제는 최근 트렌드는 저장용량을 크게 신경쓰지 않으면서 최대한 효율적인 연산을 하는 것이기 때문에, 정규화의 장점 중 저장용량의 최적화는 큰 장점이 되지 못하며, 유의미한 장점이라고 볼 수 있는 것은 결국 이상현상의 최소화이다.\n\n즉, 데이터의 무결성과 속도라는, 서로간에 장단점이 실로 명확하여 상황에 따라 정규화 혹은 반정규화를 진행해야 하는 trade-off가 있다고 볼 수 있다.\n\n \n\n결국 서비스를 운영하는 회사 입장에서 고객이 느끼는 응답속도의 저하는 굉장히 커다란 이슈임과 동시에,\n\n운영 데이터베이스에 많은 부하가 걸린다는 것은 전체 서비스의 다운이라는 최악의 상황을 초래할수도 있기 때문에 결과적으로 지나친 정규화를 하지 않는 쪽으로 가는 것 같다.\n\n \n\n“그래서 값 타입 이야기 하다 말고 뜬금없이 왜 정규화 타령이냐?” 라는 생각이 들수도 있다.\n\n \n\n위의 이유로 인해 실무에서는 지나친 정규화를 하지 않음으로써 테이블들의 컬럼이 수십개 이상인 경우가 굉장히 많다.\n\n이를 엔티티 클래스와 매핑하게 되면 테이블의 컬럼과 엔티티 클래스의 필드는 일대일로 매핑되므로\n\n엔티티 클래스의 필드도 수십개 이상이 되는 경우가 굉장히 흔하다.\n\n \n\n문제는 ORM을 실용적으로(=편리하게) 사용할 경우 엔티티 클래스가 PM(Persistence Model)과 DM(Domain Model)의 역할을 같이하게 된다는 것에서 발생한다.\n\n이러면 서비스 레이어(Service Layer)에는 코드가 별로 없고, 도메인 코드가 엔티티 클래스안에 들어있기 때문에 서비스 클래스는 엔티티들을 한데 모아 하나의 트랜잭션(Transaction)으로 묶어줌과 동시에 흐름제어를 하는 역할을 맡게 되는 경우가 많다.\n\n \n\n\n  이에 대한 자세한 예제가 궁금하다면 깃허브를 참고하시기 바랍니다.\n\n\n \n\n이러한 이유로 안그래도 엔티티 클래스에는 굉장히 많은 필드가 들어있는데, 도메인 코드마저 몰려있다면 엔티티 클래스 내부의 복잡도는 상상을 초월하게 커질수 있다.\n\n그래서 이 경우 엔티티 내부 필드들의 공통점을 찾아 별도의 클래스로 뽑아내는 작업을 하게된다.\n\n이 때 값 타입을 사용하게 된다고 이해하면 될 것 같다.\n\n \n\n사용 방법은 매우 간단하다.\n\n \n\n// file: 'Customer.java'\n@Entity\n@Getter\n@ToString(callSuper = true)\n@NoArgsConstructor(access = AccessLevel.PROTECTED)\n@RequiredArgsConstructor(access = AccessLevel.PRIVATE)\npublic class Customer extends BaseEntity {\n    @NonNull\n    private String firstName;\n\n    @NonNull\n    private String lastName;\n\n    @NonNull\n    private String phoneNumber;\n\n    @NonNull\n    private String city;\n\n    @NonNull\n    private String street;\n\n    @NonNull\n    private String zipcode;\n\n    @Builder\n    public static Customer of(@NonNull String firstName,\n                              @NonNull String lastName,\n                              @NonNull String phoneNumber,\n                              @NonNull String city,\n                              @NonNull String street,\n                              @NonNull String zipcode) {\n        return new Customer(firstName, lastName, phoneNumber, city, street, zipcode);\n    }\n\n    public String getName() {\n        return firstName + \" \" + lastName;\n    }\n\n    public String getAddress() {\n        return city + \" \" + street + \" \" + zipcode;\n    }\n}\n\n\n \n\n커머스 사이트에서 사용할만한 예제 클래스를 작성했다.\n\n고객에 대한 필수 정보라고 할만한 것들만 넣었음에도 벌써 코드가 꽤 길어져있다.\n\n단순 예제조차 이정도의 길이인데, 실무에서는 얼마나 더 길지 상상해보면 될 것 같다.\n\n그럼 이제 Customer를 값 타입을 이용해서 리팩토링해보겠다.\n\n \n\n// file: 'Customer.java'\n@Entity\n@Getter\n@ToString(callSuper = true)\n@NoArgsConstructor(access = AccessLevel.PROTECTED)\n@RequiredArgsConstructor(access = AccessLevel.PRIVATE)\npublic class Customer extends BaseEntity {\n    @NonNull\n    private Name name;\n\n    @NonNull\n    private String phoneNumber;\n\n    @NonNull\n    private Address address;\n\n    @Builder\n    public static Customer of(@NonNull Name name, @NonNull String phoneNumber, @NonNull Address address) {\n        return new Customer(name, phoneNumber, address);\n    }\n\n    public void changeAddress(String address) {\n        this.address.changeAddress(address);\n    }\n}\n\n\n \n\n// file: 'Address.java'\n@Getter\n@ToString\n@Embeddable\n@EqualsAndHashCode\n@Access(AccessType.FIELD)\n@NoArgsConstructor(access = AccessLevel.PROTECTED)\n@RequiredArgsConstructor(access = AccessLevel.PRIVATE)\npublic class Address {\n    @NonNull\n    private String city;\n\n    @NonNull\n    private String street;\n\n    @NonNull\n    private String zipcode;\n\n    @Builder\n    public static Address of(@NonNull String city, @NonNull String street, @NonNull String zipcode) {\n        return new Address(city, street, zipcode);\n    }\n\n    public String getAddress() {\n        return city + \" \" + street + \" \" + zipcode;\n    }\n\n    public void changeAddress(String address) {\n        String[] s = address.split(\" \");\n        if(s.length != 3) {\n            throw new IllegalArgumentException(\"입력 주소가 올바르지 않습니다.\");\n        }\n        this.city = s[0];\n        this.street = s[1];\n        this.zipcode = s[2];\n    }\n}\n\n\n \n\n// file: 'Name.java'\n@Getter\n@ToString\n@Embeddable // 값 타입임을 선언\n@EqualsAndHashCode\n@Access(AccessType.FIELD) // JPA가 접근자 매핑으로 오해하므로 필드 매핑임을 명시하여 컴파일 에러 방지\n@NoArgsConstructor(access = AccessLevel.PROTECTED)\n@RequiredArgsConstructor(access = AccessLevel.PRIVATE)\npublic class Name {\n    @NonNull\n    private String firstName;\n\n    @NonNull\n    private String lastName;\n\n    @Builder\n    public static Name of(@NonNull String firstName, @NonNull String lastName) {\n        return new Name(firstName, lastName);\n    }\n\n    public String getName() {\n        return firstName + \" \" + lastName;\n    }\n}\n\n\n \n\n이렇게 값 타입으로 사용할 클래스에 @Embeddable을 선언하여 JPA에 값 타입임을 알려주고, 이 클래스를 엔티티 클래스에 포함시켜 사용하면 된다.\n\n책에서는 엔티티 클래스에서 값 타입을 사용할 때 @Embedded를 선언하도록 적혀있지만 이는 생략해도 정상적으로 작동하기 때문에 작성하지 않았다.\n\n이렇게 사용함으로써 얻는 한가지 더 큰 이점은, 값 타입은 프로젝트 전체 엔티티에서 재사용 할 수 있다는 점이다.\n\n@MappedSuperclass와 @Embeddable을 적절하게 사용하면 굉장히 많은 부분을 추상화하여 재사용하도록 변경할 수 있다.\n\n이는 명백히 객체지향적인 접근 방법이기도 하기 때문에 ORM을 사용하는 관점에서 매우 권장할만한 방법이라고 볼 수 있다고 생각한다.\n\n \n\n💥 주의점\n\n\n\n어떻게 보면 굉장히 어이없는 주의점일수도 있다.\n\n왜냐하면 자바를 사용하는 입장에서 매우 당연한 일이기 때문이다.\n\n값 타입은 오브젝트이기 때문에 주소참조를 하게된다.\n\n \n\nCall By Reference, Call By Value\n\n혹은\n\n얕은복사, 깊은복사 라고 불리는 개념들에 대한 이야기다.\n\n \n\n// file: 'CustomerTest.java'\n@DataJpaTest\nclass CustomerTest {\n    @Autowired\n    CustomerRepository repository;\n\n    @Test\n    void customer(){\n        Name name = Name.of(\"firstName\", \"lastName\");\n        Address address = Address.of(\"city\", \"street\", \"zipcode\");\n\n        Customer customer1 = Customer.of(name, \"01000000001\", address);\n        Customer customer2 = Customer.of(name, \"01000000002\", address);\n\n        Customer saveCustomer1 = repository.save(customer1); // insert 쿼리 작성(쓰기지연)\n        Customer saveCustomer2 = repository.save(customer2); // insert 쿼리 작성(쓰기지연)\n        repository.flush(); // insert 쿼리 두번 발생\n\n        System.out.println(\"saveCustomer1 = \" + saveCustomer1);\n        System.out.println(\"saveCustomer2 = \" + saveCustomer2);\n\n        customer1.changeAddress(\"changeCity changeStreet changeZipcode\"); // update 쿼리 두번 작성(쓰기지연)\n        repository.flush(); // update 쿼리 두번 발생\n\n        System.out.println(\"changeCustomer1 = \" + saveCustomer1);\n        System.out.println(\"changeCustomer2 = \" + saveCustomer2);\n    }\n}\n\n\n \n\n간단하고 직관적인 테스트 코드를 작성했다.\n\naddress를 중간에 한번 변경하게 되는데, 이 경우에 address의 주소를 customer1과 customer2가 공유 참조하고 있으므로 값이 함께 변한다.\n\n \n\n실행 결과를 보자.\n\n \n\nHibernate: \n    insert \n    into\n        customer\n        (id, create_at, update_at, city, street, zipcode, first_name, last_name, phone_number) \n    values\n        (null, ?, ?, ?, ?, ?, ?, ?, ?)\nHibernate: \n    insert \n    into\n        customer\n        (id, create_at, update_at, city, street, zipcode, first_name, last_name, phone_number) \n    values\n        (null, ?, ?, ?, ?, ?, ?, ?, ?)\n        \nsaveCustomer1 = Customer(super=BaseEntity(id=1, createAt=2021-07-12T22:31:06.759843, updateAt=2021-07-12T22:31:06.759843), name=Name(firstName=firstName, lastName=lastName), phoneNumber=01000000001, address=Address(city=city, street=street, zipcode=zipcode))\nsaveCustomer2 = Customer(super=BaseEntity(id=2, createAt=2021-07-12T22:31:06.798738400, updateAt=2021-07-12T22:31:06.798738400), name=Name(firstName=firstName, lastName=lastName), phoneNumber=01000000002, address=Address(city=city, street=street, zipcode=zipcode))\n\nHibernate: \n    update\n        customer \n    set\n        create_at=?,\n        update_at=?,\n        city=?,\n        street=?,\n        zipcode=?,\n        first_name=?,\n        last_name=?,\n        phone_number=? \n    where\n        id=?\nHibernate: \n    update\n        customer \n    set\n        create_at=?,\n        update_at=?,\n        city=?,\n        street=?,\n        zipcode=?,\n        first_name=?,\n        last_name=?,\n        phone_number=? \n    where\n        id=?\n        \nchangeCustomer1 = Customer(super=BaseEntity(id=1, createAt=2021-07-12T22:31:06.759843, updateAt=2021-07-12T22:31:06.825667500), name=Name(firstName=firstName, lastName=lastName), phoneNumber=01000000001, address=Address(city=changeCity, street=changeStreet, zipcode=changeZipcode))\nchangeCustomer2 = Customer(super=BaseEntity(id=2, createAt=2021-07-12T22:31:06.798738400, updateAt=2021-07-12T22:31:06.826664100), name=Name(firstName=firstName, lastName=lastName), phoneNumber=01000000002, address=Address(city=changeCity, street=changeStreet, zipcode=changeZipcode))\n\n\n \n\naddress를 한번만 바꿨을 뿐인데 이를 참조하고 있는 customer1과 customer2의 address 값이 동시에 바뀌었음을 확인할 수 있다.\n\n \n\n이와 같은 상황을 얕은 복사라고 부른다.\n\n사실 자바를 공부하고 있다면 굉장히 기초적인 내용이긴 한데, 복잡한 실무상황에서 이런 문제가 발생하면 디버깅이 매우매우매우매우 어렵다.\n\n값 타입은 그냥 JPA관련 어노테이션이 붙었다 뿐이지, 단순히 오브젝트 타입의 필드이기 때문에 위와 같은 자바의 문제점이 그대로 적용된다.\n\n \n\n어떻게 해결할까?\n\n \n\n깊은 복사를 사용하면 된다.\n\n뭐 실제로 이렇게 값 타입을 사용하면서 값을 복사해서 쓰는 경우가 얼마나 있을지는 나도 잘 모르겠지만, 일단 알아두면 도움이 될 것 같다.\n\n나같은 경우엔 복사용 메서드를 생성해서 사용한다.\n\n \n\n// file: 'Address.java'\npublic Address newInstance() {\n    return Address.builder()\n                  .city(this.city)\n                  .street(this.street)\n                  .zipcode(this.zipcode)\n                  .build();\n}\n\n\n \n\n// file: 'CustomerTest.java'\n@DataJpaTest\nclass CustomerTest {\n    @Autowired\n    CustomerRepository repository;\n\n    @Test\n    void customer(){\n        Name name = Name.of(\"firstName\", \"lastName\");\n        Address address = Address.of(\"city\", \"street\", \"zipcode\");\n\n        Customer customer1 = Customer.of(name, \"01000000001\", address);\n        Customer customer2 = Customer.of(name, \"01000000002\", address.newInstance()); // 깊은 복사\n\n        Customer saveCustomer1 = repository.save(customer1); // insert 쿼리 작성(쓰기지연)\n        Customer saveCustomer2 = repository.save(customer2); // insert 쿼리 작성(쓰기지연)\n        repository.flush(); // insert 쿼리 두번 발생\n\n        System.out.println(\"saveCustomer1 = \" + saveCustomer1);\n        System.out.println(\"saveCustomer2 = \" + saveCustomer2);\n\n        customer1.changeAddress(\"changeCity changeStreet changeZipcode\"); // update 쿼리 한번 작성(쓰기지연)\n        repository.flush(); // update 쿼리 한번 발생\n\n        System.out.println(\"changeCustomer1 = \" + saveCustomer1);\n        System.out.println(\"changeCustomer2 = \" + saveCustomer2);\n    }\n}\n\n\n \n\n결과를 확인한다.\n\n \n\nHibernate: \n    insert \n    into\n        customer\n        (id, create_at, update_at, city, street, zipcode, first_name, last_name, phone_number) \n    values\n        (null, ?, ?, ?, ?, ?, ?, ?, ?)\nHibernate: \n    insert \n    into\n        customer\n        (id, create_at, update_at, city, street, zipcode, first_name, last_name, phone_number) \n    values\n        (null, ?, ?, ?, ?, ?, ?, ?, ?)\n        \nsaveCustomer1 = Customer(super=BaseEntity(id=1, createAt=2021-07-12T22:45:36.286366900, updateAt=2021-07-12T22:45:36.286366900), name=Name(firstName=firstName, lastName=lastName), phoneNumber=01000000001, address=Address(city=city, street=street, zipcode=zipcode))\nsaveCustomer2 = Customer(super=BaseEntity(id=2, createAt=2021-07-12T22:45:36.335236400, updateAt=2021-07-12T22:45:36.335236400), name=Name(firstName=firstName, lastName=lastName), phoneNumber=01000000002, address=Address(city=city, street=street, zipcode=zipcode))\n\nHibernate: \n    update\n        customer \n    set\n        create_at=?,\n        update_at=?,\n        city=?,\n        street=?,\n        zipcode=?,\n        first_name=?,\n        last_name=?,\n        phone_number=? \n    where\n        id=?\n        \nchangeCustomer1 = Customer(super=BaseEntity(id=1, createAt=2021-07-12T22:45:36.286366900, updateAt=2021-07-12T22:45:36.367150), name=Name(firstName=firstName, lastName=lastName), phoneNumber=01000000001, address=Address(city=changeCity, street=changeStreet, zipcode=changeZipcode))\nchangeCustomer2 = Customer(super=BaseEntity(id=2, createAt=2021-07-12T22:45:36.335236400, updateAt=2021-07-12T22:45:36.335236400), name=Name(firstName=firstName, lastName=lastName), phoneNumber=01000000002, address=Address(city=city, street=street, zipcode=zipcode))\n\n\n \n\ncustomer1 의 값만 안전하게 변경되고, update 쿼리 또한 한번만 발생한 것을 확인 할 수 있다.\n\n \n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-07-12-jpa-7/"
    },{
      "image": "/assets/img/backend/gradle-logo.png",
      "title": "Gradle 이란?",
      "date": "2021-07-14 00:00:00 +0000",
      "description": "Gradle에 대해 공부하기 전에 Gradle의 배경에 대해 알아봅시다\n",
      "content": "\n  🤔 빌드 툴이란?\n  📕 빌드 툴의 역사    \n      🚀 메이크(Make)\n      🚀 앤트(Ant)\n      🚀 메이븐(Maven)\n    \n  \n  👍 그레이들(Gradle)    \n      그레이들의 특징\n    \n  \n\n\n \n\n🤔 빌드 툴이란?\n\n\n\n소프트웨어 개발에서 대부분의 작업 순서는 정형화되어 있다.\n\n정적타이핑 언어인 자바로 작성된 애플리케이션을 예로 들면 다음과 같은 작업 순서를 따른다.\n\n \n\n\n  소스코드(.java)를 컴파일해 클래스파일(.class)을 생성한다\n  클래스파일을 기계어로 번역한다\n  기계어로 번역된 코드를 테스트를 하고 테스트 결과를 출력한다\n  Javadoc과 같은 문서를 작성한다\n  클래스파일과 리소스파일을 패키징한다 (jar 또는 war)\n  패키징한 파일을 배포하거나 저장소에 등록한다\n\n\n \n\n파이썬, 자바스크립트, 루비같은 스크립트 언어들의 경우 컴파일 과정은 생략되지만 이외의 작업은 모두 동일하게 가져간다.\n\n빌드 툴이란 이렇게 코드를 작성하는 것 외의 작업들을 자동화하기 위한 소프트웨어다.\n\n메이븐(Maven), 그레이들(Gradle) 등의 빌드 툴을 사용하지 않으면 외부 라이브러리를 자신의 프로젝트에 포함시키려 할때마다 jar등의 패키징된 파일을 직접 구해서 프로젝트의 클래스패스에 넣어줘야만 한다.\n\n하지만 메이븐 이후의 빌드 툴을 사용 할 경우 빌드 툴 설정에 의존성 설정만 해주면 모든 라이브러리를 자동으로 다운받고 설정해준다.\n\n이 외의 컴파일을 CLI환경에서 모두 수작업으로 해줘야 한다거나 배포를 하기가 매우 힘들어진다거나 하는 어려움들도 있다.\n\n더욱이 최근에는 젠킨스(Jenkins), 트래비스(Travis CI) 등의 CI/CD툴의 발전과 이러한 CI/CD 툴과 빌드 툴의 호환으로 인해 빌드 툴을 잘 다루는 것이 매우 중요해졌다.\n\n \n\n즉, 빌드 툴을 잘 다루게 되면 개발자는 자신이 개발해야 하는 중요한 비즈니스 로직에만 더욱 더 집중할 수 있게된다.\n\n프로젝트 구성, 컴파일, 의존성 설정, 테스트, 빌드, 배포, 저장소 등록 등의 모든 작업을 빌드 툴이 자동화해줄 수 있기 때문이다.\n\n간단한 예로 아직도 많은 팀들이 배포날에 야근, 철야를 하는 경우가 매우 많다는 것을 상기해보자.\n\nCI/CD 환경이 완벽하게 자동화 된 팀은 배포에 대한 리스크가 아주 미미하다.\n\n \n\n📕 빌드 툴의 역사\n\n \n\n🚀 메이크(Make)\n\n\n\n \n\n\n  https://www.gnu.org/software/make/\n\n\n \n\n메이크 이전에는 모든 작업을 수작업이나 약간의 스크립트를 작성해서 처리했다고 한다.\n\n메이크의 등장이후 Makefile이라는 것으로 모든 구조를 통일하여 처리할 수 있게 되었고, 소프트웨어 세계예 빌드라는 개념이 처음으로 생겼다고 한다.\n\nC언어는 아직도 메이크를 사용하여 빌드한다고 한다.\n\n \n\n🚀 앤트(Ant)\n\n\n\n \n\n\n  http:/ant.apache.org/\n\n\n \n\n메이크가 등장한 이후 오랫동안 큰 변화가 없다가 1990년대에 자바가 등장하면서 문제가 생겼다고 한다.\n\n자바에 메이크를 적용하려니 매우 많은 문제가 발생했기 때문이란다.\n\n그래서 자바만을 위한 빌드 툴이 등장하게 됐는데, 이것이 아직도 유명한 앤트다.\n\n \n\n앤트는 당시 혁신적이었던 JVM에 XML을 도입하여 메이크의 단점이었던 플랫폼 의존 문제를 해결했다고 한다.\n\n그렇게 자바의 유행과 함께 앤트는 자바 생태계에서 독보적인 빌드 툴로 자리잡았고, 아직까지도 사용되고 있다.\n\n \n\n앤트는 진입장벽이 매우 낮다는 장점이 있지만, 프로젝트가 약간만 복잡해져도 빌드 스크립트가 장황해져 관리하기가 어려웠다고 한다.\n\n그리고 가장 큰 단점으로 라이브러리간의 의존관계를 관리할 수 없어서 이로인한 문제가 고질적이었단다.\n\n \n\n🚀 메이븐(Maven)\n\n\n\n \n\n\n  http://maven.apache.org/\n\n\n \n\n메이븐은 자바에 XML을 사용해 플랫폼 독립성을 확보한 것은 앤트와 같으나, 빌드 생명주기와 프로젝트 객체 모델(POM)이라는 새로운 개념을 도입하였다.\n\n또한 앤트의 약점이었던 장황한 빌드 스크립트와 라이브러리 의존관계를 모두 해결한 혁명적인 빌드툴이었다고 한다.\n\n메이븐은 POM에 메타데이터를 적용하여 라이브러리 의존관계를 자동으로 관리해주는 기능을 구현했으며, 이 기능을 구현하기 위해 위해 메이븐 중앙 저장소(Maven Central Repository)를 구축했다.\n\n메이븐은 이 글을 작성하는 2021년 7월 현재에도 전 세계적으로 매우 활발하게 사용되고 있으며, Gradle은 아주 많은 의존 라이브러리를 메이븐 중앙 저장소에서 받아온다.\n\n \n\n// file: 'build.gradle'\nrepositories {\n    mavenCentral() // 메이븐 중앙 저장소\n}\n\n\n \n\n메이븐은 소프트웨어 역사에 위대한 업적을 세운 빌드 툴이지만 큰 단점도 존재한다.\n\n먼저 XML로 작성된다는 특징으로 인해 프로젝트의 유연한 구조 변경이 매우 어렵다.\n\n그리고 기능이 매우 다양한 만큼 제약또한 매우 강력하며, 이러한 규칙을 어겨가며 사용하게 될 경우 빌드 툴의 사용 난이도가 말도안되게 높아진다.\n\n \n\n👍 그레이들(Gradle)\n\n\n\n \n\n\n  From mobile apps to microservices, from small startups to big enterprises, Gradle helps teams build, automate and deliver better software, faster.\n\n\n \n\n\n  그레이들 홈페이지\n\n  그레이들 - 사용자 가이드\n\n  그레이들 - 깃허브\n\n\n \n\n그레이들은 위의 모든 빌드 툴의 단점을 타파하고 모든 장점을 가져왔으며, 위 모든 빌드 툴의 생태계를 적극적으로 활용할 수 있게 만들어졌다.\n\n우선 위의 내용을 정리하면 다음과 같다.\n\n \n\n\n  \n    \n      빌드 툴\n      타입\n      언어\n      상세\n    \n  \n  \n    \n      메이크\n      동적\n      스크립트\n      오직 처리에 중점을 둠\n    \n    \n      앤트\n      정적\n      XML\n      오직 처리에 중점을 둠\n    \n    \n      메이븐\n      정적\n      XML\n      구조와 규칙에 중점을 둠\n    \n    \n      그레이들\n      동적\n      스크립트\n      구조와 규칙에 중점을 둠\n    \n  \n\n\n \n\n각 빌드 툴은 소프트웨어 생태계에 다음과 같은 족적을 남겼다.\n\n \n\n\n  메이크: 소프트웨어 생태계에 빌드라는 개념을 확립시켰다\n  앤트: 플랫폼에 대한 범용성을 크게 늘렸다 (크로스 플랫폼)\n  메이븐: 빌드 스크립트의 혁신을 가져왔다 (규칙 기반의 빌드 툴)\n  그레이들: 모든 장점을 가지면서 유연성을 대폭 늘렸다 (스크립트 언어로의 회귀)\n\n\n \n\n그레이들은 이러한 진화를 위해 JVM 생태계의 스크립트 언어인 그루비(Groovy)를 기반 언어로 선택하였으며, 그루비로 작성된 프로그램 중 가장 성공적인 프로그램이 그레이들이기도 하다.\n\n그레이들은 그루비DSL을 도입하여 독자적인 영역을 구축했고, 그레이들은 현존하는 대부분의 언어를 빌드할 수 있다.\n\n \n\n\n  💡 DSL ?\n\n  DSL은 Domain Specific Language의 약자로, 도메인에 특화된 언어를 말한다.\n그루비DSL은 그루비와는 약간 다르며 오로지 그레이들에만 특화된 언어이다.\n\n\n \n\n그레이들의 특징\n\n\n\n\n  자유롭게 확장 가능한 그레이들 전용 언어(그루비DSL)\n  빌드 분할 등의 작업을 체계화 하기 쉬움(태스크)\n  IDE와 연계하여 그레이들을 외부에서 제어할 수 있는 API 제공(Gradle Wrapper)\n  병렬 빌드를 도입하여 빌드의 속도를 대폭 증가시킴\n  멀티 프로젝트를 아주 쉽게 구축할 수 있음\n  메이븐/아이비 저장소 뿐만 아니라 사설 저장소까지 활용하여 다양한 의존관계를 관리할 수 있게 해줌\n  앤트 프로젝트를 통합할 수 있음\n  빌드 스크립트를 그루비로 작성하여, 자바 개발자라면 쉽게 그레이들 빌드 스크립트를 작성할 수 있음\n  그레이들 래퍼(Gradle Wrapper)를 이용하여 그레이들이 설치되지 않았더라도 그레이들의 태스크를 사용 가능\n  호환성을 최대한 배려해줌\n\n",
      "categories": ["backend","gradle"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/gradle/2021-07-14-gradle-1/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "Spring REST Docs로 API 문서작성 자동화하기",
      "date": "2021-07-17 00:00:00 +0000",
      "description": "개발자간 협업에 아주 큰 도움이 되는 API 문서작성을 자동화 합니다\n",
      "content": "\n  🤔 Spring REST Docs ?\n  🤔 Spring REST Docs의 장단점    \n      👍 장점\n      😣 단점\n    \n  \n  📕 Spring REST Docs 적용    \n      🚀 개발환경\n      🚀 설정\n    \n  \n  참고\n\n\n\n\n포스팅에 사용된 예제 코드는 🚀GitHub 를 참고해주세요.\n\n🤔 Spring REST Docs ?\n\n\n\n개발자간 협업에서 API 문서는 굉장히 중요하다.\n\n개발자는 API 문서를 보면 서버에 어떤 요청을 보내면 어떤 응답이 오는지를 한눈에 알 수 있기 때문에 API 문서가 얼마나 가독성이 좋고, 정확하냐에 따라 개발 생산성의 차이가 눈에띄게 변하기 때문이다.\n\n\n\n가장 원시적인 방법으로 API를 개발하고, 이를 개발자가 직접 문서로 작성하여(wiki같은…) 공유하는 방법이 있다.\n\n이 방법의 경우 API 스펙이 변하게 되면 문서도 따라서 변경해줘야 하기 때문에 시간이 지날수록 점점 관리되지 않는 문서가 될 가능성이 높다.\n\n\n\n이러한 문제를 해결하기 위해 API 문서를 자동으로 작성해주는 방법이 존재하는데, API 문서 프레임워크의 양대 산맥으로 Swagger와 Spring REST Docs가 있다.\n\n두 프레임워크는 서로 장단점이 명확하기 때문에 개발자마다 호불호가 갈리는 것 같다.\n\n\n\n이 포스팅에서는 Spring REST Docs로 문서를 생성하는 방법에 대해 다룰것이다.\n\n\n\n🤔 Spring REST Docs의 장단점\n\n\n\n필자는 Swagger의 UI가 더 이쁘다고 생각하는데, 이는 지극히 주관적인 관점이므로 이에 대해 따로 적지 않을 것이다.\n\n누군가는 Spring Rest Docs의 문서가 더 이쁘다고 생각할수도 있기 때문이다.\n\n\n\n\n  📜 Spring REST Docs 문서 예시\n\n\n\n\n👍 장점\n\n\n\n\n  API 문서를 작성하기 위해 테스트 코드가 강제되므로 문서의 신뢰성이 매우 높다\n  Spring Boot Starter로 매우 간편하게 설정할 수 있다\n  문서가 매우 직관적이다\n\n\n\n\n😣 단점\n\n\n\n\n  문서를 작성하려면 테스트 코드가 강제되기 때문에 테스트 코드에 익숙하지 않다면 도입 난이도가 굉장히 높다\n  문서를 커스터마이징 하려면 Asciidoc 문법을 알아야 한다\n  Swagger 문서와 다르게 문서에서 API를 즉석으로 테스트 할 수 없다 (Curl 커맨드를 제공해주긴 한다)\n\n\n\n\n📕 Spring REST Docs 적용\n\n\n\nSpring REST Docs를 적용하기 위한 방법에 대해 설명한다.\n\n\n\n🚀 개발환경\n\n\n\n\n  \n    \n      항목\n      버전\n    \n  \n  \n    \n      java\n      11\n    \n    \n      gradle\n      6.9\n    \n    \n      spring-boot\n      2.6.1\n    \n    \n      asciidoctor convert plugin\n      1.5.8\n    \n  \n\n\n\n\n🚀 설정\n\n\n\n테스트하는데 사용할 수 있는 구현체가 MockMvc, Restassured, WebClient로 총 세개 존재한다.\n\n취향껏 골라 사용하면 되겠다. 각 의존성은 하기와 같다.\n\n\n\n// file: 'build.gradle'\ndependencies {\n    testImplementation 'org.springframework.restdocs:spring-restdocs-mockmvc'\n    testImplementation 'org.springframework.restdocs:spring-restdocs-restassured'\n    testImplementation 'org.springframework.restdocs:spring-restdocs-webtestclient'\n}\n\n\n\n\nSpring REST Docs는 테스트 결과를 여러개의 adoc 스니펫(조각)으로 생성해준다.\n\n이후 개발자가 생성된 스니펫들을 Asciidoc 문법을 사용해 하나의 문서로 조합하는 방식으로 동작한다.\n\n즉, 책을 하나 만든다고 생각하면 편하다.\n\n책에는 챕터가 있으며, 각 챕터에는 세부 내용들이 있을것이다.\n\n그러니까 기본적으로 3개의 depth가 생길 수 있다.\n\n\n\n아래는 Spring REST Docs를 적용하기 위한 필수적인 설정들이다.\n\n\n\n// file: 'build.gradle'\nplugins {\n    id 'java'\n    id 'org.springframework.boot' version '2.6.1'\n    id 'io.spring.dependency-management' version '1.0.11.RELEASE'\n    id 'org.asciidoctor.convert' version '1.5.8' // API 문서를 생성하기 위한 플러그인\n}\n\next {\n    set('snippetsDir', file('build/generated-snippets')) // API 문서 스니펫을 생성할 위치를 전역 변수로 지정\n}\n\ndependencies {\n    testImplementation 'org.springframework.boot:spring-boot-starter-test'\n    testImplementation 'org.springframework.restdocs:spring-restdocs-mockmvc'\n}\n\ntest {\n    outputs.dir snippetsDir // Spring REST Docs가 생성하는 스니펫을 작성할 위치  \n    useJUnitPlatform()\n}\n\nasciidoctor {\n    inputs.dir snippetsDir // Asciidoctor가 문서를 생성해낼 때 필요한 스니펫을 읽어들일 위치\n    dependsOn test\n}\n\nbootJar {\n    dependsOn asciidoctor\n    from(\"${asciidoctor.outputDir}/html5\") { // 빌드할 때 Asciidoctor가 만들어낸 HTML 문서를 jar파일에 포함시킨다\n        into 'BOOT-INF/classes/static/docs'\n    }\n}\n\ntask copyDocument(type: Copy) { // Asciidoctor가 build 디렉토리에 생성해낸 HTML 문서를 Spring의 정적 리소스 위치로 복사한다\n    dependsOn asciidoctor\n\n    from file('build/asciidoc/html5/')\n    into file('src/main/resources/static/docs')\n}\n\nbuild {\n    dependsOn copyDocument // build 태스크 실행되면 copyDocument 태스크를 먼저 유발시킨다\n}\n\n\n\n\n필수적인 빌드 스크립트 설정을 하였다면 src/docs/asciidoc/{document-name}.adoc 파일을 작성해준다.\n\nsrc/docs/asciidoc 까지의 경로는 고정이며, 하위 adoc 파일의 이름은 개발자 마음대로 작명해도 된다.\n\n나는 유저 조회, 유저 생성이라는 두개의 API를 만들것이다.\n\n따라서 API 문서는 총 두개가 나올것이며, 이들을 묶어줄 색인(index.html)도 필요하다.\n\n\n\nsrc/docs/asciidoc 경로는 버전마다 다를 수 있으니 잘 안된다면 공식문서를 참고하자!\n\n\n\n// file: 'src/docs/asciidoc/user-find.adoc'\n=== 조회\n:basedir: {docdir}/../../../\n:snippets: {basedir}/build/generated-snippets\n:icons: font\n:source-highlighter: highlightjs\n:toc: left\n:toclevels: 4\n\n==== 설명\n\n유저 조회에 성공한 경우\n\n==== 요청\n\n===== 요청 필드\n\ninclude::{snippets}/user-find/request-parameters.adoc[]\n\n===== Curl 요청 코드\n\ninclude::{snippets}/user-find/curl-request.adoc[]\n\n===== 요청 예제\n\ninclude::{snippets}/user-find/http-request.adoc[]\n\n==== 응답\n\n===== 응답 필드\n\ninclude::{snippets}/user-find/response-fields.adoc[]\n\n===== 응답 예제\n\ninclude::{snippets}/user-find/http-response.adoc[]\n\n\n\n\n// file: 'src/docs/asciidoc/user-create.adoc'\n=== 생성\n:basedir: {docdir}/../../../\n:snippets: {basedir}/build/generated-snippets\n:icons: font\n:source-highlighter: highlightjs\n:toc: left\n:toclevels: 4\n\n==== 설명\n\n유저 추가에 성공한 경우\n\n==== 요청\n\n===== 요청 필드\n\ninclude::{snippets}/user-create/request-fields.adoc[]\n\n===== Curl 요청 코드\n\ninclude::{snippets}/user-create/curl-request.adoc[]\n\n===== 요청 예제\n\ninclude::{snippets}/user-create/http-request.adoc[]\n\n==== 응답\n\n===== 응답 필드\n\ninclude::{snippets}/user-create/response-fields.adoc[]\n\n===== 응답 예제\n\ninclude::{snippets}/user-create/http-response.adoc[]\n\n\n\n\n그리고 이 문서들을 묶어줄 챕터격의 문서를 하나 더 만든다.\n\n\n\n// file: 'src/docs/asciidoc/user.adoc'\n== 유저 API\n:basedir: {docdir}/../../../\n:snippets: {basedir}/build/generated-snippets\n:icons: font\n:source-highlighter: highlightjs\n:toc: left\n:toclevels: 4\n\ninclude::./user-find.adoc[]\n\ninclude::./user-create.adoc[]\n\n\n\n\n마지막으로 챕터들이 묶여있는 책의 역할을 하는 색인(index.html)을 만들어야 한다.\n\n\n\n// file: 'src/docs/asciidoc/index.adoc'\n= API DOCUMENTATION\n:icons: font\n:source-highlighter: highlightjs\n:toc: left\n:toclevels: 4\n:sectlinks: /build/asciidoc/html5/\n:sectnums:\n\n== 소개\n\n유저 API 입니다.\n\n== 환경\n\n서비스의 각종 환경에 대한 정보를 표시합니다.\n\n=== 도메인\n\n서비스의 도메인 호스트는 다음과 같습니다.\n\nNOTE: 인프라 팀에서 설정합니다.\n\n|===\n| 환경 | URI\n\n| 개발서버\n| `io.github.shirohoo-dev`\n\n| 운영서버\n| `io.github.shirohoo`\n|===\n\ninclude::./user.adoc[]\n\n\n\n\n여기까지 완료하면 모든 설정이 끝났다.\n\n\n\nAsciidoc 문법에 대한 자세한 내용은 📜여기 와 📜여기 를 참고하세요.\n\n\n\n문서를 작성하기 위해서는 컨트롤러에 대한 테스트코드가 반드시 필요하다.\n\n예시를 위해 아주 간단한 컨트롤러를 하나 작성하고 이를 테스트하는 테스트 코드를 작성할 것이다.\n\n\n\n@RestController\npublic class ApiController {\n\n    @GetMapping\n    public ResponseEntity&lt;User&gt; get(@RequestParam String phoneNumber) {\n        Map&lt;String, User&gt; users = getRepository();\n\n        if (users.containsKey(phoneNumber)) {\n            return ResponseEntity.ok(users.get(phoneNumber));\n        }\n        return ResponseEntity.notFound().build();\n    }\n\n    @PostMapping\n    public ResponseEntity&lt;User&gt; post(@RequestBody User user) {\n        Map&lt;String, User&gt; users = getRepository();\n\n        if (users.containsKey(user)) {\n            return ResponseEntity.badRequest().build();\n        }\n        users.put(user.getPhoneNumber(), user);\n        return ResponseEntity.status(HttpStatus.CREATED)\n                .body(user);\n    }\n\n    private Map&lt;String, User&gt; getRepository() {\n        Map&lt;String, User&gt; users = new HashMap&lt;&gt;();\n        users.put(\"010-1234-5678\", new User(\"user1\", 11, \"010-1234-5678\", LocalDate.of(2000, 1, 1)));\n        users.put(\"010-1111-1111\", new User(\"user2\", 22, \"010-1111-1111\", LocalDate.of(2000, 1, 1)));\n        users.put(\"010-1234-1111\", new User(\"user3\", 33, \"010-1234-1111\", LocalDate.of(2000, 1, 1)));\n        return users;\n    }\n\n    @Data\n    @Builder\n    @NoArgsConstructor\n    @AllArgsConstructor\n    public static class User {\n\n        private String name;\n\n        private int age;\n\n        private String phoneNumber;\n\n        private LocalDate birthDay;\n\n    }\n\n}\n\n\n\n\n이제 테스트 코드를 작성해야 하는데, JUnit을 사용해보신 독자라면 스프링 컨텍스트를 매 테스트마다 리로딩하는것이 얼마나 테스트를 느리게 만드는지 잘 알것이다.\n\n이 문제를 해결하기 위해 Spring REST Docs 테스트를 실행할 때 사용할 추상 클래스를 하나 정의하도록 한다.\n\n이 추상 클래스를 사용해 테스트를 실행시키면 스프링 컨텍스트를 단 한번만 로딩한 후 이를 재사용함으로써 테스트 시간을 대폭 단축시킬 수 있게된다.\n\n\n\n@WebMvcTest(controllers = {\n    ApiController.class // 여기에 테스트 대상 컨트롤러들을 추가\n})\n@ExtendWith(RestDocumentationExtension.class)\n@AutoConfigureRestDocs(uriScheme = SCHEME, uriHost = HOST)\npublic class AbstractControllerTests {\n\n    // 여기서 문서에 표시될 정보들을 정의\n    public static final String SCHEME = \"https\";  \n    public static final String HOST = \"io.github.shirohoo\";\n\n    @Autowired\n    protected MockMvc mockMvc;\n\n    @Autowired\n    protected ObjectMapper objectMapper;\n\n    // 나중에 테스트 코드 중 문서작성부에 사용될 편의성 메서드들을 정의\n    protected static OperationRequestPreprocessor documentRequest() {\n        return Preprocessors.preprocessRequest(\n            Preprocessors.modifyUris()\n                .scheme(SCHEME)\n                .host(HOST)\n                .removePort(),\n            prettyPrint());\n    }\n\n    protected static OperationResponsePreprocessor documentResponse() {\n        return Preprocessors.preprocessResponse(prettyPrint());\n    }\n\n    protected static StatusResultMatchers status() {\n        return MockMvcResultMatchers.status();\n    }\n\n    protected static ContentResultMatchers content() {\n        return MockMvcResultMatchers.content();\n    }\n\n}\n\n\n\n\n이후로 위 추상 클래스에 테스트 할 컨트롤러를 추가하고, 다른 객체를 모킹해야 한다면 @MockBean도 여기에 선언하도록 하자.\n\n그리고 다음과 같은 테스트 코드를 작성한다.\n\n\n\nimport static org.springframework.restdocs.mockmvc.MockMvcRestDocumentation.document;\nimport static org.springframework.restdocs.payload.PayloadDocumentation.fieldWithPath;\nimport static org.springframework.restdocs.payload.PayloadDocumentation.requestFields;\nimport static org.springframework.restdocs.payload.PayloadDocumentation.responseFields;\nimport static org.springframework.restdocs.request.RequestDocumentation.parameterWithName;\nimport static org.springframework.restdocs.request.RequestDocumentation.requestParameters;\nimport io.github.shirohoo.springrestdocs.api.ApiController.User;\nimport java.time.LocalDate;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.http.MediaType;\nimport org.springframework.restdocs.payload.JsonFieldType;\nimport org.springframework.test.web.servlet.ResultActions;\nimport org.springframework.test.web.servlet.request.MockMvcRequestBuilders;\n\nclass ApiControllerTest extends AbstractControllerTests {\n\n    @Test\n    void get() throws Exception {\n        // ...given\n        String request = \"010-1234-5678\";\n        String response = objectMapper.writeValueAsString(\n                new User(\"user1\", 11, \"010-1234-5678\", LocalDate.of(2000, 1, 1))\n        );\n\n        // ...when\n        ResultActions actions = mockMvc.perform(MockMvcRequestBuilders.get(\"/?phoneNumber=\" + request));\n\n        // ...then\n        actions.andExpect(status().isOk())\n                .andExpect(content().json(response))\n                .andDo(document(\"user-find\", // 여기부터 Spring REST Docs의 문서화 코드\n                        documentRequest(), // 요청부를 전처리하고 문서에 기록한다\n                        documentResponse(), // 응답부를 전처리하고 문서에 기록한다\n                        requestParameters( // 여기부터 검증 및 문서화 코드. 검증에 실패하면 테스트도 실패한다\n                                parameterWithName(\"phoneNumber\").description(\"휴대폰 번호\")\n                        ),\n                        responseFields(\n                                fieldWithPath(\"name\").type(JsonFieldType.STRING).description(\"이름\"),\n                                fieldWithPath(\"age\").type(JsonFieldType.NUMBER).description(\"나이\"),\n                                fieldWithPath(\"phoneNumber\").type(JsonFieldType.STRING).description(\"휴대폰 번호\"),\n                                fieldWithPath(\"birthDay\").type(JsonFieldType.STRING).description(\"생일\")\n                        )\n                ));\n    }\n\n    @Test\n    void post() throws Exception {\n        // ...given\n        String request = objectMapper.writeValueAsString(\n                new User(\"user4\", 44, \"010-5678-5678\", LocalDate.of(2000, 1, 1))\n        );\n\n        // ...when\n        ResultActions actions = mockMvc.perform(MockMvcRequestBuilders.post(\"/\")\n                .content(request)\n                .contentType(MediaType.APPLICATION_JSON)\n                .accept(MediaType.APPLICATION_JSON)\n        );\n\n        // ...then\n        actions.andExpect(status().isCreated())\n                .andExpect(content().json(request))\n                .andDo(document(\"user-create\", // 여기부터 Spring REST Docs의 문서화 코드\n                        documentRequest(), // 요청부를 전처리하고 문서에 기록한다\n                        documentResponse(), // 응답부를 전처리하고 문서에 기록한다\n                        requestFields( // 여기부터 검증 및 문서화 코드. 검증에 실패하면 테스트도 실패한다\n                                fieldWithPath(\"name\").type(JsonFieldType.STRING).description(\"이름\"),\n                                fieldWithPath(\"age\").type(JsonFieldType.NUMBER).description(\"나이\"),\n                                fieldWithPath(\"phoneNumber\").type(JsonFieldType.STRING).description(\"휴대폰 번호\"),\n                                fieldWithPath(\"birthDay\").type(JsonFieldType.STRING).description(\"생일\")\n                        ),\n                        responseFields(\n                                fieldWithPath(\"name\").type(JsonFieldType.STRING).description(\"이름\"),\n                                fieldWithPath(\"age\").type(JsonFieldType.NUMBER).description(\"나이\"),\n                                fieldWithPath(\"phoneNumber\").type(JsonFieldType.STRING).description(\"휴대폰 번호\"),\n                                fieldWithPath(\"birthDay\").type(JsonFieldType.STRING).description(\"생일\")\n                        )\n                ));\n    }\n\n}\n\n\n\n\n테스트가 통과하면 빌드를 한다.\n\n빌드에 성공하면 Spring REST Docs 코드에 명시한 대로 build/generated-snippets 경로에 Asciidoc 스니펫이 생성돼있을 것이다.\n\n\n\n\n\n\n\n또한, src/main/resources/static/docs 에 몇가지 HTML 문서도 생성되어 있을 것이다.\n\n\n\n\n\n\n\n여기까지 완료하면 생성되는 index.html은 다음과 같다\n\n\n\n\n  📜 index.html\n\n\n\n\n참고\n\n\n\n\n  Spring REST Docs Document\n\n\n\n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-07-17-spring-rest-docs/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "Spring Rest Docs와 Swagger 조합하기",
      "date": "2021-07-17 00:00:00 +0000",
      "description": "API 문서 자동화를 도와주는 Spring Rest Docs와 Swagger을 조합해, 단점은 버리고 장점만 누려봅시다\n",
      "content": "\n  🙄 Spring Rest Docs    \n      👍 장점\n      😣 단점\n    \n  \n  🙄 Swagger    \n      👍 장점\n      😣 단점\n    \n  \n  🤔 문제점\n  🤔 발상\n  💡 설정\n  💡 테스트 코드 작성\n  💡 문서화\n\n\n\n\n가장 많이 사용되는 API 문서를 자동화 해주는 프레임워크로 Swagger와 Spring Rest Docs 두개가 있다.\n\n문제는 두 프레임워크의 장단점이 너무 명확하다는데서 발생한다.\n\n\n\n이 포스팅에서는 필자가 생각하는 두 프레임워크의 장단점과 이로 인해 느끼는 불편, 그리고 이를 어떻게 극복했는지에 대해 기록 할 것이다.\n\n\n\n🙄 Spring Rest Docs\n\n\n\n\n  📜 Spring Rest Docs 문서 예시\n\n\n\n\n👍 장점\n\n\n\n\n  API 문서를 작성하기 위해 테스트 코드가 강제되므로 문서의 신뢰성이 매우 높다\n  Spring Boot Starter로 매우 간편하게 설정할 수 있다\n  문서가 매우 직관적이다\n\n\n\n\n😣 단점\n\n\n\n\n  테스트 코드가 강제되기 때문에 테스트 코드에 익숙하지 않다면 도입 난이도가 굉장히 높다\n  문서를 커스터마이징 하려면 AsciiDoc 문법을 알아야 한다\n  Swagger 문서와 다르게 문서에서 API를 즉석으로 테스트 할 수 없다\n\n\n\n\n🙄 Swagger\n\n\n\n\n  📜 Swagger 문서 예시\n\n\n\n\n👍 장점\n\n\n\n\n  API 문서에서 API 테스트를 즉시 해볼 수 있다\n  커스터마이징이 상대적으로 간편하다\n  문서가 아주 이쁘다 (굉장히 주관적인 생각입니다.)\n\n\n\n\n😣 단점\n\n\n\n\n  테스트 코드없이도 문서를 생성할 수 있기 때문에, API 문서를 신뢰하기 어렵다\n  컨트롤러 코드에 Swagger 코드가 아주 많이 작성되어야 한다.\n\n\n\n\n🤔 문제점\n\n\n\nSwagger를 사용할 경우 느끼는 가장 큰 불편은 컨트롤러 계층과 요청, 응답 객체에 Swagger 코드를 떡칠해야 한다는 것이다.\n\n그래서 새로운 코드를 작성할 때마다 매번 Swagger 코드를 추가적으로 작성해야 하는게 매우매우매우 번거롭고 귀찮다.\n\n또한, 이로 인해 코드가 쓸데없이 비대해지고 가독성이 큰 폭으로 떨어진다.\n\n\n\n또한, API 검증을 하지 않더라도 개발자가 마음대로 문서를 작성할 수 있기 때문에 역설적으로 API 문서를 신뢰하기 어렵다는 문제가 있다.\n\n실제로 Swagger 문서를 참고해서 API를 개발하다가 버그를 마주친 개발자도 많을거라 생각된다.\n\n\n\nSpring Rest Docs의 경우 Swagger와 다르게 문서 작성을 위한 코드가 거의 없다시피하다.\n\n하지만 가장 큰 문제점은 테스트 코드가 강제된다는 것이다.\n\n필자는 요즘들어 이게 오히려 장점이라고 보긴 하는데, 테스트 코드. 그중에서도 통합 테스트 코드를 잘 못 짜던 시절에는 이게 너무 큰 단점이라고 생각됐다.\n\n\n\n테스트 코드를 잘 짜지 못하니 테스트 코드 작성을 위해 많은 시간을 할애해야 했고, 이로 인한 체감 진입장벽이 매우매우 높았기 때문이다.\n\n\n\n하지만 요즘 들어 테스트 코드 작성하는 것에 매우 익숙해졌기에 Spring Rest Docs가 굉장히 좋다는 생각이 들었다.\n\n일단 문서를 최소한이나마 신뢰할 수 있다는 것이 굉장히 큰 장점으로 느껴졌기 때문이다.\n\n\n\n하지만 큰 단점이 있었다.\n\n바로 Spring Rest Docs로 생성된 문서는 Swagger 문서와 다르게 문서에서 API 테스트가 불가능하다는 것이었다.\n\n\n\n그래서 두 프레임워크를 모두 사용하여 서로의 단점은 모두 버리고 장점만 취할 수 있는 방법을 강구하게 됐다.\n\n\n\n🤔 발상\n\n\n\nSwagger는 Swagger와 Swagger-UI로 나뉜다.\n\nSwagger로 코드를 작성하면 OpenAPI 코드가 작성되고, 이를 Swagger-UI로 시각화 해주는식으로 동작한다.\n\n즉, 가장 큰 장점이라고 생각되는 Swagger-UI와 가장 큰 불편을 느끼는 Swagger 코드 작성을 따로 놓고 볼 수 있다는 뜻이다.\n\n\n\n그렇다면 OpenAPI 작성을 Spring Rest Docs의 테스트 코드로 작성하고, 이렇게 작성된 OpenAPI를 Swagger-UI와 연동하면 되지 않을까?\n\n그러면 문서로 남기고자 하는 모든 API를 테스트 코드로 검증할 수 있고, OpenAPI 작성을 위한 Swagger 코드 작성을 스킵할 수 있게되며, Swagger-UI로 API 문서를 만들 수 있을 것 같았다.\n\n\n\n항상 그렇듯이 분명 이런 고민을 이미 했던 사람이 있을거라 생각했고, 구글링 결과 아주 좋은 오픈소스를 찾았다.\n\n\n\n\n  😎 ePages-de/restdocs-api-spec GitHub\n\n\n\n\nSpring Rest Docs의 테스트 코드를 활용해 OpenAPI를 생성해주는 오픈소스 라이브러리이다.\n\nSpring Rest Docs의 스펙을 최대한 따라가기 위해 작성됐으며 Spring Rest Docs와 동일하게 MockMvc, WebTestClient, RestAssured를 모두 지원한다.\n\n그리고 결과는 OpenAPI와 OpenAPI3.0으로 둘다 생성할 수 있다.\n\n\n\n사용 방법도 매우 간단하다. 기존에 작성된 Spring Rest Docs의 코드를 거의 건드리지 않게 만들어져 있기 때문이다.\n\n단지 기존 테스트 코드의 API 문서 생성부의 구현체를 이 라이브러리에서 제공하는 구현체로 바꾸기만 하면 된다.\n\n\n\nREADME가 꽤 잘 되있어서 적용하는데 큰 문제는 없었으나, 개인적으로 아쉬웠던 것은 내부 구현이 모두 코틀린으로 돼있어서 소스코드 분석은 거의 하지 못한부분이다.\n\n필자가 아직 코틀린에 대해 모르기 때문이다.\n\n\n\n💡 설정\n\n\n\n\n  모든 소스코드는 깃허브에 공개되어 있습니다.\n\n\n\n\n우선 빌드 스크립트를 작성해야 한다.\n\n플러그인을 먼저 적용한다.\n\n\n\n// file: 'build.gradle'\n// Gradle Plugin DSL을 사용하는 경우\nplugins {\n    id 'com.epages.restdocs-api-spec' version '0.11.4'\n}\n\n// buildscript를 사용하는 경우\nbuildscript {\n    repositories {\n        maven {\n            url \"https://plugins.gradle.org/m2/\" \n        }\n    }\n    dependencies {\n        classpath \"com.epages:restdocs-api-spec-gradle-plugin:0.11.4\"\n    }\n}\n\napply plugin: 'com.epages.restdocs-api-spec'\n\n\n\n\n플러그인을 사용하기 위한 설정을 추가한다.\n\n\n\n// file: 'build.gradle'\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    // ...\n    \n    // 자신이 사용하는 테스트 방식에 따라 택일\n    testCompile('com.epages:restdocs-api-spec-mockmvc:0.11.4')\n    testCompile('com.epages:restdocs-api-spec-webtestclient:0.11.4')\n    testCompile('com.epages:restdocs-api-spec-restassured:0.11.4')\n}\n\n// openapi를 사용하는 경우 설정\nopenapi {\n    host = 'localhost:8080'\n    basePath = '/api'\n    title = 'My API'\n    description = 'My API description'\n    tagDescriptionsPropertiesFile = 'src/docs/tag-descriptions.yaml'\n    version = '1.0.0'\n    format = 'json'\n}\n\n// openapi3.0을 사용하는 경우 설정\nopenapi3 {\n    server = 'https://localhost:8080'\n    title = 'My API'\n    description = 'My API description'\n    tagDescriptionsPropertiesFile = 'src/docs/tag-descriptions.yaml'\n    version = '0.1.0'\n    format = 'yaml'\n}\n\n\n\n\n이외에 Postman 관련해서도 뭘 지원하는 것 같은데 일단 필자한테는 필요없는 것 같으므로 제외했다.\n\n궁금하신 분은 따로 문서를 읽어보셔도 좋을 것 같다.\n\n\n\n💡 테스트 코드 작성\n\n\n\n필자는 하기와 같이 빌드 스크립트를 구성하였다.\n\n\n\n// file: 'build.gradle'\nplugins {\n    id 'java'\n    id 'org.springframework.boot' version '2.5.2'\n    id 'io.spring.dependency-management' version '1.0.11.RELEASE'\n    id 'com.epages.restdocs-api-spec' version '0.11.3' // OpenAPI 작성을 위한 오픈소스 라이브러리\n}\n\next {\n    set('staticsDir', file('src/main/resources/static')) // OpenAPI가 생성될 위치\n}\n\ngroup = 'io.shirohoo.docs'\narchivesBaseName = 'spring-rest-docs'\nversion = '0.0.1'\nsourceCompatibility = '11'\n\njar {\n    enabled = false\n}\n\nconfigurations {\n    compileOnly {\n        extendsFrom annotationProcessor\n    }\n}\n\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    annotationProcessor(\n            'org.springframework.boot:spring-boot-configuration-processor',\n            'org.projectlombok:lombok'\n    )\n    implementation(\n            'org.springframework.boot:spring-boot-starter-web',\n            'org.springframework.boot:spring-boot-starter-webflux', // WebClient 사용을 위한 의존성 추가\n            'org.springframework.boot:spring-boot-starter-data-jpa',\n            'org.springframework.boot:spring-boot-starter-validation',\n            'org.modelmapper:modelmapper:2.4.4'\n    )\n    testImplementation(\n            'org.springframework.boot:spring-boot-starter-test',\n            'org.springframework.restdocs:spring-restdocs-webtestclient', // WebClient 사용을 위한 의존성 추가\n            'com.epages:restdocs-api-spec-webtestclient:0.11.3' // WebClient 사용을 위한 의존성 추가\n    )\n    testImplementation(\"org.springframework.boot:spring-boot-starter-test\") { // JUnit4 제외\n        exclude group: \"junit\", module: \"junit\"\n    }\n    developmentOnly 'org.springframework.boot:spring-boot-devtools'\n    compileOnly 'org.projectlombok:lombok'\n    runtimeOnly 'com.h2database:h2'\n}\n\ntest {\n    useJUnitPlatform()\n}\n\nbootJar {\n    dependsOn(':openapi3') // OpenAPI 작성 자동화를 위해 패키징 전에 openapi3 태스크 선실행을 유발\n}\n\nopenapi3 { // epages openapi3.0 설정\n    server = 'http://localhost:8080'\n    title = 'Spring-Rest-Docs + Swagger-UI + Open-API-3.0.1'\n    description 'Spring-Rest-Docs의 장점과 Swagger의 장점을 모두 가져갈 수 있는 아키텍처를 구축한다'\n    version = '0.0.1'\n    outputFileNamePrefix = 'open-api-3.0.1'\n    format = 'json'\n    outputDirectory = \"$staticsDir/docs\" // src/main/resources/static/docs/open-api-3.0.1.json 생성\n}\n\n\n\n\n그리고 아주 간단한 CRUD API를 작성하였다.\n\n\n\n// file: 'UserApiController.java'\n@RestController\n@RequiredArgsConstructor\n@RequestMapping(\"/api/v1/user\")\npublic class UserApiController {\n    private final ModelMapper mapper;\n    private final UserService service;\n\n    @PostMapping(\"\")\n    public ResponseEntity&lt;UserResponse&gt; create(@RequestBody UserRequest request) {\n        return ResponseEntity.ok(mapper.map(service.create(request), UserResponse.class));\n    }\n\n    @GetMapping(\"{id}\")\n    public ResponseEntity&lt;UserResponse&gt; read(@PathVariable(\"id\") Optional&lt;User&gt; user) {\n        try {\n            return ResponseEntity.ok(mapper.map(user.orElseThrow(() -&gt; new NullPointerException()), UserResponse.class));\n        }\n        catch(NullPointerException e) {\n            return ResponseEntity.notFound().build();\n        }\n    }\n\n    @PutMapping(\"\")\n    public ResponseEntity&lt;UserResponse&gt; update(@RequestBody UserRequest request) {\n        return ResponseEntity.ok(mapper.map(service.update(request), UserResponse.class));\n    }\n\n    @DeleteMapping(\"{id}\")\n    public ResponseEntity delete(@PathVariable Long id) {\n        boolean result = service.delete(id);\n        if(!result) {\n            return ResponseEntity.notFound().build();\n        }\n        return ResponseEntity.ok(null);\n    }\n}\n\n\n\n\n그리고 이에 대한 테스트 코드를 작성한다.\n\n(우선 구조같은건 신경쓰지 않고 단순히 테스트가 성공하게끔만 작성하였으므로 양해 바랍니다.)\n\n\n\n// file: 'UserApiControllerTest.java'\nimport com.epages.restdocs.apispec.ResourceSnippetParameters;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport io.shirohoo.docs.domain.UserRequest;\nimport org.junit.jupiter.api.*;\nimport org.junit.jupiter.api.extension.ExtendWith;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport org.springframework.http.MediaType;\nimport org.springframework.restdocs.RestDocumentationContextProvider;\nimport org.springframework.restdocs.RestDocumentationExtension;\nimport org.springframework.restdocs.webtestclient.WebTestClientRestDocumentation;\nimport org.springframework.test.annotation.Rollback;\nimport org.springframework.test.web.reactive.server.WebTestClient;\nimport org.springframework.test.web.servlet.client.MockMvcWebTestClient;\nimport org.springframework.web.context.WebApplicationContext;\nimport org.springframework.web.reactive.function.BodyInserters;\nimport reactor.core.publisher.Mono;\n\nimport static com.epages.restdocs.apispec.ResourceDocumentation.parameterWithName;\nimport static com.epages.restdocs.apispec.ResourceDocumentation.resource;\nimport static com.epages.restdocs.apispec.Schema.schema;\nimport static com.epages.restdocs.apispec.WebTestClientRestDocumentationWrapper.document;\nimport static org.springframework.restdocs.operation.preprocess.Preprocessors.*;\nimport static org.springframework.restdocs.payload.PayloadDocumentation.fieldWithPath;\nimport static org.springframework.restdocs.webtestclient.WebTestClientRestDocumentation.*;\nimport static org.springframework.test.web.reactive.server.WebTestClient.*;\nimport static org.springframework.web.reactive.function.BodyInserters.*;\n\n@ExtendWith(RestDocumentationExtension.class)\n@TestMethodOrder(MethodOrderer.OrderAnnotation.class)\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)\nclass UserApiControllerTest {\n    @Autowired\n    ObjectMapper mapper; // json string 변환을 위해 주입\n\n    WebTestClient webTestClient;\n\n    @BeforeEach\n    void setUp(WebApplicationContext context, RestDocumentationContextProvider restDocumentation) {\n        webTestClient = MockMvcWebTestClient.bindToApplicationContext(context) // 서블릿 컨테이너 바인딩\n                                            .configureClient() // 설정 추가\n                                            .filter(documentationConfiguration(restDocumentation)) // epages 문서 설정을 추가\n                                            .build();\n    }\n\n    @Test\n    @Order(1)\n    @Rollback(false)\n    void 사용자_정보를_생성한다() throws Exception {\n        // given\n        Mono&lt;String&gt; request = Mono.just(mapper.writeValueAsString(UserRequest.builder()\n                                                                              .name(\"홍길동\")\n                                                                              .email(\"hong@email.com\")\n                                                                              .phoneNumber(\"01012341234\")\n                                                                              .build())\n                                        );\n\n        String expected = mapper.writeValueAsString(UserRequest.builder()\n                                                               .id(1L)\n                                                               .name(\"홍길동\")\n                                                               .email(\"hong@email.com\")\n                                                               .phoneNumber(\"01012341234\")\n                                                               .build());\n\n        // when\n        ResponseSpec exchange = webTestClient.post()\n                                             .uri(\"/api/v1/user\")\n                                             .contentType(MediaType.APPLICATION_JSON)\n                                             .accept(MediaType.APPLICATION_JSON)\n                                             .body(fromProducer(request, String.class))\n                                             .exchange();\n\n        // then\n        exchange.expectStatus().isOk() // 응답 상태코드가 200이면 통과\n                .expectBody().json(expected) // 응답 바디가 예상한 json string과 같으면 통과\n                .consumeWith(document(\"create\", // 문서 작성 및 추가 검증 작업\n                                      preprocessRequest(prettyPrint()), // 문서에 json 출력을 이쁘게 해준다\n                                      preprocessResponse(prettyPrint()), // 문서에 json 출력을 이쁘게 해준다\n                                      resource(\n                                              ResourceSnippetParameters.builder()\n                                                                       .tag(\"User\") // 문서에 표시될 태그\n                                                                       .summary(\"사용자 정보 생성\") // 문서에 표시될 요약정보\n                                                                       .description(\"사용자 정보를 생성한다\") // 문서에 표시될 상세정보\n                                                                       .requestSchema(schema(\"UserRequest\")) // 문서에 표시될 요청객체 정보\n                                                                       .responseSchema(schema(\"UserResponse\")) // 문서에 표시될 응답객체 정보\n                                                                       .requestFields( // 요청 field 검증 및 문서화\n                                                                                       fieldWithPath(\"id\").description(\"식별자\"),\n                                                                                       fieldWithPath(\"name\").description(\"이름\"),\n                                                                                       fieldWithPath(\"email\").description(\"이메일\"),\n                                                                                       fieldWithPath(\"phoneNumber\").description(\"전화번호\")\n                                                                                     )\n                                                                       .responseFields( // 응답 field 검증 및 문서화\n                                                                                        fieldWithPath(\"id\").description(\"식별자\"),\n                                                                                        fieldWithPath(\"name\").description(\"이름\"),\n                                                                                        fieldWithPath(\"email\").description(\"이메일\"),\n                                                                                        fieldWithPath(\"phoneNumber\").description(\"전화번호\"),\n                                                                                        fieldWithPath(\"createAt\").description(\"등록일\"),\n                                                                                        fieldWithPath(\"updateAt\").description(\"수정일\")\n                                                                                      )\n                                                                       .build()\n                                              )));\n    }\n\n    @Test\n    @Order(2)\n    void 사용자_정보를_조회한다() throws Exception {\n        // given\n        String expected = mapper.writeValueAsString(UserRequest.builder()\n                                                               .id(1L)\n                                                               .name(\"홍길동\")\n                                                               .email(\"hong@email.com\")\n                                                               .phoneNumber(\"01012341234\")\n                                                               .build());\n\n        // when\n        ResponseSpec exchange = webTestClient.get()\n                                             .uri(\"/api/v1/user/{id}\", 1)\n                                             .accept(MediaType.APPLICATION_JSON)\n                                             .exchange();\n\n        // then\n        exchange.expectStatus().isOk()\n                .expectBody().json(expected)\n                .consumeWith(document(\"read\",\n                                      preprocessRequest(prettyPrint()),\n                                      preprocessResponse(prettyPrint()),\n                                      resource(\n                                              ResourceSnippetParameters.builder()\n                                                                       .tag(\"User\")\n                                                                       .summary(\"사용자 정보 조회\")\n                                                                       .description(\"사용자 정보를 조회한다\")\n                                                                       .requestSchema(null)\n                                                                       .responseSchema(schema(\"UserResponse\"))\n                                                                       .pathParameters(\n                                                                               parameterWithName(\"id\").description(\"식별자\")\n                                                                                      )\n                                                                       .responseFields(\n                                                                               fieldWithPath(\"id\").description(\"식별자\"),\n                                                                               fieldWithPath(\"name\").description(\"이름\"),\n                                                                               fieldWithPath(\"email\").description(\"이메일\"),\n                                                                               fieldWithPath(\"phoneNumber\").description(\"전화번호\"),\n                                                                               fieldWithPath(\"createAt\").description(\"등록일\"),\n                                                                               fieldWithPath(\"updateAt\").description(\"수정일\")\n                                                                                      )\n                                                                       .build()\n                                              )));\n    }\n\n    @Test\n    @Order(3)\n    void 사용자_정보를_수정한다() throws Exception {\n        // given\n        Mono&lt;String&gt; request = Mono.just(mapper.writeValueAsString(UserRequest.builder()\n                                                                              .id(1L)\n                                                                              .name(\"아무개\")\n                                                                              .email(\"hong@email.com\")\n                                                                              .phoneNumber(\"01012341234\")\n                                                                              .build())\n                                        );\n\n        // when\n        ResponseSpec exchange = webTestClient.put()\n                                             .uri(\"/api/v1/user\")\n                                             .contentType(MediaType.APPLICATION_JSON)\n                                             .accept(MediaType.APPLICATION_JSON)\n                                             .body(fromProducer(request, String.class))\n                                             .exchange();\n\n        // then\n        exchange.expectStatus().isOk()\n                .expectBody().json(request.block())\n                .consumeWith(document(\"update\",\n                                      preprocessRequest(prettyPrint()),\n                                      preprocessResponse(prettyPrint()),\n                                      resource(\n                                              ResourceSnippetParameters.builder()\n                                                                       .tag(\"User\")\n                                                                       .summary(\"사용자 정보 수정\")\n                                                                       .description(\"사용자 정보를 수정한다\")\n                                                                       .requestSchema(schema(\"UserRequest\"))\n                                                                       .responseSchema(schema(\"UserResponse\"))\n                                                                       .requestFields(\n                                                                               fieldWithPath(\"id\").description(\"식별자\"),\n                                                                               fieldWithPath(\"name\").description(\"이름\"),\n                                                                               fieldWithPath(\"email\").description(\"이메일\"),\n                                                                               fieldWithPath(\"phoneNumber\").description(\"전화번호\")\n                                                                                     )\n                                                                       .responseFields(\n                                                                               fieldWithPath(\"id\").description(\"식별자\"),\n                                                                               fieldWithPath(\"name\").description(\"이름\"),\n                                                                               fieldWithPath(\"email\").description(\"이메일\"),\n                                                                               fieldWithPath(\"phoneNumber\").description(\"전화번호\"),\n                                                                               fieldWithPath(\"createAt\").description(\"등록일\"),\n                                                                               fieldWithPath(\"updateAt\").description(\"수정일\")\n                                                                                      )\n                                                                       .build()\n                                              )));\n    }\n\n    @Test\n    @Order(4)\n    void 사용자_정보를_삭제한다() throws Exception {\n        // when\n        ResponseSpec exchange = webTestClient.delete()\n                                             .uri(\"/api/v1/user/{id}\", 1)\n                                             .exchange();\n\n        // then\n        exchange.expectStatus().isOk()\n                .expectBody()\n                .consumeWith(document(\"delete\",\n                                      preprocessRequest(prettyPrint()),\n                                      preprocessResponse(prettyPrint()),\n                                      resource(\n                                              ResourceSnippetParameters.builder()\n                                                                       .tag(\"User\")\n                                                                       .summary(\"사용자 정보 삭제\")\n                                                                       .description(\"사용자 정보를 삭제한다\")\n                                                                       .requestSchema(null)\n                                                                       .responseSchema(null)\n                                                                       .pathParameters(\n                                                                               parameterWithName(\"id\").description(\"식별자\")\n                                                                                      )\n                                                                       .build()\n                                              )));\n    }\n}\n\n\n\n\n추가로 설명할만한 부분은 두가지다.\n\n\n\n첫째로 테스트코드 작성 중 import를 할 때 패키지명에 epages가 들어가는 것을 위주로 import해야 한다.\n\n관련하여 어려움을 느끼실 분들을 위해 예제 코드에 import 블록을 모두 추가하였다.\n\n\n\n둘째로 요청, 응답을 검증하고 문서화하는 부분이다.\n\n위 코드에서는 대체로 Http Body를 통해 통신했기 때문에 requestFields를 사용하였다.\n\n말고도 requestParameters와 pathParameters가 존재하는데, requestParameters는 get방식에서 사용하는 queryString을 검증하고 문서화하는 메서드다.\n\n그리고 pathParameters는 uri에 변수를 사용하는 경우, 그러니까 스프링 컨트롤러의 @PathVariable과 같은것들을 검증하기 위한 메서드다.\n\n\n\n인메모리 DB로 간단하게 테스트하기 위해 별로 좋아하진 않지만, 임시로 테스트에 순서를 지정하였다.\n\n생성 -&gt; 조회 -&gt; 수정 -&gt; 삭제 순으로 실행된다.\n\n그리고 테스트를 돌려보면 …\n\n\n\n\n\n\n\n테스트가 성공함을 확인했다.\n\n이제 문서화를 위한 작업에 들어간다.\n\n\n\n💡 문서화\n\n\n\n일단 빌드 스크립트를 모두 작성해두었기 때문에 build 태스크를 실행하면 OpenAPI3.0까지는 자동으로 만들어진다.\n\n경로는 src/main/resources/static/docs/open-api-3.0.1.json이다.\n\nbuild 태스크를 실행하고 openapi3 태스크가 실행되는지 확인한다.\n\n\n\n$ gradle build\n\nStarting Gradle Daemon...\nGradle Daemon started in 1 s 155 ms\nExecuting task 'build'...\n\n&gt; Task :compileJava\n&gt; Task :processResources\n&gt; Task :classes\n&gt; Task :bootJarMainClassName\n&gt; Task :compileTestJava\n&gt; Task :processTestResources NO-SOURCE\n&gt; Task :testClasses\n&gt; Task :test\n&gt; Task :check\n\n&gt; Task :openapi3 // 패키징 전 openapi3 태스크 동작 확인\n\n&gt; Task :bootJar \n&gt; Task :jar SKIPPED\n&gt; Task :assemble\n&gt; Task :build\n\nBUILD SUCCESSFUL in 19s\n10 actionable tasks: 10 executed\n오전 1:02:54: Task execution finished 'build'.\n\n\n\n\n이제 문서 작성에 필요한 OpenAPI를 만들었으니, 이를 시각화해줄 Swagger-UI를 설치한다.\n\n\n\n\n  📜 Swagger-UI 설치 페이지\n\n\n\n\n압축 파일을 다운받고 압축을 풀면 안에 dist 폴더가 있다.\n\ndist에 있는 파일들을 모두 src/main/resources/static/docs에 풀어준다.\n\n그리고 그중 index.html을 열어 스크립트를 변경해준다.\n\n기존에 연동돼있는 데이터가 아닌 Spring Rest Docs로 생성된 OpenAPI 를 연동해줘야 한다.\n\n\n\n&lt;script&gt;\nwindow.onload = function() {\n\t\n    // omitted for brevity\n    \n    url: \"./open-api-3.0.1.json\", // Spring Rest Docs로 생성된 OpenAPI를 연동\n    \n    // omitted for brevity\n    \n};\n&lt;/script&gt;\n\n\n\n\n그리고 index.html을 열어보면 다음과 같은 문서가 열린다.\n\n\n\n\n  📜 완성된 Swagger API 문서\n\n\n\n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-07-17-swagger-rest-docs/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "jacoco로 테스트 커버리지 관리하기",
      "date": "2021-07-18 00:00:00 +0000",
      "description": "모든 테스트 결과를 시각화하여 테스트 커버리지를 세밀하게 관리해봅시다\n",
      "content": "\n  📕 참고\n  🤔 jacoco\n  📕 jacoco task    \n      📜 jacocoTestReport\n      📜 jacocoTestCoverageVerification\n      📜 jacoco(custom task)\n    \n  \n\n\n\n\n📕 참고\n\n\n\n\n  jacoco docs\n  jacoco plugin\n\n\n\n\n🤔 jacoco\n\n\n\njacoco는 그냥 아주 간단하게 생각하면 된다.\n\n테스트 코드의 결과를 문서로 시각화해주는 툴이다.\n\n부가적으로 테스트 결과에 대한 검증도 가능하다.\n\ngradle을 사용중이라면 이미 jacoco 플러그인이 기본적으로 내장돼있기 때문에 사용도 매우 간단하다.\n\n\n\n// file: 'build.gradle'\nplugins {\n    id 'jacoco'\n}\n\n\n\n\n이렇게 Plugin DSL에 딱 한줄만 추가해주면 적용이 끝난다.\n\n정말 이게 끝인지 의문스러울 수 있다.\n\n정말 이게 끝이다.\n\n\n\n📕 jacoco task\n\n\n\n플러그인을 적용해주면 두개의 jacoco 태스크가 새로 생성된다.\n\n\n\n$ gradle tasks\n\n&gt; Task :tasks\n------------------------------------------------------------\nTasks runnable from root project 'spring-rest-docs'\n------------------------------------------------------------\n\n...\n\n\nVerification tasks\n------------------\ncheck - Runs all checks.\njacocoTestCoverageVerification - Verifies code coverage metrics based on specified rules for the test task.\njacocoTestReport - Generates code coverage report for the test task.\ntest - Runs the unit tests.\n\n\n...\n\nTo see all tasks and more detail, run gradle tasks --all\n\nTo see more detail about a task, run gradle help --task &lt;task&gt;\n\nBUILD SUCCESSFUL in 773ms\n1 actionable task: 1 executed\n\n\n\n\njacoco 태스크는 순서가 정해져있다.\n\ntest -&gt; jacocoTestReport -&gt; jacocoTestCoverageVerification 순으로 실행되는게 가장 바람직하다.\n\n각 태스크에 대해 알아보자.\n\n\n\n📜 jacocoTestReport\n\n\n\n테스트 결과에 대한 분석을 문서로 작성해주는 태스크다.\n\njacoco를 통해 다음 예시와 같은 문서가 만들어진다.\n\n\n\n\n  📜 jacoco test report\n\n\n\n\n\n\n\n\n생성된 문서를 보면 라인에 초록색, 빨간색, 노란색이 칠해져 있다.\n\n이것은 라인 커버라고 불리며 의미는 다음과 같다.\n\n\n\n\n  초록: 테스트 코드에서 호출되었으며 충분히 검증되었음\n  빨강: 테스트 코드로 검증되지 않았음\n  노랑: 테스트 코드에서 라인의 일부만 호출 및 검증되었음 (주로 조건문이나 메서드 체이닝으로 인해 발생)\n\n\n\n\njacoco 태스크는 일단 별도의 수정 없이 그냥 사용해도 무방하지만 필자는 jacoco 태스크를 입맛대로 사용하기 위해 약간의 커스터마이징을 시도했다.\n\n\n\n// file: 'build.gradle'\next {\n    set('staticsDir', file('src/main/resources/static')) // 문서가 저장될 위치변수\n\n    // jacoco 필터링 목록\n    excludeFilter = [ \n            '**/dto/**', // 단순 입출력용 클래스\n            '**/*Application.*', // 메인 클래스\n            '**/Q*.class', // Querydsl 클래스\n            '**/test/**', // 테스트 클래스\n    ]\n}\n\njacocoTestReport {\n    reports {\n        html.enabled true // 테스트 보고서를 html로 생성할 것\n        xml.enabled false // 테스트 보고서를 xml로 생성하지 않을 것\n        csv.enabled false // 테스트 보고서를 csv로 생성하지 않을 것\n\n        html.destination file(\"$staticsDir/coverage\") // 테스트 보고서를 생성할 위치\n    }\n\n    afterEvaluate {\n        classDirectories.setFrom(files(classDirectories.files.collect {\n            fileTree(dir: it, exclude: excludeFilter) // 문서에 출력하고 싶지 않은 파일들에 대한 목록\n        }))\n    }\n}\n\n\n\n\n📜 jacocoTestCoverageVerification\n\n\n\n테스트 커버리지에 대한 검증 태스크다.\n\n이 태스크에서 정말 많은것을 할 수 있다.\n\njacoco를 사용하면서 유난히 손이 좀 가는 태스크이긴 한 것 같다.\n\n역시 빌드 스크립트를 보는게 빠르다.\n\n\n\n// file: 'build.gradle'\next {\n    set('staticsDir', file('src/main/resources/static')) // 문서가 저장될 위치변수\n\n    // jacoco 필터링 목록\n    excludeFilter = [ \n            '**/dto/**', // 단순 입출력용 클래스\n            '**/*Application.*', // 메인 클래스\n            '**/Q*.class', // Querydsl 클래스\n            '**/test/**', // 테스트 클래스\n    ]\n}\n\njacocoTestCoverageVerification {\n    // 검증 룰 선언\n    violationRules { \n        rule {\n            enabled = true // 해당 룰을 사용할 것\n\n\t\t\texcludes = excludeFilter // 테스트 결과를 검증하지 않을 파일들에 대한 목록\n\n            element = 'CLASS' // 클래스 파일을 대상으로\n            \n            limit { // 제한한다\n                counter = 'LINE' // 라인에 대해서\n                value = 'COVEREDRATIO' // 라인 커버리지가\n                minimum = 0.50 // 최소 50%가 넘어야 한다\n            }\n\n            limit { // 제한한다\n                counter = 'LINE' // 라인에 대해서\n                value = 'TOTALCOUNT' // 라인 수(LOC)\n                maximum = 250 // LOC가 250줄이 넘으면 안된다\n            }\n        }\n    }\n}\n\n\n\n\n이런식으로 클래스, 패키지, 라인등을 타겟으로 시스템적 제약을 걸 수 있다.\n\n이렇게 테스트 결과를 다시 검증하며 이 룰이 위반되었을 경우 빌드를 실패시키고, 왜 실패했는지를 알려준다.\n\n\n\n📜 jacoco(custom task)\n\n\n\n이정도만 설정하게 되면 개발자가 매번 태스크를 수동으로 실행시켜줘야하는 불편함이 있기 때문에, build 태스크가 실행되면 모든 작업이 자동화되게 만들 것이다.\n\n\n\n// file: 'build.gradle'\ntask jacoco(type: Test) { // jacoco라는 이름의 커스텀 태스크\n    group 'verification'\n    description 'Runs the unit tests and verify coverage using jacoco' // 태스크가 실행되면 출력될 메시지\n\n    // 이 태스크가 실행되면 다음의 두 태스크가 먼저 실행되게 한다\n    dependsOn(\n            ':jacocoTestReport',\n            ':jacocoTestCoverageVerification'\n    )\n\n    // jacocoTestCoverageVerification는 반드시 jacocoTestReport가 실행된 후에 실행될 것\n    tasks['jacocoTestCoverageVerification'].mustRunAfter(tasks['jacocoTestReport'])\n}\n\nbootJar {\n    dependsOn(':jacoco') // boorJar 태스크가 실행되기 전(패키징단계)에 jacoco 태스크가 실행되도록 한다\n}\n\n\n\n\n이렇게 설정하고 gradle clean build를 실행하면…\n\n\n\n$ gradle clean build\n\nStarting Gradle Daemon...\nGradle Daemon started in 2 s 336 ms\n\n&gt; Task :compileJava\n&gt; Task :processResources\n&gt; Task :classes\n&gt; Task :bootJarMainClassName\n&gt; Task :compileTestJava\n&gt; Task :processTestResources NO-SOURCE\n&gt; Task :testClasses\n\n&gt; Task :test // 테스트 실행 \n&gt; Task :jacocoTestReport // 테스트 리포트 작성 \n&gt; Task :jacocoTestCoverageVerification // 테스트 리포트를 토대로 검증\n&gt; Task :jacoco // jacoco 태스크 실행(앞의 두 태스크를 유발하는 것 외에 아무 기능 없음)\n&gt; Task :check\n&gt; Task :bootJar // 패키징\n\n&gt; Task :jar\n&gt; Task :assemble\n&gt; Task :build\n\nBUILD SUCCESSFUL in 19s\n11 actionable tasks: 11 executed\n오후 1:06:09: Task execution finished 'build'.\n\n\n\n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-07-18-jacoco/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "JPA 기초 8 - JPQL",
      "date": "2021-07-22 00:00:00 +0000",
      "description": "JPQL은 JPA에서 사용하기 위해 추상화한 SQL입니다\n",
      "content": "\n  📕 JPQL\n  📕 JPQL 문법    \n      💡 SELECT\n      💡 UPDATE\n      💡 DELETE\n      👏 중간정리\n      💡 반환타입\n      💡 결과조회\n      💡 프로젝션(Projection)        \n          💥 임베디드 타입(=값 타입) 프로젝션\n          🤔 생성자 사용\n        \n      \n      💡 페이징\n      💡 통계        \n          😱 집합, 정렬\n          😱 GROUP BY, HAVING\n          😱 ORDER BY\n        \n      \n      💡 조인        \n          🤔 내부조인\n          🤔 외부조인\n          🤔 세타조인\n          👏 페치조인\n        \n      \n      💡 경로 표현식\n    \n  \n\n\n \n\n📕 JPQL\n\n\n\nSQL은 DB에 직접 조회를 하지만 JPA는 ORM이기 때문에 모든 쿼리의 대상이 엔티티 객체이다. 때문에 객체에 대한 쿼리를 직접 작성하기 위해 JPQL이라는 추상화된 SQL이 등장했다.\n\n이전에 다룬 연관관계 매핑만으로도 많은 쿼리를 처리할 수 있지만, 정말 복잡한 쿼리들에는 분명한 한계가 존재한다.\n\n대표적으로 통계성 쿼리같은 것들이 있을 수 있다.\n\n\n\n결국 이런 아주 복잡한 쿼리들을 직접 작성해야만 하는 순간이 반드시 오는데, 이 때 SQL을 직접 작성하면 영속성 컨텍스트와 무관해지기 때문에 JPQL을 통해 SQL을 작성한다.\n\nJPQL을 통해 쿼리를 하면 쿼리의 결과가 영속성 컨텍스트에 종속되기 때문에 JPA를 사용하는 이점을 모두 누릴 수 있게 된다.\n\n\n\n하지만 이 JPQL도 결국 SQL을 문자열로 직접 작성해야 한다는 분명한 한계점이 존재하기 때문에 이를 해결하기 위해 Criteria나 Querydsl 등의 기술이 나왔다.\n\n이 기술들은 JPQL을 문자열로 직접 작성하는게 아닌, 빌더를 통해 자바 컴파일러의 도움을 받아 JPQL을 작성할 수 있게 도와준다.\n\n여기서 Criteria는 표준 기술이지만 아주 비효율적이므로 따로 공부하는데 시간을 할애하지 않는것을 추천하며, Querydsl을 배우는데 시간을 투자할 것을 추천드린다.\n\n시간은 아주 귀중한 자원이기 때문이다.\n\n\n\n하기의 모든 내용은 JPQL에 관한 것들이며, 이 대부분의 내용은 실제로 직접 사용하지 않는다.\n\n그럼에도 불구하고 이러한 내용들을 학습해야 하는 이유는 JPA를 사용하는 경우 JPQL을 더 쉽게 사용할 수 있게 도와주는 도구 (Querydsl과 같은 것들)를 반드시 사용하게 될 것이며, 이것들을 잘 사용하기 위해서는 JPQL에 대한 이해가 필수적으로 동반되기 때문이다.\n\n\n\n📕 JPQL 문법\n\n\n\nSELECT, UPDATE, DELETE문을 지원하지만 특이하게도 JPQL 자체적으로 INSERT 문은 지원하지 않는다.\n\n왜냐하면 EntityManager.persist() 로 저장할 수 있기 때문이다.\n\nJPQL에 대해 공부하기 전 다음 사항들을 명심해야 한다.\n\n\n\n\n  JPQL은 테이블이 아닌 엔티티 객체를 대상으로 쿼리한다\n  JPQL은 특정 SQL에 의존하지 않는 추상화된 SQL이다\n  JPQL은 결국 특정 SQL로 변환되어 쿼리된다\n  JPQL은 엔티티에 관련된 것들에 대해 대소문자를 구분한다\n  JPQL은 엔티티 이름으로 쿼리한다 (@Entity(name = ‘name’), name 속성을 생략하면 기본값은 클래스 이름과 동일하다)\n  별칭이 필수이며, as 키워드는 생략해도 무방하다\n\n\n\n\n동적 쿼리의 경우 파라미터 바인딩을 할 수 있는데, 위치기반의 파라미터 바인딩과 이름기반의 파라미터 바인딩을 지원한다.\n\n바로 아래에서 자세히 보겠지만 위치기반 파라미터 바인딩의 경우 물음표(?)를 사용하고, 이름기반 파라미터 바인딩의 경우 콜론(:)을 사용한다.\n\n하지만 위치기반 방식의 경우 변경사항이 생기면 에러가 발생할 가능성이 매우 높기 때문에 아예 사용하지 않는다고 봐도 좋다.\n\n이전에 학습한 @Enumerated에서 EnumType.ORDINAL을 쓰지 않고 EnumType.STRING만을 사용하는 이유와 동일하다.\n\n\n\nJPQL 테스트를 위한 테스트 클래스는 다음과 같다.\n\n\n\n@DataJpaTest\npublic class JpqlTest {\n    private final TestEntityManager testEntityManager;\n\n    public JpqlTest(TestEntityManager testEntityManager) {\n        this.testEntityManager = testEntityManager;\n    }\n\n    private EntityManager em;\n\n    @BeforeEach\n    void setUp() {\n        em = testEntityManager.getEntityManager();\n    }\n}\n\n\n\n\n💡 SELECT\n\n\n\n@Test\n@DisplayName(\"테스트를 실행하여 SELECT 쿼리를 확인한다\")\nvoid select() {\n    em.createQuery(\"select m from Member m where m.name = 'siro'\", Member.class)\n      .getResultList();\n\n    em.createQuery(\"select m from Member m where m.name = :name\")\n      .setParameter(\"name\", \"siro\")\n      .getResultList();\n}\n\n\n\n\nJPQL은 Member 객체에서 이름(name)이 siro인 것을 조회하고있다.\n\nHibernate는 이를 다음과 같은 SQL로 변환하여 쿼리했다. (DB는 H2이다.)\n\n둘 모두 동일한 쿼리가 발생하며, 정적쿼리냐 파라미터를 받는 동적쿼리냐의 차이일 뿐이다.\n\n\n\nselect\n    member0_.id as id1_2_,\n    member0_.name as name2_2_\nfrom\n    member member0_ \nwhere\n    member0_.name='siro'\n\n\n\n\n💡 UPDATE\n\n\n\n@Test\n@DisplayName(\"테스트를 실행하여 UPDATE 쿼리를 확인한다\")\nvoid update() {\n    em.createQuery(\"update Member m set m.name = 'siro' where m.id = 1\")\n      .executeUpdate();\n\n    em.createQuery(\"update Member m set m.name = :name where m.id = :id\")\n      .setParameter(\"name\", \"siro\")\n      .setParameter(\"id\", 1L)\n      .executeUpdate();\n}\n\n\n\n\nupdate\n    member \nset\n    name='siro' \nwhere\n    id=1\n\n\n\n\n💡 DELETE\n\n\n\n@Test\n@DisplayName(\"테스트를 실행하여 DELETE 쿼리를 확인한다\")\nvoid delete() {\n    em.createQuery(\"delete from Member m where m.id = 1\")\n      .executeUpdate();\n\n    em.createQuery(\"delete from Member m where m.id = :id\")\n      .setParameter(\"id\", 1L)\n      .executeUpdate();\n}\n\n\n\n\ndelete \nfrom\n    member \nwhere\n    id=1\n\n\n\n\n👏 중간정리\n\n\n\n보다시피 일반적인 ANSI SQL과 거의 동일하다.\n\n다만 쿼리 대상이 테이블이 아닌 객체라는 점에서 아주 미세한 차이가 발생하며, 이 미세한 차이는 SQL에 익숙한 사람이라면 보자마자 바로 이해하고 사용할 수 있을 정도의 차이일 뿐이다.\n\n\n\n💡 반환타입\n\n\n\nTypedQuery와 Query가 존재한다.\n\n\n\n@Test\n@DisplayName(\"TypedQuery, Query의 차이를 확인한다\")\nvoid typeTest() throws Exception {\n    // TypedQuery: 반환 타입이 아주 명확한 경우\n    TypedQuery&lt;Member&gt; typedQuery = em.createQuery(\"select m from Member m\", Member.class);\n\n    // 명확한 타입의 객체가 반환된다.\n    List&lt;Member&gt; typedResultList = typedQuery.getResultList();\n\n    for (Member member : typedResultList) {\n        // Member 타입\n    }\n\n    // Query: 반환 타입이 명확하지 않은 경우\n    Query query = em.createQuery(\"select m.id, m.name from Member m\");\n\n    // Object 타입의 객체가 반환된다. (타입 캐스팅을 한번 더 해야하므로 약간 더 불편하다)\n    List&lt;Object[]&gt; queryResultList = query.getResultList();\n\n    for (Object[] o : queryResultList) {\n      System.out.println(\"id = \" + (Long) o[0]); // 식별자\n      System.out.println(\"name = \" + (String) o[1]); // 이름\n    }\n}\n\n\n\n\n💡 결과조회\n\n\n\n\n  getResultList\n    \n      결과를 List로 반환한다.\n    \n  \n  getSingleResult\n    \n      한개의 결과를 반환한다.\n      결과가 없는 경우 NoResultException을 던진다\n      결과가 둘 이상인 경우 NonUniqueResultException을 던진다\n    \n  \n  getResultStream\n    \n      결과를 List로 만들고 이에 대한 Stream 객체를 반환한다\n    \n  \n\n\n\n\n여기서 getSingleResult는 결과가 정확히 한개가 아닐 경우 별도의 예외를 던지는 부분을 주의한다.\n\n\n\n💡 프로젝션(Projection)\n\n\n\n@Test\nvoid typeTest() throws Exception{\n    // Query: 반환 타입이 명확하지 않은 경우\n    Query query = em.createQuery(\"select m.id, m.name from Member m\");\n\n    // Object 타입의 객체가 반환된다. (타입 캐스팅을 한번 더 해야하므로 약간 더 불편하다)\n    List&lt;Object[]&gt; queryResultList = query.getResultList();\n\n    for(Object[] o : queryResultList){\n      System.out.println(\"id = \" + (Long) o[0]); // 식별자\n      System.out.println(\"name = \" + (String) o[1]); // 이름\n    }\n}\n\n\n\n\n이처럼 엔티티 객체 전체를 조회하는 것이 아니고 특정 필드만 조회하고 싶은 경우에 특정 필드만 선택해서 조회하는 것을 프로젝션이라고 한다.\n\n프로젝션을 사용해 특정 필드만 조회하더라도 해당 필드를 갖고있는 엔티티 객체는 영속성 컨텍스트에 캐시되고 관리되며, 필드 자체는 값이기 때문에 따로 관리되지는 않는다.\n\n조금 더 쉽게 이해하기 위해 일반적인 옵티마이저의 SELECT의 논리적인 실행 순서에 대해 알면 좋을 것 같다. (사용하는 DB벤더의 옵티마이저마다 상이할 수 있다.)\n\n\n\n\n  FROM\n    \n      쿼리가 시작되면 from절을 먼저 검사하여 해당 테이블이 정말로 존재하는지, 해당 유저가 해당 테이블에 접근할 권한이 있는지를 먼저 검사한다. 여기서 문제가 있으면 옵티마이저는 SEMANTIC ERROR를 발생시킨다.\n    \n  \n  ON\n    \n      join을 할 경우 on절이 추가되는데 이 때 on절이 where절보다 실행 우선순위가 더 높다. A테이블과 B테이블을 조인한다고 하면 on절의 조건을 먼저 검사하여 필터링한다.\n    \n  \n  WHERE\n    \n      from절이나 on절에서 문제가 없으면 옵티마이저는 where절에서 검색 조건을 확인하고 해당 row들을 조회하고 가져온다.\n    \n  \n  GROUP BY\n    \n      where절에서 가져온 row들을 그루핑한다.\n    \n  \n  HAVING\n    \n      그루핑한 row에서 한번 더 조건을 확인하여 필터링한다.\n    \n  \n  SELECT\n    \n      having절에서 필터링된 row에서 select절에 명시된 컬럼만 덜어낸다. 이렇게 select절이 최후순위에서 실행되기 때문에 select * from member와 select name from member의 조회 비용은 거의 동일하다. (복합 인덱스가 존재한다면 동일하지 않을 수 있다)\n    \n  \n  ORDER BY\n    \n      select된 컬럼들을 대상으로 정렬을 한다. select보다 후순위에서 실행되기 때문에 select 절에 명시된 별칭(alias, as)을 여기서 사용할 수 있다.\n    \n  \n\n\n\n\n결국 프로젝션이라는 것은 다음과 같이 생각할 수 있다.\n\n\n\n\n  JPQL을 SQL로 변환 -&gt; SQL 실행 -&gt; SQL결과를 엔티티 객체로 반환 -&gt; 원하는 필드만 조회함(프로젝션)\n\n\n\n\n따라서 프로젝션을 사용해서 특정 필드만 조회했다고 하더라도 이미 영속성 컨텍스트에는 해당 필드를 갖고있는 엔티티 객체가 캐시되어있으며, 영속성 컨텍스트에서 관리되고있는 상태임을 이해하자.\n\n\n\n💥 임베디드 타입(=값 타입) 프로젝션\n\n\n\nJPA에서 임베디드 타입은 엔티티와 거의 동일하게 취급되지만 JPQL에서의 임베디드 타입은 엔드포인트가 될 수 없다는 차이가 있다.\n\n또한 임베디드 타입은 결국 어떠한 값이기 때문에 JPQL에서는 엔티티 객체와 다르게 영속성 컨텍스트에서 관리되지 않는다.\n\n\n\nem.createQuery(\"select a from Address a\");\n\n\n\n\n위 쿼리에서 Address가 임베디드 타입이라면 이는 잘못된 JPQL이다.\n\n임베디드 타입으로는 쿼리를 시작할 수 없기 때문이다.\n\n그렇다면 Address를 조회하려면 어떻게 해야 할까?\n\nAddress를 사용하고 있는 엔티티 객체를 대상으로 쿼리한 후 Address를 프로젝션해야 한다.\n\n\n\nList&lt;Address&gt; addresses = em.createQuery(\"select m.address from Member m\", Address.class).getResultList();\n\n\n\n\n🤔 생성자 사용\n\n\n\n@Test\n@DisplayName(\"프로젝션\")\nvoid projection() throws Exception {\n        List&lt;Object[]&gt; queryResultList = em.createQuery(\"select m.id, m.name from Member m\")\n                                            .getResultList();\n\n    List&lt;MemberDto&gt; memberDtos = new ArrayList&lt;&gt;();\n    for (Object[] o : queryResultList) {\n      Long id = (Long) o[0];\n      String name = (String) o[1];\n    \n      MemberDto memberDto = new MemberDto(id, name);\n    \n      memberDtos.add(memberDto);\n    }\n}\n\n\n\n\n이런식으로 프로젝션을 할 수 있다.\n\n하지만 보다시피 너무 장황하고 지루하다.\n\n이를 다음과 같이 생성자를 사용하여 간결하게 변경할 수 있다.\n\n\n\n@Test\n@DisplayName(\"생성자_프로젝션\")\nvoid constructorProjection() throws Exception {\n    em.createQuery(\"select new learn.jpa.dto.MemberDto(m.id, m.name) from Member m\", MemberDto.class)\n             .getResultList();\n}\n\n\n\n\n하지만 이 방식의 경우 다음과 같은 주의사항이 있다.\n\n\n  패키지 명을 포함한 전체 클래스명을 오타 없이 입력해야 한다\n  시그니처가 동일한 생성자가 반드시 필요하다\n\n\n이러한 주의사항이 존재하기 때문에 실제로 이 방법을 직접 사용하는 경우는 없다고 봐도 무방하다.\n\n대신 Querydsl에서 이 방식을 더욱 편리하게 사용할 수 있는 다음과 같은 방법을 지원한다.\n\n이 외에도 여러가지 방법이 더 존재한다.\n\n\n\n@Test\n@DisplayName(\"Querydsl 생성자 프로젝션\")\nvoid querydslConstructorProjection() throws Exception {\n    queryFactory.select(new QMemberDto(member.id, member.name))\n                .from(member)\n                .fetch();\n}\n\n\n\n\n💡 페이징\n\n\n\n페이징 쿼리의 경우 DB벤더마다 모두 다르기 때문에 이런 차이를 모두 익히려는 것은 굉장한 고역이다.\n\nJPQL은 SQL을 추상화하였기 때문에 JPQL로 페이징 쿼리를 작성할 줄 안다면 실제 DB벤더로 나가는 쿼리는 JPA가 알아서 번역해준다.\n\nJPQL로 페이징 쿼리를 작성하기 위해서는 두가지 옵션을 주면 된다.\n\n아주 간단하게 다음과 같이 생각하면 될 것 같다.\n\n\n\n\n  setFirstResult\n    \n      검색할 페이지\n    \n  \n  setMaxResults\n    \n      가져올 데이터의 개수\n    \n  \n\n\n\n\n@Test\n@DisplayName(\"페이징\")\nvoid paging() throws Exception {\n    em.createQuery(\"select m from Member m order by m.name desc\", Member.class)\n            .setFirstResult(2)\n            .setMaxResults(5)\n            .getResultList();\n}\n\n\n\n\n위와 같은 코드가 있다면 이렇게 이해할 수 있다.\n\n테이블에 총 20개의 row가 존재한다면 이를 페이지의 크기인 5로 나눈다.\n\n그러면 해당 테이블에는 총 4개의 페이지가 존재하며, 한 페이지에 5개의 row를 가질 것이다.\n\n그중 2번째 페이지를 조회하려고 하니 11~15번째의 row가 조회될 것이다 (JPQL 페이징은 1이 아닌, 0부터 시작한다.)\n\n\n\n\n\n\n\nH2DB 기준으로 하기와 같은 쿼리가 발생한다.\n\n\n\nselect\n    member0_.id as id1_2_,\n    member0_.create_at as create_a2_2_,\n    member0_.update_at as update_a3_2_,\n    member0_.age as age4_2_,\n    member0_.name as name5_2_,\n    member0_.team_id as team_id6_2_ \nfrom\n    member member0_ \norder by\n    member0_.name desc\n\n\n\n\n하지만 페이징을 위해 이러한 코드를 직접 작성하는 일은 없을것이다.\n\nSpring Data를 사용한다면 Paging관련 API가 있기 때문에 훨씬 더 쉽고 편리하게 사용할 수 있으며, Querydsl에도 관련 API가 아주 잘 되어있기 때문이다.\n\n그러니까 어떤 방식으로 돌아가는지에 대해서 이해만 해두면 될 것 같다.\n\n\n\n💡 통계\n\n\n\n일반적으로 집계함수들은 DB에 부하가 많이 들어가기 때문에 보통 런타임에 직접 사용하지는 않는다.\n\n트래픽이 적은 시간대에 배치성으로 작업해서 따로 기록하는게 일반적이기 때문에(당일 매출집계 등), 어플리케이션 레벨에서 JPA로 직접 작성하는 일은 생각보다 많지는 않은 것 같다.\n\n그러니 JPA를 쓰더라도 본인이 배치를 개발하는게 아니라면 생각보다 크게 비중이 있다고 보기는 어려울 것 같다.\n\n만일 위 조건에 해당하지 않는다면 그냥 이런것도 있구나 하고 가벼운 마음으로 보면 될 것 같다.\n\n\n\n😱 집합, 정렬\n\n\n\n\n  \n    \n      함수\n      설명\n    \n  \n  \n    \n      count\n      결과 개수를 구한다. 반환타입은 Long\n    \n    \n      max\n      최대 값을 구한다.\n    \n    \n      min\n      최소 값을 구한다.\n    \n    \n      sum\n      합을 구하며 숫자타입만 사용 할 수 있다. 반환 타입은 Long, Double, BigInteger, BigDecimal\n    \n    \n      avg\n      평균값을 구하며 숫자타입만 사용 할 수 있다. 반환 타입은 Double\n    \n  \n\n\n\n\n@Test\n@DisplayName(\"집계함수\")\nvoid aggregate() throws Exception {\n    em.createQuery(\"select count(m) from Member m\").getSingleResult();\n    em.createQuery(\"select max(m.id) from Member m\").getSingleResult();\n    em.createQuery(\"select min(m.id) from Member m\").getSingleResult();\n    em.createQuery(\"select avg(m.age) from Member m\").getSingleResult();\n    em.createQuery(\"select sum(m.age) from Member m\").getSingleResult();\n}\n\n\n\n\n발생한 쿼리는 다음과 같다.\n\n\n\nselect\n    count(member0_.id) as col_0_0_ \nfrom\n    member member0_\n\n\nselect\n    max(member0_.id) as col_0_0_ \nfrom\n    member member0_\n\n\nselect\n    min(member0_.id) as col_0_0_ \nfrom\n    member member0_\n\n\nselect\n    avg(cast(member0_.age as double)) as col_0_0_ \nfrom\n    member member0_\n\n\nselect\n    sum(member0_.age) as col_0_0_ \nfrom\n    member member0_\n\n\n\n\n😱 GROUP BY, HAVING\n\n\n\n@Test\n@DisplayName(\"집계함수\")\nvoid aggregate() throws Exception {\n    em.createQuery(\"select m.name as aa from Member m group by m.team having m.age &gt; 20\").getResultList();\n}\n\n\n\n\nMember의 전체 row를 team별로 그루핑하고, 각 그룹별로 나이가 21살 이상인 Member들의 name을 출력하는 쿼리다.\n\n이는 아주아주 간단한 예제이며, 실무에서는 이와 비교해 상상할 수 없을 만큼 훨씬 더 복잡한 통계성 쿼리를 작성한다.\n\n위 코드로 인해 발생한 쿼리는 다음과 같다.\n\n\n\nselect\n    member0_.name as col_0_0_ \nfrom\n    member member0_ \ngroup by\n    member0_.team_id \nhaving\n    member0_.age&gt;20\n\n\n\n\n😱 ORDER BY\n\n\n\n자주 사용하는 정렬 쿼리이다.\n\n사용방법은 아주 간단하지만, 무조껀 인덱스를 사용하게끔 작성하는게 더 중요한 쿼리라고 볼 수 있다.\n\n왜냐하면 인덱스는 이미 정렬되어 있기 때문에 정렬 쿼리가 인덱스를 사용하게 되면 옵티마이저가 정렬 연산을 스킵하기 때문이다.\n\n\n\n@Test\n@DisplayName(\"정렬\")\nvoid sort() throws Exception {\n    em.createQuery(\"select m from Member m order by m.age desc\").getResultList();\n}\n\n\n\n\n위 코드는 Member의 나이를 기준으로 내림차순 정렬(desc)을 한다.\n\n만약 오름차순으로 정렬하고 싶다면 asc를 주면 된다.\n\n발생한 쿼리는 다음과 같다.\n\n\n\nselect\n    member0_.id as id1_2_,\n    member0_.create_at as create_a2_2_,\n    member0_.update_at as update_a3_2_,\n    member0_.age as age4_2_,\n    member0_.name as name5_2_,\n    member0_.team_id as team_id6_2_ \nfrom\n    member member0_ \norder by\n    member0_.age desc\n\n\n\n\n💡 조인\n\n\n\n조인에 대해서는 필자가 잘 모른다.\n\n조인이라는게 조인순서를 어떻게 하는지, 컬럼을 어떻게 조회하는지 등의 사소한 차이에 따라 속도가 천차만별로 변하기 때문이다.\n\n아주아주 깊고 어려운 주제라고 생각한다.\n\n\n\n조인에 대해 정말 잘 모르기 때문에 필자는 다음과 같은 규칙하나만 세워두고 개발한다.\n\n\n\n\n  무조건 inner join이 먼저, outer join은 뒤로 뺀다.\n\n\n\n\n경험상 이렇게 하는게 항상 성능이 더 잘나왔다.\n\n언젠가 이런 주제에 대해서도 깊게 공부해봐야 겠지만 당장은 우선순위가 밀린다.\n\n시간을 만만찮게 잡아먹을 것 같은 분야여서…\n\n\n\n이러하니 그냥 문법에 대해서만 정리해보고자 한다.\n\n\n\n🤔 내부조인\n\n\n\n내부 조인은 문법상 inner join 이며 inner를 생략할 수 있다.\n\n\n\nem.createQuery(\"select m from Member m join m.team t on m.createAt = t.createAt\").getResultList();\n\n\n\n\n문법은 일반적인 SQL과 크게 다를게 없지만 조인 시 위처럼 별칭을 사용하게 된다.\n\n\n\nselect\n  member0_.id as id1_2_,\n  member0_.create_at as create_a2_2_,\n  member0_.update_at as update_a3_2_,\n  member0_.age as age4_2_,\n  member0_.name as name5_2_,\n  member0_.team_id as team_id6_2_\nfrom\n  member member0_\n    inner join\n  team team1_\n  on member0_.team_id=team1_.id\n    and (\n       member0_.create_at=team1_.create_at\n       )\n\n\n\n\n보다시피 Member가 fk로 갖고 있는 Team의 id와 Team의 pk를 기준으로 조인한다.\n\n추가적으로 create_at 컬럼도 같이 조건에 넣고 있다.\n\n\n\n하기와 같이 사용할 경우 SYNTAX ERROR가 발생한다.\n\n\n\nem.createQuery(\"select m from Member m join Team t).getResultList();\n\n\n\n\n다만 다음과 같이 할 경우에는 문제가 생기지 않는다.\n\n\n\nem.createQuery(\"select m from Member m join Team t on m.createAt = t.createAt\").getResultList();\n\n\n\n\nselect\n    member0_.id as id1_2_,\n    member0_.create_at as create_a2_2_,\n    member0_.update_at as update_a3_2_,\n    member0_.age as age4_2_,\n    member0_.name as name5_2_,\n    member0_.team_id as team_id6_2_ \nfrom\n    member member0_ \ninner join\n    team team1_ \n        on (\n            member0_.create_at=team1_.create_at\n        )\n\n\n\n\n차이라면 fk로 조인하지 않고 create_at 컬럼으로만 조인하고 있기 때문에 성능 저하가 예상된다.\n\n\n\n하지만 일반적으로 내부조인시에는 on절을 잘 사용하지 않는다.\n\non절을 생략하면 기본적으로 fk를 이용하여 조인되기 때문이기도 하고, 어차피 where절을 사용하면 on절과 동일하게 동작하기 때문이다.\n\n그냥 이런것도 있구나~ 하고 넘어가면 될 것 같다.\n\n\n\n🤔 외부조인\n\n\n\n잘 모르기 때문에 참 사용하기가 꺼려지는 조인이다.\n\n기본적으로 성능저하를 달고오고, 조건을 어떻게 주느냐에 따라 또 이 성능저하가 천차만별이기 때문이다.\n\n역시 잘 모르므로 어떻게 사용하는지 문법 정도만 정리한다.\n\n\n\n문법상 left outer join 이지만 outer는 생략 가능하기 때문에 left join으로 사용하는게 일반적이다.\n\n\n\n@Test\n@DisplayName(\"외부조인\")\nvoid leftOuterJoin() throws Exception {\n    em.createQuery(\"select m from Member m left join m.team t\").getResultList();\n}\n\n\n\n\nselect\n    member0_.id as id1_2_, \n    member0_.create_at as create_a2_2_,\n    member0_.update_at as update_a3_2_,\n    member0_.age as age4_2_,\n    member0_.name as name5_2_,\n    member0_.team_id as team_id6_2_ \nfrom\n    member member0_ \nleft outer join\n    team team1_ \n        on member0_.team_id=team1_.id\n\n\n\n\n🤔 세타조인\n\n\n\n연관관계가 없는 엔티티여도 조인할 수 있다.\n\n일명 막조인이라고 부르기도 한다.\n\n다음과 같이 where절을 사용한다.\n\n\n\n@Test\n@DisplayName(\"세타조인\")\nvoid thetaJoin() throws Exception {\n    em.createQuery(\"select m, t from Member m, Team t where m.name = t.name\").getResultList();\n}\n\n\n\n\nselect\n    member0_.id as id1_2_0_,\n    team1_.id as id1_4_1_,\n    member0_.create_at as create_a2_2_0_,\n    member0_.update_at as update_a3_2_0_,\n    member0_.age as age4_2_0_,\n    member0_.name as name5_2_0_,\n    member0_.team_id as team_id6_2_0_,\n    team1_.create_at as create_a2_4_1_,\n    team1_.update_at as update_a3_4_1_,\n    team1_.name as name4_4_1_ \nfrom\n    member member0_ cross \njoin\n    team team1_ \nwhere\n    member0_.name=team1_.name\n\n\n\n\n👏 페치조인\n\n\n\n페치조인은 join fetch를 명시적으로 걸어 연관된 엔티티를 함께 조회하는 것을 말한다.\n\n문법은 다음과 같다.\n\n\n\n@Test\n@DisplayName(\"페치조인\")\nvoid fetchJoin() throws Exception {\n    em.createQuery(\"select m from Member m join fetch m.team\").getResultList();\n}\n\n\n\n\nselect\n    member0_.id as id1_2_0_,\n    team1_.id as id1_4_1_,\n    member0_.create_at as create_a2_2_0_,\n    member0_.update_at as update_a3_2_0_,\n    member0_.age as age4_2_0_,\n    member0_.name as name5_2_0_,\n    member0_.team_id as team_id6_2_0_,\n    team1_.create_at as create_a2_4_1_,\n    team1_.update_at as update_a3_4_1_,\n    team1_.name as name4_4_1_ \nfrom\n    member member0_ \ninner join\n    team team1_ \n        on member0_.team_id=team1_.id\n\n\n\n\n만약 Member와 Team을 모두 사용해야 하는데 지연로딩 + 객체 그래프 탐색을 사용한다면 Member에 대한 select 쿼리가 먼저 발생하고, 이후 Team에 대한 select 쿼리가 발생했을 것이다.\n\n하지만 이렇게 페치조인을 사용하면 두번의 쿼리가 아닌 한번의 쿼리만 발생시키면 되기 때문에 효율적이다.\n\n\n\n단점도 있다.\n\n위처럼 Member와 Team을 모두 사용할 게 아니고 Member만 필요한 상황에서 페치조인을 사용한다면 필요없는 Team까지 조회하기 때문에 낭비다.\n\n이런 경우에는 오히려 페치조인을 사용하지 않는게 좋다.\n\n\n\n즉, 페치조인이 JPA에서 성능 최적화에 큰 기여를 하는것도 분명한 사실이지만, 제대로 알고 사용하지 않는다면 오히려 성능을 저하시킬수도 있는 trade-off가 존재한다는 점을 잘 이해하고 사용해야 하겠다.\n\n\n\n💡 경로 표현식\n\n\n\n경로 표현식이라는 것은 점(.)을 찍어 객체 그래프를 탐색하는 것이다.\n\n\n\n@Test\n@DisplayName(\"경로표현식\")\nvoid pathExpression() throws Exception {\n    em.createQuery(\"select m.team from Member m\").getResultList();\n}\n\n\n\n\n위 코드가 바로 경로표현식을 사용한 예다.\n\n위 JPQL이 실행되면 어떤 쿼리가 발생할까?\n\n\n\nselect\n    team1_.id as id1_4_,\n    team1_.create_at as create_a2_4_,\n    team1_.update_at as update_a3_4_,\n    team1_.name as name4_4_ \nfrom\n    member member0_ \ninner join\n    team team1_ \n        on member0_.team_id=team1_.id\n\n\n\n\n예상하신분도, 예상하지 못하신 분도 있겠지만 이렇게 Tema에 대한 내부조인 쿼리가 발생했다.\n\n책에서는 이를 경로 표현식에 의한 묵시적 조인이라고 표현하고 있다.\n\n이렇게 무분별한 조인이 발생할 수 있기 때문에 JPQL을 사용하면 상당히 주의해서 사용해야 될 기능이라고 볼 수 있겠다.\n\n조인은 데이터베이스에 부하를 주기 때문이다.\n\n묵시적 조인은 기본적으로 내부조인으로 발생하며, 외부조인을 하고 싶다면 명시적으로 외부조인 쿼리를 작성해줘야만 한다.\n\n\n\n경로 표현식은 다음과 같은 용어를 사용한다.\n\n\n  상태 필드(state field): 값을 저장하기 위한 필드(일반적인 값 타입)\n  연관 필드(association field): 연관관계를 위한 필드, 임베디드 타입(값 타입)을 포함한다\n    \n      단일 값 연관 필드: @~ToOne의 관계\n      컬렉션 값 연관 필드: @~ToMany의 관계\n    \n  \n\n\n\n\n또한 경로 표현식은 다음과 같은 특징을 갖는다.\n\n\n  상태 필드: 상태 필드가 선언되면 경로 탐색의 끝을 의미하며, 여기서 더 탐색할 수 없다.\n  단일 값 연관 필드: 묵시적 조인이 발생하며, 계속 이어서 탐색할 수 있다.\n  컬렉션 값 연관 필드: 묵시적 조인이 발생하며, 더이상 탐색할 수 없다. 단 from절에서 명시적 조인을 통해 별칭(as)을 얻으면 더 탐색할 수 있다.\n\n\n\n\n필자는 @~ToMany의 관계를 최대한 사용하지 않으려고 하기 때문에 컬렉션 관련해서는 사용해본적이 전무하며, 경로 표현식을 통한 묵시적 조인이 발생하는것도 별로 좋다고 생각하지 않기 때문에 조인이 필요하다면 항상 명시적 조인을 사용하고 있다.\n\n위의 내용을 제대로 이해하면 어떤 문제가 발생할 수 있는지 알 수 있기 때문에 이런 내용은 최대한 이해해두는게 도움이 될 거라고 생각한다.\n\n\n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-07-22-jpa-8/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "JPA 중급 1 - Querydsl",
      "date": "2021-07-30 00:00:00 +0000",
      "description": "Querydsl은 JPQL 빌더입니다.\n",
      "content": "\n  📕 Querydsl\n  🚀 환경설정\n  📜 사용방법    \n      검색\n      조건 검색\n      정렬\n      페이징\n      집합\n      내부조인\n      외부조인\n      세타조인(=크로스조인)\n      페치조인\n      스위치\n      문자열, 상수 이어붙이기\n      프로젝션\n      동적쿼리\n      벌크연산\n      DB 함수 사용\n    \n  \n\n\n\n\n\n  이 포스팅의 대부분 내용은 김영한님의 실전! Querydsl을 참고하여 작성됐으며, 간단한 사용법에 대한 예제일 뿐이니 더 깊은 내용이 궁금하신분은 강의를 보세요.\n\n\n📕 Querydsl\n\n\n\nQuerydsl은 JPQL 빌더 역할을 하는 비표준 오픈소스 프로젝트이다.\n\nJPA 표준 빌더는 JPA Criteria인데, 이것은 너무 장황하고 가독성이 좋지 않기 때문에 비록 표준은 아니지만 Querydsl을 사용한다.\n\nQuerydsl이 너무 훌륭하기 때문에 Spring Data 프로젝트에서도 많은 지원이 되고 있는데, 근시일내에 표준으로 자리잡지 않을까 조심스레 예상해본다.\n\n\n\nQuerydsl을 왜 사용할까?\n\n\n\nJPQL을 직접 사용하게 되면 문자열을 직접 타이핑해야 한다는 큰 단점이 존재한다.\n\nIbatis나 Mybatis를 사용해보신분은 알겠지만, 쿼리를 직접 타이핑한다는 것은 안정성이 굉장히 떨어지는 작업이라고 볼 수 있다.\n\n다음 SQL을 보자.\n\n\n\nString query = \"    select \\n\" +\n               \"        m.id\\n\" +\n               \"        t.id\\n\" +\n               \"        m.create_at\\n\" +\n               \"        m.update_at\\n\" +\n               \"        m.age\\n\" +\n               \"        m.name\\n\" +\n               \"        m.team_id\\n\" +\n               \"        t.create_at\\n\" +\n               \"        t.update_at\\n\" +\n               \"        t.name\\n\" +\n               \"    from\\n\" +\n               \"        member m \\n\" +\n               \"    inner join\\n\" +\n               \"        team t \\n\" +\n               \"            on m.team_id=t.id\";\n\n\n\n\n눈썰미가 좋으신분은 알아차리셨을수도 있겠지만, 위 SQL에는 버그가있다.\n\n뭘까?\n\n\n\nString query = \"    select \\n\" + // &lt;-- select 뒤에 띄어쓰기가 있음\n               \"        m.id\\n\" +\n               \"        t.id\\n\" +\n               \"        m.create_at\\n\" +\n               \"        m.update_at\\n\" +\n               \"        m.age\\n\" +\n               \"        m.name\\n\" +\n               \"        m.team_id\\n\" +\n               \"        t.create_at\\n\" +\n               \"        t.update_at\\n\" +\n               \"        t.name\\n\" +\n               \"    from\\n\" +\n               \"        member m \\n\" +\n               \"    inner join\\n\" +\n               \"        team t \\n\" +\n               \"            on m.team_id=t.id\";\n\n\n\n\n위처럼 SQL에 버그가 존재하는 상태로 어플리케이션이 실행이 된다는게 가장 큰 문제점이다. (컴파일 타임에 에러가 잡히질 않는다 ! 😱)\n\n즉, 배포가 완료된 후 사용자가 어떤 기능을 사용하여 해당 SQL이 포함된 메서드가 런타임에 호출되고 나서야 버그가 존재함을 알 수 있다는 것이다.\n\n실무에서 이런 상황은 즉시 대처에 들어가야하는 핫픽스 작업이며(애초에 발생해서는 안된다 !), 서비스에 대한 사용자의 신뢰성이 떨어지는 결과까지도 야기할 수 있다.\n\n심지어 원인이 오타라는, 누구나 쉽게 저지를 수 있는 실수이고 디버깅 또한 굉장히 힘들기 때문에 굉장히 질이 좋지 않은 버그라고 볼 수 있을 것 같다.\n\n\n\n또한, 위와 비슷하지만 코드를 작성하는 개발자 관점에서 봤을 때 자바 컴파일러와 IDE의 도움을 받을 수 없다는 문제도 있다.\n\n즉, 코드를 작성하다 잘 기억이 나지 않는다면 관련 문서를 계속해서 찾아야만 한다. 실수가 나올 가능성도 매우 높다.\n\n그리고 가독성이 매우 떨어진다는 문제도 있다.\n\n자바 13이후로 문자열 블록이라는 기능이 생겨서 다음과 같은 코드 작성이 가능하긴 한데, 이것도 가독성 측면에서 좋아진 것 뿐이지, 공백 유무에 의한 문제 발생 가능성은 여전히 존재한다.\n\n아직은 우리나라에서 자바8이 가장 많이 사용되고 있고 이제야 자바 11로 넘어가고 있는 추세이기 때문에 먼 이야기다. (21.9월에 자바 17 LTS 발표인데…)\n\n\n\nString query = \"\"\"\n                select\n                    m.id\n                    t.id\n                    m.create_at\n                    m.update_at\n                    m.age\n                    m.name\n                    m.team_id\n                    t.create_at\n                    t.update_at\n                    t.name\n                from\n                    member m\n                inner join\n                    team t\n                        on m.team_id=t.id\";\n               \"\"\";\n\n\n\n\nQuerydsl은 이러한 단점을 모두 보완해준다.\n\n일단 위의 SQL을 Querydsl로 작성한 예를 보자.\n\n\n\nqueryFactory\n        .selectFrom(member)\n        .join(member.team, team)\n        .fetch();\n\n\n\n\n보다시피 어떤 쿼리가 발생할지 한눈에 파악할 수 있다.\n\n굉장히 가독성이 좋으며, 문자열 사용을 최소화고 빌더 패턴으로 작성되기 때문에 자바 컴파일러와 IDE의 도움을 모두 받을 수 있다.\n\n즉, 쿼리에 문제가 있다면 아예 컴파일 에러가 발생하여 실행자체가 안됨과 동시에 어디에 어떤 문제가 있는지 에러 메시지를 받아볼 수 있으며, 다음과 같이 IDE 자동완성의 이점도 모두 누릴 수 있다.\n\n\n\n\n\n\n\n이쯤하면 왜 Querydsl을 사용하는지에 대한 납득이 되었을 것 같다.\n\n하지만 Querydsl은 단순히 JPQL 빌더이기 때문에, JPQL로 안되는 것은 Querydsl에서도 안된다.\n\nQuerydsl은 절대 만능이 아니며, 용빼는 재주가 있는게 아니다.\n\nQuerydsl은 단순히 JPQL 빌더라는 것을 명심해야 한다.\n\n\n\n🚀 환경설정\n\n\n\n빌드 스크립트에 대한 세부적인 내용이 궁금하신 분은 하기 포스팅을 참고해주세요.\n\n\n  📜 그레이들 Annotation processor 와 Querydsl\n\n\n\n\n우선 이 세팅은 2021.07.31 현재 Querydsl 최신 버전을 기준으로 하여 작성됨을 말씀드린다.\n\n프로젝트에 적용된 Querydsl 버전은 4.4.0이며, gradle 버전은 6.8.3이다.\n\n\n\n버전을 먼저 언급하는 이유가 있는데, Querydsl 3.x대 버전과 4.x대 버전 사이에 상당한 차이가 있기 때문이다.\n\n\n\n또한, Querydsl을 사용하기 위해서는 JPA Entity를 QClass라는 것으로 컴파일 해야 하는데, 여기서 annotationProcessor와 gradle의 도움이 필요하기 때문이다.\n\n\n\n필수적인 설정은 다음과 같다.\n\n\n\next {\n    querydslDir = \"$buildDir/generated/querydsl\"\n}\n\ndependencies {\n  annotationProcessor(\n          'org.springframework.boot:spring-boot-configuration-processor',\n          'jakarta.persistence:jakarta.persistence-api',\n          'jakarta.annotation:jakarta.annotation-api',\n          \"com.querydsl:querydsl-apt:${dependencyManagement.importedProperties['querydsl.version']}:jpa\",\n  )\n\n  implementation(\n          'com.querydsl:querydsl-jpa',\n  )\n}\n\n\n\n\n이 포스팅을 작성하기 위해 구성한 프로젝트의 전체적인 빌드 스크립트는 다음과 같다.\n\n\n\nplugins {\n    id 'java'\n    id 'org.springframework.boot' version '2.5.2'\n    id 'io.spring.dependency-management' version '1.0.11.RELEASE'\n}\n\next {\n    querydslDir = \"$buildDir/generated/querydsl\"\n}\n\ngroup = 'learn.jpa'\nversion = ''\nsourceCompatibility = '11'\n\nrepositories {\n    mavenCentral()\n}\n\nconfigurations {\n    developmentOnly\n    runtimeClasspath {\n        extendsFrom developmentOnly\n    }\n}\n\ndependencies {\n    annotationProcessor(\n            'org.projectlombok:lombok',\n            'org.springframework.boot:spring-boot-configuration-processor',\n            'jakarta.persistence:jakarta.persistence-api',\n            'jakarta.annotation:jakarta.annotation-api',\n            \"com.querydsl:querydsl-apt:${dependencyManagement.importedProperties['querydsl.version']}:jpa\",\n    )\n\n    implementation(\n            'org.springframework.boot:spring-boot-starter-web',\n            'org.springframework.boot:spring-boot-starter-data-jpa',\n            'org.springframework.boot:spring-boot-starter-validation',\n            'com.querydsl:querydsl-jpa',\n    )\n\n    testImplementation(\n            'org.springframework.boot:spring-boot-starter-test',\n    )\n\n    testImplementation(\"org.springframework.boot:spring-boot-starter-test\") {\n        exclude group: \"junit\", module: \"junit\"\n    }\n\n    compileOnly(\n            'org.projectlombok:lombok'\n    )\n\n    runtimeOnly(\n            'com.h2database:h2'\n    )\n}\n\ntest {\n    useJUnitPlatform()\n}\n\nclean {\n    delete file('src/main/generated')\n}\n\ntask cleanGeneatedDir(type: Delete) {\n    delete file('src/main/generated')\n}\n\n\n\n\n위 코드가 뭔지 몰라도 일단 필수 설정만 똑같이 작성하면 Querydsl을 사용하는데 큰 문제는 없을 것 같다.\n\n만약 위 코드가 더 궁금하다면 groovy와 gradle에 대한 공부가 필요할 것이다.\n\n\n\n그리고 Querydsl 4.x에서 JPAQueryFactory가 핵심적인 역할을 하는데, 이 클래스를 스프링 빈으로 만들기 위해 다음과 같은 설정파일을 작성한다.\n\n필자는 Querydsl이 JPA 도메인에 포함된다고 판단하여 JPA 설정파일에 이 설정을 집어넣는다.\n\n\n\n@Configuration\n@EnableJpaAuditing\npublic class JpaConfig {\n    @PersistenceContext\n    private EntityManager entityManager;\n\n    @Bean\n    public JPAQueryFactory jpaQueryFactory() {\n        return new JPAQueryFactory(entityManager);\n    }\n}\n\n\n\n\n참고로 이렇게 설정파일을 작성하는 이유가 두가지 존재한다.\n\n\n\n\n  Querydsl은 비표준이기 때문에 @DataJpaTest의 도움을 받지 못한다\n    \n      @DataJpaTest는 슬라이싱 테스트를 진행할 때 JPA관련 스프링 빈을 주입해주는데, JPAQueryFactory빈을 주입해주지 않기 때문에 Querydsl 테스트를 하지 못한다\n    \n  \n  JPAQueryFactory를 싱글톤으로 활용하기 위함이다\n\n\n\n\n이후 모든 Querydsl 테스트를 진행할 때 다음과 같이 진행하면 된다.\n\n여기서 JUnit은 5버전이며, 생성자 주입을 받기 위해 src/test/resources/spring.properties 를 생성한 후 다음과 같은 설정을 추가해야 한다.\n\n\n\n# file: 'src/test/resources/spring.properties'\nspring.test.constructor.autowire.mode=ALL\n\n\n\n\n@DataJpaTest\n@Import(JpaConfig.class)\nclass QueryRepositoryTest {\n  private final JPAQueryFactory queryFactory;\n  private final TestEntityManager entityManager;\n\n  QueryRepositoryTest(JPAQueryFactory queryFactory, TestEntityManager entityManager) {\n    this.queryFactory = queryFactory;\n    this.entityManager = entityManager;\n  }\n  \n  // test cases...\n}\n\n\n\n\n이렇게 설정하면 @SpringBootTest를 사용하지 않는 슬라이싱 테스트를 진행하더라도 Querydsl 테스트를 진행할 수 있다.\n\n명심해야 할 것은, Querydsl을 사용하기 위해서는 QClass가 반드시 필요하므로 항상 gradle에서 build 태스크를 먼저 실행해줘야 QClass가 컴파일되어 Querydsl이 정상적으로 동작하게 된다는 것이다.\n\n\n\n📜 사용방법\n\n\n\n우선 결과를 조회하는 fetch() 관련 메서드에 대해 알면 좋을 것 같다.\n\n자주 사용하는 fetch는 다음과 같다.\n\n\n  fetch()\n    \n      검색 결과에 대한 모든 값을 Collection에 담아 반환한다. 이 때\n    \n  \n  fetchCount()\n    \n      검색결과를 카운트로 반환한다. 반환 타입은 long\n    \n  \n  fetchOne()\n    \n      한개의 결과를 반환한다. 검색 결과가 반드시 한개인 경우에만 사용해야 한다\n      JPQL의 getSingleResult와 같다\n      결과가 둘 이상인 경우 NonUniqueResultException을 던진다\n    \n  \n  fetchFirst()\n    \n      limit 1과 같다.\n      검색 중 처음으로 매치되는 것 하나만 반환하며, 즉시 쿼리가 종료된다\n    \n  \n  fetchResults()\n    \n      페이징 쿼리를 작성할 때 사용된다\n      콘텐츠, 페이지 개수, 페이지 사이즈, 토탈 카운트를 반환한다\n      콘텐츠를 찾는 쿼리와 카운트를 찾는 쿼리가 모두 발생한다 (총 2번)\n    \n  \n\n\n\n\n검색\n\n\n\n\n\nList&lt;Member&gt; members = queryFactory\n                        .select(QMember.member)\n                        .from(QMember.member)\n                        .fetch();\n\nList&lt;Member&gt; members = queryFactory\n                        .selectFrom(QMember.member) // select절에 member를 전체 가져올 경우 selectFrom()으로 축약 가능\n                        .fetch();\n\nList&lt;Member&gt; members = queryFactory\n                        .selectFrom(member) // QMember를 static import하면 이렇게 줄일 수 있다\n                        .fetch();\n\n\n\n\n조건 검색\n\n\n\n\n\n// where절에 and()나 or()를 추가할 수 있으며, 아래 샘플 코드처럼 쉼표(,)로 구분하면 and()와 같이 동작한다.\nList&lt;Member&gt; members = queryFactory\n                        .selectFrom(member)\n                        .where(\n                                member.name.eq(\"siro\"),\n                                member.age.eq(10)\n                              )\n                        .fetch();\n\n\n\n\n정렬\n\n\n\n\n\nList&lt;Member&gt; members = queryFactory\n                      .selectFrom(member)\n                      .orderBy(member.name.desc())\n                      .fetch();\n\n\n\n\n페이징\n\n\n\n\n\nQueryResults&lt;Member&gt; results = queryFactory\n                                .selectFrom(member)\n                                .orderBy(member.name.desc())\n                                .offset(1)\n                                .limit(2)\n                                .fetchResults();\n\nList&lt;Member&gt; content = results.getResults();\nlong totalCount = results.getTotal();\n\n\n\n\n집합\n\n\n\n\n\n// Tuple은 com.querydsl.core에 존재하는 클래스로, 결과가 하나의 엔티티가 아닌 여러가지 타입일 경우를 뜻한다\nList&lt;Tuple&gt; tuples = queryFactory\n                      .select(\n                              member.count(),\n                              member.age.sum(),\n                              member.age.avg(),\n                              member.age.max(),\n                              member.age.min()\n                             )\n                      .from(member)\n                      .fetch();\n\n\n\n\n내부조인\n\n\n\n\n\n// 내부조인 시 on()절은 생략해도 무방하다. where()절이 있다면 대체된다.\nList&lt;Member&gt; members = queryFactory\n                        .selectFrom(member)\n                        .join(member.team, team) // innerJoin()과 join()은 같다\n                        .fetch();\n\n\n\n\n외부조인\n\n\n\n\n\n// 외부조인 시에는 where()절보다 on()절을 사용해야만 한다.\nList&lt;Member&gt; members = queryFactory\n                        .selectFrom(member)\n                        .leftJoin(member.team, team) // rightJoin()도 존재한다\n                        .fetch();\n\n\n\n\n세타조인(=크로스조인)\n\n\n\n\n\n// 세타조인시 join 조건절 역할을 하는 where이 없거나 잘못된 경우 카테시안 곱이 발생하므로 주의한다\nList&lt;Member&gt; members = queryFactory\n                        .select(member)\n                        .from(member, team)\n                        .where(member.name.eq(team.name)) \n                        .fetch();\n\n\n\n\n페치조인\n\n\n\n페치조인은 fetchJoin()만 추가하면 바로 적용된다.\n\n\n\nList&lt;Member&gt; fetch = queryFactory\n                      .selectFrom(member)\n                      .join(member.team, team)\n                      .fetchJoin()\n                      .fetch();\n\n\n\n\n스위치\n\n\n\n\n\n// 간단한 스위치\nList&lt;String&gt; members = queryFactory\n                        .select(member.age\n                            .when(10).then(\"열살\")\n                            .when(20).then(\"스무살\")\n                            .otherwise(\"기타\")\n                        )\n                        .from(member)\n                        .fetch();\n\n// 복잡한 스위치\nList&lt;String&gt; members = queryFactory\n                        .select(new CaseBuilder() // 케이스빌더 사용\n                            .when(member.name.startsWith(\"김\")).then(\"김씨\")\n                            .when(member.name.startsWith(\"이\")).then(\"이씨\")\n                            .otherwise(\"기타\"))\n                        .from(member)\n                        .fetch();\n\n\n\n\n문자열, 상수 이어붙이기\n\n\n\n\n\nList&lt;String&gt; members = queryFactory\n                        .select(member.name.concat(\"_\").concat(member.age.stringValue())) // concat사용\n                        .from(member)\n                        .where(member.name.eq(\"siro\"))\n                        .fetch();\n\n\n\n\n프로젝션\n\n\n\n프로젝션을 사용할 경우 필드명이 다른 경우 as를 사용해 필드명을 맞춰주면 된다.\n\n예를 들자면, Member 엔티티의 값을 꼭 MemberDto에 넣어야만 되는 것이 아니며, 다양한 DTO에 넣어줄 수 있다.\n\n기본적으로 아래의 3가지 방식을 지원한다.\n\n\n\n// 수정자(setter) 프로젝션\nList&lt;MemberDto&gt; memberDtos = queryFactory\n                              .select(Projections.bean(MemberDto.class, member.name, member.age))\n                              .from(member)\n                              .fetch();\n\n// 필드 프로젝션\nList&lt;MemberDto&gt; memberDtos = queryFactory\n                              .select(Projections.fields(MemberDto.class, member.name, member.age))\n                              .from(member)\n                              .fetch();\n\n// 생성자 프로젝션\nList&lt;MemberDto&gt; memberDtos = queryFactory\n                              .select(Projections.constructor(MemberDto.class, member.name, member.age))\n                              .from(member)\n                              .fetch();\n\n\n\n\n추가로 @QueryProjection을 생성자에 추가하면 DTO도 QClass로 컴파일되어 더 쉽게 사용할 수 있다.\n\n\n\n@Getter\npublic class MemberDto {\n    private Long id;\n    private String name;\n    private Integer age;\n\n    public MemberDto() {}\n\n    @QueryProjection\n    public MemberDto(Long id, String name) {\n        this.id = id;\n        this.name = name;\n    }\n\n    @QueryProjection\n    public MemberDto(String name, Integer age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    @QueryProjection\n    public MemberDto(Long id, String name, Integer age) {\n        this.id = id;\n        this.name = name;\n        this.age = age;\n    }\n\n    public static MemberDto createMemberDto(Long id, String name, Integer age) {\n        return new MemberDto(id, name, age);\n    }\n\n    public static MemberDto createMemberDto(Long id, String name) {\n        return new MemberDto(id, name);\n    }\n\n    public static MemberDto createMemberDto(String name, Integer age) {\n        return new MemberDto(name, age);\n    }\n}\n\n\n\n\n// @QueryProjection 프로젝션\nList&lt;MemberDto&gt; memberDtos = queryFactory\n                              .select(new QMemberDto(member.name, member.age))\n                              .from(member)\n                              .fetch();\n\n\n\n\n@QueryProjection과 생성자 프로젝션은 서로 일장일단이 존재한다.\n\n\n\n\n  @QueryProjection\n    \n      장점 - 프로젝션시 발생하는 에러를 컴파일타임에 잡을 수 있다\n      장점 - 코드가 약간 더 직관적이다\n      단점 - DTO에 Querydsl 로직이 들어간다 (DTO가 Querydsl을 의존한다)\n    \n  \n  생성자 프로젝션\n    \n      장점 - DTO가 Querydsl을 의존하지 않는다\n      단점 - 런타임 에러가 발생할 수 있는 가능성이 존재한다\n    \n  \n\n\n\n\n동적쿼리\n\n\n\nwhere절에 null을 반환하면 해당 검색조건이 무시되기 때문에 동적쿼리를 작성하기가 편리하다.\n\n외에 BooleanBuilder를 사용한 방법도 존재하는데 별로 선호하지 않으므로 패스.\n\n\n\nList&lt;Member&gt; members = queryFactory\n                        .selectFrom(member)\n                        .where(allEq(\"siro\", null))\n                        .fetch();\n\n// 계속해서 재사용할 수 있다는 큰 장점이 있다.\nprivate BooleanExpression nameEq(String name) {\n    return Objects.isNull(name) ? null : member.name.eq(name);\n}\n\nprivate BooleanExpression ageEq(Integer age) {\n    return Objects.isNull(age) ? null : member.age.eq(age);\n}\n\nprivate BooleanExpression allEq(String name, Integer age) {\n    return nameEq(name).and(ageEq(age));\n}\n\n\n\n\n벌크연산\n\n\n\n벌크연산의 경우 영속성 컨텍스트를 무시하고 DB에 직접 쿼리하기 때문에 영속성 컨텍스트와 실제 DB의 데이터 정합성이 깨질 수 있다.\n\n따라서 벌크연산을 가장 먼저 실행하거나, 후순위에 실행된다면 영속성 컨텍스트를 개발자가 직접 관리해야한다.\n\n벌크연산은 이 쿼리에 영향받은 row 개수를 long으로 반환한다.\n\n혹은 쿼리 메서드에 @Modifying을 추가하여 영속성 컨텍스트를 관리할 수 있다.\n\n잦은 업데이트가 발생하는 경우 엔티티 클래스에 @DynamicUpdate를 붙여 관리할 수도 있다.\n\n다만 @Modifying와 @DynamicUpdate는 잘 알아보고 사용해야 한다.\n\n\n\nqueryFactory\n        .update(member)\n        .set(member.age, 100)\n        .where(member.age.lt(35))\n        .execute();\n\nqueryFactory\n        .delete(member)\n        .where(member.age.eq(29))\n        .execute();\n\n\n\n\nDB 함수 사용\n\n\n\norg.hibernate.dialect.Dialect 의 DB벤더 별 확장 클래스를 찾아서 (H2Dialect같은 것) 사용하고자 하는 함수가 등록돼있는지 확인하고, 사용하려는 함수가 없는 경우(커스텀 함수 등) 해당 확장 클래스를 한번 더 확장하여 함수를 등록한 후 확장한 클래스를 설정파일에 등록해야한다.\n\n\n\nqueryFactory\n        .select(Expressions.stringTemplate(\"function('replace', {0}, {1}, {2})\", member.name, \"s\", \"S\"))\n        .from(member)\n        .fetch();\n\n\n\n\n모든 DB 벤더가 지원하는 ANSI 표준에 있는 기본적인 함수들은 이미 Hibernate가 지원하므로, stringTemplate 을 직접 사용하지 않아도 된다.\n\n\n\nqueryFactory\n        .select(member.name)\n        .from(member)\n        .where(member.name.eq(member.name.lower()))\n        .fetch();\n\n\n\n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-07-30-jpa-9/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "절판 된 개발서적을 합법적으로 구하는 방법",
      "date": "2021-08-05 13:13:00 +0000",
      "description": "개발일기\n",
      "content": "\n\n\n\n\n\n\n여기저기서 추천하는 책이 있어서 구매하려고 봤는데, 절판 된 책이었다.\n\n그래서 중고책을 알아봤는데 뭔놈의 중고책이 말도 안되게 비싸더라.\n\n찢어지고 낙서가 존재하는 중고책을 십만원돈 주고 사기는 좀 그래서 방법을 찾아보았다.\n\n좀 찾아보니 국회전자도서관에서 책을 돈받고 제본해주는 비대면 서비스가 있음을 발견했다.\n\n처음에 저작권 어쩌고 하면서 1/3만 제본 가능하니 제본하고 싶은 페이지를 입력하라길래 별 생각 없이 1-369 (전체 페이지)를 입력하고 문의를 넣었다.\n\n그러자 하루 이틀정도 검토를 한 후에 회신을 주겠다는 알람창이 떴다.\n\n\n\n정확히 2일 뒤 이런 문자가 왔다.\n\n\n\n\n\n\n\n그리고 입금을 했다.\n\n3일 후 집에 우편택배가 왔다.\n\n\n\n\n\n\n\n요즘 비대면 서비스가 참 끝내준다는 생각이 든다.\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-08-05-diary-25/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "Docker를 활용한 테스트 컨테이너 구축",
      "date": "2021-08-30 00:00:00 +0000",
      "description": "TestContainers를 사용하여 외부 요인에 의한 실패가 없는 CI 환경을 구축한 이야기.\n",
      "content": "\n  💥 Issue#51\n  🎯 문제 해결을 위한 과정\n  🤔 문제점 ?    \n      ⚙ 로컬에서 테스트가 느려지는 문제\n      ⚙ 로컬에 Docker가 설치 및 실행되고 있어야 한다\n    \n  \n\n\n\n\n이번에 진행중인 사이드 프로젝트에서 깃허브에 백엔드 프로젝트 CI를 구축하면서 마주쳤던 문제와 이를 해결한 방법을 문서로 기록합니다.\n\n\n\n💥 Issue#51\n\n저는 이번에 백엔드 서버를 구축하면서 데이터베이스 접속 정보를 숨기기 위해 데이터베이스 접속 정보를 외부 프로퍼티 파일로 작성하여 분리하였습니다.\n\n데이터베이스 유저를 따로 생성하여 SELECT, INSERT, UPDATE 세 가지의 권한만 준 상태이긴 했지만, 그럼에도 불구하고 이 유저에 대한 정보가 깃허브에 업로드되어 외부에 노출된다면 보안상 매우 취약할 것이라고 생각했기 때문이었습니다.\n\n그리고 백엔드 팀 각자의 로컬 환경에는 정해진 위치에 데이터베이스 접속정보를 갖고 있는 프로퍼티 파일이 위치하게 하였습니다.\n\n따라서 로컬 환경에서는 아무리 테스트를 시도해도 항상 성공하는 상태였습니다.\n\n\n\n문제는 깃허브 액션에서 CI가 수행되며 발생했죠.\n\n\n\n로컬에서 완벽하게 테스트하여 PR을 했다고 생각했는데, 막상 PR 이벤트가 발생하면 CI가 계속 실패하는 것이었습니다.\n\n\n\nApplicationTest &gt; boot() FAILED\n    java.lang.IllegalStateException at DefaultCacheAwareContextLoaderDelegate.java:132\n        Caused by: org.springframework.beans.factory.BeanDefinitionStoreException at ConfigurationClassParser.java:189\n            Caused by: java.io.FileNotFoundException at FileInputStream.java:-2\n\n\n\n\nCI 실패 로그를 살펴보니 FileNotFoundException이 발생하고 있었습니다.\n\n문제를 추적하니 민감정보를 숨기기 위해 외부로 분리했던 데이터베이스 접속정보 파일을 찾을 수 없는 상황이었습니다.\n\n정확히 어떤 상황이었냐면, 깃허브 액션이 진행될 때 깃허브 클라우드에 위치한 인스턴스에서 테스트가 실행됩니다.\n\n이 때 깃허브 인스턴스에는 데이터베이스 접속 정보를 갖고 있는 프로퍼티 파일이 존재하지 않기 때문에 발생하는 문제였습니다.\n\n\n\n이 문제점을 어떻게 해결할까 고민해보니 Docker가 떠오르긴 했지만, 문제는 제가 Docker를 한번도 사용해본 적이 없다는 점이었습니다.\n\n그래서 일단 다른 회피방법이 있을지 이슈를 등록하였고, 승재님의 제안을 보고 TestContainers에 대해 알아보게 됐습니다.\n\n\n\n알아보니 결국 Docker를 사용하는 방법이여서, 결국 디버깅을 하다말고 뜬금없이 Docker를 공부하게 됐습니다. 😭\n\n약 두시간 후 어느정도 Docker에 대한 감을 잡았다고 생각해 📜 TestContainers 공식 문서를 보면서 환경 구축에 들어갔습니다.\n\n다행히 문서가 아주 잘 돼있어서 크게 어려운 작업은 아니었던 것 같습니다.\n\n\n\n이 문제를 해결하기 위한 과정은 다음과 같습니다.\n\n\n  여기서 실패한 테스트의 경우 데이터베이스로 인한 문제였다.\n  외부 환경에 민감한 테스트는 독립적인 테스트 환경을 구축해주면 될 것이다.\n  해당 테스트가 실행될 때 데이터베이스(MySQL)를 Docker로 띄워준다.\n  따라서 해당 테스트가 실행될 때 외부 데이터베이스에 의존하지 않아도 되게 된다.\n  테스트 자체에 결함이 없다면 이 테스트는 깃허브 인스턴스에서도 항상 성공 할 것이다.\n\n\n\n\n🎯 문제 해결을 위한 과정\n\n📜 TestContainers 공식 문서대로 환경 구축을 시작합니다.\n\n우선 Gradle에 의존성을 추가합니다.\n\n이 때 사소하지만 GString을 이용해 버전관리를 변수로 처리해줍니다.\n\n우리 프로젝트는 MySQL8.0을 사용하고 있으므로 이것을 도커로 띄우기 위한 의존성을 추가했습니다.\n\n\n\next {\n    testContainersVersion = '1.16.0'\n}\n\ndependencies {\n    testImplementation(\n            \"org.testcontainers:junit-jupiter:$testContainersVersion\",\n            \"org.testcontainers:mysql:$testContainersVersion\",\n    )\n}\n\n\n\n\n그리고 독립적인 환경의 테스트를 해야 할 테스트 케이스가 얼마나 나올지 모르는 상태였기 때문에, 이 설정을 별도의 확장 클래스(JUnit Extension)로 작성했습니다.\n\n\n\n// 테스트 컨테이너를 매 테스트 케이스마다 올렸다 내렸다 하는 것은 굉장히 비효율적입니다.\n// 따라서 테스트가 실행될 때 테스트 컨테이너를 최초에 한번 올리고, 모든 테스트가 끝나면 테스트 컨테이너를 내려야 합니다.\n// BeforeAllCallback, AfterAllCallback를 구현합니다.\n@Testcontainers\npublic class MySQL80Extension implements BeforeAllCallback, AfterAllCallback {\n    // MySQL8.0을 도커로 띄울 것이기 때문에 TestContainers에서 이를 추상화한 객체를 선언합니다.\n    @Container\n    private static MySQLContainer&lt;?&gt; MYSQL;\n \n    // 공식 문서에 따르면 별로 중요한 내용들은 아니라고 하였으니 구색만 맞춰서 대충 작성해줬습니다.\n    private static final String DATABASE_NAME = \"inflearn_backend\";\n    private static final String USERNAME = \"username\";\n    private static final String PASSWORD = \"password\";\n    private static final int PORT = 3306;\n\n\n    @Override\n    public void beforeAll(final ExtensionContext context) {\n        // 테스트가 실행되기 전 도커로 띄워야 할 MySQL에 작성한 설정을 바인딩해줍니다.\n        MYSQL = new MySQLContainer&lt;&gt;(\"mysql:8.0.26\")\n                .withDatabaseName(DATABASE_NAME)\n                .withUsername(USERNAME)\n                .withPassword(PASSWORD)\n                .withExposedPorts(PORT);\n        \n        // 데이터베이스를 띄웁니다.\n        MYSQL.start();\n\n        // 테스트 케이스에서 도커로 띄운 데이터베이스 정보를 사용해야 할 일이 생길수도 있습니다.\n        // 혹시 모르니 이를 운영체제 환경변수에 저장합니다.\n        System.setProperty(\"spring.datasource.url\", getJdbcUrl());\n        System.setProperty(\"spring.datasource.username\", USERNAME);\n        System.setProperty(\"spring.datasource.password\", PASSWORD);\n    }\n\n    @Override\n    public void afterAll(final ExtensionContext context) {\n        // 모든 테스트가 끝나면 테스트 컨테이너를 종료합니다.\n        MYSQL.stop();\n    }\n\n    private String getJdbcUrl() {\n        return String.format(\"jdbc:mysql://localhost:%d/%s\", MYSQL.getFirstMappedPort(), DATABASE_NAME);\n    }\n}\n\n\n\n\n그리고 데이터베이스 접속 파일을 찾게 하지 않도록, 테스트를 위한 프로파일을 하나 별도로 추가해줍니다.\n\n\n\n# src/test/resources/application-test.properties\n\nhibernate.dialect=org.hibernate.dialect.MySQL8Dialect\nspring.jpa.hibernate.ddl-auto=update\nspring.jpa.properties.hibernate.format_sql=true\ndecorator.datasource.p6spy.enable-logging=true\n\n\n\n\n처음에는 그냥 설정을 다 추가했는데, 저를 포함한 다른 분들이 이러한 설정을 매번 추가하려면 우선 매우 귀찮고, 휴먼에러가 생길수도 있는 부분이라 판단해 커스텀 어노테이션을 작성 했습니다.\n\n(이 방법은 표준이 아니기 때문에 개인적으로 선호하는 방법은 아닙니다.)\n\n\n\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n@ActiveProfiles(\"test\") // 추가한 프로파일을 사용합니다.\n@ExtendWith(MySQL80Extension.class) // 추가한 MySQL8.0 확장을 사용합니다.\n@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE) // 임베디드 DB를 사용하지 않습니다.\npublic @interface EnableDockerContainers {\n}\n\n\n\n\n그리고 이에 대한 모의 테스트를 작성하여 구동했습니다.\n\n// 커스텀 애노테이션입니다.\n// Querydsl이 비표준이므로 @DataJpaTest를 사용한 슬라이싱 테스트 시 JPAQueryFactory Bean이 로딩되지 않는 현상을 해결해줍니다\n@ExtensionJpaTest  \n@EnableDockerContainers\n@DisplayName(\"Docker로 Test용 MySQL Container가 적용되는지 테스트. 이 테스트를 실행할 때 반드시 Docker가 실행중이어야 함 !\")\nclass MemberRepositoryTest {\n    private final RoleRepository roleRepository;\n    private final MemberRepository memberRepository;\n\n    public MemberRepositoryTest(final MemberRepository memberRepository, final RoleRepository roleRepository) {\n        this.memberRepository = memberRepository;\n        this.roleRepository = roleRepository;\n    }\n\n    @Test\n    void save() throws Exception {\n        Role role = roleRepository.save(Role.of(RoleType.MEMBER, false));\n        Member member = memberRepository.save(Member.of(\"siro@gmail.com\", \"password\", role));\n        Assertions.assertThat(member.getEmail()).isEqualTo(\"siro@gmail.com\");\n        Assertions.assertThat(member.getPassword()).isEqualTo(\"password\");\n        Assertions.assertThat(member.getRole()).isEqualTo(role);\n    }\n}\n\n\n\n\n그리고 어마어마한 길이의 Docker 로그가 발생하며 테스트가 성공합니다.\n\n\n\n\n\n\n\n🤔 문제점 ?\n\n이 방법을 사용하면서 두 가지 문제를 생각했습니다.\n\n\n\n\n  로컬에서도 테스트가 느려진다.\n  로컬에 Docker가 설치 및 실행되고 있어야 한다.\n\n\n\n\n⚙ 로컬에서 테스트가 느려지는 문제\n\nCI에서  테스트가 약간 느려져봐야 사실 큰 문제는 아닙니다만, 로컬환경에서 테스트가 느려지면 개발자 입장에서 매우 답답해지기 마련입니다.\n\n테스트를 돌리면 즉각적인 피드백이 나와줘야 하는데, Docker 띄우고 내린다고 한세월이니까요.\n\n이 문제는 고민을 좀 해봤는데, JUnit에서 지원하는 태깅을 통해 로컬환경에서는 Docker 테스트가 동작하지 않도록 하는게 괜찮지 않을까 생각했습니다.\n\n\n\n⚙ 로컬에 Docker가 설치 및 실행되고 있어야 한다\n\n현재 멤버에 변동이 생길지 안생길지는 모르겠으나, 우선 이 프로젝트에 익숙하지 않은 사람의 경우 처음 신경써야 할 포인트가 하나 더 생겼다고 생각합니다.\n\n모든 개발자가 로컬에 Docker를 띄워서 관리하고 있지는 않을테니까요.\n\n이 부분은 팀 차원에서 가이드를 해주거나 꾸준한 문서화가 해결해 줄 수 있을거라고 생각합니다.\n\n\n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2021-08-30-testcontainers/"
    },{
      "image": "/assets/img/spring/spring-security/security-logo.png",
      "title": "Spring Security - HTTP API 기반의 인증 아키텍처",
      "date": "2021-08-30 00:00:00 +0000",
      "description": "Spring Security - HTTP API 기반의 인증 아키텍처\n",
      "content": "\n\n  동작하는 전체 코드는 🕋 깃허브 저장소를 참고해주세요.\n\n\nDelegatingFilterProxy 는 표준 서블릿 필터를 구현하고 있고, 내부에 FilterChainProxy라는 이름의 위임 대상을 갖습니다.\n\n\n\nSpring Security를 프로젝트에 적용하면 FilterChainProxy 을 통해 SpringFilterChain을 구현하여 동작합니다.\n\n\n\nSpringFilterChain에는 정말 많은 수의 필터가 이미 구현돼있고, 얼마든지 더 확장할 수 있는 구조로 만들어져 있습니다.\n\n이 글에서는 서버사이드 렌더링(SSR)을 하지 않는 상황을 가정하고 HTTP API 방식으로 이메일&amp;비밀번호 인증을 구현하는 방법을 다룹니다.\n\n이 경우 인증 요청 컨텐츠로 이메일과 비밀번호가 JSON으로 들어오기 때문에 내부적인 처리 로직은 사실 기존 폼로그인 방식과 크게 다를 게 없지만 예외 처리나 응답 등에서 아주 약간의 차이가 있을 수 있습니다. (특히 응답)\n\n우선 전체적인 흐름은 다음과 같습니다.\n\n\n  클라이언트가 서버로 로그인을 시도합니다\n  클라이언트 애플리케이션이 이메일과 비밀번호를 입력받아 서버에 인증 요청을 보내옵니다\n  서버는 이메일과 비밀번호를 받아 내부적으로 인증처리를 진행하고 클라이언트에 적절한 응답을 반환합니다\n\n\n이때 응답은 처리 결과에 따라 Http Status로 구분하고 응답 바디에 JSON 문자열을 담아줍니다.\n\n우선 기존에 인증을 처리하는 주체인 AuthenticationProvider를 확장하여 커스터마이징합니다. 이름은 CustomAuthenticationProvider로 명명하였습니다.\n\n그리고 CustomAuthenticationProvider는 UserDetailsService를 확장한 CustomUserDetailsService를 의존합니다.\n\nCustomUserDetailsService는 CustomAuthenticationProvider의 메시지를 받아 데이터베이스에서 인증 주체의 정보를 가져오는 책임을 갖습니다.\n\n@Service\n@RequiredArgsConstructor\npublic class CustomUserDetailsService implements UserDetailsService {\n    private final UserRepository userRepository;\n\n    @Override\n    public UserDetails loadUserByUsername(String email) throws UsernameNotFoundException {\n        try {\n            return userRepository.findBy(email);\n        } catch (NoSuchElementException e) {\n            throw new UsernameNotFoundException(\"email not found\");\n        }\n    }\n}\n\n\n\n\nCustomAuthenticationProvider는 유저의 인증처리를 하고 판별하는 책임을 갖습니다.\n\n필터를 통해 AuthenticationManager가 미인증 상태의 Authentication을 생성하여 AuthenticationProvider.authenticate로 넘기며 이곳에 넘어온 Authentication은 사용자가 서버에 인증을 요청하기 위해 전달한 정보를 담고 있습니다. 이 정보는 이전에 요청을 받은 필터의 전처리에 따라 달라질수도 있습니다.\n\n예를 들어 AuthenticationProvider에 인증 요청을 위임한 필터가 UsernamePasswordAuthenticationFilter라면 AuthenticationProvider.authenticate로 넘어오는 파라미터는 아이디, 이메일과 비밀번호 같은 것들이 될 수 있습니다.\n\n\n  참고로 Authentication은 스프링 시큐리티에서 사용하는 모든 인증 토큰을 규격화한 인터페이스로 스프링 시큐리티에서 아주 핵심적인 책임을 갖습니다.\n\n\n\n\n@RequiredArgsConstructor\npublic final class CustomAuthenticationProvider implements AuthenticationProvider {\n    private final PasswordEncoder passwordEncoder;\n    private final UserDetailsService userDetailsService;\n\n    @Override\n    public Authentication authenticate(Authentication authentication) throws AuthenticationException {\n        // 데이터베이스에서 유저의 정보를 조회합니다\n        // 만약 데이터베이스에 유저의 정보가 없다면 UsernameNotFoundException가 던져지고 인증 핸들러로 처리가 위임됩니다\n        UserDetails user = userDetailsService.loadUserByUsername(authentication.getName());\n\n        // 데이터베이스에서 조회한 유저의 정보에서 비밀번호를 조회합니다\n        // 이 비밀번호는 암호화된 상태입니다\n        String dbPassword = user.getPassword();\n\n        // 사용자가 입력한 비밀번호를 문자열로 캐스팅합니다\n        String enteredPassword = (String) authentication.getCredentials();\n\n        // 사용자가 입력한 비밀번호를 암호화하여 데이터베이스에서 조회한 비밀번호와 매치시켜봅니다\n        // 만약 올바른 비밀번호를 입력했다면, 암호화된 비밀번호는 데이터베이스의 비밀번호와 일치할 것입니다\n        // 일치하지 않는다면 BadCredentialsException를 던지고 역시 인증 핸들러로 처리가 위임됩니다\n        if (!passwordEncoder.matches(enteredPassword, dbPassword)) {\n            throw new BadCredentialsException(\"password not matched.\");\n        }\n\n        // 여기까지 도달했다면 사용자가 올바른 이메일과 비밀번호를 입력한것입니다\n        // 이제 인증에 성공했다는 토큰을 발급해야 합니다\n        // 사용자의 요청이 HTTP API를 통해 들어왔는지 판별하고 맞다면 HttpAuthenticationToken를 발급합니다\n        // 이 때 인증 토큰에 비밀번호가 들어있으면 보안상 좋지 않으므로 비밀번호는 null로 치환합니다\n        if (isHttpAuthenticationToken(authentication.getClass())) {\n            return HttpAuthenticationToken.authenticated(\n                    /*principal*/ user.getUsername(),\n                    /*credentials*/ null, user.getAuthorities()\n            );\n        }\n        \n        // 사용자의 요청이 폼 로그인방식을 통해 들어왔다면 UsernamePasswordAuthenticationToken를 발급합니다\n        // 이 때 인증 토큰에 비밀번호가 들어있으면 보안상 좋지 않으므로 비밀번호는 null로 치환합니다\n        return UsernamePasswordAuthenticationToken.authenticated(\n                /*principal*/ user.getUsername(),\n                /*credentials*/ null,\n                /*authorities*/ user.getAuthorities()\n        );\n    }\n\n    // 인증처리자(AuthenticationProvider)가 어떤 종류의 토큰에 대한 처리를 지원할 것인지에 대한 여부를 재정의해야합니다\n    // 사실 폼 로그인 방식과 HTTP API 방식의 인증 처리는 큰 차이가 없기 때문에 이 예제에서는 인증처리자가 두 방식을 모두 지원하도록 하였습니다\n    @Override\n    public boolean supports(Class&lt;?&gt; authentication) {\n        return isFormLoginAuthenticationToken(authentication) || isHttpAuthenticationToken(authentication);\n    }\n\n    private boolean isHttpAuthenticationToken(Class&lt;?&gt; authentication) {\n        return HttpAuthenticationToken.class.isAssignableFrom(authentication);\n    }\n\n    private boolean isFormLoginAuthenticationToken(Class&lt;?&gt; authentication) {\n        return UsernamePasswordAuthenticationToken.class.isAssignableFrom(authentication);\n    }\n}\n\n\nHttpAuthenticationToken은 HTTP API 방식의 처리에서 사용 될 토큰으로, AbstractAuthenticationToken을 상속하여 확장하였습니다.\n\n\n  참고로 여기서 AbstractAuthenticationToken은 Authentication을 일부 구현한 추상 클래스입니다.\n\n\nHTTP API 방식의 인증 요청이 들어올 경우 해당 요청을 처리하는 필터에서 요청을 받아 이 토큰을 생성하고, AuthenticationProvider에 처리를 위임합니다.\n\n이 때 AuthenticationProvider를 구현한 여러 콘크리트 클래스 중 CustomAuthenticationProvider.supports가 HTTPAuthenticationToken.class를 지원하고 있음을 명시하고 있으니 HTTP API 방식의 인증처리는 CustomAuthenticationProvider를 통해 진행되게 됩니다.\n\npublic class HttpAuthenticationToken extends AbstractAuthenticationToken {\n    @Serial\n    private static final long serialVersionUID = SpringSecurityCoreVersion.SERIAL_VERSION_UID;\n    private final Object principal;\n    private Object credentials;\n\n    private HttpAuthenticationToken(Object principal, Object credentials) {\n        super(null);\n        this.principal = principal;\n        this.credentials = credentials;\n        setAuthenticated(false);\n    }\n\n    public static HttpAuthenticationToken unauthenticated(Object principal, Object credentials) {\n        return new HttpAuthenticationToken(principal, credentials);\n    }\n\n    private HttpAuthenticationToken(Object principal, Object credentials, Collection&lt;? extends GrantedAuthority&gt; authorities) {\n        super(authorities);\n        this.principal = principal;\n        this.credentials = credentials;\n        super.setAuthenticated(true);\n    }\n\n    public static HttpAuthenticationToken authenticated(Object principal, Object credentials, Collection&lt;? extends GrantedAuthority&gt; authorities) {\n        return new HttpAuthenticationToken(principal, credentials, authorities);\n    }\n\n    @Override\n    public Object getCredentials() {\n        return this.credentials;\n    }\n\n    @Override\n    public Object getPrincipal() {\n        return this.principal;\n    }\n\n    @Override\n    public void setAuthenticated(boolean isAuthenticated) throws IllegalArgumentException {\n        Assert.isTrue(!isAuthenticated, \"can't set this token to trusted - use constructor which takes a GrantedAuthority list instead\");\n        super.setAuthenticated(false);\n    }\n\n    @Override\n    public void eraseCredentials() {\n        super.eraseCredentials();\n        this.credentials = null;\n    }\n}\n\n\n이제 HTTP API 기반의 인증처리를 담당 할 HttpLoginFilter를 작성합니다.\n\npublic class HttpLoginFilter extends AbstractAuthenticationProcessingFilter {\n    private final ObjectMapper objectMapper;\n\n    // \"/api/v1/login\"로 요청이 들어 올 경우 이 필터가 동작합니다\n    public HttpLoginFilter(ObjectMapper objectMapper) {\n        super(new AntPathRequestMatcher(\n                /*default path to verify*/ \"/api/v1/login\"));\n        this.objectMapper = objectMapper;\n    }\n\n    @Override\n    public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException, IOException, ServletException {\n        // 들어온 요청이 위의 URI는 맞지만 넘어온 파라미터가 HTTP API 기반의 요청이 아닐 경우 예외를 던집니다\n        if (!isApplicationJson(request)) {\n            throw new IllegalStateException(\"request content format is not application/json\");\n        }\n\n        // HTTP API 기반의 인증 요청이 맞다면 요청 데이터를 LoginRequest에 바인딩합니다\n        LoginRequest body = objectMapper.readValue(request.getReader(), LoginRequest.class);\n\n        // 만약 이메일이나 비밀번호 데이터가 실제로 있지는 않다면 (필드는 있는 상태) 예외를 던집니다\n        if (body.isEmptyContents()) {\n            throw new IllegalStateException(\"no email or password entered.\");\n        }\n\n        // AuthenticationProvider에 미인증 상태의 토큰을 생성해 넘겨야 하므로 HTTPAuthenticationToken의 생성자를 호출합니다\n        HttpAuthenticationToken token = HttpAuthenticationToken.unauthenticated(body.getEmail(), body.getPassword());\n        return getAuthenticationManager().authenticate(token);\n    }\n\n    private boolean isApplicationJson(HttpServletRequest request) {\n        return APPLICATION_JSON_VALUE.equals(request.getContentType());\n    }\n}\n\n\n여기서 위의 LoginRequest 코드는 다음과 같습니다.\n\n@Getter\n@NoArgsConstructor(access = PRIVATE)\npublic class LoginRequest {\n    @Email\n    @NotNull(message = \"please enter your email.\")\n    private String email;\n\n    @NotNull(message = \"please enter your password.\")\n    @Pattern(\n            regexp = \"^[a-zA-Z0-9!@#$%^&amp;*]{12,32}$\",\n            message = \"The password must be 12 to 32 characters, combining alphanumeric special characters without spaces.\"\n    )\n    private String password;\n\n    public LoginRequest(String email, String password) {\n        this.email = email;\n        this.password = password;\n    }\n\n    public boolean isEmptyContents() {\n        return email == null || email.isBlank() ||\n                password == null || password.isBlank();\n    }\n}\n\n\n여기까지 HTTP API 인증 처리에 대한 모든 코드 작성이 끝났습니다. 이제 인증 요청 성공, 인증 요청 실패에 대한 처리를 담당하는 핸들러를 작성해야 합니다.\n\n우선 인증 성공시 이후의 처리를 책임질 핸들러입니다.\n\n현재 코드에서는 딱히 하는게 없습니다. 세션-쿠키방식이나 JWT를 쓴다던가 한다면 이곳에서 별도의 설정을 더 해주면 되겠습니다.\n\n@RequiredArgsConstructor\npublic class CustomAuthenticationSuccessHandler implements AuthenticationSuccessHandler {\n    private final ObjectMapper objectMapper;\n\n    @Override\n    public void onAuthenticationSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException {\n        response.setCharacterEncoding(\"UTF-8\");\n        response.setStatus(OK.value());\n        response.setContentType(APPLICATION_JSON_VALUE);\n\n        HttpResponse&lt;String&gt; httpResponse = new HttpResponse&lt;&gt;(OK, \"logged in\");\n        objectMapper.writeValue(response.getWriter(), httpResponse);\n    }\n}\n\n\n인증 실패시 처리를 책임질 핸들러입니다.\n\n여기로는 Spring Security가 던진 예외가 넘어오는데, 예외를 체크하여 별도의 처리를 분기시켜주면 됩니다.\n\n@RequiredArgsConstructor\npublic class CustomAuthenticationFailureHandler implements AuthenticationFailureHandler {\n    private final ObjectMapper objectMapper;\n\n    @Override\n    public void onAuthenticationFailure(HttpServletRequest request, HttpServletResponse response, AuthenticationException exception) throws IOException {\n        response.setCharacterEncoding(\"UTF-8\");\n        response.setStatus(UNAUTHORIZED.value());\n        response.setContentType(APPLICATION_JSON_VALUE);\n\n        String message = \"email or password is invalid.\";\n\n        if (exception instanceof BadCredentialsException) {\n            message = \"email or password is invalid.\";\n        }\n\n        HttpResponse&lt;String&gt; httpResponse = new HttpResponse&lt;&gt;(UNAUTHORIZED, message);\n        objectMapper.writeValue(response.getWriter(), httpResponse);\n    }\n}\n\n\n\n\n마지막으로 위에 작성한 모든 인증 컴포넌트들을 모아 SpringFilterChain bean을 작성합니다.\n\n이 예제에서는 Spring Security 6+을 사용하고 있기 때문에 별도로 SpringFilterChain을 만들지만, 이보다 낮은 버전에서는 WebSecurityConfigurerAdapter를 상속하고 @EnableWebSecurity를 선언하는 방식으로 구현될 것입니다.\n\n\n\n@Configuration\n@RequiredArgsConstructor\npublic class SecurityConfiguration {\n    @Bean\n    public SecurityFilterChain filterChain(\n            HttpSecurity http,\n            UserDetailsService userDetailsService,\n            AuthenticationProvider authenticationProvider,\n            HttpLoginFilter httpLoginFilter\n    ) throws Exception {\n        http\n                .httpBasic().disable()\n                .csrf().disable()\n                .authorizeHttpRequests(authorize -&gt; authorize\n                        .mvcMatchers(POST, \"/api/v1/login\").permitAll()\n                        .anyRequest().authenticated())\n                .authenticationProvider(authenticationProvider)\n                .userDetailsService(userDetailsService)\n                .addFilterBefore(httpLoginFilter, UsernamePasswordAuthenticationFilter.class);\n\n        return http.build();\n    }\n\n    @Bean\n    public PasswordEncoder passwordEncoder() {\n        return PasswordEncoderFactories.createDelegatingPasswordEncoder();\n    }\n\n    @Bean\n    public AuthenticationManager authenticationManager(AuthenticationConfiguration authenticationConfiguration) throws Exception {\n        return authenticationConfiguration.getAuthenticationManager();\n    }\n\n    @Bean\n    public AuthenticationProvider authenticationProvider(PasswordEncoder passwordEncoder, UserDetailsService userDetailsService) {\n        return new CustomAuthenticationProvider(passwordEncoder, userDetailsService);\n    }\n\n    @Bean\n    public UserDetailsService userDetailsService(UserRepository userRepository) {\n        return new CustomUserDetailsService(userRepository);\n    }\n\n    @Bean\n    public HttpLoginFilter httpLoginProcessingFilter(ObjectMapper objectMapper, AuthenticationManager authenticationManager) {\n        HttpLoginFilter filter = new HttpLoginFilter(objectMapper);\n        filter.setAuthenticationManager(authenticationManager);\n        filter.setAuthenticationSuccessHandler(new CustomAuthenticationSuccessHandler(objectMapper));\n        filter.setAuthenticationFailureHandler(new CustomAuthenticationFailureHandler(objectMapper));\n        return filter;\n    }\n}\n\n\n마지막으로 이에 대한 아주 간단한 테스트 코드를 작성합니다.\n\n@AutoConfigureWebTestClient\n@SpringBootTest(webEnvironment = RANDOM_PORT)\nclass LoginTests {\n    WebTestClient webTestClient;\n\n    @BeforeEach\n    void setUp(WebApplicationContext context) {\n        webTestClient = MockMvcWebTestClient.bindToApplicationContext(context)\n                .apply(springSecurity())\n                .configureClient()\n                .build();\n    }\n\n    @Test\n    void shouldBeSuccessfulLogin() {\n        webTestClient.post()\n                .uri(\"http://localhost:8080/api/v1/login\")\n                .contentType(APPLICATION_JSON)\n                .bodyValue(new LoginRequest(\"siro@gmail.com\", \"aaaaaaaaaaaa@#!123456\"))\n                .exchange()\n                .expectStatus()\n                .is2xxSuccessful();\n    }\n}\n\n",
      "categories": ["spring","spring-security"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-security/2021-08-30-http-login/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "Gradle로 JMH 사용해보기",
      "date": "2021-09-06 00:00:00 +0000",
      "description": "3rd Party plugin을 사용하여 jmh를 쉽게 사용해봅니다.\n",
      "content": "\n  서문\n  JMH Gradle Plugin    \n      사용\n      어떤 플러그인 버전을 사용할 것인가?\n      구성\n      Gradle 태스크\n      구성 옵션\n      JMH 옵션 매핑\n      프로젝트 파일에 대한 종속성\n      Shadow Plugin과 함께 JMH Gradle Plugin사용\n      중복 종속성 및 클래스\n      알려진 문제\n    \n  \n\n\n\n\n서문\n\n\n  📜원본 깃허브 레파지토리\n\n\n설정은 원 저작자 문서에도 잘 나와 있습니다만, 샘플 코드를 게시합니다.\n\n이 글의 깃허브는 📜 여기 를 참고해주세요.\n\n제가 구성한 빌드 스크립트는 다음과 같습니다.\n\n플러그인을 적용하고, 플러그인이 제공하는 jmh 태스크를 실행시키면 @Benchmark가 적용된 코드들에 대한 벤치마크가 진행됩니다.\n\n\n  주의! @Benchmark가 적용된 코드는 반드시 src/jmh/java에 위치해야 합니다.\n\n\n\n\n// file: 'build.gradle'\nplugins {\n    id 'java'\n    id 'me.champeau.jmh' version '0.6.6'\n}\n\njava {\n    toolchain {\n        languageVersion = JavaLanguageVersion.of(11)\n    }\n}\n\ngroup 'io.shirohoo'\n\nrepositories {\n    mavenCentral()\n}\n\njmh {\n    fork = 1\n    warmupIterations = 1\n    iterations = 1\n}\n\ndependencies {\n    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.7.0'\n    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.7.0'\n}\n\ntest {\n    useJUnitPlatform()\n}\n\n\n\n\n이 플러그인을 사용할 때 다음과 같은 문제를 마주칠 수 있습니다.\n\n\n  0.6.0 이전 버전의 플러그인을 사용 할 경우 디렉토리 구조를 문서에 나와있는 것 처럼 직접 설정해야 합니다. 단, 0.6.0 이후 버전의 플러그인을 사용 할 경우 디렉토리 구조가 자동적으로 설정됩니다.\n  Preferences &gt; Build, Execution, Deployment &gt; Compiler &gt; Annotation Processors 에 Enable annotation processing가 체크되어 있지 않다면 체크하십시오.\n  벤치마크할 소스는 src/jmh/java 하위에 존재해야 합니다.\n  인텔리제이의 Gradle 탭에서 벤치마크 수행 되지 않을 경우 터미널에서 ./gradlew jmh 혹은 gradle jmh를 입력하여 수행해보세요.\n  이 문서를 작성한 작성자는 0.6.6 버전의 플러그인을 사용했으며, 벤치마크 수행 시 결과는 build/results/jmh/results.txt에 기록됐습니다.\n\n\n아래 문서는 melix/jmh-gradle-plugin 의 README.md를 번역한 문서입니다.\n\n\n\nJMH Gradle Plugin\n\n이 플러그인은 JMH micro-benchmarking framework 를 Gradle과 통합합니다.\n\n사용\n\n// build.gradle\nplugins {\n  id 'me.champeau.jmh' version '0.6.6'\n}\n\n\n|경고|0.6.0 이전 버전의 플러그인 id는 me.champeau.gradle.jmh를 사용했습니다.|\n|—|—|\n\n샘플 코드는 여기 에 있습니다.\n\n어떤 플러그인 버전을 사용할 것인가?\n\n플러그인 0.6+ 이상은 Gradle 6.8+을 필요로 합니다.\n\n\n  \n    \n      Gradle\n      Plugin\n    \n  \n  \n    \n      7.0\n      0.5.3\n    \n    \n      5.5\n      0.5.0\n    \n    \n      5.1\n      0.4.8\n    \n    \n      4.9\n      0.4.7(지연 작업 API 이점)\n    \n    \n      4.8\n      0.4.5\n    \n    \n      4.7\n      0.4.5\n    \n    \n      4.6\n      0.4.5\n    \n    \n      4.5\n      0.4.5\n    \n    \n      4.4\n      0.4.5\n    \n    \n      4.3\n      0.4.5\n    \n    \n      4.2\n      0.4.4\n    \n    \n      4.1\n      0.4.4\n    \n  \n\n\n구성\n\n플러그인을 사용하면 특정 구성 덕분에 기존 프로젝트에 쉽게 통합할 수 있습니다. 특히 벤치마크 소스 파일은 src/jmh디렉토리 에서 찾을 수 있습니다.\n\nsrc/jmh\n     |- java       : java sources for benchmarks\n     |- resources  : resources for benchmarks\n\n\n이 플러그인은 타사 라이브러리에 의존해야 할 경우 필요한 jmh구성을 생성합니다 . 예를 들어 commons-io를 사용하려는 경우 다음과 같이 종속성을 추가할 수 있습니다.\n\n// build.gradle\ndependencies {\n    jmh 'commons-io:commons-io:2.4'\n}\n\n\n플러그인은 JMH 1.29를 사용합니다. dependencies블록의 버전을 변경하기만 하면 버전을 업그레이드할 수 있습니다 .\n\n// build.gradle\ndependencies {\n    jmh 'org.openjdk.jmh:jmh-core:0.9'\n    jmh 'org.openjdk.jmh:jmh-generator-annprocess:0.9'\n}\n\n\nGradle 태스크\n\n이 플러그인은 프로젝트에 다음과 같은 몇가지 Gradle 태스크를 추가합니다.\n\n\n  jmhClasses : 저수준의 벤치마크 코드를 컴파일합니다.\n  jmhRunBytecodeGenerator : 저수준의 벤치마크 코드에 대해 바이트코드 생성기를 실행하고 실제 벤치마크를 생성합니다.\n  jmhCompileGeneratedClasses : 생성된 벤치마크를 컴파일합니다.\n  jmhJar : JMH 런타임과 컴파일된 벤치마크 클래스를 포함하는 JMH jar를 빌드합니다.\n  jmh : 벤치마크를 실행합니다.\n\n\njmh 태스크는 메인 태스크이며 다른 태스크에 의존하므로 일반적으로 이 태스크를 실행하는 것으로 충분합니다.\n\ngradle jmh\n\n\n구성 옵션\n\n기본적으로 모든 벤치마크가 실행되고 결과는 $buildDir/reports/jmh에 생성됩니다.\n\n그러나 jmh구성 블록 덕분에 다양한 옵션을 변경할 수 있습니다.\n\nincludes를 제외한 모든 옵션은 JMH 기본 값으로 설정됩니다.\n\n// build.gradle\njmh {\n   includes = ['some regular expression'] // 실행할 벤치마크에 대한 패턴(정규 표현식) 포함.\n   excludes = ['some regular expression'] // 실행할 벤치마크에 대한 제외 패턴(정규 표현식).\n   iterations = 10 // 측정을 반복 수행할 횟수.\n   benchmarkMode = ['thrpt','ss'] // 벤치마크 모드. 사용 가능한 모드: [Throughputthrpt, AverageTimeavgt, SampleTimesample, SingleShotTimess, Allall]\n   batchSize = 1 // 배치 크기: 작업당 벤치마크 메서드 호출 수. (일부 벤치마크 모드는 이 설정을 무시할 수 있음)\n   fork = 2 // 단일 벤치마크를 포크할 횟수입니다. 포크를 완전히 비활성화하려면 0을 사용.\n   failOnError = false // 벤치마크에서 복구할 수 없는 오류가 발생한 경우 JMH가 즉시 실패해야 합니까?\n   forceGC = false // JMH가 반복 간에 GC를 강제해야 합니까?\n   jvm = 'myjvm' // 분기할 때 사용할 사용자 정의 JVM.\n   jvmArgs = ['Custom JVM args to use when forking.']\n   jvmArgsAppend = ['Custom JVM args to use when forking (append these)']\n   jvmArgsPrepend =[ 'Custom JVM args to use when forking (prepend these)']\n   humanOutputFile = project.file(\"${project.buildDir}/reports/jmh/human.txt\") // 사람이 읽을 수 있는 출력 파일.\n   resultsFile = project.file(\"${project.buildDir}/reports/jmh/results.txt\") // 결과 파일.\n   operationsPerInvocation = 10 // 호출당 작업.\n   benchmarkParameters =  [:] // 벤치마크 매개변수.\n   profilers = [] // 프로파일러를 사용하여 추가 데이터를 수집합니다. 지원되는 프로파일러: [cl, comp, gc, stack, perf, perfnorm, perfasm, xperf, xperfasm, hs_cl, hs_comp, hs_gc, hs_rt, hs_thr, async]\n   timeOnIteration = '1s' // 각 측정 반복에 소요되는 시간.\n   resultFormat = 'CSV' // 결과 형식 유형(CSV, JSON, NONE, SCSV, TEXT 중 하나)\n   synchronizeIterations = false // 반복을 동기화하시겠습니까?\n   threads = 4 // 실행할 작업자 스레드 수.\n   threadGroups = [2,3,4] // 비대칭 벤치마크에 대한 스레드 그룹 분포를 재정의.\n   timeout = '1s' // 벤치마크 반복 수행 시 타임아웃.\n   timeUnit = 'ms' // 출력할 시간 단위. 사용 가능한 시간 단위: [m, s, ms, us, ns].\n   verbosity = 'NORMAL' // 자세한 정보 표시 모드. 사용 가능한 모드: [SILENT, NORMAL, EXTRA]\n   warmup = '1s' // 각 워밍업 반복에 소요되는 시간. \n   warmupBatchSize = 10 // 워밍업 배치 크기: 작업당 벤치마크 메서드 호출 수. \n   warmupForks = 0 // 단일 벤치마크에 대해 몇 개의 웜업 포크를 만들지. 0은 워밍업 포크를 비활성화.\n   warmupIterations = 1 // 수행할 워밍업 반복 횟수.\n   warmupMode = 'INDI' // 선택한 벤치마크를 웜업할 워밍업 모드: [INDI, BULK, BULK_INDI].\n   warmupBenchmarks = ['.*Warmup'] // 이미 선택한 것 외에 실행에 포함할 워밍업 벤치마크. JMH는 이러한 벤치마크를 측정하지 않고 워밍업에만 사용합니다.\n\n   zip64 = true // 더 큰 아카이브에 ZIP64 형식을 사용\n   jmhVersion = '1.29' // JMH 버전 지정\n   includeTests = true // 테스트 소스를 포함하여 JMH jar를 생성할 수 있습니다. 즉, 벤치마크가 테스트 클래스에 따라 달라질 때 사용합니다.\n   duplicateClassesStrategy = DuplicatesStrategy.FAIL // fat jar를 생성하는 동안(즉, jmhJar 태스크를 실행하는 동안) 중복 클래스가 발생할 때 적용할 전략\n}\n\n\nJMH 옵션 매핑\n\n다음 표에서는 JMH의 명령줄 옵션과 플러그인의 확장 속성 간의 매핑을 설명합니다.\n\n\n  \n    \n      JMH 옵션\n      의미\n    \n  \n  \n    \n      -bm \n      benchmarkMode\n    \n    \n      -bs \n      batchSize\n    \n    \n      -e &lt;regexp+&gt;\n      exclude\n    \n    \n      -f \n      fork\n    \n    \n      -foe \n      failOnError\n    \n    \n      -gc \n      forceGC\n    \n    \n      -i \n      iterations\n    \n    \n      -jvm \n      jvm\n    \n    \n      -jvmArgs \n      jvmArgs\n    \n    \n      -jvmArgsAppend \n      jvmArgsAppend\n    \n    \n      -jvmArgsPrepend \n      jvmArgsPrepend\n    \n    \n      -o \n      humanOutputFile\n    \n    \n      -opi \n      operationsPerInvocation\n    \n    \n      -p &lt;param={v,}*&gt;\n      benchmarkParameters?\n    \n    \n      -prof \n      profilers\n    \n    \n      -r \n      timeOnIteration\n    \n    \n      -rf \n      resultFormat\n    \n    \n      -rff \n      resultsFile\n    \n    \n      -si \n      synchronizeIterations\n    \n    \n      -t \n      threads\n    \n    \n      -tg &lt;int+&gt;\n      threadGroups\n    \n    \n      -to \n      timeout\n    \n    \n      -tu \n      timeUnit\n    \n    \n      -v \n      verbosity\n    \n    \n      -w \n      warmup\n    \n    \n      -wbs \n      warmupBatchSize\n    \n    \n      -wf \n      warmupForks\n    \n    \n      -wi \n      warmupIterations\n    \n    \n      -wm \n      warmupMode\n    \n    \n      -wmb &lt;regexp+&gt;\n      warmupBenchmarks\n    \n  \n\n\n프로젝트 파일에 대한 종속성\n\njmh 플러그인을 사용하면 별도의 프로젝트를 만들지 않고도 기존 소스를 쉽게 테스트할 수 있습니다. 따라서 src/main/java 대신 src/jmh/java에 벤치마크 소스 파일을 넣어야 합니다.\n\n즉, 기본적으로 jmh 태스크는 main(production) 소스 세트에 따라 달라집니다.\n\nShadow Plugin과 함께 JMH Gradle Plugin사용\n\n선택적으로 Shadow Plugin을 사용하여 실제 JMH jar 생성을 수행할 수 있습니다.\n\nJMH jar용 Shadow Plugin 구성은 jmhJar 블록을 통해 수행됩니다. 예:\n\n// build.gradle\njmhJar {\n    append('META-INF/spring.handlers')\n    append('META-INF/spring.schemas')\n    exclude 'LICENSE'\n}\n\n\n중복 종속성 및 클래스\n\n이 플러그인은 jmh, runtime 및 testRuntime 구성의 일부로 정의된 모든 종속성을 jmhJar 태스크를 실행할 때 생성되는 fat jar에 단일 집합으로 병합합니다.\n\n이렇게 하면 생성된 jar에 중복되는 종속성이 생기지 않습니다.\n\n또한 플러그인은 fat jar를 만드는 동안 duplicateClassStrategy 확장 속성을 통해 정의된 DuplicatesStrategy를 모든 클래스에 적용합니다.\n\n기본적으로 이 속성은 DuplicatesStrategy.FAIL로 설정됩니다. 중복 클래스가 감지되면 태스크가 실패됩니다.\n\njmh 블록을 통해 duplicateClassStrategy 속성을 구성하여 이 동작을 변경할 수 있습니다\n\n// build.gradle\njmh {\n  duplicateClassesStrategy = DuplicatesStrategy.WARN\n}\n\n\n그러나 기본값에 문제가 발생할 경우 프로젝트의 클래스 패스나 소스에 중복 클래스가 포함되어 있음을 의미하므로 fat jar가 생성될 때 사용할 클래스를 예측할 수 없습니다.\n\nShadow Plugin 기능을 사용하는 클래스 이외의 중복 파일을 처리하려면 Shadow Plugin과 함께 JMH Gradle Plugin 사용 을 참조하십시오 .\n\n알려진 문제\n\n벤치마크가 Groovy로 작성된 경우 Gradle과 함께 제공된 것과 동일한 버전의 Groovy를 사용해야 합니다.\n\n이는 향후 수정될 Gradle Worker API의 한계입니다.\n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2021-09-06-jmh-gradle/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "이펙티브 자바 1회독 완료",
      "date": "2021-09-06 00:00:00 +0000",
      "description": "개발일기\n",
      "content": "\n\n\n오늘 드디어 이펙티브 자바를 완독했다.\n\n원래 평소에 독서를 많이하는 편이여서, 기술서적이 아닌 경우에는 하루에 한권꼴로 읽을 정도로 독서속도가 빠른편이다.\n\n개발 서적들 같은 경우는 이보다 느리긴했는데, 한달내내 책 한권을 붙들고 있었던 적은 정말 몇년만인지 모르겠다는 생각마저 든다…\n\n\n\n우선 이펙티브 자바는 내용이 너무 어려웠다.\n\n그래서 처음 이펙티브 자바를 보려고 했던 시점에는 아예 이해조차 잘 되질 않아서 나중을 기약했었다.\n\n자바에 대해 어느정도 이해가 생겼다고 자부하는 지금와서 다시 보기 시작한 것인데, 그럼에도 불구하고 1회독을 하는데 한달이나 걸렸다.\n\n아이템이 총 90개인가 나오는데, 자바 개발자 입장에서 내용 하나하나가 너무 심오하고 유의미한 내용들이여서, 아이템 하나를 보더라도 여러번 곱씹게 되는 그런 책이었다.\n\n겨우 책한권 1회독하고 이렇게 뿌듯하게 느껴진다는게 참 묘한 기분마저 든다.\n\n\n\n1회독 한 시점에서 머릿속에서 잊히지 않고 남아있는 내용이 몇가지 되지 않는데 그 내용들을 나열해보자면.\n\n\n  정적 팩토리 메서드\n  Enum 사용법\n  방어적 복사\n  람다와 스트림, 표준 함수형 라이브러리\n  예외처리\n\n\n정도가 되는 것 같다.\n\n그 외에 독학하면서 학습했던 부분들도 상당수 나왔어서 무릎을 쳐가면서 본 내용도 상당히 됐던 것 같다.\n\n대충 “아~ 이게 그런 의미였구나 !” 정도의 느낌이었던 것 같다.\n\n\n\n이펙티브 자바를 볼까 말까 고민하고 있는데 이 글을 보신분이 계신다면, 블로그 쥔장은 다음과 같은 경우라면 독서를 추천드린다.\n\n\n  자바로 개발을 반년이상 했다.\n  스스로 생각하기에 자바의 정석과 같은 자바 기본 서적의 내용 중 최소 약 70% 정도를 숙달했다고 여겨진다.\n  자바의 고급 기법과 꿀팁(?)들에 대해 목이 마르다.\n\n\n\n\n아무튼 개발 공부를 시작하고 읽었던 도서 중 수위에 꼽힐만한 명저서였고, 앞으로도 최소 네번이상은 더 봐야 할거라고 생각되는 도서였다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-09-06-diary-26/"
    },{
      "image": "/assets/img/spring/spring-mvc/spring-mvc-logo.png",
      "title": "HTTP 통신내역을 기록하기",
      "date": "2021-09-06 00:00:00 +0000",
      "description": "Spring MVC의 Filter와 Interceptor를 활용한 로깅\n",
      "content": "\n  🕋 서론\n  ⚙ 구현    \n      🛠 ServletWrappingFilter\n      🛠 HttpLogInterceptor\n      🛠 HttpLog\n      🛠 HttpLogQueryRepository\n      🛠 InterceptorConfig\n    \n  \n  👏 결과\n\n\n이 글에서는 Spring MVC 중 Filter와 Interceptor에 관한 내용을 다룹니다.\n\n\n\n🕋 서론\n\n명제 - “모든 HTTP 통신내역을 어디서 기록해야 가장 효율적일까?” 에 대해 어떻게 생각하시나요?\n\n저는 Interceptor라고 생각합니다.\n\nFilter는 Spring과 별개의 Context이기 때문에 세밀한 컨트롤이 매우 힘듭니다.\n\n따라서 Spring Context에 들어오는 Interceptor가 가장 적당하다고 봤습니다.\n\n\n\n\n\n\n\nInterceptor에서 모든 HTTP 통신내역을 기록하기 위해 우선 Filter를 건드려야 합니다.\n\n우리 프로젝트는 현재 Spring MVC를 사용하고 있는데, 이 때 WAS는 Tomcat이 기동됩니다.\n\nEmbedded Tomcat의 버전은 Spring Boot 버전에 따라 다르지만 대체로 8.5 이상이기 때문에 최소 servlet 3.1을 제공합니다.\n\n그리고 Filter는 Servlet의 영역이기 때문에 Tomcat에 종속적입니다.\n\nTomcat의 Filter는 데이터를 한번 읽어버리면 데이터가 유실되는데, 이 문제를 해결하기 위해 Spring MVC에서 확장을 해 둔 라이브러리가 있습니다.\n\n\n\n\n  📜 ContentCachingRequestWrapper\n\n\n\n  📜 ContentCachingResponseWrapper\n\n\n\n\n그리고 HTTP 요청 &amp; 응답에서 데이터를 딱 한번만 추출하여 기록하면 되기 때문에 역시 Spring MVC에서 확장한 📜 OncePerRequestFilter 를 사용합니다.\n\n\n\nOncePerRequestFilter에 대한 자세한 내용은 아래 글을 확인 해 주세요.\n\n\n\n\n  📜 What is OncePerRequestFilter?\n\n\n\n\n⚙ 구현\n\n플로우는 다음과 같습니다.\n\n\n\n\n  사용자가 서버에 요청을 보냅니다.\n  해당 요청을 Filter에서 낚아 채 캐시합니다. (👏 데이터 유실 방지)\n  Filter는 요청을 Interceptor로 넘겨줍니다.\n  Interceptor는 데이터를 다듬고 Database에 기록합니다.\n\n\n\n\n🛠 ServletWrappingFilter\n\nServletWrappingFilter는 로깅한 데이터가 유실되지 않고 정상적으로 사용자에게 응답될 수 있도록 해 줄겁니다.\n\n\n\n// OncePerRequestFilter를 상속하여 데이터를 캐시 해 줄 Filter를 만듭니다.\n@Component\npublic class ServletWrappingFilter extends OncePerRequestFilter {\n    @Override\n    protected void doFilterInternal(final HttpServletRequest request, final HttpServletResponse response, final FilterChain filterChain) throws IOException, ServletException {\n        final String contentType = request.getHeader(\"Content-Type\");\n\n        // Content-Type이 비었거나, 데이터가 사진, 음악, 동영상 등의 컨텐츠 일 경우 기록하지 않습니다.\n        if (Objects.nonNull(contentType) &amp;&amp; contentType.toLowerCase().contains(\"multipart/form-data\")) {\n            filterChain.doFilter(request, response);\n        }\n  \n        // 위 조건을 제외한 모든 데이터는 데이터베이스에 기록하기 위해 캐시합니다.\n        else {\n            final ContentCachingRequestWrapper wrappingRequest = new ContentCachingRequestWrapper(request);\n            final ContentCachingResponseWrapper wrappingResponse = new ContentCachingResponseWrapper(response);\n            filterChain.doFilter(wrappingRequest, wrappingResponse);\n\n            // 데이터 유실 방지를 위해 응답을 복사해둡니다.\n            wrappingResponse.copyBodyToResponse();\n        }\n    }\n}\n\n\n\n\n🛠 HttpLogInterceptor\n\nHttpLogInterceptor는 데이터를 섬세하게 정제하여 데이터베이스에 기록합니다.\n\n\n\n@Slf4j\n@Component\n@RequiredArgsConstructor\npublic class HttpLogInterceptor implements HandlerInterceptor {\n    // 데이터를 이쁘게 가공하기 위해 주입받습니다.\n    private final ObjectMapper objectMapper;\n\n    // 데이터를 데이터베이스에 저장하기 위해 주입받습니다.\n    private final HttpLogRepository httpLogRepository;\n\n    // HandlerInterceptor를 구현하면 preHandler, postHandelr, afterCompletion 세 가지의 메서드가 있습니다.\n    // 저는 afterCompletion 를 사용하겠습니다. 자세한 사항은 세가지 메서드에 대해 구글링 !\n    @Override\n    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) {\n        logging(request, response);\n    }\n\n    private void logging(HttpServletRequest request, HttpServletResponse response) {\n        // 요청이 Interceptor에 넘어왔다는 것은, Spring Security Filter Chain을 지나왔음을 뜻합니다.\n        // Spring Security는 유저 정보에 대한 것들을 따로 wrapping하기 때문에, 이 부분과의 충돌을 방지하기 위한 조건을 추가합니다.\n        // 이 조건이 없다면, 유저 정보에 대해 두 번 wrapping하게 되므로 문제가 발생할 수 있습니다.\n        if (request.getClass().getName().contains(\"SecurityContextHolderAwareRequestWrapper\")) {\n            return;\n        }\n\n        // 모든 조건을 만족하면 데이터베이스에 기록합니다.\n        httpLogRepository.save(HttpLog.of(request, response, objectMapper));\n    }\n}\n\n\n\n\n🛠 HttpLog\n\n사용자의 요청과 응답에 대해 디테일한 데이터 정제작업을 합니다.\n\n어떤 데이터를 기록하고, 어떤 데이터를 기록하지 않을지.\n\n데이터를 어떤 형태로 저장할 것인지 등의 판단과 책임을 갖습니다.\n\n\n\n@Slf4j\n@Entity\n@Getter\n@NoArgsConstructor(access = AccessLevel.PROTECTED)\npublic class HttpLog extends AbstractEntity {\n    private String clientIp; // 데이터 베이스에 기록 할 사용자의 IP주소\n    private String httpMethod; // 사용자가 어떤 요청을 보냈는지 (Get, Post, Put, Delete 등)\n    private String requestUri; // 사용자가 어떤 URI로 요청을 보냈는지\n    private String requestBody; // 사용자가 어떤 내용의 요청을 보냈는지\n    private String responseBody; // 사용자가 어떤 응답을 받았는지\n    private String token; // 사용자가 요청을 보내며 사용했던 토큰\n    private int httpStatusCode; // 기록된 HTTP 통신의 최종 상태 코드\n\n    @Builder(access = AccessLevel.PUBLIC)\n    private HttpLog(final String clientIp, final String httpMethod, final String requestUri, final String requestBody, final String responseBody, final String token, final Integer httpStatusCode) {\n        this.clientIp = clientIp;\n        this.httpMethod = httpMethod;\n        this.requestUri = requestUri;\n        this.requestBody = requestBody;\n        this.responseBody = responseBody;\n        this.token = token;\n        this.httpStatusCode = httpStatusCode;\n    }\n\n    // 데이터를 직접적으로 넣어주는데, 응답 바디가 없을 경우를 의미합니다.\n    // 점층적 생성자 패턴을 응용하여 오버로딩합니다.\n    public static HttpLog of(final String httpMethod, final String uri, final String requestBody, final String ip, final String token, final Integer httpStatusCode) {\n        return of(httpMethod, uri, requestBody, null, ip, token, httpStatusCode);\n    }\n\n    // 모든 데이터가 직접적으로 넘어오는 경우입니다. 즉시 생성자를 호출하여 객체를 초기화합니다.\n    public static HttpLog of(final String httpMethod, final String uri, final String requestBody, final String responseBody, final String ip, final String token, final Integer httpStatusCode) {\n        return new HttpLog(ip, httpMethod, uri, requestBody, responseBody, token, httpStatusCode);\n    }\n\n    // 생성자로 HTTP 요청과 응답 객체가 넘어오는 경우입니다.\n    // 이 경우는 Interceptor에서 호출한 경우를 의미합니다.\n    public static HttpLog of(final HttpServletRequest request, final HttpServletResponse response, final ObjectMapper objectMapper) {\n        return getResponseBody(response, objectMapper)\n                .map(responseBody -&gt; HttpLog.builder()\n                        .httpMethod(request.getMethod())\n                        .requestUri(request.getRequestURI())\n                        .requestBody(getRequestBody(request, objectMapper))\n                        .responseBody(responseBody.toString())\n                        .clientIp(getClientIp(request))\n                        .token(getToken(request))\n                        .httpStatusCode(response.getStatus())\n                        .build()\n                )\n                .orElse(HttpLog.builder()\n                        .httpMethod(request.getMethod())\n                        .requestUri(request.getRequestURI())\n                        .requestBody(getRequestBody(request, objectMapper))\n                        .clientIp(getClientIp(request))\n                        .token(getToken(request))\n                        .httpStatusCode(response.getStatus())\n                        .build());\n    }\n\n    // 응답 바디를 읽을 수 있는 응답일 경우 응답 바디를 읽고 읽은 데이터를 정제하여 반환합니다.\n    // 만약 읽을 수 없는 응답이라면 빈 Optional을 반환합니다.\n    private static Optional&lt;JsonNode&gt; getResponseBody(final HttpServletResponse response, final ObjectMapper objectMapper) {\n        final ContentCachingResponseWrapper cachingResponse = (ContentCachingResponseWrapper) response;\n        if (isReadableResponse(cachingResponse)) {\n            return readTree(objectMapper, cachingResponse);\n        }\n        return Optional.empty();\n    }\n\n    private static boolean isReadableResponse(final ContentCachingResponseWrapper cachingResponse) {\n        return Objects.nonNull(cachingResponse.getContentType()) &amp;&amp; isJson(cachingResponse.getContentType()) &amp;&amp; cachingResponse.getContentAsByteArray().length != 0;\n    }\n\n    private static Optional&lt;JsonNode&gt; readTree(final ObjectMapper objectMapper, final ContentCachingResponseWrapper cachingResponse) {\n        try {\n            return Optional.of(objectMapper.readTree(cachingResponse.getContentAsByteArray()));\n        } catch (IOException e) {\n            log.warn(\"ContentCachingResponseWrapper parse error! returns null. info : {}\", e.getMessage());\n            return Optional.empty();\n        }\n    }\n\n    // 요청 바디를 읽을 수 있는 요청일 경우 요청 바디를 읽고 읽은 데이터를 정제하여 반환합니다.\n    // 만약 읽을 수 없는 요청이라면 공백을 반환합니다.\n    private static String getRequestBody(final HttpServletRequest request, final ObjectMapper objectMapper) {\n        final ContentCachingRequestWrapper cachingRequest = (ContentCachingRequestWrapper) request;\n        if (isReadableRequest(cachingRequest)) {\n            return readTree(objectMapper, cachingRequest);\n        }\n        return \"\";\n    }\n\n    private static boolean isReadableRequest(final ContentCachingRequestWrapper cachingRequest) {\n        return Objects.nonNull(cachingRequest.getContentType()) &amp;&amp; isJson(cachingRequest.getContentType()) &amp;&amp; cachingRequest.getContentAsByteArray().length != 0;\n    }\n\n    private static boolean isJson(final String contentType) {\n        return contentType.contains(\"application/json\");\n    }\n\n    private static String readTree(final ObjectMapper objectMapper, final ContentCachingRequestWrapper cachingRequest) {\n        try {\n            final JsonNode jsonNode = objectMapper.readTree(cachingRequest.getContentAsByteArray());\n            removeSecurityInformation(jsonNode);\n            return jsonNode.toString();\n        }\n        catch (IOException e) {\n            log.warn(\"ContentCachingRequestWrapper parse error! returns null. info : {}\", e.getMessage());\n            return \"\";\n        }\n    }\n\n    // 비밀번호는 데이터베이스에 대놓고 저장하면 안되는 민감정보이기 때문에 제외합니다.\n    // 이런 데이터는 여러가지가 존재할 수 있기 때문에, 이 메서드는 필요하면 확장될 수도 있습니다.\n    private static void removeSecurityInformation(final JsonNode jsonNode) {\n        final Iterator&lt;Map.Entry&lt;String, JsonNode&gt;&gt; fields = jsonNode.fields();\n        while (fields.hasNext()) {\n            if (fields.next().toString().contains(\"password\")) {\n                fields.remove();\n            }\n        }\n    }\n\n    // 사용자의 IP주소를 얻기위한 필터체인입니다.\n    // 많은 경우의 수를 따져 요청 객체에서 사용자의 올바른 IP주소를 획득합니다.\n    private static String getClientIp(final HttpServletRequest request) {\n        String clientIp = request.getHeader(\"X-Forwarded-For\");\n        if (!StringUtils.hasLength(clientIp) || \"unknown\".equalsIgnoreCase(clientIp)) {\n            clientIp = request.getHeader(\"Proxy-Client-IP\");\n        }\n        if (!StringUtils.hasLength(clientIp) || \"unknown\".equalsIgnoreCase(clientIp)) {\n            clientIp = request.getHeader(\"WL-Proxy-Client-IP\");\n        }\n        if (!StringUtils.hasLength(clientIp) || \"unknown\".equalsIgnoreCase(clientIp)) {\n            clientIp = request.getHeader(\"HTTP_CLIENT_IP\");\n        }\n        if (!StringUtils.hasLength(clientIp) || \"unknown\".equalsIgnoreCase(clientIp)) {\n            clientIp = request.getHeader(\"HTTP_X_FORWARDED_FOR\");\n        }\n        if (!StringUtils.hasLength(clientIp) || \"unknown\".equalsIgnoreCase(clientIp)) {\n            clientIp = request.getRemoteAddr();\n        }\n        return clientIp;\n    }\n\n    // 사용자의 요청 객체에 토큰이 있을 경우 토큰을 획득합니다.\n    private static String getToken(final HttpServletRequest request) {\n        return request.getHeader(\"Authorization\");\n    }\n}\n\n\n\n\n🛠 HttpLogQueryRepository\n\n기왕 만드는 기능에 당일 사용자의 수와, 누적 사용자의 수를 같이 얻어낼 수 있는 기능을 추가하면 일석이조라고 판단해 추가합니다.\n\n기록된 HTTP 통신내역에서 특정 날짜로 필터링하고, 해당 날짜에서 중복된 IP를 모두 제거하면 당일 사용자 수(DAU)가 나옵니다.\n\n그리고 전체 HTTP 통신내역을 모두 검색하고, 여기서 중복된 IP주소를 제거하면 누적 사용자 수가 나옵니다.\n\n\n\npublic interface HttpLogQueryRepository {\n    Long searchDau();\n    Long searchTotalVisitors();\n}\n\n@RequiredArgsConstructor\npublic class HttpLogQueryRepositoryImpl implements HttpLogQueryRepository {\n    private final JPAQueryFactory queryFactory;\n\n    @Override\n    @Transactional(readOnly = true) // 읽기 전용이므로 flush가 필요없습니다.\n    public Long searchDau() {\n        return queryFactory\n                .select(httpLog.clientIp.countDistinct())\n                .from(httpLog)\n                .where(httpLog.regDate.gt(onTime()))\n                .fetchOne();\n\n    }\n\n    @Override \n    @Transactional(readOnly = true) // 읽기 전용이므로 flush가 필요없습니다.\n    public Long searchTotalVisitors() {\n        return queryFactory\n                .select(httpLog.clientIp.countDistinct())\n                .from(httpLog)\n                .groupBy(date(httpLog.regDate))\n                .fetch()\n                .stream()\n                .reduce(0L, Long::sum);\n    }\n\n    private StringTemplate date(DateTimePath regDate) {\n        return stringTemplate(\"date({0})\", regDate);\n    }\n\n    private LocalDateTime onTime() {\n        return LocalDateTime.of(LocalDateTime.now().getYear(),\n                LocalDateTime.now().getMonth(),\n                LocalDateTime.now().getDayOfMonth(),\n                0, 0, 0);\n    }\n}\n\n\n\n\n🛠 InterceptorConfig\n\n마지막으로 작성된 Interceptor를 Spring MVC에서 사용하기 위해 등록해줍니다.\n\n@Configuration\n@RequiredArgsConstructor\npublic class InterceptorConfig implements WebMvcConfigurer {\n    private final HttpLogInterceptor httpLogInterceptor;\n\n    @Override\n    public void addResourceHandlers(final ResourceHandlerRegistry registry) {\n        // 효율적인 로딩을 위해 정적 리소스를 캐싱하고 제공합니다.\n        registry\n                .addResourceHandler(\"/resources/**\")\n                .addResourceLocations(\"/resources/\")\n                .setCachePeriod(86400) // 단위는 초입니다. 24시간을 의미합니다.\n                .resourceChain(true)\n                .addResolver(new PathResourceResolver());\n    }\n\n    @Override\n    public void addInterceptors(final InterceptorRegistry registry) {\n        registry\n                .addInterceptor(httpLogInterceptor) // httpLogInterceptor는 \n                .excludePathPatterns(\"/docs/**\", \"images/**\", \"/js/**\", \"/css/**\") // 이 위치에 대한 요청,응답은 기록하지 않습니다.\n                .addPathPatterns(\"/**\"); // 위의 경로를 제외한 모든 요청, 응답을 기록합니다.\n    }\n}\n\n\n\n\n👏 결과\n\n\n\n\n\n\n\n하루동안 로봇인지 뭔지 모를것들의 요청기록들이 상당히 쌓여있는 모습입니다.\n\n웹에서 활동하는 정체모를 것들이 굉장히 많다는 생각이 드네요 🤷‍♂️\n\n\n",
      "categories": ["spring","spring-mvc"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-mvc/2021-09-06-http-logging/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "JDK 17, Spring 6, Spring Boot 3",
      "date": "2021-09-09 00:00:00 +0000",
      "description": "2021년 9월, Java 에코 시스템에 뜬 몇가지 뉴스들\n",
      "content": "\n  ✔ Java 17 LTS\n  ✔ Spring 6, Spring Boot 3\n\n\n\n\n✔ Java 17 LTS\n\n\n\n다음 자바 LTS는 17이고 정식 발표일은 9월 15일로 알고있었는데, 이 글을 작성하는 현재(2021-09-09) 기준으로 인텔리제이에 JDK 17이 들어왔습니다.\n\n자바의 버전별 변천사는 하기 내용들을 참고해주세요.\n\n\n  최범균님의 유튜브 정리\n  나무위키: Java\n  JEP(JDK Enhancement Proposal)\n\n\n\n\n✔ Spring 6, Spring Boot 3\n\n\n\n스프링 공홈에 차세대 스프링에 대한 아티클이 떴습니다.\n\n\n  📜 A Java 17 and Jakarta EE 9 baseline for Spring Framework 6\n\n\n2022년 4분기에 Spring 6과 Spring Boot 3이 출시 될 예정이며, 이 프레임 워크는 최소 Java 17/Tomcat 10/Jetty 11(Jakarta EE 9 compatibility)를 필요로 한다고 합니다.\n\n현재 추세를 보면 Spring Boot 2+ 와 Java 8혹은 Java 11이 주력으로 쓰이고 있습니다. 이 중 Java 8과 Java 11의 비율이 약 7:3정도로 보이는데, Spring Boot 3+이 나오는 시점부터는 Java 11을 건너뛰고 Java 17이 대세가 되지 않을까 조심스레 예상해봅니다.\n\n참 하루하루 기술발전이 눈부시다는 생각만 드는 하루입니다. (그만큼 배워야 할것도 많아지는…😭)\n\n저도 회사에서 미리미리 대비를 해야겠다는 생각이 드네요.\n\n\n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2021-09-09-jdk-17-spring-6/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Spring을 사용하는 이유?",
      "date": "2021-09-13 00:00:00 +0000",
      "description": "개발일기\n",
      "content": "\n  나는 왜 자바와 스프링을 사용하고 있는가 ?\n  스프링이 뭘까 ?\n  스프링의 장단점 ?\n  스프링이 없어진다면 ?\n\n\n\n\n나는 왜 자바와 스프링을 사용하고 있는가 ?\n\n\n\n오늘 문득 이런 생각이 들었습니다.\n\n결론은 간단하게 나왔습니다.\n\n1분도 채 안걸린 것 같네요.\n\n제가 백엔드 개발자로서의 커리어를 시작 할 당시, 시장조사 결과 자바와 스프링으로 시작하는게 진입장벽이 낮을것이다. 라는 결론이 나왔기 때문입니다.\n\n따라서 시작을 자바와 스프링으로 했고, 그게 이어지고 있는 것이 전부입니다.\n\n\n\n이쯤에서 이런 생각이 듭니다.\n\n\n\n“그럼 스프링이 대체 뭘까?”\n\n“나는 자바와 스프링없이는 아무것도 아닌 개발자인걸까?”\n\n\n\n이러한 자문에 결론을 내기 위해 스프링이 뭔지에 대해 대충이나마 정리해봤습니다.\n\n\n\n스프링이 뭘까 ?\n\n\n\n스프링(Spring)의 의미는 자바 개발자들에게 겨울이 끝나고 봄이 왔다는 의미이며, 스프링 부트(Spring Boot)의 경우는 봄에서 조금 더 봄이 왔다라는 의미라고 합니다.\n\n스프링이 나오기 전 Java EE가 사용되고 있었는데, Java EE의 자질구레한 문제를 대체하기 위해 여러가지 프레임워크가 난립하는 전국시대와 같은 상황이 있었습니다.\n\n스프링은 이 때 로드 존슨 이라는 분의 제안으로 시작됐고, 결국 스프링이 자바 진영의 전국시대를 종결내버리게 됩니다.\n\n\n\n스프링이라는 것은 스프링 트라이앵글이라고 불리우는 IoC, AOP, PSA 세 가지의 기술을 기반으로 하며 이 세 가지의 기술을 통해 모든 문제를 해결하고자 하고 있습니다.\n\n그리고 스프링으로 해결하고자 하는 문제의 종류에 따라 여러가지 스프링 프레임워크가 존재합니다. (Spring Batch, Spring Data, Spring Cloud…)\n\n\n\n스프링의 장단점 ?\n\n\n\n스프링의 장점과 단점을 나열하자면 한도끝도 없겠죠.\n\n잠깐만 생각해봐도 엔터프라이즈 환경에서 필요한 도구를 거의 전부 지원한다 라거나, 정적타입과 빡센 제약으로 인해 협업에 용이하고 안정성이 높다 라거나, 운영체제와 같은 플랫폼에 독립적이다 라거나 등의 이유가 떠오르지만, 그 어떤 이유도 반드시 스프링을 사용해야만 한다 라거나 스프링이 아니면 안된다라는 주장에 합당한 근거가 될 수 없다고 생각합니다.\n\n왜냐하면 Google, Amazon, Apple, Facebook 등의 세계구급 대기업들이 모두 다 스프링만을 사용하고 있지 않으며, Ruby On Rails, Flask, Django등의 여러가지 프레임워크를 사용하고 있기 때문입니다.\n\n한국에서 자바와 스프링이 대세가 된 이유에 대한 제 생각을 먼저 요약하자면  기업 입장에서 봤을 때, 한국 시장에서 실력있는 개발자를 구인하기가 가장 용이하다.는 이유가 전부가 아닐까 싶습니다.\n\n\n\n아마 대부분의 기업에서 자바와 스프링을 다루는 개발자를 구인하는 이유도 위와 크게 다르지 않을 것이라고 사료되며, 실제로 여러가지 채용 공고들을 보면 다음과 같은 구문이 자주 보입니다.\n\n\n\n\n  Java 언어 사용이 능숙한 분\n  Spring Framework 개발 경험이 있으신 분\n\n\n\n\n우리 나라의 개발 업계는 매출 규모로 따졌을 때 SI업계가 전체 시장의 대부분을 점유(약 70%)하고 있으며, SI업계는 스프링 기반의 전자정부프레임워크(a.k.a egov)라고 불리우는 것을 업계 표준으로 사용합니다.\n\n따라서 국내 개발 시장에서 절대다수의 개발자가 자바 스프링을 사용하고 있기 때문에, 실력있는 개발자를 구인하기 용이하다는 측면에서 자바 스프링을 사용하는 개발자를 많이 채용한다가 제 결론입니다.\n\n참고로 위 채용공고처럼 시장에서 말하는 스프링이라는 것은 일반적으로 Spring MVC를 의미하며, 이것은 웹(Web)에 관련된 문제를 해결하기 위한 프레임워크를 말합니다.\n\n\n\n스프링이 없어진다면 ?\n\n\n\n제 고민의 핵심이라고 볼 수 있을 것 같습니다.\n\n그리고 어느정도 답이 나온 고민이기도 합니다.\n\n\n\n백엔드 개발자로 업무를 진행하면서 깨달은 것은, 결국 언어와 프레임워크는 도구일 뿐이며 핵심은 얼마나 문제의 밑바탕을 잘 이해하고 있느냐였습니다.\n\n좀더 풀어서 설명하자면, 예를 들어 Spring MVC를 이용해 웹 기능을 구현한다고 한들, 결국 조금 더 좋은 구조로 만들거나, 발생한 에러를 디버깅하기 위해서는 Web과 HTTP에 대한 이해가 필수적이었습니다.\n\n역시 Spring Data를 이용해 데이터베이스와 관련된 기능을 개발한다고 해도 결국 문제 해결을 위해서는 SQL과 네트워크 IO에 대한 이해가 필수적이었습니다.\n\n\n\n이렇게 근본적인 문제 해결을 위해서는 항상 해당 문제에 대한 지식, 흔히 CS지식이라고 불리우는 기본기가 더 중요했었습니다.\n\n각 스프링 프레임워크는 항상 특정 문제를 더 쉽게 해결하기 위한 여러가지 방법을 제공해주는 도구에 가까웠으며, 이러한 기본기를 토대로 스프링 프레임워크가 제공하는 방법을 취사선택하기만 하면 됐습니다.\n\n아마 사용하는 언어와 프레임워크를 Javascript와 Node.js로 바꾼다 한들 이러한 것들은 절대 바뀌지 않을거라고 생각됩니다.\n\n물론 제가 현재 자바와 스프링을 이용해 업무를 진행하는 만큼, 디테일을 위해 자바와 스프링을 계속해서 학습해야 함은 분명합니다. 이 부분은 제가 다른 언어와 프레임워크로 업무를 진행하게 되는것이 아니고서야 절대 변할일이 없을것입니다.\n\n아무리 언어와 프레임워크가 도구라고 생각한다고 한들, 각 언어와 프레임워크에는 자신들만의 철학과 사상이 담겨 있고, 디테일한 동작구조는 분명히 다르기 때문입니다.\n\n\n\n저는 자바와 스프링이 천년만년 사용될거라고 생각하지 않습니다.\n\n실제로 최근에도 Kotlin으로의 전환이 많이 이루어지고 있는 추세이고요.\n\n극단적인 생각으로는 10년안에 자바와 스프링이 대체될수도 있다는 생각마저도 하고 있습니다.\n\n\n\n하지만 기본기만큼은 제가 소프트웨어 엔지니어로 일하는 한 항상 필요한 절대적인 가치일거라는 확신은 듭니다.\n\n따라서 “내가 어떤것에 계속 시간을 투자해야 좋은 개발자가 될 수 있을까?” 라는 고민에 대한 답은 명약관화한 것 같습니다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-09-13-diary-27/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "웹 서버와 웹 애플리케이션 서버의 차이?",
      "date": "2021-09-15 00:00:00 +0000",
      "description": "면접 단골 질문에 대해 알아봅시다.\n",
      "content": "\n  웹 서버와 웹 애플리케이션 서버의 차이    \n      ⚖️ 보안\n      ⚖️ 유지보수 용이성과 고가용성\n    \n  \n  결론\n\n\n\n\n면접에서 단골 질문으로 나오는 주제입니다.\n\n그래서 인터넷에 검색해보면 굉장히 많은 글이 있는 주제이기도 합니다.\n\n하지만 대다수의 글이 제대로 이해했거나 제대로 이해하하려는 노력 없이 사전적인 정의를 복사 붙여넣기한 수준의 글들인 것 같은 느낌이 강하게 들었습니다.\n\n현업에서 일하고 있는 입장에서 잘 와닿지 않는 글들이 대부분이었기 때문입니다.\n\n저도 제가 이 주제를 제대로 이해했는지는 잘 모르겠지만, 그럼에도 불구하고 아마 단순 사전적인 정의를 떠난, 약간 새로운 관점의 글이 되지 않을까 싶습니다.\n\n\n\n웹 서버와 웹 애플리케이션 서버의 차이\n\n\n\n사전적인 정의만 놓고보면 아주 간단합니다.\n\n웹 서버는 정적 컨텐츠의 처리를 주 목적으로 하며, 웹 애플리케이션 서버는 정적, 동적 컨텐츠를 모두 처리할 수 있다. 입니다.\n\n그럼 웹 애플리케이션 서버만 써도 웹 서버의 역할까지 함께 수행할 수 있는데 왜 굳이 나눴을까요?\n\n\n\n이유는 고대의 선배님들이 사용하시던 하드웨어는 옛말로 정말 조선컴수준이었기 때문에, 웹 서버를 따로 사용해 정적 컨텐츠와 동적 컨텐츠를 분리해내면서까지 성능 최적화를 위한 노력을 했기 때문이었습니다.\n\n당시 EJB라는 괴물로 작업하시던 한 개발자분(로드 존슨 형님…)이 “야~! 이거 도저히 못해먹겠다~!” 해서 탄생한 것이 바로 현재 우리가 많이 사용하는 Spring이죠. (과연 로드 존슨 형님께는 봄이 왔을까요…? 😥)\n\n\n\n현재는 무어의 법칙에 따라 하드웨어의 성능이 비약적으로 증가해서 어지간한 애플리케이션은 서버에 부담조차 안가는 수준입니다.\n\n또한 Spring Boot을 정말 많이 사용하고 있고 이에 따라 자연스레 내장 톰캣을 사용하기 때문에 서버를 아주 쉽게 올렸다 내렸다 할 수 있게 됐습니다.\n\n내장 톰캣은 경량 WAS로 나왔기 때문에 기존의 외장 톰캣보다 확실히 가볍습니다.\n\n즉, 하드웨어와 소프트웨어의 발달로 이제는 웹 애플리케이션 서버만 사용하더라도 대부분의 작업을 아주 빠르게 처리해낼 수 있게 됐다는 뜻이죠.\n\n\n\n그럼에도 불구하고 웹 서버는 여전히 필수적으로 사용되고 있습니다.\n\n대표적으로 Nginx가 있죠?\n\n\n\n제 생각에 현업에서 웹 서버를 사용하는 이유는 크게 두가지가 있는 것 같습니다.\n\n그리고 아주 중요한 역할을 해내고 있다고 생각합니다.\n\n\n\n⚖️ 보안\n\n\n\n전 세계의 port에 대한 표준을 관리하는 IANA라는 단체가 있습니다.\n\n이 단체에서 Well Known Port 라는 것을 관리하고 있는데요, 쉽게 얘기하면 고정적인 포트를 의미합니다.\n\nftp=21, ssh=22, http=80, https=443 등 아주 친숙한 프로토콜과 이에 매핑되는 포트들이 있죠.\n\n이런것들을 관리한다고 생각하시면 됩니다.\n\n\n\n\n  📜 Service Name and Transport Protocol Port Number Registry\n\n\n\n\n이 Well Known Port들은 생략하고 사용할 수 있는 경우가 많습니다.\n\n왜냐하면 이미 전 세계적인 표준이기 때문에 유닉스 시스템에 이미 이 정보가 입력돼있거든요.\n\n그리고 유닉스 시스템에서 root 권한이 있어야만 사용할 수 있다는 특징을 갖습니다.\n\n우리가 자주 사용하는 톰캣은 기본 포트가 8080이죠?\n\n즉, 우리가 스프링 애플리케이션을 개발해서 기동하면 http://localhost:8080으로 접속할 수 있습니다.\n\n\n\n하지만 우리가 구글에 접속 할 경우 https://www.google.com:443 이라고 접속하진 않습니다.\n\n위 URI의 경우 https 프로토콜을 사용하므로 443 포트를 사용 할 것인데, 443은 Well Known Port이므로 생략할 수 있기 때문입니다.\n\n그리고 이러한 포트들을 사용하기 위해서는 애플리케이션을 root 권한으로 실행해야만 합니다.\n\n만약 Well Known Port를 사용하는 애플리케이션인데, root 권한으로 실행하지 않을 경우 권한이 없다는 에러가 발생하며 실행되지 않을 것입니다.\n\n\n\n그럼 우리가 개발한 스프링 애플리케이션의 기본포트인 8080을 http의 포트인 80으로 변경하고, root 권한으로 실행해도 되겠네요?\n\n물론 됩니다! 하지만, 이 경우 보안 문제가 생길 수 있습니다.\n\n\n\n만약 해커가 80포트로 접속해서 권한을 탈취한다면, 장악당한 애플리케이션에 대해 모든 권한을 갖는것과 다를게 없기 때문입니다.\n\n서버의 데이터를 조작하거나 서버를 다운시켜버리는 등의 행위도 가능해질 것이며, 장악당한 애플리케이션이 돈이 오고가는 중요한 비즈니스를 처리하고 있다거나 하면 문제는 더욱 심각해질수도 있을겁니다.\n\n따라서 WAS(웹 애플리케이션 서버)는 별도의 권한을 주어 8080, 8081 등의 포트들로 실행하고, 웹 서버를 따로 구축하여 웹 서버만 root 권한으로 실행하는 것입니다.\n\n\n\nNginx는 Master process 와 Worker process로 나뉘며, 일반적으로 Master process를 root 권한으로 실행합니다. Worker process가 실제로 작업을 수행하는 주체이지만, 반대로 탈취당할 경우 보안상의 이슈가 있기 때문에 보통 www-data등의 유저로 설정하고 아예 셸(Shell)에 접근조차 못하게 하는 경우가 많습니다.\n\n\n\n이렇게 하면 웹 서버가 해커에게 탈취당하더라도 웹 서버가 자체적으로 수행해내는 중요한 비즈니스가 없기 때문에 상대적으로 보안상 안전해집니다.\n\n그리고 웹 서버는 정적 컨텐츠를 서빙하거나 WAS로 라우팅 해주는 역할들을 함께 수행하게 됩니다.\n\n\n\n⚖️ 유지보수 용이성과 고가용성\n\n\n\n이 부분이 아주 큰 이유가 아닐까 싶습니다.\n\n특히 B2C서비스를 하는 회사들의 경우 B2B 사업을 하는 회사들에 비해 감당해내야 하는 트래픽이 굉장히 크기 때문에, 서버의 고가용성이 정말 중요합니다.\n\n이러한 문제를 웹 서버를 도입하여 상당부분 해결할 수 있습니다.\n\n\n\n웹 서버로 요즘 Nginx를 아주 많이 사용합니다.\n\n웹 서버는 WAS에 비해 경량이고, Nginx의 경우 Event Driven이라는 방식으로 동작하기 때문에, 실시간 처리에 매우 강력한 모습을 보입니다.\n\n이러한 특징으로 인해 Nginx는 사전적인 정의대로의, 정적 컨텐츠를 제공하는 웹 서버의 역할이 아닌 리버스 프록시 로서의 역할을 아주 훌륭하게 수행 해냅니다.\n\n그리고 리버스 프록시라는 일종의 초고성능 라우터를 도입하게 됨으로써 로드 밸런싱, 무중단 배포, 애플리케이션 인스턴스의 스케일아웃 등의 작업이 원활하게 이루어질 수 있게됩니다.\n\n웹 서버를 사전적인 정의대로 단순히 정적 페이지만 제공해주는 서버라고 생각했다면 이 부분들을 정말 이해하기 힘들 수도 있습니다.\n\n\n\n결론\n\n\n\n사전적인 의미야 물론 중요합니다만, 본질적인 것에 대한 이해가 수반되지 않는다면 큰 의미가 없다고 저는 생각합니다.\n\n많은 면접관분들이 이 주제를 질문하고, 많은 취준생분들이 사전적인 정의를 암기합니다.\n\n하지만 이런 실무와는 동떨어진 사전적인 정의들을 암기한다고 그러한 개념들을 실무에 녹여내고 어떤 가치를 만들어낼 수 있을까요?\n\n과연 웹 서버를 사용해야만 하는 상황이 닥치면 웹 서버를 효율적으로 사용해낼 수 있을까요?\n\n아니, 애초에 웹 서버를 도입해야 한다는 생각 자체를 할 수 있을까요?\n\n위 내용들에 호기심이 생기신 분들은 리버스 프록시, 로드 밸런싱, 무중단 배포, 스케일업, 스케일아웃 등의 키워드로 추가적인 검색을 해보시는것도 추천드립니다 !\n\n글 읽어주셔서 감사드리고, 이만 마치겠습니다. 🙇‍♂️\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-09-15-webserver-was/"
    },{
      "image": "/assets/img/spring/spring-boot/spring-boot-logo.png",
      "title": "스프링 부트의 이벤트 처리",
      "date": "2021-09-15 00:00:00 +0000",
      "description": "스트링 부트에서 Event Driven 방식의 처리를 어떻게 하는지 정리합니다.\n",
      "content": "\n\n\n스프링 4.2 이후로 이벤트 처리 방식이 아주 쉽게 바뀌었습니다.\n\n만약 스프링 부트 2+를 사용하신다면 자연스럽게 구현체로 스프링 5+를 사용하실 것이기 때문에, 이 방식을 바로 적용하실 수 있습니다.\n\n어떤 처리를 한 후 이벤트를 발생시키면, 해당 이벤트를 수신하는 리스너 객체가 특정한 처리를 해주는 것으로, 콜백이라고 생각하셔도 무방합니다.\n\n기존에는 이러한 처리를 위해 스프링 패키지의 특정한 클래스를 상속해야만 하는 침투적인 방식이였다면, 이제는 POJO를 사용하는 비침투적인 방식으로 처리할 수 있습니다.\n\n\n\n파일 업로드 요청이 들어오면 발생시킬 이벤트 객체입니다.\n\n\n\n// file: 'FileEvent'\n@Data\n@Builder\n@ToString\npublic class FileEvent {\n\n    private String eventId;\n    private EventType type;\n    private Map&lt;String, Object&gt; data;\n\n    // 파일 업로드가 성공할 경우 발생시킬 이벤트입니다.\n    public static FileEvent toCompleteEvent(final Map&lt;String, Object&gt; data) {\n        return FileEvent.builder()\n                .eventId(UUID.randomUUID().toString())\n                .type(EventType.COMPLETE)\n                .data(data)\n                .build();\n    }\n\n    // 파일 업로드가 실패할 경우 발생시킬 이벤트입니다.\n    public static FileEvent toErrorEvent(final Map&lt;String, Object&gt; data) {\n        return FileEvent.builder()\n                .eventId(UUID.randomUUID().toString())\n                .type(EventType.ERROR)\n                .data(data)\n                .build();\n    }\n\n    public enum EventType {\n        COMPLETE, ERROR\n    }\n\n}\n\n\n\n\n// file: 'FileEventPublisher'\n@Component\n@RequiredArgsConstructor\npublic class FileEventPublisher {\n\n    // 스프링에서 제공하는 이벤트 퍼블리셔입니다.\n    private final ApplicationEventPublisher publisher;\n\n    // 파일 업로드 요청 발생 시 이벤트를 입력받아 리스너에 이벤트를 전달합니다.\n    public void notify(final FileEvent fileEvent) {\n        publisher.publishEvent(fileEvent);\n    }\n\n}\n\n\n\n\n// file: 'FileEventListener'\n@Slf4j\n@Component\npublic class FileEventListener {\n\n    // 스프링에서 제공하는 애노테이션입니다. 해당 메서드가 이벤트를 수신하고 처리하는 리스너임을 명시합니다.\n    // ApplicationEventPublisher가 FileEvent를 주입해주면 특정한 처리를 합니다. \n    @EventListener\n    public void onFileEvent(final FileEvent fileEvent) {\n        log.info(\"file event receive: {}\", fileEvent);\n    }\n\n}\n\n\n\n\n// file: 'FileService'\n@Slf4j\n@Service\n@RequiredArgsConstructor\npublic class FileService {\n\n    private final FileEventPublisher publisher;\n\n    public void fileUpload(final Map&lt;String, Object&gt; data) {\n        // 파일 업로드의 성공/실패 유무를 try-catch문을 통해 판단하고 처리합니다.\n        try {\n            log.info(\"file upload complete.\");\n            // 파일 업로드가 성공했으므로 성공 이벤트를 퍼블리셔에 전달합니다.\n            publisher.notify(FileEvent.toCompleteEvent(data));\n        } catch (Exception e) {\n            log.error(\"file upload fail.\", e);\n            // 파일 업로드가 실패했으므로 실패 이벤트를 퍼블리셔에 전달합니다.\n            publisher.notify(FileEvent.toErrorEvent(data));\n        }\n    }\n\n}\n\n\n\n\n테스트용으로 임의의 더미데이터를 입력해줬습니다.\n\n\n\n@RestController\n@RequiredArgsConstructor\npublic class FileApiController {\n\n    private final FileService fileService;\n\n    @GetMapping(\"/upload/image\")\n    public ResponseEntity&lt;?&gt; fileUpload() {\n        fileService.fileUpload(Map.of(\"type\", \"image\", \"size\", \"5MB\"));\n        return new ResponseEntity&lt;&gt;(HttpStatus.OK);\n    }\n\n}\n\n\n\n\n해당 엔드포인트로 요청을 보내면 다음과 같이 처리됩니다.\n\n\n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::                (v2.5.4)\n\n2021-09-15 16:46:57.068  INFO 292 --- [nio-8080-exec-1] io.shirohoo.events.service.FileService   : file upload start.\n2021-09-15 16:46:57.070  INFO 292 --- [nio-8080-exec-1] i.s.events.listener.FileEventListener    : file event receive: FileEvent(eventId=f4784967-0535-40c7-aa75-5bde0e385cfe, type=COMPLETE, data={size=5MB, type=image})\n2021-09-15 16:46:57.074  INFO 292 --- [nio-8080-exec-1] io.shirohoo.events.service.FileService   : file upload complete.\n\n\n\n",
      "categories": ["spring","spring-boot"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-boot/2021-09-15-spring-events/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "CORS, HTTP Only",
      "date": "2021-09-28 00:00:00 +0000",
      "description": "HTTP, CORS 에 대한 이해 부족으로 발생한 문제\n",
      "content": "\n  SOP(Same-Origin Policy)\n  CORS(Cross-Origin Resource Sharing)    \n      Preflight\n      Simple Request\n      Credentialed Request\n      CORS 해결\n    \n  \n  HttpOnly\n\n\n\n\n스스로 HTTP와 CORS에 대해 어느정도 이해하고 있다고 생각하고 있었으나, 이번 사이드 프로젝트를 진행 중, 서버를 A to Z로 구축하며 여러번 몇번의 삽질을 하게 되어 삽질을 하게 만든 두 가지 문제와 이 문제의 원인 및 해결방안에 대해 기고합니다.\n\n\n\nSOP(Same-Origin Policy)\n\n\n\n웹(Web)에는 다른 출처로의 리소스 요청을 제한하는 SOP(Same-Origin Policy)라는 보안정책이 있습니다.\n\nSOP는 2011년에 RFC-6454 에 제안되었으며, 말 그대로 같은 출처에 대해서만 리소스를 요청할 수 있어야 한다는 보안정책을 의미합니다.\n\n이 정책이 나온 이유는 XSS, CSRF 등의 보안공격이 주 원인이며, XSS, CSRF는 매번 OWASP Top 10에 들 정도로 빈번하게 사용되는 위험한 공격방법입니다.\n\n흔히 특정 사이트를 똑같이 베낀 페이크 사이트를 통해 민감정보를 탈취하거나 악의적인 스크립트를 내장한 이메일을 무차별로 살포해서 민감정보를 탈취하는 등의 수법들이 있으며, 출처를 모르는 이메일의 링크는 함부로 클릭하지 말라는 말을 다들 어디선가 한번쯤은 들어보셨을 정도로 유명한 공격 방법입니다.\n\n\n\n\n  🔔 RFC: 간단하게 모든 인터넷 기술의 표준을 정의한 문서라고 생각해도 무방합니다.\n\n\n\n\n이러한 SOP 정책으로 인해 기본적으로 다른 출처로의 요청은 금지돼있으나, 이렇게 FM으로 다 막아버리면 효율성이 너무 떨어집니다.\n\n\n\n비유가 좀 이상하긴 하지만, 원칙적으로 도로를 건널때는 횡단보도, 육교, 지하도를 통해 건너야 하는데 골목길이나 이면도로같은 곳에서는 현실적으로 무단횡단이 빈번하게 일어나고, 경찰이 이를 보더라도 제지하지는 않습니다.\n\n도로가 좁거나 차가 많이 지나다니지 않는곳에선 사고가 발생할 가능성이 현저히 낮기 때문에, 횡단보도가 1km 앞에 있다면 대부분의 사람들은 횡단보도로 건너기 위해 1km를 걸어가느니 그냥 무단횡단하는것을 선택할 가능성이 높습니다.\n\n이편이 훨씬 더 시간을 절약할 수 있으니까요. (물론 법적으로는 불법이긴 합니다. 무단횡단은 가급적 하지말고, 하더라도 조심조심 합시다…)\n\n\n\n비슷하게 웹 개발을 하다 보면 타 출처로의 리소스 요청은 빈번하게 있는 일이기 때문에 항상 동일 출처로만 리소스 요청을 하도록 강제하는 것은 위와 비슷한 비효율적인 상황을 빈번하게 조성할 수 있습니다.\n\n따라서 타 출처로의 리소스 요청은 SOP를 근거로 원칙적으로 금지하되, 특정한 조건을 만족하면 타 출처로의 리소스 요청을 허용하는 CORS라는 이름의 일종의 위법성 조각 사유를 만들어 놓은 것입니다.\n\n만약 CORS 정책마저 만족하지 못한다면 SOP를 근거로 타 출처로의 리소스 요청이 금지되고 웹 브라우저 콘솔창에는 CORS 관련 에러메시지가 표시되게 됩니다.\n\n\n\n\n  Access to fetch at ‘http://localhost:3000’ from origin ‘https://www.google.com/’ has been blocked by CORS policy: No ‘Access-Control-Allow-Origin’ header is present on the requested resource. If an opaque response serves your needs, set the request’s mode to ‘no-cors’ to fetch the resource with CORS disabled.\n\n\n\n\nCORS(Cross-Origin Resource Sharing)\n\n\n\n물론 완벽하게 정확하진 않겠지만, CORS를 아주 간단하게 요약해보자면 현재 보고있는 페이지로 현재 페이지를 준 서버와는 다른 서버의 리소스를 가져오는 것을 의미합니다.\n\n우리가 웹 브라우저에서 https://www.google.com/에 접속한다면 다음과 같은 화면을 볼 수 있습니다.\n\n\n\n\n\n\n\n위 페이지는 html, css, javascript로 이루어져 있는 리소스이며, 이러한 데이터들은 모두 https://www.google.com/라는 도메인을 사용하고있는 모종의 서버에서 나온 것입니다.\n\n이때 위 리소스의 출처(Origin)는 https://www.google.com/가 되는 것이죠.\n\n\n\n그리고 이렇게 https://www.google.com/에서 받아온 리소스에서 내부적으로 자바스크립트를 통해 https://www.naver.com/로 임의의 데이터를 요청하는 상황을 CORS라고 부르게 됩니다.\n\nhttps://www.google.com/와 https://www.naver.com/는 서로 다른 출처(Origin)이기 때문이죠.\n\n\n\n여기서 출처(Origin)에 대해 조금 더 자세히 설명해보자면, URL과 관련이 있습니다.\n\nURL에는 정말 많은 요소가 존재하지만, 기본적으로 아래의 요소가 모두 같은 경우 출처가 같다(Same-Origin)고 말합니다.\n\n\n\n\n\n\n\n\n  위 이미지에서 Protocol은 Scheme이라고 부르기도 합니다.\n\n\n\n\n한가지 짚고 넘어가자면 우리는 보통 브라우저에서 https://www.google.com/ 라고 입력하여 구글에 접속하지, https://www.google.com:443/ 이라고 입력해서 접속하진 않죠?\n\n이렇게 생략할 수 있는 특별한 포트(Port)들이 존재하는데 이러한 포트들을 Well Known Ports라고 부르며, 이 특별한 포트들을 관리하는 범세계적인 기구가 IANA입니다.\n\n위 포트들에 대한 내용은 https://www.iana.org/의 Service Name and Transport Protocol Port Number Registry문서에서 확인하실 수 있습니다.\n\n위 URL에서 스킴(Scheme)은 https이므로 자연스레 Well Known Port인 443을 사용하게 되고, 이는 생략할 수 있게 되는것입니다.\n\n\n\n이에 대한 추가적인 레퍼런스는 HTTP/1.1이 정의된 RFC-2616을 참고하시면 됩니다.\n\n\n\n\n  3.3.2 http URL\n\n  If the port is empty or not given, port 80 is assumed. \nThe semantics are that the identified resource is located at the server listening for TCP connections on that port of that host, and the Request-URI for the resource is abs_path (section 5.1.2).\n\n\n\n\n혹은 영문서라 부담스럽다 싶으시면 흔히 다람쥐책이라고 불리우는 HTTP 완벽 가이드를 읽어보시는 것도 좋을 것 같습니다.\n\n\n\nCORS는 세가지 방식을 통해 허용됩니다.\n\n일단 명심해야 할 것은 아래의 모든 시나리오는 결국 서버에서 내려주는 응답 헤더에 Access-Control-Allow-Origin가 포함돼있는지를 알기 위함임을 잊지 말아야 하며, 아래의 모든 시나리오를 잘 이해해야 결과적으로 CORS로 인한 문제를 회피하거나 해결할 수 있습니다.\n\n\n\nPreflight\n\n\n\n사전요청(Preflight)은 타 출처로의 리소스 요청시 요청을 받는 서버에서 CORS 요청에 대한 메서드와 헤더에 대해 인식하고 있는지를 먼저 체크하는 것으로, 가장 일반적인 시나리오입니다.\n\n\n\n\n\n\n\n사전요청(Preflight)은 Access-Control-Request-Method, Access-Control-Request-Headers, Origin 총 3가지의 HTTP 요청 헤더를 사용하는 OPTIONS 요청입니다.\n\n\n\n\n  OPTIONS는 GET, POST와 같이 자주사용되는 표준 HTTP Methods의 일종으로 서버가 해당 API에 대해 어떤 옵션들을 허용하고 있는지를 서버에 질의(Query)하는 요청입니다.\n\n\n\n\n우리가 자바스크립트의 fetch API 같은 것을 사용하여 브라우저에게 타 서버의 특정 API를 통해 리소스를 받아오라는 명령을 내리면 브라우저는 해당 API로 사전요청을 먼저 보내고, 서버는 사전요청에 대한 응답으로 현재 자신의 특정 API에서 어떤 것들을 허용하고, 어떤 것들을 허용하지 않는지에 대한 정보를 응답 헤더에 담아서 브라우저에게 다시 보내주게 됩니다.\n\n\n\nOPTIONS /resource/foo\nAccess-Control-Request-Method: DELETE\nAccess-Control-Request-Headers: origin, x-requested-with\nOrigin: https://foo.bar.org\n\n\n\n\nHTTP/1.1 204 No Content\nConnection: keep-alive\nAccess-Control-Allow-Origin: https://foo.bar.org\nAccess-Control-Allow-Methods: POST, GET, OPTIONS, DELETE\nAccess-Control-Max-Age: 86400\n\n\n\n\n이후 브라우저는 자신이 타 서버로 보낸 사전요청과 서버가 응답에 담아준 내용을 비교한 후, 이후 보낼 요청을 서버에서 허용하고 있음을 확인하면 다시 같은 API로 본래 보내려던 진짜 요청을 보내게 됩니다.\n\n이후 서버가 본 요청에 대한 응답을 하면 브라우저는 최종적으로 이 응답 데이터를 자바스크립트에게 넘겨줍니다.\n\n간단하게 vue cli를 통해 프로젝트를 하나 만들고, axios를 통해 사전요청 시나리오를 재현해봤습니다.\n\n\n\nlogin() {\n      let uri = 'http://www.ark-inflearn.shop/api/v1/login';\n      let data = {\n        email: \"test12551@email.com\",\n        password: \"AASHFKHQWFQYW#qwhfgqwf123!\",\n      }\n      axios.post(uri, data)\n          .then(() =&gt; {\n            alert(\"Successes login!\");\n          })\n          .catch(err =&gt; {\n            alert(err.response.data.responseBody);\n          });\n    }\n\n\n\n\n\n\n\n\nLogin API에 대해 사전요청이 먼저 발생 후 이에 200 응답을 받고, Login API로 본 요청이 전송됐음을 확인할 수 있었습니다.\n\n\n\n만약 서버에서 사전요청에 대한 알맞은 처리가 돼있지 않다면 사전요청 시 아래와 같은 에러 메시지가 발생하게 됩니다.\n\n\n\n\n  OPTIONS http://www.ark-inflearn.shop/api/v1/login 405 (Method Not Allowed) Failed to load http://www.ark-inflearn.shop/api/v1/login: Response to preflight request doesn’t pass access control check: No ‘Access-Control-Allow-Origin’ header is present on the requested resource. Origin ‘http://localhost:3000’ is therefore not allowed access. The response had HTTP status code 405. If an opaque response serves your needs, set the request’s mode to ‘no-cors’ to fetch the resource with CORS disabled.\n\n\n\n\nSimple Request\n\n\n\n\n\n\n\nMDN 문서를 보면 특정한 조건을 만족할때 사전요청이 배제된 단순요청(Simple Request)이 발생한다고 나와있습니다.\n\n\n\n\n\n\n\n첫번째 조건은 다른 Http Methods를 쓰면 되지만, 두번째와 세번째 조건을 보니  사실상 단순요청이 발생하는 상황을 만들기가 어려울 것 같다는 생각이 듭니다.\n\n대체로 API 서버를 개발할때 Content-Type은 application/json이나 text/xml을 사용하고, 기본적인 HTTP 헤더를 제외한 다른 헤더를 사용하면 안된다는 것은 매우 지키기 어렵기 때문입니다.\n\n이 시나리오로 진행할 수 있다면 사전 요청을 생략할 수 있으므로 하는게 좋을 것 같지만, 현실적으로 어려워보이니 그냥 이런것도 있구나 정도로 이해하고 넘기면 될만한 내용인 것 같습니다.\n\n\n\nCredentialed Request\n\n\n\n일반적인 HTTP 요청과 다르게 HTTP 요청에 자격증명(Credential)이 포함된 경우를 의미합니다.\n\n여기서 자격증명(Credential) 이라는 것은, 인증과 관련된 헤더(JWT, 커스텀 인증키 등)와 쿠키같은 것들을 의미하는데, 기본적으로 브라우저가 제공하는 XMLHttpRequest나 Fetch API를 사용하게 되면 요청에 이러한 자격증명을 담지 않습니다.\n\n이렇게 되면 만약 서버에서 인증정보를 요구하는 경우, 예를 들자면 세션-쿠키 방식의 인증체계를 사용하는데, 인증이 필요한 경우에 브라우저에서 절대 쿠키를 보내지 않게 되어 결과적으로 성공적으로 로그인이 됐음에도 서버는 계속해서 인증정보를 요구하는 상황이 발생할 수 있습니다.\n\n사용자 입장에서 보면 분명 로그인을 했는데 뭐만하면 계속 로그인 페이지로 이동되는 상황이니 “무슨 이딴 웹페이지가 다 있냐? 안 써! 😡” 같은 대참사가 발생할 수도 있는것이죠.\n\n따라서 브라우저는 서버에 임의의 요청을 보낼 경우 HTTP 헤더에 인증 정보를 담아야 하는데, 이때 사용할 수 있는 옵션이 credentials 옵션입니다.\n\n이 부분은 코드로 보시는게 더 이해하기 쉬울 것 같습니다.\n\n\n\nlogin() {\n      let uri = 'http://www.ark-inflearn.shop/api/v1/login';\n      let data = {\n        email: \"test12551@email.com\",\n        password: \"AASHFKHQWFQYW#qwhfgqwf123!\",\n      }\n      axios.post(uri, data, { withCredentials: true })\n          .then(() =&gt; {\n            alert(\"Successes login!\");\n          })\n          .catch(err =&gt; {\n            alert(err.response.data.responseBody);\n          });\n    }\n\n\n\n\naxios 헤더에 { withCredentials: true }라는 코드를 작성했습니다.\n\nhttp://www.ark-inflearn.shop/api/v1/login로 요청을 보낼 때 쿠키 등의 인증정보를 함께 보내겠다는 의미입니다.\n\n\n\n이렇게 보면 매우 간단하지만 이 경우 정말 생각지도 못한 골때리는 문제가 발생합니다. (제가 이번에 삽질을 하게 된 문제 중 하나가 이 문제였습니다. 😭)\n\n\n\n\n\n바로 Access-Control-Allow-Origin에 와일드카드(*, asterisk)를 사용할 수 없다는 것입니다.\n\n\n\n\n\n\n\n와일드카드를 통해 어떤 경우에라도 CORS 헤더를 응답하는것을 허용하겠다고 했는데 되려 와일드카드를 사용했기 때문에 안된다니? 처음에 이 부분이 정말 이해가 안되서 삽질을 했던거죠.\n\n바로 CORS 시나리오 중 HTTP 요청에 자격증명(Credential)이 포함됐을 경우에 대한 내용을 이해하지 못했기 때문이었습니다.\n\n이 시나리오에서는 두가지 규칙을 반드시 지켜야만 합니다.\n\n\n\n\n  Access-Control-Allow-Origin에는 *를 사용할 수 없으며, 반드시 명시적인 URL을 작성해야 합니다.\n  응답 헤더에는 반드시 Access-Control-Allow-Credentials: true가 존재해야 합니다.\n\n\n\n\n이 내용을 이해했음에도 약간 더 삽질을 하게 됐는데, 우리가 진행하는 사이드 프로젝트의 현 상황때문이었습니다.\n\n백엔드 서버는 구축이 되어 특정한 도메인을 갖고 24시간 가동중인데, 프론트 서버가 아직 구축되지 않은 상태라 프론트 팀에서는 각자의 로컬에 프론트 서버를 띄우고 작업하고 있었기 때문에 명시할 URL이 마땅찮았습니다.  (보안상 권장되지 않는 방법임에도 불구하고 와일드카드를 통해 CORS를 허용한 이유이기도 합니다)\n\n로컬에서 리액트 프로젝트를 npm run dev등의 명령어를 통해 띄울 경우 http://localhost:3000으로 서버가 뜨니 생각나는 URL이래봐야 http://localhost:3000/이라던가 http://127.0.0.1:3000 따위의 것들인데, 해봤자 안될게 뻔했기 때문이죠. (내부적으로 hosts 파일을 통해 라우팅되는 도메인이므로…😫)\n\n결국 생각나는 유효한 방법은 프론트 개발자들이 사용하는 로컬 서버의 공인 IP를 전달받아 모두 등록하는 방법뿐이었습니다.\n\n그리고 이 방법은 일단 사용하고 싶지 않았습니다.\n\n\n\nCORS 해결\n\n\n\n\n  여기부턴 자바, 스프링 부트와 스프링 시큐리티의 내용을 다룹니다.\n\n\n\n\nCORS관련 문제의 원인은 알았는데, 마땅한 해결 방법을 찾지 못하던 중 다행히 스프링 시큐리티(Spring Security)의 문서에서 이러한 상황을 해결할 수 있는 방법을 찾아냈습니다.\n\n\n\n\n\n\n\n스프링 부트에서는 스프링 MVC를 통해 CORS를 허용하는 방법과 스프링 시큐리티를 통해 CORS를 허용하는 두가지 방법이 있습니다.\n\n스프링 MVC 공식 문서의 CORS 섹션 에서는 CORS를 허용하려면 다음과 같은 코드를 작성하라고 소개해주고 있습니다.\n\n\n\n@Configuration\n@EnableWebMvc\npublic class WebConfig implements WebMvcConfigurer {\n\n    @Override\n    public void addCorsMappings(CorsRegistry registry) {\n\n        registry.addMapping(\"/api/**\")\n            .allowedOrigins(\"https://domain2.com\")\n            .allowedMethods(\"PUT\", \"DELETE\")\n            .allowedHeaders(\"header1\", \"header2\", \"header3\")\n            .exposedHeaders(\"header1\", \"header2\")\n            .allowCredentials(true).maxAge(3600);\n\n        // Add more mappings...\n    }\n}\n\n\n\n\n반대로 스프링 시큐리티 공식문서의 CORS 섹션에서는 이렇게 서술합니다.\n\n\n  Spring Framework provides first class support for CORS. CORS must be processed before Spring Security because the pre-flight request will not contain any cookies (i.e. the JSESSIONID). If the request does not contain any cookies and Spring Security is first, the request will determine the user is not authenticated (since there are no cookies in the request) and reject it.\n\n  The easiest way to ensure that CORS is handled first is to use the CorsFilter. Users can integrate the CorsFilter with Spring Security by providing a CorsConfigurationSource using the following:\n\n\n\n\n\n  🤔 JSESSIONID ? :\n\n  자바 서블릿이 정의한 쿠키 이름 표준 스펙입니다.\n\n  자바 서블릿을 구현한 구현체로 네티, 언더토우, 톰캣, 아파치 등등이 있는데, 이처럼 자바 서블릿을 구현한 웹 서버라면 기본적으로 자바 서블릿 표준 스펙을 따르기 때문에 쿠키 이름이 JSESSIONID으로 응답됩니다.\n\n  이는 서버 개발자가 임의로 변경할수도 있습니다.\n\n  편의상 자바 진영에서 톰캣을 가장 많이 사용하기 때문에 톰캣이 발급하는 쿠키 이름이라고도 많이 표현되는 편입니다.\n\n  📜 관련 레퍼런스: https://javaee.github.io/servlet-spec/downloads/servlet-4.0/servlet-4_0_FINAL.pdf\n\n  7.1.1 Cookies\n\n...\n\nThe container sends a cookie to the client. The client will then return the cookie on\neach subsequent request to the server, unambiguously associating the request with a\nsession. The standard name of the session tracking cookie must be JSESSIONID.\nContainers may allow the name of the session tracking cookie to be customized\nthrough container specific configuration.\n\n...\n  \n\n\n\n\n위 내용에 대해 설명드리자면, 사전요청(Preflight)에는 쿠키가 없으므로 CORS는 반드시 스프링 시큐리티보다 먼저 체크되고 처리되어야 한다는 것입니다.\n\n왜냐하면 쿠키가 없는 요청에 대해 스프링 시큐리티가 검증하려들면, 쿠키가 없기 때문에 인증되지 않은 사용자로 구분될 것이 분명하고 결과적으로 요청이 항상 튕겨져 나가게 되기 때문입니다.\n\n이를 스프링 시큐리티에서 가장 간단하게 해결할 수 있는 방법으로 CorsFilter를 사용하는 방법을 소개하고 있습니다.\n\n\n\n\n  이러한 이유로 CorsFilter는 Spring Security Filter Chain의 선두에 위치하고 있습니다.\n\n\n\n\n저는 스프링 시큐리티를 사용하므로 모든 인증 관련 처리를 스프링 시큐리티에서 통합해 관리하고 싶어 스프링 MVC를 사용한 방식이 아닌 스프링 시큐리티의 CorsFilter를 설정했고, 아래와 같은 코드를 추가했습니다.\n\n\n\n@Override\nprotected void configure(final HttpSecurity http) throws Exception {\n    http\n        .cors() // Bean으로 등록된 CorsFilter를 사용. Bean이 없다면 스프링 시큐리티에서 제공하는 기본 CorsFilter 사용.\n    ...\n}\n\n@Bean // Bean으로 등록 필요\npublic CorsConfigurationSource corsConfigurationSource() {\n    CorsConfiguration configuration = new CorsConfiguration();\n\n    configuration.setAllowedOrigins(Collections.singletonList(\"*\")); // 모든 Origin에서의 요청을 허용\n    configuration.setAllowedMethods(List.of(\"GET\", \"POST\", \"PUT\", \"PATCH\", \"DELETE\", \"OPTIONS\")); // 해당 Http Methods를 사용하는 요청을 허용\n    configuration.setAllowedHeaders(List.of(\"authorization\", \"content-type\", \"x-auth-token\")); // 해당 헤더를 사용하는 요청을 허용\n    configuration.setExposedHeaders(Collections.singletonList(\"x-auth-token\")); // 헤더에 CSRF 토큰이 있는 요청에 대해 모든 응답 헤더를 노출\n    configuration.setAllowCredentials(true); // 사용자 자격 증명(쿠키, 인증키) 사용을 허용할 것\n\n    UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();\n    source.registerCorsConfiguration(\"/**\", configuration); // 모든 URL에 대해 위의 설정을 사용해 CORS 처리를 할 것\n    return source;\n}\n\n\n\n\nconfiguration.setAllowedOrigins(Collections.singletonList(\"*\"));\n\n\n\n\n위 코드가 문제였는데, 명시해야 할 URL이 없었기 때문입니다.\n\n다행히 스프링 시큐리티 팀에서 해당 문제를 회피할 수 있는 setAllowedOriginPatterns라는 API를 하나 제공하고 있었습니다.\n\n\n\nconfiguration.setAllowedOriginPatterns(Collections.singletonList(\"*\"));\n\n\n\n\n이 API에 대한 문서를 찾아보니 다음과 같은 내용이 있습니다.\n\n\n\npublic CorsConfiguration setAllowedOriginPatterns(@Nullable List&lt;String&gt; allowedOriginPatterns)\n\nAlternative to setAllowedOrigins(java.util.List&lt;java.lang.String&gt;) that supports more flexible origins patterns with \"*\" anywhere in the host name in addition to port lists. Examples:\n\nhttps://*.domain1.com -- domains ending with domain1.com\nhttps://*.domain1.com:[8080,8081] -- domains ending with domain1.com on port 8080 or port 8081\nhttps://*.domain1.com:[*] -- domains ending with domain1.com on any port, including the default port\n\nIn contrast to allowedOrigins which only supports \"*\" and cannot be used with allowCredentials, when an allowedOriginPattern is matched, the Access-Control-Allow-Origin response header is set to the matched origin and not to \"*\" nor to the pattern. \nTherefore allowedOriginPatterns can be used in combination with setAllowCredentials(java.lang.Boolean) set to true.\n\nBy default this is not set.\n\nSince:\n5.3\n\n\n\n\n즉, Origin을 명시해야 하는데, 명시해야 할 Origin이 마땅치 않으니 이를 패턴을 통해 보다 더 유연한 방법으로 요청을 구분하고 허용하는 것입니다.\n\n간단히 말해 위와 아래의 차이는 서버로 오는 모든 요청에 대해 허용하느냐, 서버로 오는 모든 요청 중 특정한 패턴을 만족하는 요청만 허용하느냐의 차이인 것이죠…\n\n저는 근데 여기다가 와일카드를 사용했고, 이는 서버로 오는 모든 요청 중 모든 패턴의 요청을 허용이 되므로 결과적으로 말장난 같긴 합니다 ㅎㅎㅎ 🤣\n\n아마 내부적으로는 모종의 복잡한 과정을 거쳐 결과적으로 configuration.setAllowedOrigins(Collections.singletonList(\"*\"));를 사용한 것과 같은 효과를 내게 되겠죠?\n\n아무튼 이렇게 CORS 문제를 해결할 수 있었습니다.\n\n하지만 이게 끝이 아니었습니다… 😣\n\n\n\nHttpOnly\n\n\n\n이건 뭔지 몰라서 실제로 문제가 없는데 문제가 있는 걸로 착각했던 내용이었습니다.\n\nCORS 문제를 해결했음에도 불구하고 크롬 개발자도구에서 서버에서 응답한 쿠키를 찾을 수 없어서, 서버에서 인증요청에 대한 쿠키가 제대로 응답되지 않은 줄 알았습니다.\n\n그래서 패킷을 까봤는데, HTTP 응답 헤더에는 쿠키가 제대로 들어있었죠. 🤔\n\n\n\n\n\n\n\n근데 위 이미지에서 보시다시피 맨 끝에 HttpOnly라는 알수없는 태그가 노란 느낌표와 함께 달려있었고, 이게 원인인것 같아 찾아보다가 결국 OWASP 에서 관련 내용을 찾을 수 있었습니다.\n\n\n\n\n  If the HttpOnly flag (optional) is included in the HTTP response header, the cookie cannot be accessed through client side script (again if the browser supports this flag). As a result, even if a cross-site scripting (XSS) flaw exists, and a user accidentally accesses a link that exploits this flaw, the browser (primarily Internet Explorer) will not reveal the cookie to a third party.\n\n\n\n\n원칙적으로 SOP에 의해 출처(Origin)가 다른 서버에서 리소스를 얻어올 수 없는데, 이를 CORS 정책을 통해 임의의 리소스를 얻어오게 되면 자연스럽게 XSS, CSRF 등의 공격에 취약해지게 됩니다.\n\n따라서 이 문제를 보완하기 위한 추가적인 보안 기법이 적용됬는데, 이게 바로 HttpOnly라는 이름의 세션 탈취 방어 기법입니다.\n\nHttpOnly는 HttpOnly가 설정된 쿠키는 HTTP 통신 상에서만 사용되어야 한다는 것으로, HTTP 통신에서만 사용되는 데이터이기 때문에 자바스크립트 같은 외부 프로세스가 접근할 수 없게 됩니다.\n\n\n\n쉽게 말하자면 “이거 원래 안되는건데 니가 하도 달라고해서 준거니까, 여기다 이상한짓 하지말고 준대로 쓰기만 해 !” 라고 강제하는 것입니다.\n\n\n\n실제로 자바스크립트를 통해 해당 쿠키에 접근하려고 하니 HttpOnly 설정이 되어 있어 액세스할 수 없다는 에러 메시지가 발생하였습니다. (이미지 캡처를 깜빡했습니다…)\n\n\n\n하지만 HttpOnly는 세션 관련 공격들에 대해 최소한의 방어는 보장하지만, XST(Cross-site Tracing) 공격의 여지가 조금이나마 남아있어 결국 완벽한 방어는 보장하지 못하기 때문에, 고수준의 보안 정책을 고려한다면 결국 XSS Filter, CSRF Filter등의 추가적인 보안 시스템을 구축해야 합니다.\n\n\n\n정리하자면 CORS 문제를 해결했고 이후 정상적인 인증과정을 거쳐 서버에서는 인증 쿠키를 응답하였으나 해당 쿠키는 HttpOnly가 적용된 보안 쿠키였기 때문에, 클라이언트 환경에서 해당 쿠키가 노출되지 않는 상태였습니다.\n\n저는 쿠키가 넘어오지 않는 (실제론 넘어왔으나 보이지만 않은 😅) 이 상황이 이해되지 않아 HTTP 패킷을 뜯어 HTTP 헤더를 분석했고, 거기서 숨겨져있는 쿠키와 함께 HttpOnly라는 키워드를 얻어 이 문제의 전말을 깨닫게 된 것이죠. 🤣\n\n\n\n원래 정상인걸 문제있다고 오판한 것이니 해결방법이랄건 딱히 없었고 좋은 것 하나 배웠다고 생각합니다.\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-09-28-cors/"
    },{
      "image": "/assets/img/spring/spring-security/security-logo.png",
      "title": "Remember-Me",
      "date": "2021-10-08 00:00:00 +0000",
      "description": "주로 자동로그인 등에 사용되는 Remember-Me 기능에 대해 알아봅시다.\n",
      "content": "\n  Dependencies\n  ✅ Remember-Me    \n      암호화 시그니처를 사용한 토큰 기반        \n          토큰 기반 Remember-Me 기능의 원리\n          속성\n        \n      \n      데이터베이스를 사용한 영구 토큰 기반        \n          구현\n          확장\n        \n      \n    \n  \n  참고\n\n\n\n\nDependencies\n\n\n\n이 글의 예제 코드를 적용하기 위해서는 다음과 같은 의존성을 빌드 스크립트에 추가해야만 합니다.\n\n빌드툴은 Gradle을 기준으로 작성하며, Spring Boot 2.5.5 기반입니다.\n\n웹 브라우저는 크롬을 사용하였습니다.\n\n\n\n// file: 'build.gradle'\ndependencies {\n    implementation 'org.springframework.boot:spring-boot-starter-security'\n    implementation 'org.springframework.boot:spring-boot-starter-data-jpa'\n    \n    ...\n\n    runtimeOnly 'com.h2database:h2'\n}\n\n\n\n\n✅ Remember-Me\n\n\n\nJava Servlet 기반의 WAS를 사용 할 경우 인증 요청 대한 인증 성공 시 발급되는 쿠키의 기본 이름은 JSESSIONID 입니다.\n\n이것은 Java Servlet 표준 스펙에 정의된 부분이기 때문에 Java Servlet을 구현하는 모든 WAS가 동일합니다.\n\nSpring MVC를 사용 할 경우 기본적으로 톰캣을 사용하기 때문에 위의 내용이 적용됩니다.\n\n따라서 Spring Security 적용 후 발급되는 인증 쿠키의 이름은 JSESSIONID가 됩니다.\n\n\n\n\n  이 이름은 물론 개발자가 커스터마이징할 수 있습니다.\n\n\n\n\nRemember-Me 기능은 사용자에게 매우 큰 편리성을 제공하는 기능입니다.\n\n사용자가 서버에 인증한 순간 웹 브라우저에 remember-me 쿠키를 저장해 놓음으로써 이후 사용자의 세션이 만료되거나, 불특정한 사유로 JSESSIONID가 없어졌을 경우에도 해당 사용자를 기억할 수 있게 됩니다.\n\n\n\n\n\n\n\n즉, Spring Security Filter Chain에서 유효한 remember-me 쿠키를 인식하면 해당 사용자가 현재 인증되지 않은 사용자라고 할지라도 즉시 자동으로 재 인증을 시켜주므로, 사용자는 이 기능을 통해 로그인 시 쿠키가 유효한 시점까지 아이디/패스워드 등의 정보를 다시 입력하지 않아도 되게 됩니다.\n\n단, 사용자에게 편의성을 제공하면 할수록 보안 수준은 반비례하여 점점 떨어질 수 밖에 없기 때문에, 이 부분은 항상 주의해야 합니다.\n\n\n\n스프링 시큐리티는 Remember-Me 기능에 대해 기본적으로 두 가지 구현체를 제공합니다.\n\n\n  암호화 시그니처를 사용한 토큰 기반의 Remember-Me, 구현체의 이름은 TokenBasedRememberMeServices\n  데이터베이스를 사용한 영구 토큰 기반의 Remember-Me, 구현체의 이름은 PersistentTokenBasedRememberMeServices\n\n\n그리고 위의 두 구현체는 모두 UserDetailsService를 의존하기 때문에 Remember-Me 기능을 구현하기 위해서는 UserDetailsService를 반드시 설정해주어야만 합니다.\n\n\n\n암호화 시그니처를 사용한 토큰 기반\n\n\n\n기본적인 적용은 아주 심플합니다.\n\n\n\n// file: 'SecurityConfiguration.java'\n\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(final AuthenticationManagerBuilder auth) throws Exception {\n        auth\n            .inMemoryAuthentication()\n            .withUser(\"test\").password(\"{noop}test\").authorities(\"ROLE_USER\"); // 개발 편의성을 위한 인메모리 유저를 설정합니다.\n    }\n\n    @Override\n    protected void configure(final HttpSecurity http) throws Exception {\n        http\n            .authorizeRequests() // 서버로 오는 요청들에 대한 보안 정책\n            .anyRequest().authenticated() // 모든 요청에 대해 인증이 필요합니다.\n\n            .and()\n\n            .rememberMe().key(\"key\") // remember-me 토큰 암호화에 사용할 키를 설정합니다. 기본값은 무작위로 설정된 문자열입니다.\n            .userDetailsService(userDetailsService()) // Remember-Me 기능 설정에 필요한 필수 옵션\n\n            .and()\n\n            .formLogin()\n        ;\n    }\n\n}\n\n\n\n\n이후 프로젝트를 실행하고 /login 으로 접근하면 다음과 같은 웹 페이지가 뜹니다.\n\n저는 localhost:8080/login으로 접근했습니다.\n\n\n\n\n\n\n\n여기에 위에서 설정한 인메모리 유저정보를 입력하고 로그인을 하면 성공적으로 로그인이 되며, 웹 브라우저의 개발자 도구를 열어 쿠키 정보를 보면 아래와 같은 정보가 뜰 것입니다.\n\n이 때, Value는 이미지와 다를 수 있으며, 쿠키 이름이 JSESSIONID이기만 하면 됩니다.\n\n위 정보는 서버에서 로그인 요청(=인증 요청)을 성공적으로 받아 처리하였으며, 이에 대한 인증 쿠키를 웹 브라우저에 내려주었음을 의미합니다.\n\n\n\n\n\n\n\n이제 Remember-Me 기능을 사용할 것임을 의미하는 아래의 체크박스에 체크를 하고, 동일하게 로그인을 시도해봅니다.\n\n아래의 과정을 진행하기 전 /logout으로 접근하여 서버에 로그아웃 요청을 보내 세션을 지워주어야 합니다.\n\n저는 localhost:8080/logout으로 접근하였습니다.\n\n\n\n\n\n\n\n\n\n\n\n역시 성공적으로 로그인이 되며 아까와 다르게 remember-me 라는 이름의 새로운 쿠키가 하나 더 생겨있음을 알 수 있습니다.\n\n여기서 한가지 짚고 넘어갈 것이 있는데, 로그인 페이지의 HTML을 살펴보면,\n\n\n\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"&gt;\n    &lt;meta name=\"description\" content=\"\"&gt;\n    &lt;meta name=\"author\" content=\"\"&gt;\n    &lt;title&gt;Please sign in&lt;/title&gt;\n    &lt;link href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css\" rel=\"stylesheet\" integrity=\"sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M\" crossorigin=\"anonymous\"&gt;\n    &lt;link href=\"https://getbootstrap.com/docs/4.0/examples/signin/signin.css\" rel=\"stylesheet\" crossorigin=\"anonymous\"/&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n     &lt;div class=\"container\"&gt;\n      &lt;form class=\"form-signin\" method=\"post\" action=\"/login\"&gt;\n        &lt;h2 class=\"form-signin-heading\"&gt;Please sign in&lt;/h2&gt;\n        &lt;p&gt;\n          &lt;label for=\"username\" class=\"sr-only\"&gt;Username&lt;/label&gt;\n          &lt;input type=\"text\" id=\"username\" name=\"username\" class=\"form-control\" placeholder=\"Username\" required autofocus&gt;\n        &lt;/p&gt;\n        &lt;p&gt;\n          &lt;label for=\"password\" class=\"sr-only\"&gt;Password&lt;/label&gt;\n          &lt;input type=\"password\" id=\"password\" name=\"password\" class=\"form-control\" placeholder=\"Password\" required&gt;\n        &lt;/p&gt;\n        &lt;p&gt;\n          &lt;input type='checkbox' name='remember-me'/&gt; Remember me on this computer.\n        &lt;/p&gt;\n          &lt;input name=\"_csrf\" type=\"hidden\" value=\"facf4bbf-4c91-455f-8ee2-ac777f8e901c\" /&gt;\n          &lt;button class=\"btn btn-lg btn-primary btn-block\" type=\"submit\"&gt;Sign in&lt;/button&gt;\n      &lt;/form&gt;\n     &lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\n\n\n\n체크박스 관련 HTML에 name이 remember-me로 돼있음을 볼 수 있습니다.\n\n만약 서버에서 Remember-Me 파라미터 이름을 변경한다면, HTML도 함께 변경되어야만 합니다.\n\n스프링 시큐리티의 기본 설정 파라미터명은 remember-me이며, 이 이름은 기본 쿠키 이름과도 동일합니다.\n\n\n\npublic final class RememberMeConfigurer&lt;H extends HttpSecurityBuilder&lt;H&gt;&gt; extends AbstractHttpConfigurer&lt;RememberMeConfigurer&lt;H&gt;, H&gt; {\n\n    /**\n     * The default name for remember me parameter name and remember me cookie name\n     */\n    private static final String DEFAULT_REMEMBER_ME_NAME = \"remember-me\";\n  \n    ...\n}\n\n\n\n\n이제 웹 브라우저 개발자 모드에서 JSESSIONID 쿠키를 강제로 제거한다면 웹 브라우저에서는 인증 쿠키가 사라지는 것이므로, 서버는 당연히 이후 요청에 대해 인증 요청을 강제할 것입니다.\n\n하지만 웹 브라우저에는 아직 remember-me 쿠키가 남아있으므로, 추가적인 로그인과정 없이도 다시 로그인이 될 것임을 예상해볼 수 있습니다.\n\n\n\n\n\n\n\nJSESSIONID 쿠키를 클릭하여 키보드의 delete키를 입력하면 쿠키가 강제로 제거됩니다.\n\n\n\n\n\n\n\n그리고 다시 서버에 임의의 요청을 보낸다면, 자동적으로 로그인처리가 될 것이므로 JSESSIONID 쿠키가 다시 생겨야만 합니다.\n\n크롬의 강력 새로고침(SHIFT + CTRL + R)기능을 이용하여 서버에 임의의 요청을 보내면…\n\n\n\n\n\n\n\n다시 인증 처리가 되어 새로운 쿠키가 생성돼있음을 확인할 수 있습니다.\n\n이전에 한 설정으로 인해 서버로 오는 모든 요청은 인증이 필요하므로 원래라면 인증 쿠키가 없어 로그인 페이지로 리다이렉트 됐어야 했으나, remember-me 쿠키로 인해 그러한 과정 없이 재 인증이 된 것입니다.\n\n\n\n토큰 기반 Remember-Me 기능의 원리\n\n\n\nremember-me는 인증된 사용자에 대한 여러 정보를 담아 MD5 방식으로 암호화한 토큰입니다.\n\n최초 인증시 인증에 성공할 경우 해당 사용자의 여러 정보를 모아 설정한 키(Key)를 사용해 암호화 하고 해당 값을 사용자에게 돌려주는 것이죠.\n\n사용자가 받는 쿠키는 아래의 정보들을 담고 있습니다.\n\n\n\n\n\n\n\n사용자는 인증 성공 시 인증 성공에 대한 JSESSIONID라는 쿠키와, 자동로그인을 위한 remember-me 라는 이름의 쿠키를 받는 것입니다. (2개)\n\n또한, remember-me 쿠키가 갖고있는 토큰값은 만료날짜, 사용자의 정보등을 추가적으로 집어넣어 암호화함으로써 레인보우 테이블 공격에 대비합니다.\n\n\n  레인보우 테이블\n\n  해커들이 수백만개 이상의 임의의 데이터를 단방향 암호화하여 기록한 테이블이 레인보우 테이블입니다.\n보통 사용자의 민감정보를 안전하게 보관하기 위해 데이터를 단방향으로 암호화 하는데, 암호화를 하였더라도 해당 정보가 탈취된다면,\n이후 레인보우 테이블에서 해당 정보를 검색해보고 일치하는 값이 있을 경우 보안 공격에 노출되게 됩니다.\n\n\n\n\n이후 임의의 사용자로부터 remember-me 쿠키를 이용한 요청이 들어 올 경우, 기본적으로 쿠키는 신뢰할 수 없는 데이터이기 때문에 검증에 들어갑니다.\n\n\n\n\n\n\n\n유효한 시그니처를 만들어내기 위해서는 4가지의 정보가 필요합니다.\n\n\n  사용자명\n  패스워드\n  만료일\n  키\n\n\n\n\n위의 네가지 정보가 모두 올바른 값이라면, 유효한 시그니처가 생성되게 되고, 이 시그니처를 토대로 체크섬하여 유효성을 검증합니다.\n\n\n\n웹 브라우저에서 보내는 remember-me 쿠키에는 세가지의 정보가 들어있습니다.\n\n\n  사용자명\n  만료일\n  시그니처\n\n\n\n\n웹 브라우저에서 보내오는 쿠키에서 시그니처를 만드는데 필요한 사용자명, 만료일을 얻을 수 있습니다.\n\n그리고 서버는 시그니처를 만들 때 사용한 키(Key)를 이미 알고있죠.\n\n따라서 네가지의 정보 중 패스워드만 더 얻으면 시그니처를 만들어낼 수 있으며, 사용자명을 토대로 데이터베이스를 조회하여 패스워드를 얻어올 수 있습니다.\n\n이렇게 remember-me 쿠키로 인증 요청이 들어오면 위의 과정을 거쳐 유효한 시그니처를 만들어내며, 생성된 유효한 시그니처와 remember-me 쿠키에 들어있는 시그니처를 비교합니다.\n\n만약 두 시그니처가 같다면, 해당 쿠키는 신뢰할 수 있는 쿠키이기 때문에 인증 처리 합니다.\n\n\n\n속성\n\n\n\n// file: 'SecurityConfiguration.java'\n@EnableWebSecurity\npublic class SecurityConfiguration extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(final HttpSecurity http) throws Exception {\n        http\n            .rememberMe().key(\"key\") // remember-me 토큰 암호화에 사용할 키를 설정합니다. 기본값은 무작위로 설정된 문자열입니다.\n            .userDetailsService(userDetailsService()) // Remember-Me 기능 설정에 필요한 필수 옵션입니다.\n\n//            .rememberMeParameter(\"remember-me\") // 클라이언트 뷰에서 설정한 파라미터명과 동일해야 합니다. 기본값은 remember-me\n//            .tokenValiditySeconds(86400) // 토큰 유효기간을 설정합니다. 기본값은 14일이며 단위는 초입니다. -1로 설정 할 경우 브라우저가 종료되면 함께 사라집니다.\n//            .alwaysRemember(true) // Remember-Me 기능이 활성화 되지 않아도(체크박스에 체크하지 않아도, 혹은 체크박스가 아예 없더라도) 항상 적용하도록 합니다.\n//            .rememberMeCookieName(\"remember-me\") // Remember-Me 응답 쿠키이름입니다.. 기본값은 remember-me\n\n            .and()\n\n            .formLogin()\n        ;\n    }\n\n}\n\n\n\n\n데이터베이스를 사용한 영구 토큰 기반\n\n\n\n\n\n\n\n\n\n이 방식은 세션-쿠키 방식과 유사하며, 이 방식을 사용하기 위해서는 먼저 두가지 속성을 이해해야 합니다.\n\n\n  \n    시리즈(Series): 사용자가 처음 로그인할 때 생성되는 랜덤한 고유 값이며 불변합니다. 즉, 이후 사용자가 Remember-Me 기능을 이용해 인증을 시도할 때마다 항상 동일한 값을 가집니다. 데이터베이스의 PK(Primary Key)가 됩니다.\n  \n  \n    토큰(Token): 사용자가 Remember-Me 기능을 이용해 인증을 시도할 때마다 계속해서 변경되는 고유 값입니다.\n  \n\n\n\n\n처음 인증 시 인증 토큰을 데이터베이스에 저장해두고, 이후 사용자가 보내오는 쿠키와 데이터베이스의 쿠키를 비교합니다.\n\n따라서 remember-me 쿠키가 탈취당했는지의 여부를 알 수 있고, 만약 쿠키가 탈취당했다면 해당 토큰을 강제로 정지시켜버리거나, 사용자에게 쿠키가 탈취당했음을 경고하는 등의 작업도 할 수 있게 됩니다.\n\n\n\n구현\n\n\n\n데이터베이스는 H2를 사용할것이며, 데이터베이스 접속 방식은 JPA(Hibernate)를 이용할 것입니다.\n\n먼저, 스프링 시큐리티 팀에서 제공하는 DDL을 적용해야 하는데, 이 포스팅에서는 JPA를 이용 할 것이므로 해당 DDL을 참고하여 엔티티를 설계 및 구현합니다.\n\n\n\ncreate table persistent_logins\n(\n    username  varchar(64) not null,\n    series    varchar(64) primary key,\n    token     varchar(64) not null,\n    last_used timestamp   not null\n)\n\n\n\n\n이를 엔티티로 구현하면 대략 다음과 같습니다. 그리고 나중에 사용하게 될 몇가지 메서드를 함께 추가하였습니다.\n\n\n\n@Entity\n@Table(name = \"persistent_logins\")\npublic class PersistentLogin implements Serializable {\n\n    @Id\n    private String series;\n\n    private String username;\n\n    private String token;\n\n    private Date lastUsed;\n\n    // JPA의 한계로 기본생성자가 반드시 필요하지만 private으로는 설정할 수 없다.\n    protected PersistentLogin() {\n    }\n\n    // 생성자를 외부에 노출하지 않습니다.\n    private PersistentLogin(final PersistentRememberMeToken token) {\n        this.series = token.getSeries();\n        this.username = token.getUsername();\n        this.token = token.getTokenValue();\n        this.lastUsed = token.getDate();\n    }\n\n    // 정적 팩토리 메서드\n    public static PersistentLogin from(final PersistentRememberMeToken token) {\n        return new PersistentLogin(token);\n    }\n\n    public String getSeries() {\n        return series;\n    }\n\n    public String getUsername() {\n        return username;\n    }\n\n    public String getToken() {\n        return token;\n    }\n\n    public Date getLastUsed() {\n        return lastUsed;\n    }\n\n    public void updateToken(final String tokenValue, final Date lastUsed) {\n        this.token = tokenValue;\n        this.lastUsed = lastUsed;\n    }\n\n}\n\n\n\n\n이후 위 엔티티를 데이터베이스와 결합하게 도와줄 JPA Repository를 작성합니다.\n\n\n\npublic interface PersistentLoginRepository extends JpaRepository&lt;PersistentLogin, String&gt; {\n\n    Optional&lt;PersistentLogin&gt; findBySeries(final String series);\n\n    List&lt;PersistentLogin&gt; findByUsername(final String username);\n\n}\n\n\n\n\n그리고 위에서 작성한 구현체들을 스프링 시큐리티에서 제공하는 PersistentTokenRepository로 확장해줘야 합니다.\n\n이렇게 하는 이유는, SecurityConfiguration에서 Remember-Me 기능을 데이터베이스 기반 토큰 방식으로 구현 할 경우 데이터베이스에 접근 할 때 사용할 Repository 구현체를 요구하게 되는데, 기본적으로 스프링 시큐리티에서 JPA를 이용한 구현체가 제공되지 않기 때문에 이 구현체를 직접 구현해 확장하는 것입니다.\n\n\n\n// PersistentTokenRepository에서 요구하는 네가지 메서드를 재정의(Override)하도록 합니다.\npublic class JpaPersistentTokenRepository implements PersistentTokenRepository {\n\n    // 스프링 팀에서 권장하는 생성자 DI를 이용합니다\n    private final PersistentLoginRepository repository;\n\n    public JpaPersistentTokenRepository(final PersistentLoginRepository repository) {\n        this.repository = repository;\n    }\n\n    // 새로운 remember-me 쿠키를 발급할 때 담을 토큰을 생성하기 위한 메서드입니다.\n    @Override\n    public void createNewToken(final PersistentRememberMeToken token) {\n        repository.save(PersistentLogin.from(token));\n    }\n\n    // 토큰을 변경할때 호출될 메서드입니다.\n    @Override\n    public void updateToken(final String series, final String tokenValue, final Date lastUsed) {\n        repository.findBySeries(series)\n            .ifPresent(persistentLogin -&gt; {\n                persistentLogin.updateToken(tokenValue, lastUsed);\n                repository.save(persistentLogin);\n            });\n    }\n\n    // 사용자에게서 remember-me 쿠키를 이용한 인증 요청이 들어올 경우 호출될 메서드입니다.\n    // 사용자가 보내온 쿠키에 담긴 시리즈로 데이터베이스를 검색해 토큰을 찾습니다.\n    @Override\n    public PersistentRememberMeToken getTokenForSeries(final String seriesId) {\n        return repository.findBySeries(seriesId)\n            .map(persistentLogin -&gt;\n                new PersistentRememberMeToken(\n                    persistentLogin.getUsername(),\n                    persistentLogin.getSeries(),\n                    persistentLogin.getToken(),\n                    persistentLogin.getLastUsed()\n                ))\n            .orElseThrow(IllegalArgumentException::new);\n    }\n\n    // 세션이 종료될 경우 데이터베이스에서 영구 토큰을 제거합니다.\n    @Override\n    public void removeUserTokens(final String username) {\n        repository.deleteAllInBatch(repository.findByUsername(username));\n    }\n\n}\n\n\n\n\n그리고 위의 커스텀 구현체들을 SecurityConfiguration에  추가해줍니다.\n\n테스트를 위해 몇가지 설정을 더 추가하였으나, 이 포스팅의 상단에서 설정한 것과 크게 달라진 것은 없을 것입니다.\n\n\n\n@EnableWebSecurity\npublic class SecurityConfiguration extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private PersistentTokenRepository tokenRepository;\n\n\n    @Override\n    protected void configure(final AuthenticationManagerBuilder auth) throws Exception {\n        auth\n            .inMemoryAuthentication()\n            .withUser(\"test\").password(\"{noop}test\").authorities(\"ROLE_USER\");\n    }\n\n    @Override\n    protected void configure(final HttpSecurity http) throws Exception {\n        http\n            .csrf().disable() // 테스트 편의성을 위해 CSRF 비활성화\n            .headers().frameOptions().sameOrigin() // H2-Console에 접속해 영구 토큰을 확인하기 위해 설정\n\n            .and()\n\n            .authorizeRequests() // 서버로 오는 요청들에 대한 보안 정책\n            .antMatchers(\"/h2-console/**\").permitAll() // H2-Console에 접속해 영구 토큰을 확인하기 위해 설정\n            .anyRequest().authenticated() // 모든 요청에 대해 인증이 필요합니다.\n\n            .and()\n\n            .rememberMe().key(\"key\") // remember-me 토큰 암호화에 사용할 키를 설정합니다. 기본값은 무작위로 설정된 문자열입니다.\n            .userDetailsService(userDetailsService()) // Remember-Me 기능 설정에 필요한 필수 옵션\n            .tokenRepository(tokenRepository)\n\n//            .rememberMeParameter(\"remember-me\") // 클라이언트 뷰에서 설정한 파라미터명과 동일해야 한다. 기본값은 remember-me\n//            .tokenValiditySeconds(86400) // 토큰 유효기간을 설정한다. 기본값은 14일이며 초단위이다. -1로 설정 할 경우 브라우저가 종료되면 함께 사라진다.\n//            .alwaysRemember(true) // Remember-Me 기능이 활성화 되지 않아도(체크박스에 체크하지 않아도, 혹은 체크박스가 아예 없더라도) 항상 적용하도록 한다.\n//            .rememberMeCookieName(\"remember-me\") // Remember-Me 응답 쿠키이름. 기본값은 remember-me\n\n            .and()\n\n            .formLogin()\n        ;\n    }\n\n    @Bean\n    public PersistentTokenRepository persistentTokenRepository(final PersistentLoginRepository repository) {\n        return new JpaPersistentTokenRepository(repository);\n    }\n\n}\n\n\n\n\n그리고 간단한 테스트를 위해 프로젝트 설정을 조금 추가해줍니다.\n\n\n\n# file: 'resources/application.yaml'\nspring:\n  h2:\n    console:\n      enabled: true\n  jpa:\n    show-sql: true\n    properties:\n      hibernate:\n        format_sql: true\n    hibernate:\n      ddl-auto: create\n\n\n\n\n이후 서버를 기동하면 서버 콘솔에 로그가 쭉 뜨는데, 그중 다음과 같은 로그를 찾습니다.\n\n\n\n2021-10-12 11:37:38.744  INFO 10844 --- [  restartedMain] o.s.b.a.h2.H2ConsoleAutoConfiguration    : H2 console available at '/h2-console'. Database available at 'jdbc:h2:mem:b1152f26-a567-4c05-9bf4-4f4260366b44'\n\n\n\n\n스프링 설정에 H2 콘솔을 사용할 것이라고 설정했기 때문에 스프링에서 인메모리 데이터베이스 콘솔에 접속할 수 있는 수단을 제공해줍니다.\n\n서버가 기동된 후 http://localhost:8080/h2-console/ 로 접속하면 다음과 같은 화면에 들어갈 수 있는데, 위에서 찾은 JDBC URL을 입력합니다.\n\n\n\n\n\n\n\n이후 접속하면 다음과 같은 화면이 뜹니다.\n\n\n\n\n\n\n\n\n  화면 좌측 메뉴의 PERSISTENT_LOGINS 를 클릭하면 우측 콘솔에 SELECT 쿼리가 생성됩니다.\n  바로 위의 RUN을 누르면 생성된 쿼리가 실행됩니다.\n  화면 하단에 쿼리의 결과가 노출됩니다.\n\n\n\n\n현재는 로그인을 단 한번도 하지 않았으므로 데이터베이스에 토큰이 없는것이 당연합니다.\n\nlocalhost:8080/login으로 접속해 아이디와 비밀번호(test/test)를 입력하고, Remember-Me 기능을 사용할 것임을 체크하고 로그인한 뒤 다시 H2 콘솔을 확인하도록 합니다.\n\n\n\n\n\n\n\n우선 로그인 후 역시 remember-me 쿠키가 잘 응답된 것을 확인할 수 있습니다.\n\n\n\n\n\n\n\nH2 콘솔에 접속 후 동일한 쿼리를 실행하면 위와 같이 새로운 영구토큰이 데이터베이스에 저장됐음도 확인할 수 있습니다.\n\n\n\n이후 로그아웃이 될 경우 세션 종료를 의미하기 때문에, 클라이언트에 설정된 remember-me 쿠키와 데이터베이스에 저장된 영구 토큰이 모두 제거되어야만 합니다.\n\nlocalhost:8080/logout으로 접속하여 로그아웃한 후 다시 한번 더 확인해봅니다.\n\n\n\n\n\n\n\n\n\n\n\n모두 성공적으로 제거된 것을 확인할 수 있습니다.\n\n\n\n확장\n\n\n\n여기까지는 remember-me 쿠키를 영속성 레이어(Persistent Layer)에 저장하고 관리하는 기본적인 방법들에 대해 알아봤습니다.\n\n\n\n만약 쿠키에 대한 추가적인 제어가 필요하다면 스프링 시큐리티에서 제공하는 PersistentTokenBasedRememberMeServices를 통해 다음과 같이 간단하게 몇가지 제어를 더 추가할 수 있으며, 더욱 복잡한 구성이 필요 할 경우 PersistentTokenBasedRememberMeServices를 확장하면 되겠습니다.\n\n\n\n// file: 'SecurityConfiguration.java'\n@Bean\npublic PersistentTokenBasedRememberMeServices rememberMeServices(final PersistentTokenRepository repository) {\n  PersistentTokenBasedRememberMeServices services = new PersistentTokenBasedRememberMeServices(\"key\", userDetailsService(), repository);\n\n  services.setAlwaysRemember(true);\n  services.setParameter(\"remember-me-param-name\");\n\n  return services;\n}\n\n\n\n\n위 방식의 경우 만료된 토큰들에 대한 상세한 제어가 없습니다.\n\n따라서 만료된 토큰들을 주기적으로 데이터베이스에서 제거하는 코드를 추가로 작성합니다.\n\n\n\n// Runnable을 구현하여 별도의 스레드로 동작시키도록 합니다.\npublic class ExpiredTokenJpaRepositoryCleaner implements Runnable {\n\n    private final PersistentLoginRepository repository;\n    private final long tokenValidityInMs;\n\n    private ExpiredTokenJpaRepositoryCleaner(final PersistentLoginRepository repository, final long tokenValidityInMs) {\n        if (isNull(repository)) {\n            throw new IllegalArgumentException(\"PersistentTokenRepository cannot be null.\");\n        }\n\n        if (tokenValidityInMs &lt; 1) {\n            throw new IllegalArgumentException(\"tokenValidityInMs must be greater than 0. Got \" + tokenValidityInMs);\n        }\n\n        this.repository = repository;\n        this.tokenValidityInMs = tokenValidityInMs;\n    }\n\n    public static ExpiredTokenJpaRepositoryCleaner of(final PersistentLoginRepository repository, final long tokenValidityInMs) {\n        return new ExpiredTokenJpaRepositoryCleaner(repository, tokenValidityInMs);\n    }\n\n    @Override\n    public void run() {\n        final long expiredInMs = System.currentTimeMillis() - tokenValidityInMs;\n        repository.deleteAllInBatch(repository.findByLastUsedAfter(new Date(expiredInMs)));\n    }\n\n}\n\n\n\n\n이제 위의 설정을 스프링에서 제공하는 스케쥴러를 이용해 주기적으로 실행시키도록 하면 됩니다.\n\n\n\n@Configuration\n@EnableScheduling\npublic class ScheduleConfigurer {\n\n    private final PersistentLoginRepository persistentLoginRepository;\n\n    public ScheduleConfigurer(final PersistentLoginRepository persistentLoginRepository) {\n        this.persistentLoginRepository = persistentLoginRepository;\n    }\n\n    @Scheduled(fixedDelay = 10_000) // 단위는 ms. 따라서 1,000=1초. 10초에 한번 실행됨을 의미함.\n    public void cleanExpiredTokens() {\n        // 토큰의 유효시간이 10초\n        new Thread(ExpiredTokenJpaRepositoryCleaner.of(persistentLoginRepository, 10_000L))\n            .start();\n    }\n\n}\n\n\n\n\n이후 서버를 기동하고 로그인을 하면 remember-me 쿠키가 발급되고, 토큰의 유효기간을 10초로 설정하였으므로 약 10초 후에 다음과 같은 쿼리가 발생합니다.\n\n\n\nHibernate: \n    select\n        persistent0_.series as series1_0_,\n        persistent0_.last_used as last_use2_0_,\n        persistent0_.token as token3_0_,\n        persistent0_.username as username4_0_ \n    from\n        persistent_logins persistent0_ \n    where\n        persistent0_.last_used&gt;?\nHibernate: \n    delete \n    from\n        persistent_logins \n    where\n        series=?\n\n\n\n\n참고\n\n\n\n\n  Spring Security - Third Edition: Secure your web applications, RESTful services, and microservice architectures (ISBN 9781787129511)\n\n",
      "categories": ["spring","spring-security"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-security/2021-10-08-remember-me/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "URL과 리소스",
      "date": "2021-10-09 00:00:00 +0000",
      "description": "HTTP 완벽 가이드 2장 정리\n",
      "content": "\n  URI(Uniform Resource Identifier)\n  URL(Uniform Resource Locator)    \n      URL 상세        \n          상대경로\n          URL 예제\n          URL 인코딩            \n              제한된 문자\n            \n          \n        \n      \n    \n  \n  URN(Uniform Resource Name)\n\n\n\n\nURI(Uniform Resource Identifier)\n\n\n\n책에서는 URI(Uniform Resource Identifier) 는 URL(Uniform Resource Locator), URN(Uniform Resource Name) 로 이루어진 종합적인 개념이라고 소개합니다.\n\n\n\n\n\n\n\nURI는 한국어로 표현하면 통합 자원 식별자 정도로 표현할 수 있을 것 같은데, 이 용어 역시 제대로 와닿는 용어는 아닙니다.\n\n제가 생각하는 URI는 리소스를 식별할 수 있는 문자의 나열입니다.\n\n여기서 리소스(Resource)가 아주 핵심적인데, 이 리소스가 무엇이냐 ?\n\nRFC-2396 Overview of URI 에서는 리소스에 대해 다음과 같이 말합니다.\n\n\n\n\n  Resource\n\n  A resource can be anything that has identity.\n\n  Familiar\nexamples include an electronic document, an image, a service\n(e.g., “today’s weather report for Los Angeles”), and a\ncollection of other resources.\n\n  Not all resources are network\n“retrievable”; e.g., human beings, corporations, and bound\nbooks in a library can also be considered resources.\n\n\n\n\n동영상, 이미지, 전자문서, 실시간 교통흐름, 환율 등 식별할 수 있는 모든것은 리소스(자원)가 될 수 있다고 합니다.\n\n단, 모든 리소스가 항상 검색엔진에서 검색 가능하지는 않다고 하네요.\n\n\n\n즉, 웹에서 사용되는 리소스를 식별하기 위한 모든 문자열의 나열은 URI라고 불러도 무방할 것 같습니다.\n\n\n\nURL(Uniform Resource Locator)\n\n\n\nURL은 많이 들어보셨을 것입니다.\n\nURL은 리소스의 정확한 위치를 표현한 것입니다.\n\n여기서 URI와 URL의 차이점이 무엇이냐? 라는 의문이 드실 수 있습니다.\n\n일단 URL은 URI의 부분집합으로서 모든 URL은 URI라고 불러도 무방합니다.\n\n\n\n더 자세한 차이에 대해 설명드리자면 제 블로그(https://shirohoo.github.io/) 에서 index.html 이라는 리소스를 찾고자 할 때 웹 브라우저에 다음과 같은 문자열들을 입력할 수 있습니다.\n\n\n\n\n  URI: https://shirohoo.github.io/index\n  URL: https://shirohoo.github.io/index.html\n\n\n\n\nURI와 URL은 이 정도의 차이라고 볼 수 있습니다.\n\n위의 URI와 URL은 웹 브라우저에 입력 시 같은 결과를 반환하며, URL은 보시다시피 index.html이라는 리소스의 위치까지 정확하게 표현한 것이고, URI는 리소스의 정확한 위치를 표현하지 않더라도 내부적인 매핑등으로 인해 어느정도 해당 리소스의 위치를 파악할 수 있기 때문에 역시 index.html을 반환합니다.\n\n즉, 완벽하게 다 입력하지 않더라도 이미 해당 리소스를 식별할 수 있다는 뜻입니다.\n\n\n\nURL 상세\n\n\n\nURL 문법은 대체로 9개의 컴포넌트로 나눠집니다.\n\n\n\n\n\n\n\n\n  \n    \n      컴포넌트\n      설명\n      기본값\n    \n  \n  \n    \n      scheme(=protocol)\n      리소스를 가져오기 위해 어떤 프로토콜을 사용해 서버에 접근할지를 기술합니다.\n      -\n    \n    \n      username\n      특정 프로토콜은 사용자 이름을 요구하는 경우가 있습니다.\n      anonymous\n    \n    \n      password\n      사용자의 비밀번호를 의미합니다.\n      email\n    \n    \n      host\n      리소스를 호스팅하는 서버의 IP나 도메인을 의미합니다.\n      -\n    \n    \n      port\n      리소스를 호스팅하는 서버가 오픈한 포트 번호 입니다. 프로토콜에 따라 다를 수 있고, Well Known Port의 경우 생략 가능합니다.\n      프로토콜에 따라 다름\n    \n    \n      path\n      해당 리소스가 서버의 어떤 위치에 존재하는지에 대한 표현으로, /표시로 구분됩니다.\n      -\n    \n    \n      parameter\n      특정 프로토콜에서 필요한 입력 파라미터를 기술하는 용도로 쓰입니다.\n      -\n    \n    \n      query\n      서버에 찾고자하는 리소스에 대한 정보를 보낼때 사용합니다. 키=값으로 이루어져 있으며, ?문자로 시작되며 쿼리를 추가할 때 &amp;를 통해 이어붙입니다. 보통 쿼리스트링이라고도 부릅니다.\n      -\n    \n    \n      fragment\n      리소스의 특정 부분에 대한것을 기술할 때 사용됩니다. 주로 ToC와 같이 문서의 목차등에서 사용되며 #문자로 구분됩니다.\n      -\n    \n  \n\n\n\n\n상대경로\n\n\n\nURL에서 사용되는걸 본적은 많이 없는 것 같고, 오히려 프로그래밍을 할 때 많이 사용되는 부분인 것 같습니다.\n\n두 가지만 기억하시면 됩니다.\n\n\n\n\n  . 은 현재 위치를 기준으로 합니다.\n  .. 은 현재 위치의 상위 경로를 기준으로 합니다.\n\n\n\n\nURL 예제\n\n\n\n\n  Web URL 1\n\n\n\n\n\n  Web URL 2\n\n\n\n\n\n  Database URL\n\n\n\n\n\n\nURL 인코딩\n\n\n\n특정 프로토콜에서 URL이 소실되는 경우를 방지하기 위해 URL에 안전하지 않은 문자가 포함 된 경우 이를 인코딩합니다.\n\n여기서 안전하지 않은 문자라 하면, ASCII로 대체할 수 없는 문자를 의미하며, 이러한 모든 안전하지 않은 문자를 %와 ASCII 코드로 시작되는 두 개의 16진수 숫자로 변경합니다.\n\n이를 URL Encoding 혹은 Percent Encoding 이라고 부릅니다.\n\n인코딩 방식은 주로 UTF-8이 사용되며, EUC-KR도 종종 사용됩니다.\n\n\n\n아래와 같은 URL이 있다고 가정합니다.\n\n\n\n\n  http://www.example.com/?value=”&gt;”\n\n\n\n\n이 URL에는 안전하지 않은 문자가 포함되므로 아래와 같이 인코딩 됩니다.\n\n\n\n\n  http://www.example.com/?value=%22%3E%22\n\n\n\n\n제한된 문자\n\n\n\n프로그래밍에는 흔히 예약어라고 불리는, 어떤 특수한 목적을 갖는 문자들이 반드시 존재합니다.\n\nURL에도 이와 비슷한 개념이 존재합니다.\n\n관련 내용은 RFC-3986 Percent-Encoding 에 아주 상세히 작성돼있으며, 간략한 내용은 위키백과의 내용을 첨부합니다.\n\n\n\n\n\n\n\nURN(Uniform Resource Name)\n\n\n\nURL의 단점을 해결하기 위해 나온 방식입니다.\n\nURL의 경우 리소스의 정확한 위치를 표현하는데, 만약 서버에서 해당 리소스의 실제 위치가 바뀐다면?\n\n그 즉시 해당 리소스의 위치를 표현하던 URL은 아무런 의미를 갖지 못하게 됩니다.\n\n따라서 서버에서 URL을 한번 외부로 노출시키면 해당 URL은 하위호환성을 고려할 때 함부로 변경할 수 없어지게 되는 것이죠.\n\n\n\nURN은 이러한 문제에서 자유롭습니다.\n\nURN은 문법상 urn:카테고리:식별자로 사용된다고 하는데, 저는 아직 URN을 사용하는 경우를 단 한번도 보지 못했습니다.\n\n예제는 다음과 같습니다.\n\n\n\n\n  urn:isbn:1251795 - 어떤 ISBN 번호로 책을 식별합니다.\n  urn:uuid:7e3bd412-2n5a-23h9-3769-1950342c9a51 - 어디서나 사용 가능한 중복되지 않는 고유한 식별자입니다.\n\n\n\n\n이전에 URL을 URN으로 대체하려는 시도가 한번 있었다고 하는데, 잘 되지 않았다고 합니다.\n\nURL에 분명한 한계가 존재하긴 하지만, 이미 범용적으로 잘 사용되고 있는 상황에 세계적인 범위로 이를 대체하는게 쉽지 않은 작업이었다고 하네요.\n\n하지만 먼 미래에는 URN으로 모두 대체될 것이라는 이야기가 분명히 존재하는 만큼, 이러한 것도 있다는 것은 알고 있어야 할 것 같습니다.\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-10-09-url-resource/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "에라토스테네스의 체",
      "date": "2021-10-18 00:00:00 +0000",
      "description": "CS와 PS\n",
      "content": "\n  소수(Prime Number)\n  에라토스테네스의 체\n  구현\n\n\n\n\n소수(Prime Number)\n\n\n\n우선 소수(Prime Number)의 사전적 정의를 찾아보니 1과 자기 자신으로밖에 나누어 떨어지지 않고 자기 자신의 곱셈의 역수가 없는 수 라고 합니다.\n\n여기서 1은 기초수라 부르며, 소수도 합성수도 아니라고 합니다.\n\n일단 항상 뭔가를 학습하기 전 왜 배워야 하는가?와 그 이유가 타당하다면 그 이유에 대한 수용으로 인해 발생하는 동기부여가 중요하다고 생각하기 때문에, 우선 소수를 왜 구해야 하는가?가 궁금해 찾아보니, 소인수 분해에 쓰이기 때문이라고 하네요.\n\n그럼 소인수 분해는 무엇인가?\n\n단어만 보면 소인수를 분해한다는 것인데, 저는 소인수가 정확히 무슨 의미를 갖는 단어인지 기억이 안났습니다.\n\n그래서 소인수의 사전적 정의를 찾아보니 어떤 수의 약수인 소수를 소인수라고 한다고 합니다.\n\n그렇다면 인수는 어떤 수의 약수를 뜻하며, 그 약수가 소수라면 소인수라는 것임을 알 수 있습니다.\n\n문제는 여기까지 이해하고서 그럼 소인수분해는 왜 알아야하고 왜 배워야하는가? 에 대한 답을 찾지 못했기 때문에, 이후로 동기부여가 썩 잘되진 않았습니다.\n\n아무튼 이렇다고 하니 이제 이 소수를 찾는 알고리즘인 에라토스테네스의 체를 알아봅시다.\n\n\n\n에라토스테네스의 체\n\n\n\n\n\n\n\n자연수 n이 주어지면 1부터 n까지의 자연수 중 모든 소수(Prime Number)를 구하는 현존하는 가장 빠른 알고리즘이라고 합니다.\n\n좀 찾아보니 수식과 어려운 용어가 굉장히 많이 나오는데, 저는 이런걸 잘 못하기 때문에 나름대로 최대한 쉽게 이해해서 구현했습니다.\n\n\n\n우선 소수를 구하기 위해서는 1과 자기자신만을 약수로 갖는지를 판별하면 됩니다.\n\n예를 들어 n=20 이라고 쳤을 때 20의 약수는 다음과 같습니다.\n\n\n\n\n  1 2 4 5 10 20\n\n\n\n\n1과 20만 약수로 가지면 20은 소수인데, 그렇지 않으니 20은 소수가 아닌 합성수입니다.\n\nn=30일 경우의 약수를 구해보면,\n\n\n\n\n  1 2 3 5 6 10 15 30\n\n\n\n\n역시 30도 소수가 아닙니다.\n\n위의 간단한 계산에서 알 수 있는 사실이 있는데, 약수를 구하는 방법은 대칭성을 갖는다는 것입니다.\n\n약수는 1부터 시작하며, 가장 큰 약수는 n을 1로 나누었을 때(n/1)의 값인 30입니다.\n\n따라서 다음과 같습니다.\n\n\n\n\n  1                 30\n\n\n\n\n다음으로 30을 2로 나누어 보면 15로 나누어 떨어지기 때문에 두 수도 30의 약수입니다.\n\n\n\n\n  1 2            15 30\n\n\n\n\n이런식으로 대칭성을 띄게 됩니다.\n\n이렇게 약수의 대칭성에 소수는 소수로 나누어떨어지지 않는다는 특징을 더하면 아래와 같은 방식이 됩니다.\n\n\n\n1은 기초수이니 제외하고 2부터 n-1의 범위에 속하는 자연수가 약수로 존재하지 않는다면 소수이며, 최단 연산을 하려면 2부터 n의 제곱근 미만인 소수로 n을 모조리 나눠보면 됩니다.\n\n그리고 나누어 떨어지지 않고 살아남은 자연수는 모두 소수가 되는것이죠.\n\n\n\n1부터 10까지의 모든 소수를 구한다고 가정합니다.\n\n10의 제곱근은 3.16입니다. 따라서 3.16보다 작은 소수인 3까지만 연산하면 됩니다.\n\n\n\n\n  1 2 3 4 5 6 7 8 9 10\n\n\n기초수인 1을 지웁니다.\n\n\n  2 3 4 5 6 7 8 9 10\n\n\n2를 제외한 2의 배수를 모두 지웁니다.\n\n\n  1 2 3 5 7 9\n\n\n3을 제외한 3의 배수를 모두 지웁니다.\n\n\n  1 2 3 5 7\n\n\n4는 소수가 아니며, 이미 2의 배수를 지울때 지워졌으니 스킵합니다.\n\n5는 소수이지만 10의 제곱근인 3.16보다 높은 자연수이므로 역시 더이상 연산 할 필요가 없습니다.\n\n즉, 3의 배수를 모두 제거한 시점에서 남은 모든 자연수는 소수입니다.\n\n이를 코드로 구현하면 다음과 같습니다.\n\n\n\n구현\n\n\n\npublic class PrimeNumberTest {\n\n    @Test\n    void getPrimeNumber() throws Exception {\n        final int range = 50;\n\n        List&lt;Integer&gt; primeNumbers = new ArrayList&lt;&gt;(range);\n        for (int i = 2; i &lt; range; i++) {\n            if (isPrimeNumber(i)) {\n                primeNumbers.add(i);\n            }\n        }\n\n        // 50이하의 모든 소수 출력\n        // [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\n        System.out.println(primeNumbers);\n    }\n\n    private boolean isPrimeNumber(final int number) {\n        int divider = 2;\n        while (divider * divider &lt;= number) { // 약수는 대칭성을 보이므로 n의 제곱근만큼 순회하면 모든 약수를 판별할 수 있다\n            if (number % divider == 0) { // 1과 자기자신을 제외한 어떤수로도 나누어 떨어지기만 하면 소수가 아님\n                return false;\n            }\n            divider++; // 나누어 떨어지지 않았다면 나눔수를 1증가시키고 다음 루프를 시작한다\n        }\n        return true; // number 의 제곱근만큼 순회하며 모두 나누었음에도 나누어 떨어지지 않았다면 소수이다\n    }\n\n}\n\n\n\n\nn까지의 모든 소수를 구하고, 구한 소수의 개수를 반환하는 알고리즘을 자바 8 스타일로 구현한다면 다음과 같습니다.\n\n\n\npublic class SieveOfEratosthenes {\n\n    public long solution(final int value) {\n        return range(2, value + 1) // value가 20일 경우 2~20까지의 수를 생성해야하는데, 레인지 함수는 인덱스 시작이 0부터이므로 +1 연산을 해준다.\n            .filter(this::isPrimeNumber)\n            .count();\n    }\n\n    private boolean isPrimeNumber(final int number) {\n        return range(2, getRangeEnd(number) + 1) // 레인지 함수는 인덱스 시작이 0부터이므로 +1 연산을 해준다.\n            .noneMatch(divisorOf(number));\n    }\n\n    private int getRangeEnd(final int number) {\n        return toIntExact(round(sqrt(number)));\n    }\n\n    private IntPredicate divisorOf(final int number) {\n        return divider -&gt; number % divider == 0;\n    }\n\n}\n\n\n\n",
      "categories": ["cs","data-structure-algorithm"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/data-structure-algorithm/2021-10-18-sieve-eratosthenes/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "밑바닥부터 만드는 컴퓨팅 시스템 진행기",
      "date": "2021-10-24 00:00:00 +0000",
      "description": "CS 지식을 쌓기위한 여정…\n",
      "content": "\n  밑바닥부터 만드는 컴퓨팅 시스템\n\n\n\n\n밑바닥부터 만드는 컴퓨팅 시스템\n\n\n\n비전공자로 개발에 입문하면서 CS지식이 빈약했던 나는 CS공부가 참 어렵다고 생각하고 있었다.\n\n실제로 개발할때와 대학에서 배우는 CS 지식간에 괴리감이 있었기 때문이다.\n\n그러니까, KOCW등을 통해 컴공 과목을 수강해봐도, “이거 이렇게 배워서 내가 개발하는데 도움받을 일이 있을까?”\n\n라는 생각이 많이 들었고, 이 부분에서 동기부여가 잘 되지 않았던 것 같다.\n\n\n\n아무튼 그런 생각을 항상 갖고 있었는데 넥스트 스텝 과정을 진행할 때 박재성님이 아드님과 진행하셨다는 밑바닥부터 만드는 컴퓨팅 시스템 스터디에 대해 감명 깊게 들었었다.\n\n이 책은 컴퓨터를 직접 만들어보면서 컴퓨터가 어떤 것인지, 어떤 원리로 동작하는지를 이해하는데 목적을 두고있는 책이였다.\n\n즉시 승재님과 이 책으로 스터디를 하기로 모의하고 실행에 옮겼다.\n\n주말 하루에 둘이 만나서 약 7시간 가량의 스터디를 매주 진행해보자는 것이었다.\n\n\n\n1장은 불 논리였는데 OR, AND, NAND 등의 기본 게이트를 이해하고 진리표를 작성하고 회로도를 그린 후 HDL이라는 언어로 코딩을 하여 칩을 구성하는 것이었다.\n\n처음엔 별 생각이 없었다. “OR? 입력값 두개를 더하는거네”. “AND? 입력값 두개를 곱하는거네” 등등\n\n이정도만 이해하고 HDL로 코딩해보니 그냥 바로바로 통과가 됐기 때문이다.\n\n중요한건 진리표와 회로도를 직접 그려보고 이를 더욱 효율적으로 간소화하는 작업이었는데, 이걸 간과했던 것이다. (이때는 몰랐다 😎)\n\n아무튼 그렇게 알맹이만 쏙 빼먹은 채로 진행을 하다보니 ALU를 구현하는데서 바로 벽을 만나버렸다.\n\n\n\n\n\n\n\n…\n\n\n\n\n\n\n\n이 시점에 우리 둘은 뭔가 단단히 잘못됐다는 것을 깨닫게 됐다.\n\n“아! 이렇게 공부해봐야 아무런 의미가 없다. 다시 처음으로 돌아가자. 하나를 하더라도 제대로 해보자.”\n\n\n\n관련 자료들을 최대한 찾아보니 우리가 이번 스터디의 1장을 어떻게 진행해야 하는지를 알 수 있었고, 새로운 방식을 적용해 이 책의 1장부터 다시 시작했다.\n\n방법은 이랬다.\n\n\n\n\n  논리 게이트의 진리표를 먼저 그린다.\n  진리표를 토대로 논리식을 도출한다.\n  논리식을 더욱 간소화할 수 있는지 분석한다.\n  더 이상 간소화할 수 없다고 생각되면 회로도를 그려본다.\n  이를 HDL로 옮긴다.\n  테스트 코드를 실행하고 통과되는지 확인한다.\n\n\n\n\n입력이 2개인 XOR 게이트를 기준으로 설명하자면 이렇게 진행이 됐다.\n\n배타적 논리합(XOR)은 두 입력이 다를 경우에만 참을 반환한다. 이것을 이해하고 진리표를 작성한다.\n\n\n\n\n\n\n\n이제 작성한 진리표에서 논리식을 도출해낸다.\n\n이 때 결과가 1이 나오는 경우만 따져서 식을 도출해야 간소화가 조금 더 편해진다.\n\n\n\n\n\n\n\n위의 수식은 내 생각에 더 이상 간소화할 수 없으므로 회로도로 그린다.\n\n(첨언하자면, 이 수식을 진리표로 그려보면 XOR의 진리표와 같음을 알 수 있다.)\n\n\n\n\n\n\n\n이것을 HDL로 옮긴다.\n\n\n\nCHIP Xor {\n    IN a, b;\n    OUT out;\n\n    PARTS:\n    Not(in=a, out=nota);\n\tNot(in=b, out=notb);\n\tAnd(a=a, b=notb, out=o1);\n\tAnd(a=nota, b=b, out=o2);\n\tOr(a=o1, b=o2, out=out);\n}\n\n\n\n\n그리고 위에 작성한 코드를 밑바닥부터 만드는 컴퓨팅 시스템에서 제공해주는 시뮬레이터에 세팅하고, 같이 제공 된 테스트 코드도 함께 세팅한 다음 실행해본다.\n\n\n\n\n\n…성공! 이때의 희열은 이루 말로 할 수 없었다!\n\n\n\n(대략 무지막지한 노가다와 삽질의 흔적들… 수십장 되는 듯 하다… 😱)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“이걸 배워서 어디다 써먹어야 될까?” 같은 생각을 떠나서 그냥 참 재미있다고 느꼈다.\n\nCS를 공부하면서 이런 감정을 느껴본건 처음이었던 것 같다. 왜일까?\n\n이것을 해내기 위해 수시간 동안 디지털논리회로 과목의 기초를 보며 명제, 카르노맵, 분배 법칙, 결합 법칙, 흡수 법칙, 교환 법칙, 드모르간의 법칙 등과, 컴퓨터가 사칙연산을 어떻게 덧셈으로만 다 해낼 수 있는지.\n\n반가산기, 전가산기 등이 왜 중요한지 등등 정말 많은 개념을 학습해야만 했다.\n\n아무튼 이런 개념들을 학습하고 즉시 코드에 적용 해 결과물을 받아볼 수 있다는 것은, 내가 현재 학습하고 있는 지식들이 죽은 지식이 아닌 살아있는 지식임을 느끼게 해주었고, 이것이 내게 흥미와 재미로 다가왔던 것 같다.\n\n\n\n한참동안 2진수에 대해 학습하다 문득 승재님과 재미있는 것을 하나 했다.\n\n우리가 학습한 내용을 응용해보면 홀수 짝수 연산을 조금 더 효율적으로 할 수 있지 않을까 였다.\n\n\n\n역시 많은 삽질이 있었지만, 우리가 깨달은 내용은 이랬다.\n\n2진수의 각 자릿수는 2의 거듭제곱으로 표현되는데, 여기서 가장 오른쪽 자리수만이 유일하게 2의 거듭제곱이면서도 홀수인 1을 나타낸다. (2^0 == 1)\n\n즉, 2의 거듭제곱을 쭉 나열해보면 1,2,4,8,16,32,64 … 여기서 1을 제외한 모든 수가 짝수이다.\n\n나중에 안 사실인데 이를 최하위비트(Least Significant Bit, LSB)라고 부른다고 하더라.\n\n아무튼 예를 들면 다음과 같다.\n\n\n\n짝수인 8을 2진수로 변환하면 1000 이다.\n\n홀수인 9를 2진수로 변환하면 1001 이다.\n\n짝수인 10을 2진수로 변환하면 1010 이다.\n\n홀수인 11을 2진수로 변환하면 1011 이다.\n\n\n\n여기서 어떤 법칙을 발견했다.\n\n최하위비트가 1이면 홀수, 0이면 짝수인 것.\n\n이 발상에 착안 해 인수가 짝수라면 true를 반환하고 홀수라면 false를 반환하는 함수를 자바로 구현하니 다음과 같은 코드가 나왔다.\n\n\n\nreturn (number &amp; 1) == 0;\n\n\n\n\n어떻게 위와 같은 코드가 나오게 되는 것일까?\n\n\n\nnumber는 자바의 비트연산자로 인해 2진수로 형변환이 되며, 1 역시 같은 비트를 갖는 2진수로 형변환이 된다.\n\n즉, number=8이라면 이는 1000으로 형변환이 되며, 1은 0001로 형변환이 되게 되며, 이를 논리곱연산(&amp;) 하면 각 자릿수끼리 곱셈하게 된다.\n\n\n\n\n\n\n\nnumber=9인 경우를 보자.\n\n9는 1001로 변환되고, 1 역시 같은 비트수를 갖는 0001로 변환된다.\n\n\n\n\n\n\n\n즉, 두 2진수의 논리곱 결과가 10진수 0이라면 짝수, 1이라면 홀수라는 결론이 나온다.\n\n그리고 이 코드의 성능이 궁금해져 JMH로 성능 측정을 해봤다.\n\n@BenchmarkMode(Mode.Throughput)\n@OutputTimeUnit(TimeUnit.NANOSECONDS)\npublic class EvenNumberChecker {\n\n    @Benchmark\n    public void isEvenNumber(Blackhole bh) {\n        for (int i = 0; i &lt; 100_000_000; i++) {\n            bh.consume(isEvenNumber(i));\n        }\n    }\n\n    public static boolean isEvenNumber(final int number) {\n        return number % 2 == 0;\n    }\n\n    @Benchmark\n    public void isEvenNumberWithBitwiseOperation(Blackhole bh) {\n        for (int i = 0; i &lt; 100_000_000; i++) {\n            bh.consume(isEvenNumberWithBitwiseOperation(i));\n        }\n    }\n\n    public static boolean isEvenNumberWithBitwiseOperation(final int number) {\n        return (number &amp; 1) == 0;\n    }\n\n}\n\n\n\n\n결과는 아래와 같았다.\n\n\n\nResult \"io.shirohoo.benchmarks.EvenNumberChecker.isEvenNumber\":\n  4.961 ±(99.9%) 1.602 ops/s [Average]\n  (min, avg, max) = (4.872, 4.961, 5.048), stdev = 0.088\n  CI (99.9%): [3.359, 6.563] (assumes normal distribution)\n  \nResult \"io.shirohoo.benchmarks.EvenNumberChecker.isEvenNumberWithBitwiseOperation\":\n  4.986 ±(99.9%) 1.287 ops/s [Average]\n  (min, avg, max) = (4.920, 4.986, 5.061), stdev = 0.071\n  CI (99.9%): [3.699, 6.273] (assumes normal distribution)\n\n\n\n\n일단 유의미한 성능차이는 없는 것 같긴 한데, 비트연산으로 작성한 코드가 평균적으로 더 좋은 성능을 낸다고 봐도 될 것 같다고 생각했다.\n\n\n\n이 스터디를 진행하며 느낀 것은 현재 학습하는 CS 지식들이 개발에 즉각적인 도움을 주지는 않는다는 것이다.\n\n다만, 이러한 것들을 위해 계속 해야만 하는 고강도의 논리적인 사고가 내 사고를 점점 효율적으로 만들어준다는 것은 느낄 수 있었다.\n\n이런 학습을 장기간 지속할 수 있다면 내 개발 스타일이 점점 더 세밀하게 좋아질 것 같다는 생각이 들었다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-10-24-diary-28/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "클래스 멤버로만 이루어진 추상 클래스?",
      "date": "2021-11-04 00:00:00 +0000",
      "description": "어떤 이점을 얻기 위해 이런 구조를 채택했을까?\n",
      "content": "\n  StringUtils\n\n\n\n\nStringUtils\n\n\n\n심심해서 스프링 코드 분석을 하다가 스프링 코어에서 제공하는 StringUtils가 특이한 구조로 설계돼있음을 알았다.\n\nStringUtils는 추상 클래스인데 모든 멤버가 클래스 멤버(static)로 이루어져 있었다.\n\n\n\n\n\n\n\n\n\n\n\n특히 작성자란에 스프링의 아버지인 로드 존슨형님이 계셨기 때문에 분명히 어떤 고의적인 의도를 갖고 채택된 구조라는 생각이 들었다.\n\n즉시 호기심이 머리를 치켜들었다.\n\n이런 구조를 가져감으로서 얻을 수 있는 이점으로 대체 무엇이 있을까?\n\n\n\n우선 든 생각은 이랬다.\n\n\n\n\n  StringUtils는 유틸성 클래스이다.\n  추상 클래스는 자체적으로 인스턴스를 생성할 수 없다.\n  1과 2를 조합해 일종의 싱글톤 패턴과 비슷한 효과를 노린게 아닐까? (==메모리 절약)\n\n\n\n\n그래서 생성자를 보니 의외로 기본 생성자가 public으로 명시되어 작성돼있었다.\n\n이게 무슨 의미냐면, 자바 컴파일러는 생성자를 작성하지 않을 경우 기본 생성자를 알아서 생성해준다.\n\n그럼에도 불구하고 기본 생성자가 굳이 public 이라는 접근 제한자로 작성돼있다는 것은 클래스 설계자들이 기본 생성자를 고의적으로 열어두었다는 의미와 같다.\n\n즉, 클래스 설계자들은 이 클래스가 확장될수도 있다고 예상했음이다.\n\n또한, 싱글톤 패턴의 효과를 노렸다면 차라리 싱글톤 패턴을 적용하고 말지, 이런 구조로 작성할 이유가 없다.\n\n따라서 내 생각은 클래스 설계자들의 의도에서 벗어난다.\n\n\n\n그럼 클래스 설계자들은 어떤 의도로 이 클래스를 이렇게 만들었을까?\n\n주변에 조언을 구하니 정말 다양한 의견을 얻을 수 있었다.\n\n최종적으로 정리한 내용은 하기와 같으며, 내가 생각하기에 아래에 정리된 내용이 클래스 설계자들의 의도에 가장 근접했다고 생각한다.\n\n\n\n\n  생성자가 오픈된 추상 클래스이기 때문에 구현상속할 수 있고, 이 경우 메서드 시그니처의 하위호환성도 함께 보장해줄 수 있다\n    \n      하지만 StringUtils같은 완성형 유틸 클래스가 확장되야만 하는 경우가 존재할까?\n      이 세상에 평생동안 요구사항이 변하지 않는 코드는 존재하지 않는다. 즉, 클래스 설계자들은 미래에 이 클래스에 추가적인 기능이 필요해 결국 확장될 수 있다고 생각했을 가능성이 충분히 존재한다\n    \n  \n  추가적인 기능이 필요하지 않아 그대로 사용 할 경우 인스턴스 생성을 못하게 강제할 수 있기 때문에 메모리 절감 효과를 충분히 누릴 수 있으면서도 언제든지 확장될 수 있는 클래스이다.\n\n\n\n\n아무튼 구루들이 개발한 프로그램들은 뭐 하나 허투루 작성된게 없는 것 같다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-11-04-diary-29/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "HTTP/2.0",
      "date": "2021-11-05 00:00:00 +0000",
      "description": "HTTP 완벽 가이드 10장 정리\n",
      "content": "\n  개요\n  HTTP/2.0\n  HTTP/2.0 적용\n  문제점 ?\n  HTTP/2.0의 목표\n  참고\n\n\n\n\n개요\n\n\n\nHTTP/2.0은 시간이 지날수록 늘어나는 네트워크 트래픽으로 인한 HTTP/1.1의 기술적 한계를 극복하기 위해 고안됐습니다.\n\n2015년에 정식으로 승인된 최신기술로, 구글에서 HTTP/1.1의 한계를 극복하기 위해 제안한 스피디(SPDY) 에 기반하고 있다고 합니다.\n\nHTTP/1.1은 요청을 한번 보내고 응답을 한번 받는다는 극강의 단순함으로 아주 견고한 프로토콜이지만, 이 단순한 구조로 인해 빠른 처리속도를 가지지는 못합니다.\n\n웹 개발을 어느정도 해봤다면 다음과 같은 상황을 생각해 볼 수 있습니다.\n\n\n\n\n  브라우저에 https://www.w3schools.com/ 를 입력합니다. (HTTP 커넥션 생성, HTTP 요청)\n  index.html 을 받습니다. (HTTP 응답, HTTP 커넥션 종료)\n  index.html 의 A 레이아웃에 필요한 여러 동적 데이터를 얻기 위해 자바스크립트로 오리진 서버에 데이터를 요청합니다. (HTTP 커넥션 생성, HTTP 요청)\n  받아온 데이터를 index.html 의 A 레이아웃에 채워넣어 화면을 구성합니다. (HTTP 응답, HTTP 커넥션 종료)\n  index.html 의 B 레이아웃에 필요한 여러 동적 데이터를 얻기 위해 자바스크립트로 오리진 서버에 데이터를 요청합니다. (HTTP 커넥션 생성, HTTP 요청)\n  받아온 데이터를 index.html 의 B 레이아웃에 채워넣어 화면을 구성합니다. (HTTP 응답, HTTP 커넥션 종료)\n\n\n\n\n…\n\n\n\n이렇게 단순히 웹 페이지 하나를 한번 로드하는데 값비싼 핸드셰이킹을 여러번 해야만 합니다.\n\n왜? 한번의 요청을 보내면 한번의 응답을 받고 커넥션을 종료한다는 단순한 구조로인해서요.\n\n이러한 문제들을 해결하기 위해 Keep-alive, Pipelining 등이 적용됐지만, 역시 각각 문제들이 있었습니다.\n\n커넥션이 너무 많아져 서버에 부하가 많이 간다던가, 동기적인 처리로 인해 브라우저 렌더링에 지장이 생긴다든가 하는 문제(일명 HOL blocking 문제라고도 합니다.)들이요.\n\n\n\n\n\nHTTP/1.1 Pipelining\n\n\n\n그래서 HTTP/1.1로 통신할때 브라우저들은 한개의 커넥션만 사용하지 않고 여러개의 커넥션을 동시에 사용해 리소스를 받아옵니다.\n\n\n\n\n\n\n\nHTTP/1.1로 이루어져 있는 우리나라 모 공공기관의 홈페이지에 접속해봤습니다.\n\n단순히 메인 화면 하나를 로드하기 위해 많은 커넥션을 사용했고, 긴 시간동안 통신을 해야만 했습니다.\n\n아래는 HTTP/2.0이 적용된 https://www.w3schools.com/에 접속했을 때의 결과입니다.\n\n데이터의 밀도가 높아져 지연시간(Latency)이 대폭 감소된 것을 볼 수 있습니다.\n\n\n\n\n\n\n\nHTTP/2.0\n\n\n\n우선 이부분은 명확히 알고있어야 할 부분입니다.\n\nHTTP/2.0에 대해 알아볼 때 가장 중요했던 부분은 기존 HTTP/1.1과의 하위호환성을 보장한다는 것이었습니다.\n\n즉, HTTP/2.0을 적용 할 조건이 갖춰졌다는 가정하에 HTTP/1.1을 사용하고 있었다면 별 문제없이 업그레이드가 가능하다는 것입니다.\n\n그럼 HTTP/2.0은 어떻게 이런 결과를 낼 수 있었을까요?\n\n\n\nHTTP/2.0 역시 통신을 위한 커넥션을 맺습니다.\n\n다만, 바이너리 프레이밍 계층이라는 것을 사용해 요청과 응답의 멀티플렉싱을 지원한다고합니다.\n\n\n\n💡 멀티플렉싱이란? 하나의 통신 채널을 통해서 둘 이상의 데이터를 전송하는데 사용되는 기술이다. 기본적으로 멀티플렉싱이란 여러 개를 하나로 묶어 다중화 시킨다는 뜻이다.\n\n\n\n\n\n프레이밍(Framing)\n\n\n\nHTTP 메시지의 헤더와 바디를 바이너리 형태의 프레임(Frame)으로 나누고 이를 전송하고, 수신처에서 나눠 받은 프레임을 HTTP 메시지로 다시 조립합니다.\n\n이렇게 요청과 응답이 동시다발적으로 이루어지니 하나의 커넥션에 여러 요청과 응답이 뒤섞여 있습니다.\n\n하지만 프레이밍 작업은 기본적으로 서버와 클라이언트(=브라우저)에서 모두 해주기 때문에 큰 걱정을 하지않아도 됩니다.\n\n즉, 바이너리 프레이밍과 멀티플렉싱을 이용해 여러 개의 커넥션 연결 없이 단 하나의 커넥션으로, 한쌍의 요청과 응답이 아닌 여러쌍의 요청과 응답을 동시다발적으로 처리할 수 있게됨과 동시에 기존 파이프라이닝의 HOL문제도 해결한 것입니다.\n\n\n\n\n\n출처: 구글 개발자 페이지 - 바이너리 프레이밍 계층\n\n\n\n한쌍의 요청과 응답은 하나의 스트림위에서 처리되며, 이 스트림은 커넥션에 여러개 존재할 수 있습니다. (병렬 스트림)\n\n비유를 들자면, HTTP/1.1은 구리선이 하나만 들어있는 케이블이라고 볼 수 있고, HTTP/2.0은 구리선이 여러개 들어있는 케이블이라고 볼 수 있습니다.\n\n\n\n또한 HTTP 헤더는 모두 압축되어 처리됩니다.\n\n\n\n추가적으로 서버 푸시라는 것이 가능해지는데, 서버에서 임의의 요청에 대해 여러 리소스를 능동적으로 한꺼번에 응답해주는 것을 말합니다.\n\n이 기능은 제가 사용하는 Spring Framework 5에서 도입됐으며(PushBuilder), 매우 당연하게도 HTTP2.0을 필요로 합니다.\n\n\n\n\n  PushBuilder에 관한 내용을 다룬 블로그\n\n\n\n\n크롬 시크릿 브라우저 세션에서 성능측정 페이지에 접속해 HTTP/1.1과 HTTP/2.0의 성능을 수차례 비교해보니 최대 100%까지도 차이가 나는것을 확인할 수 있었습니다.\n\n\n\n\n\n\n\nHTTP/2.0 적용\n\n\n\nHTTP/2.0을 적용하기 위해서는 HTTPS 적용 필수적이라고 하는데, 이미 HTTPS는 적용돼있었습니다.\n\n저는 Nginx를 사용하고 있었는데, 관련 문서를 읽어보니 제가 사용하고있는 최신 버전의 Nginx에서는 HTTPS가 적용돼있다는 가정하에 키워드 하나만 추가하고 Nginx를 리로드 하는 정도에서 끝날정도로 아주 손쉬웠습니다.\n\n\n\n\n\n\n\n\n\nHTTP/2.0 적용된 모습\n\n\n\n문제점 ?\n\n\n\n우선 제가 생각해본 문제점은 두개였습니다.\n\n\n\n\n  컴퓨팅 리소스를 지나치게 많이 사용하지는 않을지\n  커넥션 내의 스트림간 간섭문제는 없는지\n\n\n\n\n1번에 대한 부분은 컴퓨팅 리소스를 더 사용해서라도 월등한 성능을 얻을 수 있다면 생각보다 큰 문제가 될 것 같다고 생각되진 않았습니다.\n\n\n\n2번에 대한 부분은 별도의 내용을 찾지 못했는데, 개발사가 구글이니 아마 어떤 처리가 돼있지 않을까 조심스레 추측만 해보고 있는 상태입니다.\n\n다만, 이 간섭으로 인한 데이터의 유출문제는 HTTP/2.0 적용을 위한 필수조건에 HTTPS 구축이 포함돼있어 별 문제가 되지 않을 것 같습니다.\n\n\n\nHTTP/2.0의 목표\n\n\n\n\n  클라이언트와 서버가 HTTP/1.1, HTTP/2.0 혹은 다른 비 HTTP 프로토콜 사용을 협상할 수 있는 메커니즘 구현\n  HTTP/1.1과 호환성 유지\n  다음과 같은 방법들을 이용하여 지연 시간을 감소시켜 웹 브라우저의 페이지 로드 속도 개선\n    \n      HTTP 헤더 데이터 압축\n      서버 푸시 기술\n      요청을 HTTP 파이프라인으로 처리\n      HTTP/1.x의 HOL blocking 문제 해결\n      TCP 연결 하나로 여러 요청을 다중화 처리\n    \n  \n  데스크탑 브라우저, 모바일 웹 브라우저, 웹 API, 웹 서버, 프록시 서버, 리버스 프록시 서버, 방화벽, 콘텐츠 전송 네트워크 등 자주 쓰이는 것들을 지원\n\n\n\n\n출처: 위키백과 HTTP2.0\n\n\n\n참고\n\n\n\n제가 사용하는 Spring Framework는 5부터 HTTP/2.0을 안정적으로 지원하며, 이 때 Tomcat은 8.5+ 이상이어야 합니다.\n그외 Netty, Apache, Nginx 등도 모두 HTTP/2.0을 구현하여 지원하고 있음을 알 수 있습니다.\n\n\n\n\n  HTTP 완벽 가이드 - 10장\n  RFC7540\n  구글 개발자 페이지\n  HTTP/2.0 성능 테스트\n  HTTP/2.0을 구현한 시스템들\n  HTTP/2.0을 구현한 툴들\n\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-11-05-http2_0/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Swagger - Fail to load API definition.",
      "date": "2021-11-16 00:00:00 +0000",
      "description": "Fetch error undefiend ~\n",
      "content": "\n  🚨 문제\n  🚧 원인\n  🚑 해결\n\n\n\n\n🚨 문제\n\n\n\nSpring REST Docs로 open-api-3.0.1.json을 생성하고 이를 Swagger UI에 연동하던 중 발생\n\n모든 작업을 마친 후 Swagger 문서 진입시 하기와 같은 에러가 발생했다.\n\n\n\n\n\n\n\n🚧 원인\n\n\n\n에러 메시지대로 sprout.jar를 확인해보니 /BOOT-INF/classes/static/docs/api/open-api-3.0.1.json 이 존재하지 않았다.\n\n그레이들 서드파티 플러그인을 사용해 open-api-3.0.1.json 파일을 생성한 후 패키징이 진행되는데, 여기서 어떤 문제가 있었다고 추측되었다.\n\n\n\n&gt; Task :module-web:compileJava FROM-CACHE\n&gt; Task :module-web:classes\n&gt; Task :module-web:bootJarMainClassName\n&gt; Task :module-web:compileTestJava FROM-CACHE\n&gt; Task :module-web:testClasses UP-TO-DATE\n&gt; Task :module-web:test FROM-CACHE\n&gt; Task :module-web:check UP-TO-DATE\n&gt; Task :module-web:openapi3\n&gt; Task :module-web:bootJar\n&gt; Task :module-web:jar SKIPPED\n&gt; Task :module-web:assemble\n&gt; Task :module-web:build\n\n\n\n\n\n\n\n\n🚑 해결\n\n\n\n패키징 하기전 그레이들 플러그인이 생성한 open-api-3.0.1.json 파일을 원하는 위치에 강제로 포함시킨 후 패키징하도록 bootJar 태스크에 별도의 빌드 스크립트를 추가했다.\n\n\n\n// file: 'build.gradle'\nbootJar {\n    dependsOn(\n            'openapi3',\n    )\n    \n    // 추가\n    from(\"$apiDir/open-api-3.0.1.json\") {\n        into 'BOOT-INF/classes/static/docs/api'\n    }\n}\n\n\n\n\n\n\n수정 후 sprout.jar/BOOT-INF/classes/static/docs/api/open-api-3.0.1.json 확인.\n\n\n\n\n\n정상 동작 확인\n\n\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-11-16-debugging-11/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Nginx 80 to 443 port forwarding not working",
      "date": "2021-11-22 00:00:00 +0000",
      "description": "HTTP(=80) 접속 시 HTTPS(=443)로 포트포워딩이 되지 않는 문제\n",
      "content": "\n  🚨 문제\n  🚧 원인\n  😂 해결\n\n\n\n\n🚨 문제\n\n\n\n사이드 프로젝트 서버 구축중 한 삽질이다\n\n\n\n\n  Nginx를 리버스 프록시로 도입\n  SSL 발급 및 HTTPS 구축\n  HTTPS 2.0 설정\n\n\n\n\n완료 후 우리 사이드 프로젝트 도메인에 접속하는데, http://domain 으로 접속하면 https://domain 으로 포트포워딩이 되지 않는 문제가 있음을 알았다.\n\n\n\n🚧 원인\n\n\n\n처음엔 바로 nginx.conf 를 확인했으나, 역시 아무런 이상 없이 잘 설정돼있었다.\n\n\n\n server {\n        listen 80;\n        listen 443 ssl http2;\n        server_name example.com www.example.com;\n        root         /var/www/html;\n\n        gzip on;\n        gzip_comp_level 6;\n        gzip_min_length 500;\n        gzip_buffers 16 8k;\n        gzip_proxied any;\n\n        access_log /var/log/nginx/access.log;\n        error_log /var/log/nginx/error.log;\n\n        ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\n        ssl_protocols TLSv1.2;\n        ssl_ciphers HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers on;\n\n        if ($scheme != \"https\") {\n            return 301 https://$host$request_uri;\n        }\n\n\n\n\n분명 아무런 문제가 없는데 당연히 되야 할 것이 안되니 애꿎은 nginx.conf만 계속 고쳐봤다. (이러면 안되는데 😭)\n\n한시간정도 이짓거리를 하다가 잠깐 현타가 와서 멍때리는데, 문득 설마 방화벽이 문젠가? 라는 생각이 들어서 방화벽을 확인해보니…\n\n\n\n$ sudo iptables -t nat -L --line-numbers\nChain PREROUTING (policy ACCEPT)\nnum  target     prot opt source               destination\n1    REDIRECT   tcp  --  anywhere             anywhere             tcp dpt:http redir ports 8080\n\nChain INPUT (policy ACCEPT)\nnum  target     prot opt source               destination\n\nChain OUTPUT (policy ACCEPT)\nnum  target     prot opt source               destination\n\nChain POSTROUTING (policy ACCEPT)\nnum  target     prot opt source               destination\n\n\n\n\n리눅스 방화벽에서 80포트 접속시 8080으로 포트포워딩이 걸려있었다…\n\n이때 내가 처음 서버 구축할때 임시로 이걸 설정해뒀던게 섬광처럼 떠올랐다… 😫😫😫\n\n\n\n그러니까 웹서버에도 포트포워딩이 걸려있고, OS 방화벽에도 포트포워딩이 걸려있는 상태였고, OS 방화벽이 웹서버보다 더 먼저 외부 요청을 받으니 방화벽에 걸려있는 포트포워딩이 작동한셈이다.\n\n따라서 방화벽의 포트포워딩 을 제거하면 자연스레 웹서버의 포트포워딩이 동작하게 될 것이다.\n\n\n\n😂 해결\n\n\n\n\n\n\n\n$ sudo iptables -t nat -D PREROUTING 1\n\n\n\n\n… 자괴감에 허우적대며 해당 옵션을 제거하니 역시 잘 해결되었다…\n\n내 한시간… 😫\n\n\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-11-22-debugging-12/"
    },{
      "image": "/assets/img/spring/spring-mvc/spring-mvc-logo.png",
      "title": "HandlerMethodArgumentResolver",
      "date": "2021-11-23 00:00:00 +0000",
      "description": "Spring MVC의 HandlerMethodArgumentResolver 가 하는 일\n",
      "content": "\n  💡 HandlerMethodArgumentResolver\n  ⚙ 구조\n  ✨ ModelAttributeMethodProcessor\n  ✨ RequestParamMethodArgumentResolver\n  🤔 정리\n\n\n💡 HandlerMethodArgumentResolver\n\n\n\n\n\n\n\n\n  코드는 📦 깃허브 에 있습니다.\n\n\n\n\n스프링 MVC 프로젝트에는 사용자의 HTTP 요청을 파싱하고 처리한 후 컨트롤러에 값을 넘겨주는 HandlerMethodArgumentResolver 인터페이스가 있으며 (여기서 말하는 핸들러는 우리가 흔히 이야기하는 컨트롤러이다), HandlerMethodArgumentResolver의 콘크리트 클래스는 20종이 넘게 존재한다.\n\n\n\nHandlerMethodArgumentResolver는 데이터가 HTTP 헤더에 존재하는 경우 알아서 데이터를 파싱하고 객체에 바인딩 하지만, 만약 클라이언트가 POST 등의 방식을 통해 요청을 보내어 데이터가 HTTP 바디에 존재하는 경우엔  MessageConverter에게 처리를 위임한다. (응답도 마찬가지다.)\n\n위 경우에는 HTTP 바디의 데이터를 받겠다는 의미의 @RequestBody를 선언해주어야 한다.\n\n마찬가지로 응답에는 @ResponseBody를 선언하며 @RestController를 사용한다면 @ResponseBody를 생략할 수 있다.\n\n\n\n무슨 말인지 잘 모르겠다면 역시 코드를 보자 !\n\nHandlerMethodArgumentResolver에 대한 포스팅이니 상단 이미지의 5번부터 보면 되겠다.\n\n또한 이 포스팅에서는 가장 많이 사용하는 @ModelAttribute와 @RequestParam에 대해서만 다룰 것이다.\n\n\n\n@Slf4j\n@RestController\npublic class HelloApiController {\n\n    // 사용자의 요청을 파싱해 helloV1()에 선언된 Person을 만들고 데이터를 바인딩해준다\n    @GetMapping(\"/v1/hello\")  \n    public Person helloV1(Person person) { // @ModelAttribute가 없는 경우\n        log.info(\"person={}\", person);\n        return person;\n    }\n\n    @GetMapping(\"/v2/hello\")\n    public Person helloV2(@ModelAttribute Person person) { // @ModelAttribute가 있는 경우\n        log.info(\"person={}\", person);\n        return person;\n    }\n\n    @GetMapping(\"/v3/hello\")\n    public String helloV3(String name, int age) { // @RequestParam이 없는 경우\n        log.info(\"name={}, age={}\", name, age);\n        return \"ok\";\n    }\n\n    @GetMapping(\"/v4/hello\")\n    public String helloV4(@RequestParam String name, @RequestParam int age) { // @RequestParam이 있는 경우\n        log.info(\"name={}, age={}\", name, age);\n        return \"ok\";\n    }\n\n}\n\n@Getter\n@Setter\n@ToString\npublic class Person {\n\n    private String name;\n    private int age;\n\n}\n\n\n\n\n서버를 기동하고 브라우저에 localhost:8080/v1/hello?name=siro&amp;age=11을 입력하면 데이터가 서버로 전송되고(GET), 핸들러 매핑을 통해 결국 위 컨트롤러 코드에 도달할 것이다.\n\n이때 Person이라는 객체를 만들고 이곳에 핸들러 어댑터에게 전달받은 데이터들을 바인딩한 후 컨트롤러로 넘겨주는 역할을 HandlerMethodArgumentResolver가 한다.\n\n그러면 개발자는 그냥 쿼리스트링을 전달받을 Person 클래스를 생성해서 선언하거나 혹은, 스칼라타입인 String과 int만 선언하면 하면 된다. 굉장히 편리하다.\n\n테스트를 하기에 앞서 매번 서버를 껏다켰다하는 노가다를 할 수는 없으니 간단한 테스트 코드를 작성했다.\n\n\n\n// file: 'HelloApiControllerTest.class'\n@WebMvcTest(HelloApiController.class)\nclass HelloApiControllerTest {\n\n    @Autowired\n    private MockMvc mvc;\n\n    @Test\n    @DisplayName(\"@ModelAttribute가 존재하지 않는 경우\")\n    void helloV1() throws Exception {\n        performGet(\"v1\");\n    }\n\n    @Test\n    @DisplayName(\"@ModelAttribute가 존재하는 경우\")\n    void helloV2() throws Exception {\n        performGet(\"v2\");\n    }\n\n    @Test\n    @DisplayName(\"@RequestParam이 존재하는 경우\")\n    void helloV3() throws Exception {\n        performGet(\"v3\");\n    }\n\n    @Test\n    @DisplayName(\"@RequestParam이 존재하지 않는 경우\")\n    void helloV4() throws Exception {\n        performGet(\"v4\");\n    }\n\n    private void performGet(String version) throws Exception {\n        mvc.perform(get(\"/\" + version + \"/hello?name=siro&amp;age=11\"))\n            .andDo(print())\n            .andExpect(status().isOk());\n    }\n\n}\n\n\n\n\n⚙ 구조\n\n\n\n러프하게 봤을 때,\n\n\n\n\n  사용자의 요청을 받아 관리하는 DispatcherServlet (Dispatcher는 관제탑에서 앞에 모니터 여러개 두고 헤드셋 낀 상태로 ~하세요. ~하세요. 하는 사람들을 연상하면 된다.)\n  사용자의 요청을 처리할 핸들러(=컨트롤러)를 찾아주는 HandlerMapping\n  사용자의 요청을 처리할 핸들러를 DispatcherServlet와 연결해주는 HandlerAdapter\n  HandlerAdapter의 요청(메시지)를 받아 요청을 파싱해 핸들러에 넘어갈 매개변수로 만들어주는 HandlerMethodArgumentResolver\n  HandlerMethodArgumentResolver가 처리하지 못하는 경우(=데이터가 HTTP 바디에 들어있는 경우), 이를 대신 처리해줄 MessageConverter\n\n\n\n\n가 있다, 물론 훨씬 더 많은 클래스가 존재하지만 다 보기에는 너무너무 방대하므로 일단 이정도만 보자.\n\nHandlerAdapter의 콘크리트 클래스중에는 @RequestMapping이 달려있는 컨트롤러들을 처리하는 RequestMappingHandlerAdapter가 존재하며, 이녀석이 가장 높은 우선순위를 갖고 호출된다.\n\nRequestMappingHandlerAdapter는 매개변수 생성을 ModelFactory에 의존하며, ModelFactory는 HandlerMethod의 콘크리트 클래스인 InvocableHandlerMethod을 의존한다.\n\n그리고 InvocableHandlerMethod는 내부 필드로 HandlerMethodArgumentResolverComposite를 갖는데, 이름에서 이녀석이 하는 역할을 아주 극명하게 나타내고 있다.(여기서 이펙티브 자바의 상속보다는 컴포지션을 활용하라라는 문구가 떠올랐다.)\n\nHandlerMethodArgumentResolverComposite는 내부적으로 HandlerMethodArgumentResolver의 모든 콘크리트 클래스를 ArrayList로 갖고 있으며(27개), 요청을 받으면 루프를 돌며 알맞은 HandlerMethodArgumentResolver를 찾고 처리를 위임한다.(=커맨드 패턴)\n\n\n\n✨ ModelAttributeMethodProcessor\n\n\n\n그중 ModelAttributeMethodProcessor는 @ModelAttribute를 처리해주는 HandlerMethodArgumentResolver의 콘크리트 클래스 중 하나이다.\n\n코드에 이해한 내용을 주석으로 달았다.\n\n\n\n// file: 'InvocableHandlerMethod.class'\npublic class InvocableHandlerMethod extends HandlerMethod {\n    protected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,\n        Object... providedArgs) throws Exception {\n\n        MethodParameter[] parameters = getMethodParameters(); // 컨트롤러의 메서드에 선언된 매개변수의 개수를 의미한다. 여기선 1개(Person)가 되겠다\n        if (ObjectUtils.isEmpty(parameters)) { // 컨트롤러의 메서드에 선언된 매개변수의 개수가 0개라면 ArgumentResolver가 어떤 처리를 할 필요가 없다\n            return EMPTY_ARGS;\n        }\n\n        Object[] args = new Object[parameters.length]; // 만들어야 할 매개변수의 수만큼의 길이를 갖는 정적배열을 생성한다\n        for (int i = 0; i &lt; parameters.length; i++) {\n            MethodParameter parameter = parameters[i];\n            parameter.initParameterNameDiscovery(this.parameterNameDiscoverer);\n            args[i] = findProvidedArgument(parameter, providedArgs); // 커스텀 확장을 위해 열어둔 부분으로 사료된다\n            if (args[i] != null) {\n                continue;\n            }\n            if (!this.resolvers.supportsParameter(parameter)) { // ArgumentResolver가 해당 매개변수를 만들어낼 수 있는지를 체크\n                throw new IllegalStateException(formatArgumentError(parameter, \"No suitable resolver\")); // 만들어낼 수 없다면 예외를 던진다\n            }\n            try {\n                // 실제로 컨트롤러에 전달될 매개변수를 만들어내는 부분으로 내부 구현은 커맨드 패턴으로 이루어져있다.\n                // resolveArgument()는 HandlerMethodArgumentResolverComposite.getArgumentResolver()를 호출한다\n                // getArgumentResolver()는 ArgumentResolver가 들어있는 List를 순회하며 resolver.supportsParameter()를 호출한다\n                // 해당 매개변수를 생성 할 수 있는 ArgumentResolver를 찾아 반환한다. 없다면 null을 반환한다.\n                // resolveArgument()는 반환받은 ArgumentResolver의 resolveArgument()를 호출해 데이터가 바인딩 된 매개변수 인스턴스를 생성하고 반환한다.\n                args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory);\n            }\n            catch (Exception ex) {\n                if (logger.isDebugEnabled()) {\n                    String exMsg = ex.getMessage();\n                    if (exMsg != null &amp;&amp; !exMsg.contains(parameter.getExecutable().toGenericString())) {\n                        logger.debug(formatArgumentError(parameter, exMsg));\n                    }\n                }\n                throw ex;\n            }\n        }\n        return args;\n    }\n}\n\n\n\n\n// file: 'HandlerMethodArgumentResolverComposite.class'\npublic class HandlerMethodArgumentResolverComposite implements HandlerMethodArgumentResolver { \n    \n    ...\n\n    @Override\n    @Nullable\n    public Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer,\n        NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception {\n\n        HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter); // 매개변수를 생성해낼 ArgumentResolver를 가져온다 \n        if (resolver == null) { // 매개변수를 생성할 수 있는 ArgumentResolver가 없다면 예외를 던진다\n            throw new IllegalArgumentException(\"Unsupported parameter type [\" +\n                parameter.getParameterType().getName() + \"]. supportsParameter should be called first.\");\n        }\n        return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory); // ArgumentResolver가 존재한다면 매개변수 생성을 위임한다\n    }\n\n    @Nullable\n    private HandlerMethodArgumentResolver getArgumentResolver(MethodParameter parameter) {\n        HandlerMethodArgumentResolver result = this.argumentResolverCache.get(parameter);\n        if (result == null) {\n            for (HandlerMethodArgumentResolver resolver : this.argumentResolvers) {\n                // ArgumentResolver가 들어있는 List를 순회하며 매개변수를 생성할 수 있는 ArgumentResolver를 찾는다\n                if (resolver.supportsParameter(parameter)) { \n                    result = resolver;\n                    this.argumentResolverCache.put(parameter, result);\n                    break;\n                }\n            }\n        }\n        return result;\n    }\n\n}\n\n\n\n\n@ModelAttribute를 처리하는 ArgumentResolver는 ModelAttributeMethodProcessor이다.\n\n\n\n// file: 'ModelAttributeMethodProcessor.class'\n@Override\n@Nullable\npublic final Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer,\n    NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception {\n\n    Assert.state(mavContainer != null, \"ModelAttributeMethodProcessor requires ModelAndViewContainer\");\n    Assert.state(binderFactory != null, \"ModelAttributeMethodProcessor requires WebDataBinderFactory\");\n\n    // 컨트롤러에 선언된 매개변수명을 가져온다. 컨트롤러 매개변수에 Person person으로 선언했으므로 \"person\"이 나오게 된다.\n    String name = ModelFactory.getNameForParameter(parameter); \n    ModelAttribute ann = parameter.getParameterAnnotation(ModelAttribute.class); // @ModelAttribute가 컨트롤러 매개변수에 선언돼있는지 체크한다\n    if (ann != null) { // @ModelAttribute가 있다면 ModelAndViewContainer에 별도의 설정을한다. 이 부분은 SSR시 View에 데이터가 바인딩되는 부분을 처리하는 것 같다.\n        mavContainer.setBinding(name, ann.binding());\n    }\n\n    Object attribute = null; // 실제로 생성될 매개변수 인스턴스를 담을 변수\n    BindingResult bindingResult = null; // ModelAndView 바인딩 결과를 캡슐화한 클래스\n\n    if (mavContainer.containsAttribute(name)) { // ModelAndViewContainer에 person을 키로 갖는 인스턴스가 존재하면 꺼내온다 (HashMap)\n        attribute = mavContainer.getModel().get(name);\n    }\n    else {\n        try {\n            attribute = createAttribute(name, parameter, binderFactory, webRequest); // 인스턴스가 없다면 컨트롤러의 매개변수가 될 인스턴스를 새로 만들어야 할 것이므로 생성한다\n        }\n        catch (BindException ex) {\n            if (isBindExceptionRequired(parameter)) {\n                throw ex;\n        }\n        if (parameter.getParameterType() == Optional.class) {\n            attribute = Optional.empty();\n        }\n        else {\n            attribute = ex.getTarget();\n        }\n        bindingResult = ex.getBindingResult();\n        }\n    }\n\n    // ... 아래 메서드로 잠시 이동\n}\n\nprotected Object createAttribute(String attributeName, MethodParameter parameter,\n    WebDataBinderFactory binderFactory, NativeWebRequest webRequest) throws Exception {\n\n    // 생성해야 할 매개변수의 타입이 Optional인 경우 별도의 처리를 진행하는걸로 보인다\n    MethodParameter nestedParameter = parameter.nestedIfOptional();\n    Class&lt;?&gt; clazz = nestedParameter.getNestedParameterType();\n\n    // 생성해야 할 매개변수의 생성자를 가져온다. 기본적으로 기본생성자를 가져오지만, AllArgumentConstructor가 있다면 이것을 가져온다.\n    Constructor&lt;?&gt; ctor = BeanUtils.getResolvableConstructor(clazz);  \n    \n    // 가져온 생성자에 클라이언트가 보낸 요청 데이터를 모두 바인딩한다. 위에서 AllArgumentConstructor가 아닌 생성자를 가져왔다면 별도의 Setter가 필요하다.\n    // Setter가 없다면 null이나 기본값으로 바인딩하며, 인수 타입이 맞지 않다면 BindException을 던지고, 생성자를 호출하지 못했다면 Exception을 던진다.\n    Object attribute = constructAttribute(ctor, attributeName, parameter, binderFactory, webRequest);\n    \n    if (parameter != nestedParameter) { \n        attribute = Optional.of(attribute);\n    }\n    return attribute;\n}\n\n@Override\n@Nullable\npublic final Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer,\n        NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception {\n    \n    // ... 다시 돌아옴\n    // 이 시점에서 기본생성자를 호출했기 때문에 attribute = Person(name=null, age=0) 이며,\n    // 만약 AllArgumentConstructor를 가져와 만들었다면 이 시점에서 Person(name=siro, age=11)이다.\n    // mavContainer에 대한 처리가 아직 완료되지 않았으므로 이 시점에서 bindingResult는 항상 null 이다.\n    \n    // 어찌됐든 이 시점에서는 attribute = Person(name=null, age=0)이다.\n        \n    if (bindingResult == null) {\n        WebDataBinder binder = binderFactory.createBinder(webRequest, attribute, name);\n        if (binder.getTarget() != null) {\n            if (!mavContainer.isBindingDisabled(name)) {\n                bindRequestParameters(binder, webRequest); // Setter를 호출해서 데이터를 모두 바인딩한다. 이 시점에서 Person(name=siro, age=11)이다.\n            }\n            validateIfApplicable(binder, parameter); // 유효성 검증 로직\n            if (binder.getBindingResult().hasErrors() &amp;&amp; isBindExceptionRequired(binder, parameter)) { // 유효성 검증 로직\n                throw new BindException(binder.getBindingResult());\n            }\n        }\n        if (!parameter.getParameterType().isInstance(attribute)) { // 유효성 검증 로직\n            attribute = binder.convertIfNecessary(binder.getTarget(), parameter.getParameterType(), parameter);\n        }\n        bindingResult = binder.getBindingResult();\n    }\n\n    // 만약 반환타입이 ModelAndView일 경우를 대비해 ModelAndViewContainer에 데이터를 함께 바인딩해준다\n    Map&lt;String, Object&gt; bindingResultModel = bindingResult.getModel();\n    mavContainer.removeAttributes(bindingResultModel);\n    mavContainer.addAllAttributes(bindingResultModel);\n\n    // 컨트롤러에 전달되어야 할 매개변수가 만들어졌고, 모든 데이터가 바안딩되었다. 이를 반환한다.\n    return attribute;\n}\n\n\n\n\n✨ RequestParamMethodArgumentResolver\n\n\n\n그중 RequestParamMethodArgumentResolver는 @RequestParam을 처리해주는 HandlerMethodArgumentResolver의 콘크리트 클래스 중 하나이다.\n\nRequestParamMethodArgumentResolver는 대부분의 처리를 상위 추상 클래스인 AbstractNamedValueMethodArgumentResolver에 의존하며 핵심 처리는 자신이 오버라이딩한 메서드를 통해 처리한다.\n\n역시 이해한 내용을 코드에 주석으로 달았다.\n\n\n\n// file: 'AbstractNamedValueMethodArgumentResolver.class'\npublic abstract class AbstractNamedValueMethodArgumentResolver implements HandlerMethodArgumentResolver {\n    @Override\n    @Nullable\n    public final Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer,\n        NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception {\n        \n        NamedValueInfo namedValueInfo = getNamedValueInfo(parameter); // 주어진 메소드 매개변수에 대해 명명된 값을 얻는다.\n        MethodParameter nestedParameter = parameter.nestedIfOptional(); // 매개변수가 Optional로 선언된 경우 별도의 처리를 하고, 아닐경우 그냥 반환한다.\n\n        // 유효성 검사\n        Object resolvedName = resolveEmbeddedValuesAndExpressions(namedValueInfo.name); \n        if (resolvedName == null) {\n            throw new IllegalArgumentException(\n                \"Specified name must not resolve to null: [\" + namedValueInfo.name + \"]\");\n        }\n\n        // 이곳에서 RequestParamMethodArgumentResolver이 오버라이딩한 곳으로 넘어간다.\n        // 컨트롤러에 선언된 매개변수 타입과 변수명을 넘긴다.\n        // 첫번째 인수는 변수명인데 사용자가 보낸 변수명과 컨트롤러 메서드에 선언된 매개변수의 변수명을 둘다 의미한다\n        // 두번째 인수는 컨트롤러에 선언된 매개변수를 추상화한 클래스\n        // 세번째 인수는 사용자의 요청 그 자체를 의미한다\n        Object arg = resolveName(resolvedName.toString(), nestedParameter, webRequest);\n        \n        ...\n\n        return arg;\n    }\n}\n\n\n\n\n// file: 'RequestParamMethodArgumentResolver.class'\npublic class RequestParamMethodArgumentResolver extends AbstractNamedValueMethodArgumentResolver\n    implements UriComponentsContributor {\n    \n    // 어떤 경우 RequestParamMethodArgumentResolver가 처리를 진행할지에 대한 코드이다\n    @Override\n    public boolean supportsParameter(MethodParameter parameter) {\n    \n        // 매개변수에 @RequestParam 이 선언된 경우 \n        if (parameter.hasParameterAnnotation(RequestParam.class)) {\n\t\n            // @RequestParam Optional&lt;E&gt; var 식으로 선언된 경우 별도의 처리를 하고 결과를 반환\n            if (Map.class.isAssignableFrom(parameter.nestedIfOptional().getNestedParameterType())) {\n                RequestParam requestParam = parameter.getParameterAnnotation(RequestParam.class);\n                return (requestParam != null &amp;&amp; StringUtils.hasText(requestParam.name()));\n            }\n\t    \n            // @RequestParam이 달려있으면서 Optional이 아닌 경우 true를 반환\n            else {\n                return true;\n            }\n        }\n        else {\n\t\n            // 매개변수에 @RequestPart가 선언된 경우 false를 반환\n            if (parameter.hasParameterAnnotation(RequestPart.class)) {\n                return false;\n            }\n\n            // 매개변수에 @RequestPart가 선언돼있지 않으면서, Optional이고 Multipart 관련된 타입인 경우 true를 반환\n            parameter = parameter.nestedIfOptional();\n            if (MultipartResolutionDelegate.isMultipartArgument(parameter)) {\n                return true;\n            }\n            \n            // RequestParamMethodArgumentResolver는 useDefaultResolution라는 이름의 boolean 상태값을 갖는다.\n            // useDefaultResolution=false이면 @RequestParam이 존재하는 경우 처리한다는 뜻이다\n            // useDefaultResolution=true이면 개발자가 @RequestParam을 생략한 경우 처리한다는 뜻이다\n            \n            // useDefaultResolution=true 인 경우이므로 @RequestParam이 없으면서, SimpleProperty인 경우 true를 반환한다는 뜻이다\n            // 문서에 의하면 SimpleProperty의 정의는 다음과 같다\n            // - primitive or primitive wrapper\n            // - enum\n            // - String or other CharSequence\n            // - Number\n            // - Date or Temporal            \n            // - URI or URL\n            // - Locale or a Class.\n            else if (this.useDefaultResolution) { \n                return BeanUtils.isSimpleProperty(parameter.getNestedParameterType());\n            }\n            \n            // 모두 아니라면 false를 반환한다 (자신이 처리하지 않겠다는 뜻)\n            else {\n                return false;\n            }\n        }\n    }\n    @Override\n    @Nullable\n    protected Object resolveName(String name, MethodParameter parameter, NativeWebRequest request) throws Exception {\n        HttpServletRequest servletRequest = request.getNativeRequest(HttpServletRequest.class);\n\n        // 선언된 매개변수가 Multipart 관련된 타입이라면 여기서 처리한다\n        if (servletRequest != null) {\n            Object mpArg = MultipartResolutionDelegate.resolveMultipartArgument(name, parameter, servletRequest);\n            if (mpArg != MultipartResolutionDelegate.UNRESOLVABLE) {\n                return mpArg;\n            }\n        }\n\n        Object arg = null;\n\n        // 요청이 Multipart 관련된 타입이라면 여기서 처리한다\n        MultipartRequest multipartRequest = request.getNativeRequest(MultipartRequest.class);\n        if (multipartRequest != null) {\n            List&lt;MultipartFile&gt; files = multipartRequest.getFiles(name);\n            if (!files.isEmpty()) {\n                arg = (files.size() == 1 ? files.get(0) : files);\n            }\n        }\n        \n        // Multipart가 아닌 경우라면 여기서 처리한다\n        if (arg == null) {\n            String[] paramValues = request.getParameterValues(name);\n            if (paramValues != null) {\n                arg = (paramValues.length == 1 ? paramValues[0] : paramValues);\n            }\n        }\n\t\n        // 생성된 매개변수의 인스턴스를 반환한다\n        return arg;\n    }\n}\n\n\n\n\n🤔 정리\n\n\n\n\n  @RequestParam은 생략하지 않고 붙여주면 쓸데없는 루프 순회를 줄이는데 도움을 준다.\n  @RequestParam을 생략하면 스레드당 필요없는 루프 순회를 적게는 수십번, 많게는 수백번 더 돌지만 코드가 더 간결해진다.\n  코드상으로 보기에 @ModelAttribute가 하는 일이 ModelAndView를 설정하는 것이 주 목적으로 보이는데 이 부분에서 약간 혼선이 온다.\n    \n      실제로 @ModelAttribute가 없어도 쿼리스트링으로 넘어오는 데이터들은 바인딩이 아주 잘 된다.\n      결국 @ModelAttribute가 있고 없고의 차이는 mavContainer(ModelAndViewContainer)를 어떻게 처리하는가이다.\n      그렇다면 만약 SSR 방식이 아니고 CSR 방식이라 @RestController를 사용한다면 @ModelAttribute를 생략하는 것이 조금 더 효율적일까? CSR 방식이라면 ModelAndView를 신경쓰지 않아도 .\n        \n          이렇게 보기엔 RequestMappingHandlerAdapter가 처음에는 @ModelAttribute가 있는 매개변수를 조회하고, 마지막에는 @ModelAttribute가 없는 매개변수를 다시 조회한다.\n          따라서 어차피 @ModelAttribute가 있든 없든 무조건 조회되므로 효율적이라고 보기 힘들 것 같다.\n          이런 구조로 만든 이유가 무엇일까? 지금 내 수준으로선 짐작하기 어렵다.\n        \n      \n    \n  \n\n\n// file: 'RequestMappingHandlerAdapter.class'\nprivate List&lt;HandlerMethodArgumentResolver&gt; getDefaultArgumentResolvers() {\n    List&lt;HandlerMethodArgumentResolver&gt; resolvers = new ArrayList&lt;&gt;(30);\n\n    // Annotation-based argument resolution\n    resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), false)); // @RequestParam이 있는 경우\n    resolvers.add(new RequestParamMapMethodArgumentResolver());\n    resolvers.add(new PathVariableMethodArgumentResolver());\n    resolvers.add(new PathVariableMapMethodArgumentResolver());\n    resolvers.add(new MatrixVariableMethodArgumentResolver());\n    resolvers.add(new MatrixVariableMapMethodArgumentResolver());\n    resolvers.add(new ServletModelAttributeMethodProcessor(false)); // @ModelAttribute가 있는 경우\n    resolvers.add(new RequestResponseBodyMethodProcessor(getMessageConverters(), this.requestResponseBodyAdvice));\n    resolvers.add(new RequestPartMethodArgumentResolver(getMessageConverters(), this.requestResponseBodyAdvice));\n    resolvers.add(new RequestHeaderMethodArgumentResolver(getBeanFactory()));\n    resolvers.add(new RequestHeaderMapMethodArgumentResolver());\n    resolvers.add(new ServletCookieValueMethodArgumentResolver(getBeanFactory()));\n    resolvers.add(new ExpressionValueMethodArgumentResolver(getBeanFactory()));\n    resolvers.add(new SessionAttributeMethodArgumentResolver());\n    resolvers.add(new RequestAttributeMethodArgumentResolver());\n    \n    ...\n\n    // Type-based argument resolution\n\t\n    ... \n\n    // Custom arguments\n\t\n    ...\n\n    // Catch-all\n    resolvers.add(new PrincipalMethodArgumentResolver());\n    resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), true)); // @RequestParam이 없는 경우\n    resolvers.add(new ServletModelAttributeMethodProcessor(true)); // @ModelAttribute가 없는 경우\n\t\n    return resolvers;\n}\n\n\n\n\n\n  정적 팩토리 메서드를 사용해 생성자의 접근제한자가 private이나 protected가 되더라도 상관없다.\n  리플렉션을 통해 별도의 설정을 하고 접근하기 때문에 접근가능하다.\n    \n      즉, 생성자를 숨기고 정적팩토리 메서드를 노출해도 바인딩이 아주 잘 된다.\n    \n  \n\n\n\n\n\n  수정자(Setter)를 무조건 달아야 하는 줄 알았어서 객체지향을 공부하다 보니 이게 매우 불-편했는데, 코드를 뜯어보니 수정자가 항상 필요한건 아니다.\n    \n      즉, 생성자로 데이터 바인딩을 커버칠 수 있다면 수정자는 아예 없어도 된다\n      다만 접근자(Getter)는 무조건 있어야만 하는데, 이유는 데이터를 반환할때 데이터를 꺼내야하기 때문이다.\n      접근자를 제거했더니 하기와 같은 예외가 발생했다.\n    \n  \n\n\n\n  DefaultHandlerExceptionResolver : Resolved [org.springframework.web.HttpMediaTypeNotAcceptableException: Could not find acceptable representation]\n\n\n\n\n\n  굉장히 웃기지만 하기와 같은 방식으로도 바인딩이 가능하다.\n    \n      생성자를 통해 String name에 siro를 바인딩한다.\n      수정자를 통해 int age에 11을 바인딩한다.\n    \n  \n\n\n@ToString\npublic class Person {\n\n    private String name; // 생성자를 통해 객체 생성과 동시에 바인딩\n    private int age; // 이후 수정자를 통해 바인딩\n\n    public Person(String name) {\n        this.name = name;\n    }\n\n    public void setAge(int age) {\n        this.age = age;\n    }\n\n}\n\n\n\n",
      "categories": ["spring","spring-mvc"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-mvc/2021-11-23-argument-resolver/"
    },{
      "image": "/assets/img/spring/spring-mvc/spring-mvc-logo.png",
      "title": "HttpMessageConverter",
      "date": "2021-11-29 00:00:00 +0000",
      "description": "Spring MVC의 HttpMessageConverter 가 하는 일\n",
      "content": "\n  💡 HttpMessageConverter    \n      RequestResponseBodyMethodProcessor\n      HttpEntityMethodProcessor\n    \n  \n  정리\n\n\n\n\n\n  코드는 📦 깃허브 에 있습니다.\n\n\n\n\n💡 HttpMessageConverter\n\n\n\n\n\n\n\nHttpMessageConverter는 HandlerMethodArgumentResolver가 처리하지 못하는 유형의 요청을 대신 처리해준다.\n\n여기서 HandlerMethodArgumentResolver가 처리하지 못하는 유형의 요청이란, 데이터가 HTTP 바디에 들어있는 경우를 의미한다.\n\n(이때, 요청은 처리 주체가 Spring MVC이므로 HTTP 요청임을 가정한다.)\n\n\n\n\n\n\n  이미지 출처: https://developer.mozilla.org/ko/docs/Web/HTTP/Messages\n\n\n\n\nHTTP 메시지는 첫줄에 요청의 핵심정보를 표시하고, 이어서 두번째 줄부터 HTTP 헤더라는 이름의 메타데이터를 쭉 나열한다. (요청에 대한 상세 설명이라고 이해하면 되겠다)\n\n이후 공백라인이 한줄 들어가고, 다음부터는 HTTP 바디라는 이름의 본격적인 데이터를 담는 공간이 존재한다.\n\n다만 GET같은 방식은 HTTP 바디를 사용하지 않고, URL에 요청에 필요한 데이터를 나열하는데, 이를 쿼리스트링 혹은 쿼리파라미터라고 부른다.\n\n일반적으로 HandlerMethodArgumentResolver는 이 쿼리스트링을 분석해 객체로 변환해주는 역할을 하며, HttpMessageConverter는 HTTP 바디를 분석해 객체로 변환해주는 역할을 한다.\n\n\n\nHttpMessageConverter는 다음과 같은 추상메서드들을 포함한 인터페이스로 정의돼있다.\n\n이름이 매우 직관적이라 따로 설명이 필요할 것 같진 않지만, 혹시 몰라 이에 대한 설명은 코드에 주석으로 작성하였다.\n\n\n\npublic interface HttpMessageConverter&lt;T&gt; {\n\n    // HttpMessageConverter가 지정된 타입을 읽을 수 있는지의 여부를 판단한다.\n    // 첫번째 인자는 읽고자 하는 타입이며, 두번째 인자는 HTTP 헤더의 Content-Type을 의미한다\n    boolean canRead(Class&lt;?&gt; clazz, @Nullable MediaType mediaType);\n\n    // HttpMessageConverter가 지정된 타입을 작성할 수 있는지의 여부를 판단한다.\n    // 첫번째 인자는 작성하고자 하는 타입이며, 두번째 인자는 HTTP 헤더의 Accept를 의미한다.\n    boolean canWrite(Class&lt;?&gt; clazz, @Nullable MediaType mediaType);\n\n    // HttpMessageConverter가 지원하는 미디어타입의 목록을 반환한다.\n    List&lt;MediaType&gt; getSupportedMediaTypes();\n\n    // 인자로 넘어온 타입에 대해 지원(읽기, 쓰기)하는 모든 미디어 타입을 반환한다.\n    default List&lt;MediaType&gt; getSupportedMediaTypes(Class&lt;?&gt; clazz) {\n\t    return (canRead(clazz, null) || canWrite(clazz, null) ?\n\t    \t\tgetSupportedMediaTypes() : Collections.emptyList());\n    }\n\n    // HTTP 메시지를 읽고 첫번째 인자로 넘어온 타입의 인스턴스를 생성한 후 데이터를 바인딩해 반환한다\n    // 두번째 인자는 클라이언트가 보낸 요청이다.\n    T read(Class&lt;? extends T&gt; clazz, HttpInputMessage inputMessage)\n\t\t    throws IOException, HttpMessageNotReadableException;\n\n    // 첫번째 인자로 넘어온 타입을 읽어 두번째 인자로 넘어온 Content-Type으로 파싱한다.\n    // 이후 세번째 인자로 넘어온, 클라이언트에게 보낼 응답에 작성한다. \n    void write(T t, @Nullable MediaType contentType, HttpOutputMessage outputMessage)\n\t\t    throws IOException, HttpMessageNotWritableException;\n\n}\n\n\n\n\nHttpMessageConverter에는 10개의 구현체가 존재한다.\n\n약간 첨언하자면, 클라이언트의 요청을 분석할때는 HTTP 헤더의 Content-Type을 참고하며, 클라이언트에게 응답을 반환할때는 HTTP 헤더의 Accept를 참고한다.\n\n\n\n\n  💡 Content-Type: 클라이언트가 서버에 보내는 데이터의 타입을 명시한 표준 헤더\n\n  💡 Accept: 클라이언트가 서버에게서 응답받길 원하는 데이터의 타입을 명시한 표준 헤더\n\n\n\n\n즉, Content-Type과 Accept에 따라 10개의 HttpMessageConverter중 어떤것이 사용될지가 결정된다.\n\n\n\n\n\n\n\n이중 경험상 가장 많이 사용되는 구현체는 MappingJackson2HttpMessageConverter인데, 이녀석은 이름 그대로 application/json 타입의 메시지를 파싱하는 책임을 갖는다. (Jackson은 json을 처리하는 표준 라이브러리의 이름이다. ex) ObjectMapper)\n\n헌데 위 이미지 속 리스트 7,8번 인덱스에 위치한 MappingJackson2HttpMessageConverter가 두개인데, 왜 두개인지 살펴보면 인코딩이 다르다.\n\n하나는 ISO-8859-1이며, 하나는 UTF-8인데 관련 히스토리를 찾아보니, 예전 스프링은 ISO-8859-1만을 지원하고 있었던 듯 하다.\n\n이후 유니코드가 대세로 사용됨에 따라 추가된것으로 보인다.\n\n관련 커밋은 다음 링크를 참고바란다.\n\n\n\n\n  💡 https://github.com/spring-projects/spring-framework/commit/c38542739734c15e84a28ecc5f575127f25d310a\n\n\n\n\n10개의 HttpMessageConverter는 ArrayList로 관리되고 있으며, 이 녀석들에게 처리를 위임하는 HandlerMethodArgumentResolver의 구현체는 다음 두 종류가 존재하는 것 같다. (더 있을 수도 있다.)\n\n\n  RequestResponseBodyMethodProcessor\n  HttpEntityMethodProcessor\n\n\n\n\nRequestResponseBodyMethodProcessor\n\n\n\nRequestResponseBodyMethodProcessor가 사용되는 경우는 다음과 같다.\n\n\n\npublic class RequestResponseBodyMethodProcessor extends AbstractMessageConverterMethodProcessor {\n\n    // 클라이언트의 요청을 분석할때 사용될지 여부\n    @Override\n    public boolean supportsParameter(MethodParameter parameter) {\n        return parameter.hasParameterAnnotation(RequestBody.class); // @RequestBody가 달려있는 경우\n    }\n\n    // 클라이언트에게 응답할 때 사용될지 여부\n    @Override\n    public boolean supportsReturnType(MethodParameter returnType) {\n        return (AnnotatedElementUtils.hasAnnotation(returnType.getContainingClass(), ResponseBody.class) ||\n            returnType.hasMethodAnnotation(ResponseBody.class)); // @ResponseBody가 달려있는 경우\n    }\n\n}\n\n\n\n\n코드를 보면 인자에 @RequestBody가 존재하는 경우와 리턴타입이나 메서드에 @ResponseBody가 존재하는 경우 이 구현체가 사용될것임을 알 수 있다.\n\n여기서 @ResponseBody가 사용되는 경우가 생각보다 굉장히 많은데, 혹자는 HTTP API라고 말하고, 혹자는 REST API라고 말하는, 우리가 자주 사용하는 @RestController를 사용하게 되면 다음과 같은 코드가 숨겨져있다.\n\n\n\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Controller\n@ResponseBody // &lt;- 요녀석\npublic @interface RestController {\n}\n\n\n\n\n즉, RequestResponseBodyMethodProcessor는 생각보다 아주 많이 사용되는 구현체이다.\n\n전체적인 세부 동작은 사실 HandlerMethodArgumentResolver와 큰 차이가 없고 이에 대한 내용은 이전 문서에 작성하였으니 생략하겠다.\n\n\n\nHttpEntityMethodProcessor\n\n\n\nHttpEntityMethodProcessor가 사용되는 경우는 다음과 같다.\n\n\n\npublic class HttpEntityMethodProcessor extends AbstractMessageConverterMethodProcessor {\n    \n    // 클라이언트의 요청을 분석할때 사용될지 여부\n    @Override\n    public boolean supportsParameter(MethodParameter parameter) {\n        return (HttpEntity.class == parameter.getParameterType() ||\n            RequestEntity.class == parameter.getParameterType());\n    }\n\n    // 클라이언트에게 응답할 때 사용될지 여부\n    @Override\n    public boolean supportsReturnType(MethodParameter returnType) {\n        return (HttpEntity.class.isAssignableFrom(returnType.getParameterType()) &amp;&amp;\n            !RequestEntity.class.isAssignableFrom(returnType.getParameterType()));\n    }\n\n}\n\n\n\n\n코드를 보면 요청을 처리하는 메서드의 인자가 HttpEntity 타입이거나 RequestEntity 타입인 경우 동작한다.\n\n클라이언트에게 응답을 반환하는 경우는 HttpEntity 타입이면서 RequestEntity가 아닌 경우를 의미한다.\n\n즉, HttpEntity이거나 ResponseEntity인 경우이다.\n\n\n\n여기서 HttpEntity는 스프링 프레임워크에서 제공하는 클래스로, HTTP 메시지 자체를 자바 객체로 모델링한 클래스이며, 크게 이를 상속받은 RequestEntity와 ResponseEntity로 나뉜다.\n\n\n\n\n\n\n\n실제로 다음과 같다. (HttpMessageConverter를 사용하기 위해 HTTP 바디에 데이터를 담는 POST 방식의 코드를 예시로 추가합니다.)\n\n\n\n@Slf4j\n@RestController\npublic class PostApiController {\n    \n    @PostMapping(\"/v1/hello\")\n    public String helloV1(@RequestBody Cat cat) {\n        log.info(\"cat={}\", cat);\n        return \"ok\";\n    }\n\n}\n\n\n\n\n\n이런 코드도 잘 동작하지만 (인자에 @RequestBody가 선언돼있으니 RequestResponseBodyMethodProcessor가 사용될 것임을 유추할 수 있다.)\n\n\n\n@Slf4j\n@RestController\npublic class PostApiController {\n    \n    @PostMapping(\"/v1/hello\")\n    public String helloV1(RequestEntity&lt;Cat&gt; cat) { // RequestEntity&lt;T&gt;인 경우\n        log.info(\"cat={}\", cat);\n        return \"ok\";\n    }\n\n    @PostMapping(\"/v2/hello\")\n    public String helloV2(HttpEntity&lt;Cat&gt; cat) { // HttpEntity&lt;T&gt;인 경우\n        log.info(\"cat={}\", cat);\n        return \"ok\";\n    }\n\n}\n\n\n\n\n\n이렇게 작성해도 아주 잘 동작한다.\n\n여기서는 HttpEntityMethodProcessor 가 사용될 것을 유추할 수 있다.\n\n\n\n정리\n\n\n\n\n  @RequestBody를 사용할때는 @RequestParam처럼 각 키별로 하나하나 떼오기 위해 Map을 사용해야 한다.\n    \n      이게 싫다면 별도의 컨버터를 구현하여 직접 등록해야만 한다 !\n    \n  \n\n\n\n\n\n\n\n  @RequestBody를 사용할때는 기본생성자가 반드시 필요하며, 접근제한자는 private이여도 무방하다.\n    \n      구현체마다 조금씩 다르겠지만 일반적으로 리플렉션을 통해 동작하기 때문이며, 특히 우리가 자주 사용하는 @RestController에서는 ObjectMapper가 사용된다.\n      이말인즉슨, 수정자(Setter)가 필요하지 않다는 의미이도 하다.\n    \n  \n\n\n\n\n\n  POST 방식처럼 HTTP 바디에 데이터를 담는 형식의 통신을 하더라도 HTTP 프로토콜의 특성상 여전히 쿼리스트링은 사용할 수 있다.\n    \n      즉, @PostMapping에서도 @RequestParam을 사용할 수 있다.\n      단, 이 경우 일반적으로 SSR(서버사이드렌더링)을 하지 않으므로 @ModelAttribute를 사용해야할 이유가 아예 존재하지 않지만, 일부러 테스트 해본결과 역시 비정상적으로 동작함을 확인했다.\n    \n  \n\n\n\n",
      "categories": ["spring","spring-mvc"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-mvc/2021-11-29-http-message-converter/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "Validation API",
      "date": "2021-12-01 00:00:00 +0000",
      "description": "JSR-380에 정의된 자바 유효성 검사 표준\n",
      "content": "\n  ✔ Validation\n  설치\n  사용\n\n\n\n\n✔ Validation\n\n\n\nValidation API는 JSR-380 에 정의된 자바 플랫폼의 유효성 검사 표준으로 javax.validation 패키지에 위치한다.\n\n\n\n\n  💡 JSR(Java Specification Request) ?\n\n  자바 스펙 요구서로 자바 플랫폼에 추가된 사양 및 기술을 정의하는 공식 문서이다.\n\n\n\n\n다양한 사용 방법이 있으나, 이번 포스팅에서는 별도의 유틸리티 클래스를 통해 도메인 계층에서 유효성을 검증하는 방법을 작성한다.\n\nValidation API에 대한 조금 더 자세한 사용방법들은 Baeldung - Validation 을 참고해보자.\n\n\n\n설치\n\n\n\n// file: 'build.gradle'\n\ndependencies {\n    implementation 'javax.validation:validation-api:2.0.1.Final'\n    implementation 'org.hibernate.validator:hibernate-validator:7.0.1.Final'\n}\n\n\n\n\n만약 스프링 부트를 사용한다면 스타터를 지원한다.\n\n// file: 'build.gradle'\n\ndependencies {\n    implementation 'org.springframework.boot:spring-boot-starter-validation'\n}\n\n\n\n\n사용\n\n\n\n다음과 같은 클래스가 있다.\n\n\n\n@Value(staticConstructor = \"of\")\npublic class Cat {\n\n    String name;\n    Long age;\n\n}\n\n\n\n\n고양이의 이름과 나이가 절대로 비어있으면 안된다고 가정하면 다음과 같은 코드를 매번 작성해야만 한다.\n\n\n\npublic class CatService {\n\n    public void doSomething(Cat cat) {\n        Objects.requireNonNull(cat, \"cat must not be null\");\n        Objects.requireNonNull(cat.getName(), \"cat name must not be null\");\n        Objects.requireNonNull(cat.getAge(), \"cat age must not be null\");\n        // other codes...\n    }\n\n}\n\n\n\n\n이런 귀찮은 작업을 모두 대신 처리해주는게 Validation API라고 볼 수 있는데, 이것을 사용하면 다음과 같이 바꿀 수 있다.\n\n\n\n@Value(staticConstructor = \"of\")\npublic class Cat {\n\n    @NotNull // 고양이 이름은 null일 수 없다\n    String name;\n\n    @NotNull // 고양이 나이는 null일 수 없다\n    Long age;\n\n}\n\n\n\n\n이제 어노테이션을 사용하려면 일반적으로 @Valid나 @Validated 를 사용하면 되는데, 이는 컨트롤러 레이어에 사용시에만 제대로 동작한다.\n\n\n\n\n  @Validated가 @Valid를 포함하는 포괄적인 개념이라고 봐도 무방하겠다.\n\n\n\n\n왜 컨트롤러 레이어에서만 제대로 동작하느냐면, Spring MVC를 사용 할 경우 제공되는 인터셉터에 위 어노테이션들을 사용해 검증하는 상세 구현이 있기 때문이다.\n\n\n\n하지만 유효성 검사를 컨트롤러 레이어에 종속시키는 것보다 도메인에서 담당하게 하는 것이 설계상 조금 더 좋다고 보는데, 서비스 레이어에서 위 어노테이션들을 사용 할 경우 이 어노테이션들이 제대로 동작하지 않는 문제가 존재한다.\n\n왜냐하면 서비스 레이어는 Spring MVC에서 구현한 인터셉터의 영향을 받지 않기 때문이다. (굳이 동작하게 하려면 번거로운 짓을 좀 해야한다.)\n\n따라서 컨트롤러 레이어를 제외한 곳에서 사용 할 별도의 검증기를 만들어 주면 매우 유용하다.\n\n\n\n// 일단 정적 메서드로 다 해결할 수 있으므로 추상 클래스로 작성\npublic abstract class ValidateUtils {\n\n    // 어노테이션 기반으로 검증을 처리해주는 검증기를 선언\n    private static final Validator VALIDATOR = Validation.buildDefaultValidatorFactory().getValidator();\n\n    // 추후에 확장될수도 있으므로 기본 생성자를 작성\n    public ValidateUtils() {\n    }\n\n    // 검증 메서드\n    public static void validate(@NonNull Object... objects) {\n        // 넘어온 인자를 순회하며 검증\n        for (Object object : objects) {\n            // 인자에 선언된 어노테이션으로 검증. 만약 유효성 검사에 통과하지 못하면 에러메시지를 반환한다\n            Set&lt;ConstraintViolation&lt;Object&gt;&gt; violations = VALIDATOR.validate(object);\n            \n            // 유효성 검사에 통과하지 못했다면 에러메시지가 들어있을 것이다.\n            // 즉, isEmpty()==false일 경우 유효성 검사에 통과하지 못했음을 의미한다.\n            if (!violations.isEmpty()) {\n                throw new ConstraintViolationException(violations);\n            }\n        }\n    }\n\n}\n\n\n\n\n이후 도메인 코드는 다음과 같이 바뀔 수 있다.\n\n\n\npublic class CatService {\n\n    public void doSomething(Cat cat) {\n        ValidateUtils.validate(cat);\n        // other codes...\n    }\n\n}\n\n\n\n\nclass CatServiceTest {\n\n    private CatService catService;\n\n    @BeforeEach\n    void setUp() {\n        catService = new CatService();\n    }\n\n    // 테스트가 성공한다\n    @Test\n    void doSomething() throws Exception {\n        assertThatThrownBy(() -&gt; catService.doSomething(Cat.of(null, null)))\n            .isInstanceOf(ConstraintViolationException.class)\n            .hasMessage(\"age: 널이어서는 안됩니다, name: 널이어서는 안됩니다\");\n    }\n\n}\n\n\n\n\n하지만 위 방식에도 아주 큰 단점이 존재하는데, 모든 도메인에 검증하는 코드를 매번 추가로 작성해야 한다는 것이다.\n\n이러한 것을 횡단관심사라고 부르며 이러한 문제를 해결할 수 있는 아주 좋은 방법이 존재하는데, 그것이 AOP이다.\n\n별도의 Aspect를 작성하면 위의 단점또한 아주 쉽게 해결할 수 있다.\n\n하지만 Aspect를 이 포스팅에서 함께 다루기엔 그 자체로 심오한 내용이 많기 때문에 주제가 묻힐것 같다는 생각이 든다.\n\n따라서 그냥 이런 문제가 존재하고, 이런 문제를 어떻게 해결할 수 있다 정도만 알고있도록 하자.\n\n\n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2021-12-01-javax-validation/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "리눅스 기초",
      "date": "2021-12-04 00:00:00 +0000",
      "description": "리눅스 기초 정리\n",
      "content": "\n  리눅스(Linux)\n  셸(Shell)\n  포트(Port)\n  파일시스템 디렉토리\n  명령어    \n      ls\n      touch\n      cat\n      head\n      tail\n      pwd\n      which\n      echo\n      clear\n      cd\n      mkdir\n      rmdir\n      cp\n      mv\n      rm\n      find\n      grep\n      whoami\n      passwd\n      df\n      free\n      top\n      vmstat\n      ps\n      chmod\n      chown\n    \n  \n  유저 생성, 제거\n\n\n\n\n리눅스(Linux)\n\n\n\n1991년 핀란드 헬싱키 공대 대학생이었던 리누스 토르발스(Linus Benedict Torvalds)가 개발한 커널이다. 혹은 이 커널을 사용하는 운영체제를 말한다.\n\n리눅스 운영체제는 유닉스(Unix)에서 갈라져 나왔으며, 당시 유닉스의 가격이 막대했기에 개인이 함부로 사용할 수 없었다고 한다. (요즘 어지간한 대학의 컴퓨터과학과에는 한대정도씩 있다는듯…)\n\n따라서 리눅스는 Unix-like 라고 부른다고도 한다.\n\n\n\n커널이란, 컴퓨터의 하드웨어 자원을 프로세스에 할당해주거나 프로세스를 제어하거나 메모리를 제어하는 등의 전체적인 스케쥴링을 해주는 핵심적인 프로세스를 말한다.\n\n\n\n여담이지만, 리누스 토르발스는 깃(Git)의 아버지이기도 하다… (😲)\n\n코드와 모든 개발 과정이 완벽하게, 투명하 공개된 최초의 오픈소스 프로젝트이자, 현재 전 세계에서 가장 참여자가 많은 프로젝트이기도 하다는 듯…\n\n\n\n\n\n  리누스 토르발스(Linus Benedict Torvalds)\n\n\n\n\n기본적으로 유닉스와 리눅스의 사용방법은 매우 유사하며, 이 말인즉슨 MacOS를 잘 다룬다면 리눅스도 큰 어려움 없이 잘 다룰 수 있음을 의미하며, 역시 그 반대도 성립한다.\n\nApple의 MacOS는 그 자체로 개인용 유닉스이므로, Unix-like라고 부르지 않는다고 한다.\n\n\n\n리눅스는 아주 크게 Debian, RedHat 계열로 나뉘는데 대략적인 족보는 다음과 같다. (세세하게는 더 있는 것 같지만, 거기까진 몰라도 될 것 같다.)\n\n\n\n\n  Debian\n    \n      Debian\n      Ubuntu\n      …\n    \n  \n  RedHat\n    \n      RedHat\n      Fedora\n      CentOS\n      …\n    \n  \n\n\n\n\n나도 30년 가까운 인생을 살면서 리눅스를 단 한번도 사용해보지 않았고, 오직 윈도우만 사용해봤던 사람이다.\n\n본격적으로 개발자로 전업하며 리눅스를 처음 접했고 공부를 제대로 시작한것은 얼마 되지 않았다.\n\n개발자 생활을 이어가다 보니 보통 개인적인 용도로는 데비안 계열의 Ubuntu를 사용하게 되었고, 실무에서 사용하는 서버 컴퓨터들은 모조리 CentOS를 사용하고있다.\n\n근데 주변을 둘러봐도 나만 이런게 아니고 대체로 다 비슷한 것 같았다.\n\n\n\n이 얘기를 왜 하냐면, Debian과 RedHat으로 계열이 나뉜다 한들 사실 실제로 사용하는 입장에서는 큰 차이가 없었다는 말을 하고 싶었기 때문이다.\n\n두 계열을 일단 다 써보기는 했는데, 결국 디렉토리의 구조와 패키지 관리자가 조금 다르다 정도를 제외하면 대부분의 경우에 큰 차이를 느끼기 힘들정도였다.\n\n즉, 아무 리눅스에 대해 잘 공부해두면 어떤 계열의 리눅스를 쓰던 별 문제 없이 사용할 수 있을 것 같다는 생각이 들었다.\n\n\n\n셸(Shell)\n\n\n\n\n\n\n\n리눅스는 커널이며, 이 커널을 둘러싼 껍데기가 존재한다.\n\n이 껍데기를 셸(Shell, 조개껍데기)이라고 부르며 셸은 커널과 사용자 사이에 위치해 커널을 외부에서 보호하고, 사용자들에게 조금 더 인간에게 친화적인 인터페이스를 제공하는 역할을 한다.\n\n\n\n셸의 종류도 여러가지 존재하지만 크게 두가지만 알면 큰 문제 없을 것 같다.\n\n\n\n\n  sh (Bourne Shell)\n    \n      유닉스에서 사용하는 슈퍼 셸. 모든 셸의 조상격.\n      그 자체로 기능이 매우 적기 때문에, 역설적으로 정말 가볍고 빠르다.\n    \n  \n  bash (Bourne-again Shell)\n    \n      csh(C Shell), ksh(Korn Shell)을 포함.\n      즉, 기능이 많은 만큼 무겁다.\n      셸 스크립트를 작성했을 때 sh에 비해 상대적으로 느리다고 한다.\n    \n  \n\n\n\n\n리눅스에서는 대부분의 처리를 이 셸로 처리하기 때문에, 셸에 대해 알면 알수록 리눅스에 대한 모든 작업이 수월해진다.\n\n일례로 리눅스에서 사용하는 모든 커맨드는 셸 스크립트(Shell Script)로 작성되어 어딘가에 위치하고 있다고 생각해도 무방하다.\n\n\n\n\n\n단, 셸 스크립트의 경우 깊게 파면 어지간한 프로그래밍 언어 수준으로 어렵다. 다만 그 시간을 투자할 가치는 충분히 있는 것 같다.\n\n\n\n포트(Port)\n\n\n\n유닉스와 리눅스는 IANA(Internet Assigned Numbers Authority)라는 범세계적인 기구에서 관리하는 Well Known Ports에 대해 알고있다.\n\n\n\n\n  📜 Service Name and Transport Protocol Port Number Registry\n\n\n\n\n이것들은 그냥 우리는 이 포트는 이 용도로 사용하자! 라고 전 세계적으로 약속된 포트들이라고 이해하면 편하다.\n\n굉장히 많지만 주로 자주 사용되어 알고있으면 좋을 것 같은 포트는 아래 표에 정리해뒀다.\n\n\n\n\n  \n    \n      Port\n      Protocol\n    \n  \n  \n    \n      21\n      FTP\n    \n    \n      22\n      SSH, SFTP…\n    \n    \n      23\n      Telnet\n    \n    \n      25\n      SMTP\n    \n    \n      465\n      SMTPS\n    \n    \n      43\n      whois\n    \n    \n      53\n      DNS\n    \n    \n      80\n      HTTP\n    \n    \n      443\n      HTTPS\n    \n    \n      123\n      NTP\n    \n  \n\n\n\n\n파일시스템 디렉토리\n\n\n\n윈도우는 보통 C:\\Windows 하위에 존재하며, 가끔 뭔가 만질일이 생기면 System32폴더를 건드는 경우가 있다.\n\n리눅스는 윈도우와 다르게 root 경로(cd /)에 수많은 파일시스템 디렉토리가 존재한다.\n\n역시 매우 많지만 알고있으면 좋을만한 것들만 기록해뒀다.\n\n\n\n\n  \n    \n      Directories\n      Description\n    \n  \n  \n    \n      /bin\n      기본 리눅스 명령어들이 위치한 곳\n    \n    \n      /sbin\n      관리자용 명령어들이 위치한 곳\n    \n    \n      /home\n      유저들의 홈\n    \n    \n      /etc\n      유저 비밀번호, 각종 프로그램의 설정파일, 리눅스의 설정파일 등이 위치한 곳\n    \n    \n      /lib\n      리눅스에 등록된 유저들이 공유하는 프로그램 등이 위치한 곳\n    \n    \n      /proc\n      프로세스의 정보들이 위치한 곳\n    \n    \n      /tmp\n      임시 파일들이 위치한 곳\n    \n    \n      /usr\n      각종 코드나 프로그램들이 위치한 곳\n    \n    \n      /var\n      로그, 메일처럼 점점 사이즈가 커지는 것들이 위치한 곳\n    \n  \n\n\n\n\n명령어\n\n\n\nls\n\n\n\nlist segments. 파일과 디렉토리의 모든 정보를 리스트로 나열한다.\n\n여러가지 alias가 걸려있으며 주로 ll, l, ls -a 등의 명령어를 사용하게 된다.\n\n윈도우 프롬프트를 오래 사용한 분들은 dir로 사용하는 경우도 있다.\n\n\n\ntouch\n\n\n\n파일을 생성한다. touch testFile.txt 를 입력하면 현재 위치에 testFile.txt라는 파일이 생성된다.\n\n\n\ncat\n\n\n\n파일의 내용을 터미널에 출력하는 용도로 사용된다.\n\n\n\nhead\n\n\n\n파일의 내용중 최상단의 내용을 출력한다.\n\n예를 들어 head -500 testFile.txt를 입력하면 testFile.txt의 맨 윗줄부터 500줄 까지의 내용이 출력된다.\n\n\n\ntail\n\n\n\nhead와 반대이다. 파일의 가장 아래쪽 부분을 터미널에 출력한다.\n\n보통 로그파일을 볼 때 -f 옵션을 붙여 자주 사용하는데, 실시간으로 기록되는 로그가 계속해서 터미널에 출력되게 된다.\n\n\n\npwd\n\n\n\nprint work directory의 약어로, 현재의 위치를 터미널에 출력한다.\n\n\n\nwhich\n\n\n\n해당 파일의 위치를 읽어 터미널에 출력해준다.\n\n이 경우 시스템 환경변수에 등록돼있지 않다면 알 수 없을수도 있다.\n\n\n\necho\n\n\n\n터미널에 내용을 출력한다.\n\necho hello world 를 입력하면 터미널에 hello world가 출력된다.\n\n자바로 치면 System.out.println(\"hello world\"),\n\n자바스크립트로 치면 console.log(\"hello world\")\n\n파이썬으로 치면 print(\"hello world\") 와 비슷하다.\n\n\n\nclear\n\n\n\n터미널의 모든 내용을 지운다.\n\n주로 명령어를 많이 입력해 터미널이 지저분할 경우 사용하며, ls와 같이 자주 사용하게 되는 명령어중 하나.\n\n\n\ncd\n\n\n\nchange directory의 약자로 말 그대로 다른 디렉토리로 접근하는 명령어.\n\ncd ~를 입력하면 현재 로그인한 사용자의 홈(/home/{사용자})으로 이동한다.\n\ncd ..를 입력하면 현재 위치의 상위 디렉토리로 이동한다.\n\ncd -를 입력하면 이전 위치로 이동한다.\n\n\n\nmkdir\n\n\n\nmake directory의 약자. 새로운 디렉토리를 생성한다.\n\n\n\nrmdir\n\n\n\nremove directory의 약자. 디렉토리를 제거한다.\n\n사용할 때 매우 주의하자.\n\n\n\ncp\n\n\n\ncopy의 약자. 주로 파일이나 디렉토리를 옮기거나 복사할 때 사용한다.\n\n\n\nmv\n\n\n\nmove의 약자. 나는 보통 cp를 사용해서 잘 사용하지 않게 되는 명령어였다.\n\n\n\nrm\n\n\n\nremove의 약자. 파일이나 디렉토리를 제거한다.\n\n역시 사용할 때 매우 주의해야 한다.\n\nrm -rf 와 관련한 여러가지 밈이 있다.\n\n\n\nfind\n\n\n\n위치를 기준으로 특정 조건을 만족하는 파일을 찾는다.\n\n\n\ngrep\n\n\n\nfind와 자주 헷갈리는데, grep은 파일에서 원하는 단어를 찾는 명령어이다.\n\n검색할때 이 명령어를 자주 사용하게 된다.\n\n혹은 다른 명령어에 옵션으로 끼워넣어 사용하는 경우도 많다.\n\n예를 들어 현재 실행중인 프로세스 중 특정 정보를 포함하는 프로세스가 찾고싶다면 다음과 같은 명령어를 입력한다.\n\nps -ef | grep java - 현재 실행중인 프로세스 중 java라는 단어가 들어있는 프로세스를 출력해라.\n\n\n\nwhoami\n\n\n\n현재 로그인한 유저가 누구인지 알고싶을 때 입력.\n\n\n\n\n\n\n\npasswd\n\n\n\n현재 로그인한 유저의 비밀번호를 바꾸고 싶을 경우 입력. (pwd와 헷갈리지 말자!)\n\n\n\ndf\n\n\n\n현재 서버의 파일시스템 사용 정보를 출력한다.\n\n비슷한 유형의 명령어들에 -h (human의 약자로 추정) 옵션을 추가하면 조금 더 사람이 읽기 쉽게 포매팅되어 출력된다.\n\ndf -h를 입력하면 다음과 같다.\n\n\n\n\n\n\n\nfree\n\n\n\n현재 서버의 메모리 사용 정보를 출력한다.\n\n역시 free -h를 입력하면 다음과 같은 정보를 볼 수 있다.\n\n\n\n\n\n\n\ntop\n\n\n\n현재 서버의 전체적인 시스템 자원 사용 현황을 볼 수 있다.\n\n주로 장애상황이나 평소 모니터링시 사용하며, 이 명령어를 입력 후 키보드의 1을 누르면 CPU의 현황을 코어별로 나눠서 볼 수도 있다.\n\n\n\n\n\n\n\nvmstat\n\n\n\ntop을 조금 더 편하게 쓰는 느낌이라고 해야할 까? 뭐라 정의하기 힘들다.\n\nvmstat 1을 입력하면 현재 서버의 상태를 1초주기로 업데이트해서 계속 보여준다.\n\n역시 서버의 상태를 모니터링할 때 사용한다. 주로 이쪽을 사용하는 듯.\n\n\n\n\n\n\n\nps\n\n\n\n현재 실행중인 프로세스의 정보를 모두 출력한다.\n\n주로 ps -ef를 자주 사용한다.\n\nPID는 프로세스의 아이디, PPID는 프로세스의 부모 아이디(parent)를 의미한다.\n\n즉, 일반적으로 프로세스 하나를 제거하면 자식 프로세스도 모두 종료된다.\n\n\n\n\n\n\n\nchmod\n\n\n\n파일의 읽기(read), 쓰기(write), 실행(execute)에 대한 권한을 조정한다.\n\nls -a 같은 명령어를 입력하면 현재 위치한 디렉토리에 존재하는 파일들의 상세 정보를 알려주는데 대략 다음과 같은 뜻이 있다.\n\n\n\n\n\n\n\nchmod +x file.txt를 입력하면 모든 유저들에게 해당 파일에 대한 실행(execute) 권한을 허용(+)하는 것을 의미하며, chmod -x file.txt를 입력하면 실행 권한을 제거하는 것이 된다.\n\n혹은 chmod 755 file.txt를 입력하면 자신에게 읽기, 쓰기, 실행 권한을 주고, 그룹과 타인에게는 읽기와 실행권한만 주라는 의미이다.\n\n이는 이진수에 대한 이해가 필요한데, 10진수 7은 2진수로 111를 의미하며, 111은 각각 읽기, 쓰기, 실행 권한이 참(true)임을 의미하기도 하기 때문이다.\n\n즉, 10진수 5는 2진수로 101이기 때문에, 읽기에 대한 권한이 1, 쓰기에 대한 권한이 0, 실행에 대한 권한이 1임을 의미한다.\n\n\n\nchown\n\n\n\n파일에 대한 소유권을 변경하는데 사용된다.\n\n소유권은 개인과 그룹이 존재하며 둘 모두를 변경하거나 하나만 변경할수도 있다.\n\n하지만 이쪽은 chmod와 다르게 생각보다 자주 사용되지는 않는것 같다.\n\n\n\n유저 생성, 제거\n\n\n\n몇가지 방법이 있지만, 가장 편리한 것은 adduser 명령어를 사용하는 것이다.\n\n이 명령어를 통해 유저를 생성하면 관련된 모든 폴더를 자동으로 함께 생성해주기 때문이다.\n\nadduser {유저이름}을 입력하면 몇가지 설정에 대한 질문이 출력되는데, 잘 모르겠으면 그냥 엔터를 마구 눌러도 괜찮다.\n\n어차피 크게 중요하지도 않고 나중에 바꿀수도 있다.\n\n\n\n\n\n유저를 생성한 후 /home 폴더로 들어가 ls -a를 입력하면 새로 생성 된 것을 확인할 수 있다.\n\n\n\n\n\n\n\n유저를 제거하고 싶다면 deluser {유저명} 명령어를 이용하면 손쉽게 제거된다.\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-12-04-linux/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "HTTP 캐시",
      "date": "2021-12-11 00:00:00 +0000",
      "description": "불필요한 네트워크 비용을 줄이는 효율적인 방법\n",
      "content": "\n  💡 Cache\n  😄 캐시는 어려운게 아니다\n  🚀 HTTP 캐시\n  📜 시나리오 1: no-store\n  📜 시나리오 2: no-cache\n  📜 시나리오 3: max-age\n  📜 시나리오 4: ETag\n  🚧 HTTP 캐시 Policy\n  📕 참고\n\n\n\n\n💡 Cache\n\n\n\n캐시라는 것은 매우 많은 분야에서 사용되는 개념이다.\n\n캐시에 대해 러프하게 설명해보자면, 원본을 복제한 사본을 만들고 이를 가까운곳에 저장해 사용하는것을 의미한다.\n\n캐시는 기본적으로 데이터 지역성(Locality)의 원리를 이용하는데, 그 내용은 다음과 같다.\n\n\n\n\n  시간 지역성(Temporal locality)\n    \n      for, while 같은 반복문에 사용되는 조건 변수처럼 한번 참조된 데이터는 잠시 후에 다시 참조될 가능성이 높다.\n    \n  \n\n\n\n\n\n  공간 지역성(Spatial Locality)\n    \n      메모리에 접근할 때 참조된 데이터 근처에 있는 데이터가 잠시 후에 다시 참조될 가능성이 높다.\n      대표적으로 배열이 있으며, list[0]이 참조되면 잠시 후 list[1]이 참조될 가능성이 높다는 것이다.\n    \n  \n\n\n\n\n\n  순차적 지역성(Sequential Locality)\n    \n      분기가 발생하는 비순차적 실행이 아닌 이상 명령어들이 메모리에 저장된 순서대로 실행하는 특성을 이용한 원리로 순차적일수록 다음 순서의 데이터가 사용될 가능성이 높다.\n      즉, 프로세스는 위에서 아래로 순차적으로 실행되므로, 어떤 코드라인 한줄이 실행되면 짧은 시간 안에 바로 아래 위치한 코드라인이 실행될 가능성이 높다는 것이다.\n    \n  \n\n\n\n\n😄 캐시는 어려운게 아니다\n\n\n\n딱딱하기만 한 교과서적인 이야기는 잠시 치워두고 캐시를 조금 더 쉽게 이해해보자.\n\n\n\n첫번째 예로 지갑을 들 수 있다.\n\n지갑이 없다면 우리는 현금이 필요할 때마다 ATM이나 은행에 가서 돈을 인출해야 한다.\n\n하지만 미리 돈을 인출해서 지갑에 넣어둔다면 현금이 필요할 때 ATM이나 은행을 찾지 않고 즉시 현금을 사용할 수 있다.\n\n\n\n두번째 예로 식당에서 미리 테이블을 세팅해두는 것을 들 수 있다.\n\n보통 회사 근처의 식당들은 점심시간에 손님이 몰리는데, 손님이 올때마다 테이블을 세팅하면 매번 움직이는데 적지 않은 시간적, 체력적인 비용이 발생한다.\n\n따라서, 점심시간이 되기 전 모든 테이블을 미리 세팅해둔다면 이러한 비용을 아낄 수 있을 것이다.\n\n\n\n이러한 개념들을 우리가 개발하는것들에 접목한 것이 캐시이다.\n\n즉, ~을 캐시한다 라는 것은 ~을 미리 저장 해둔다 혹은 ~을 미리 해둔다 정도의 의미로 받아들여도 무방하다.\n\n\n\n다음과 같은 것들을 떠올려 보자.\n\n\n\n\n  CPU와 RAM 사이에 위치한 캐시메모리\n  넷플릭스, 유튜브 등의 다국적 기업들이 각 국가에 구축해둔 CDN\n  데이터베이스는 가장 최근에 실행된 쿼리에 대한 결과를 캐시해둔다\n  DNS 서버는 최근에 실행된 쿼리에 대한 결과를 캐시해둔다\n\n\n\n\n마찬가지로 이러한 개념을 HTTP에 접목한 것을 HTTP 캐시라 하며, 이 포스팅에서 다룰 내용이기도 하다.\n\n\n\n🚀 HTTP 캐시\n\n\n\n웹이나 모바일에서 화면의 어떤 버튼을 누를때마다 필요한 모든 리소스를 다시 다운받아야 한다면 이는 매우 비효율적인 일이다.\n\n특히 TCP에 대해 어느정도 이해하고 있는 사람이라면 이러한 이벤트가 발생할때 처리해야 하는 Handshaking이 얼마나 비싼 비용을 지불하는지 알 것이다.\n\n\n\ncss, javascript 파일들은 크면 코드라인만 만단위로 작성되기도 한다.\n\nimage의 경우 그 자체로 용량이 kb 혹은 MB단위가 되는 경우도 허다하다.\n\n그렇다면 용량이 큰 이런 정적 파일들을 브라우저에 캐시해놓는다면 어떨까?\n\n이것이 바로 HTTP 캐시이다.\n\n브라우저는 이러한 용량이 큰 파일들을 처음 다운받을 때 브라우저 내부 어딘가에 캐시해두고, 사용자가 어떤 버튼을 클릭하면 서버로 요청을 보내기 전 브라우저 캐시를 먼저 확인해본다.\n\n그리고 이미 브라우저가 해당 파일(=리소스)을 캐시했다면 이는 서버에 요청하지 않고 갖고 있는 것을 그대로 사용하는 것이다.\n\n\n\n그렇다면 HTTP 캐시는 어떻게 사용해야 할까?\n\nHTTP 캐시를 사용하기 위해서는 Cache-Control 이라는 HTTP 헤더를 사용하면 된다.\n\n\n\n\n\n\n\n위 내용이 아직 무슨 말인지 몰라도 괜찮다.\n\n하나씩 차근차근 테스트해보면서 감을 잡을 수 있을 것이다.\n\n\n\n위 이미지에서 Expires는 생각보다 중요하진 않지만, max-age와의 우선순위 문제가 있어 추가해두었다. 주로 사용되는 헤더는 max-age임을 기억하자 !\n\n\n\n\n\n\n\n아주 간단하게 위와 같은 HTML을 작성하고 localhost:8080/에 접근하면 HTML을 반환하게 하였다.\n\n잡다한 텍스트와 커다란 이미지 하나를 포함하는 심플한 HTML이며, 이 HTML을 가지고 몇가지 시나리오를 테스트하면서 HTTP 캐시가 무엇인지 감을 잡아볼 것이다.\n\n\n\n📜 시나리오 1: no-store\n\n\n\n아주 간단하게 스프링 MVC 프로젝트를 생성하고 응답 헤더에 Cache-Control: no-store를 추가했다.\n\n이는 해당 컨텐츠를 브라우저가 캐시하지 않을것임을 명시하는 헤더이다.\n\n\n\n\n\n\n\nHTML은 절대 캐시되지 않을 것이며, URL을 입력할때마다 새로운 HTML을 다운받을 것을 예상할 수 있다.\n\n정말 그럴까?\n\n\n\n\n\n\n\n이미지의 크기는 460kb이며, 다운받아오는데 7ms가 걸렸다.\n\n브라우저에 캐시 되지 않았을 것이므로, 페이지를 새로고침하면 새로운 컨텐츠를 다시 다운받아올 것을 예상한다.\n\n\n\n\n\n\n\n페이지를 새로고침 할때마다 계속해서 460kb의 이미지를 새로 다운받고 있음을 확인할 수 있다.\n\n\n\n\n\n\n\nHTTP 헤더를 까보니 Cache-Control: no-store가 제대로 들어있음을 확인할 수 있다.\n\n\n\n📜 시나리오 2: no-cache\n\n\n\nCache-Control: no-cache는 캐시를 하지 않는다는 뜻이 아니고, 기본적으로 컨텐츠를 캐시하되 매번 서버에 사용해도 되는 캐시인지 물어본다는 의미이다.\n\n브라우저가 캐시한 컨텐츠가 브라우저에 캐시된 이후로 변경된 적이 없다면 브라우저가 갖고있는 캐시를 사용하고, 변경된 적이 있다면 새로운 컨텐츠를 다운받아 다시 캐시하는 것이다.\n\n\n\n\n\n\n\n\n\n\n\n인터넷의 상태를 느린 3G로 변경하고 localhost:8080/에 접근하니 이미지를 다운받는데 11.22s가 걸렸다.\n\n최초 접근이니 브라우저에 캐시된 것이 없어 새로 다운받는 것은 당연한 현상이다.\n\n\n\n\n\n\n\n페이지를 새로고침했더니 상태코드 304 Not Modified와 함께 279B의 통신이 발생했다.\n\n상태코드 304가 응답됐다는 것은 컨텐츠가 변경되지 않았음을 의미하며, 279B의 통신비용은 브라우저가 서버에 자신이 갖고 있는 캐시가 가장 최신의 컨텐츠인지를 물어보면서 발생한 것이다.\n\n\n\n\n\n\n\nHTTP 헤더를 까보니 If-Modified-Since라는 요청 헤더가 추가돼있음을 확인할 수 있다.\n\n이는 브라우저가 추가한 것으로 자신이 갖고 있는 컨텐츠가 해당 시점에 마지막으로 수정됐음을 의미한다.\n\n서버에서 응답한 Last-Modified는 서버에서 갖고 있는 컨텐츠가 해당 시점에 마지막으로 수정됐음을 의미하기 때문에, If-Modified-Since와 Last-Modified가 동일하다면 브라우저가 캐시한 컨텐츠는 가장 최신의 컨텐츠라고 봐도 무방할 것이다.\n\n따라서 새로운 컨텐츠를 다운받는 절차가 생략되었으며, 이 말인즉슨 이미지를 새로 다운받아 발생하는 460kb의 통신비용이 아닌, 서로의 상태를 확인하는 텍스트를 주고받아 통신을 끝내어 279B의 통신 비용이 발생했음이다.\n\n\n\n📜 시나리오 3: max-age\n\n\n\nCache-Control: max-age는 캐시가 어느정도의 기간동안 유효한지를 서버에서 마킹하여 응답하는 것이다.\n\n이는 초(Second) 단위로 사용되며, 주로 사용되는 단위는 다음과 같다.\n\n\n\n\n  1일: 86,400\n  7일: 604,800\n  30일: 2,592,000\n  1년: 31,536,000\n\n\n\n\n브라우저는 캐시한 컨텐츠에 max-age가 붙어있고, 캐시가 유효하다면 서버에 사용해도 되는 컨텐츠인지 물어보는 과정조차 생략된다.\n\n이는 매우 중요한 것으로, TCP 커넥션이 아예 맺어지지 않음을 의미하고, 이 말인즉슨 값 비싼 Handshaking과정이 아예 일어나지 않음과 일맥상통한다.\n\n\n\n\n\n\n\n20s 동안 캐시가 유효할 것이라고 마킹하여 응답했다.\n\n\n\n\n\n\n\n역시 최초 요청이므로 이미지를 다운받는 460kb의 통신비용이 발생한다.\n\n\n\n\n\n\n\n이후 주기적으로 페이지를 새로고침했는데, 여태까지와는 다르게 (메모리 캐시)라는 텍스트가 뜨는것을 확인할 수 있다.\n\n즉, 브라우저 캐시를 그대로 사용했음을 의미한다.\n\n캐시가 만료되는 시점마다 280B정도의 통신비용이 발생했는데, 이는 max-age에 지정된 시간이 만료되어 브라우저가 서버에 자신이 캐시한 컨텐츠가 최신의 컨텐츠인지를 물어보는 과정이 발생했기 때문이다.\n\n원래라면 max-age가 만료된 시점에는 무조건적으로 최신 컨텐츠인지 확인(279B~280B)가 아닌 이미지 다운로드(460kb)가 발생해야만 하는데, 헤더에 Cache-Control: must-revalidate를 추가했기 때문에, 매번 새로 다운받는 것이 아닌 브라우저가 캐시한 컨텐츠가 최신인지를 서버에 확인하는 과정이 추가된 것이다.\n\n\n\n(메모리 캐시)가 아닌 (하드디스크 캐시)가 뜨는 경우도 있는데, 이는 브라우저가 알아서 판단해 적용하는 부분이며 어쨋건 둘다 캐시가 되긴 한 것이다.\n\n\n\n\n\n\n\n기본적으로 max-age와 must-revalidate를 조합해서 사용하되, 컨텐츠의 이름으로 버저닝하는 것도 아주 좋은 방법이다.\n\n예를 들어 1만줄이 넘어가는 style.css라는 파일이 있다고 가정하고, 이 파일의 max-age를 1년으로 설정해두었다고 가정하자.\n\n이후 style.css가 수정되어도 1년이 지나지 않았다면 서버에 확인조차 안할것이기 때문에 파일이 변경되어도 실제로 적용되지 않는 치명적인 문제가 발생한다.\n\n하지만 style-0.0.1.css 처럼 파일명으로 버저닝을 한다면, 캐시는 문제없이 되면서도 컨텐츠가 변경됐을때 기존 캐시의 업데이트 또한 수월하게 될 수 있다.\n\n\n\n📜 시나리오 4: ETag\n\n\n\nETag는 서버가 컨텐츠의 내용에 서버의 어떤 값을 추가하여 고유한 해시값을 만들어 낸 것이다. (MD5 digest)\n\n하지만 이는 Cache-Control에서 우선순위가 가장 높기 때문에 잘못 사용하면 캐시가 되지 않는 경우도 존재한다.\n\n일례로 웹 서버를 여러개 사용하고 있을 경우 실제 컨텐츠는 같더라도 각 웹 서버별로 생성해내는 ETag가 달라 캐시가 되지 않는 경우가 존재할 수 있다.\n\n따라서 ETag를 사용한다면 이러한 부분을 숙지하고 사용하도록 하자.\n\n\n\n\n\n\n\n컨텐츠의 내용을 해싱하여 ETag를 생성하도록 코드를 작성했다.\n\n\n\n\n\n\n\n최초 요청 시 서버에서 응답한 컨텐츠에 ETag 헤더가 달려있음을 확인할 수 있다.\n\nETag는 컨텐츠의 내용이 바뀌어야만 하기 때문에 이번에는 이미지가 아닌 텍스트를 변경하였다.\n\nHTML 좌측에 Added ETag라는 글자가 삽입된 것을 볼 수 있다.\n\n\n\n\n\n\n\n페이지를 새로고침했다.\n\n아직은 컨텐츠가 변경되지 않았으므로, 브라우저가 캐시한것을 사용했다.\n\n이를 서버에 확인하는 과정을 거쳐 279B의 통신비용이 발생했다.\n\n만약 HTML을 새로 다운받았다면 5.3kb의 통신비용이 발생했을 것이다.\n\n\n\n\n\n\n\nHTTP 헤더를 까보니 브라우저가 서버로 보낸 요청 헤더에 If-None-Match에 컨텐츠의 ETag가 붙은채로 요청이 간 것을 볼 수 있다.\n\n이름 그대로 서버가 갖고있는 컨텐츠와 자신이 보낸 ETag가 일치하지 않는다면 새로운 컨텐츠를 응답해달라는 의미이다.\n\n\n\n\n\n\n\n이번에는 서버에서 Added ETag라는 글자를 제거하였다.\n\n즉시 새로운 컨텐츠를 다운받아 5.3kb의 통신비용이 발생했음을 확인할 수 있다.\n\n\n\n\n\n\n\nHTTP 헤더를 까보니 역시 브라우저는 요청 헤더에 If-None-Match를 달아서 요청을 보냈고, 서버가 갖고 있는 HTML은 이미 변경되어 ETag도 함께 변경됐기 때문에 브라우저가 보낸 ETag와 일치하지 않았다.\n\n따라서 서버는 가장 최근에 생성된 ETag와 함께 최신 컨텐츠를 응답했다.\n\n\n\n🚧 HTTP 캐시 Policy\n\n\n\n위에서 캐시가 무엇인지, HTTP 캐시를 어떻게 사용해야 하는지에 대한 간략한 테스트를 해보았다.\n\n각 캐시 헤더는 장단점이 분명히 존재하며, 이러한 캐시 헤더의 장단점을 명확히 파악하고 적절하게 사용하는 것은 매우 중요하다고 볼 수 있다.\n\n구글 개발자 페이지에서 이러한 HTTP캐시를 어떻게 사용할 것인지에 대해 아주 알아보기 쉬운 가이드를 제시한 내용이 있어 발췌해왔다.\n\n\n\n\n이미지 출처: 구글 개발자 페이지\n\n\n\n📕 참고\n\n\n\n\n  HTTP 완벽 가이드 7장 - 캐시\n  구글 개발자 페이지 - HTTP 캐시\n  Nginx - Cache-Control 설정\n  RFC-2616\n\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2021-12-11-http-cache/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "스프링부트 2.5+, Hibernate 사용시 DB 초기화 이슈",
      "date": "2021-12-14 00:00:00 +0000",
      "description": "스프링부트 버전업에 의한 이슈 정리\n",
      "content": "\n  🚨 문제\n  🚧 원인\n  ✅ 해결\n\n\n\n\n🚨 문제\n\n\n\n학습 프로젝트 진행 중 발견한 이슈이다.\n\n\n\n\n  Hiberate를 사용하고 있었음\n  스프링부트 버전 2.4 대에서 2.5+ 이상으로 버전업\n  data.sql이 아래와 같은 메시지와 함께 정상동작하지 않음\n\n\n\n\n\n\n\n\n🚧 원인\n\n\n\n스프링부트 📜 릴리즈노트 에서 찾았다.\n\n\n\n- Hibernate and data.sql\n\nBy default, data.sql scripts are now run before Hibernate is initialized. \n\nThis aligns the behavior of basic script-based initialization with that of Flyway and Liquibase. \n\nIf you want to use data.sql to populate a schema created by Hibernate, set spring.jpa.defer-datasource-initialization to true. \n\nWhile mixing database initialization technologies is not recommended, this will also allow you to use a schema.sql script to build upon a Hibernate-created schema before it’s populated via data.sql.\n\n\n\n\n대략 스프링부트 2.5부터는 data.sql이 Hibernate가 실행하는 ddl-auto 보다 먼저 실행된다는 것 같다.\n\n따라서 기존과 같이 사용하고 싶다면 spring.jpa.defer-datasource-initialization=true 옵션을 추가하라고 한다.\n\n\n\n실제로 이것이 문제인게 맞는지 우선 버전을 변경해 테스트해보았다.\n\n\n\n우선 데모 프로젝트를 2.4.3 버전으로 생성했다.\n\n의존성은 아주 간단하게 web, data-jpa, h2만 추가했다.\n\n\n\n\n\n\n\n그리고 application.yaml 파일을 다음과 같이 설정했다.\n\n\n\n# file: 'application.yaml'\nspring:\n  h2:\n    console:\n      enabled: true\n      settings:\n        web-allow-others: true\n\n  datasource:\n    url: jdbc:h2:mem:testdb\n    username: sa\n    password:\n\n  jpa:\n    properties:\n      hibernate:\n        format_sql: true\n    hibernate:\n      ddl-auto: create-drop\n\n\n\n\n그리고 Hibernate가 테이블을 생성하도록 다음과 같이 간단한 엔티티 클래스를 작성했다.\n\n\n\n@Entity\npublic class Member implements Serializable {\n\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    private String name;\n\n    private int age;\n\n}\n\n\n\n\n마지막으로 Hibernate가 생성한 테이블에 삽입될 데이터를 resources/data.sql에 추가했다.\n\n-- file: 'resources/data.sql'\ninsert into member (name, age)\nvalues ('name1', 10);\n\ninsert into member (name, age)\nvalues ('name2', 10);\n\n\n\n\n그리고 프로젝트를 실행하고 localhost:8080/h2-console로 접근하여 테이블이 정상적으로 생성되었는지, 데이터가 정상적으로 삽입되었는지를 확인했다.\n\n\n\n\n\n\n\n버전을 내려서 진행하니 정상적으로 동작함을 확인했다.\n\n\n\n✅ 해결\n\n\n\n2.4대에서 2.5+이상의 버전으로 변경 할 경우 옵션을 줘야한다고 하니 데모 프로젝트의 스프링부트 버전을 2.6.1로 변경하고, application.yaml에 옵션을 추가했다.\n\n\n\n\n\n\n\n# file: 'application.yaml'\nspring:\n  h2:\n    console:\n      enabled: true\n      settings:\n        web-allow-others: true\n  datasource:\n      url: jdbc:h2:mem:testdb\n      username: sa\n      password:\n  jpa:\n    defer-datasource-initialization: true # 추가 !\n    properties:\n      hibernate:\n        format_sql: true\n    hibernate:\n      ddl-auto: create-drop\n\n\n\n\n마찬가지로 프로젝트를 실행하고 localhost:8080/h2-console로 접근하여 테이블이 정상적으로 생성되었는지, 데이터가 정상적으로 삽입되었는지를 확인했다.\n\n\n\n\n\n\n\n아무런 문제 없이 정상적으로 동작함을 확인했다.\n\n\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-12-14-debugging-13/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "프로그래머스 - 로또의 최고 순위와 최저 순위",
      "date": "2021-12-17 00:00:00 +0000",
      "description": "프로그래머스 77484번 문제\n",
      "content": "\n\n\n아주 쉬운 문제다.\n\n당첨 번호 대비 자신의 번호가 몇개 일치하는지를 알아내고, 이를 등수로 환산하면 최저 순위.\n\n당첨 번호 대비 자신의 번호가 몇개 일치하는지를 알아내고 여기에 0의 개수를 더한 후, 이를 등수로 환산하면 나올 수 있는 최고 순위이다.\n\n그대로 구현하기만 하면 된다.\n\n\n\n@DisplayName(\"프로그래머스 77484 - 로또의 최고 순위와 최저 순위\")\nclass Programmers77484Test {\n\n    private Programmers77484 solve = new Programmers77484();\n\n    private static Stream&lt;Arguments&gt; solution() {\n        return Stream.of(\n            Arguments.of(new int[]{44, 1, 0, 0, 31, 25}, new int[]{31, 10, 45, 1, 6, 19}, new int[]{3, 5}),\n            Arguments.of(new int[]{0, 0, 0, 0, 0, 0}, new int[]{38, 19, 20, 40, 15, 25}, new int[]{1, 6}),\n            Arguments.of(new int[]{45, 4, 35, 20, 3, 9}, new int[]{20, 9, 3, 45, 4, 35}, new int[]{1, 1})\n        );\n    }\n\n    @MethodSource\n    @ParameterizedTest\n    void solution(int[] lottos, int[] winNums, int[] expected) throws Exception {\n        int[] actual = solve.solution(lottos, winNums);\n        Assertions.assertThat(actual).isEqualTo(expected);\n    }\n\n}\n\n\n\n\n처음엔 enum을 사용해 구현했다.\n\nenum 내부에 Map 등을 사용하면 더 최적화가 되긴 했겠지만, 이정도 수준에서는 유의미한 차이를 내기 힘들 것 같았다. (귀찮았다…)\n\n\n\npublic class Programmers77484 {\n\n    public int[] solution(int[] lottos, int[] winNums) {\n        long countOfZero = Arrays.stream(lottos)\n            .filter(num -&gt; num == 0)\n            .count();\n\n        long matchCount = Arrays.stream(winNums)\n            .filter(winNum -&gt; Arrays.stream(lottos)\n                .anyMatch(lotto -&gt; winNum == lotto))\n            .count();\n\n        return new int[]{\n            MatchPrize.findRankByMatchCount((int) (matchCount + countOfZero)),\n            MatchPrize.findRankByMatchCount((int) matchCount)\n        };\n    }\n\n    private enum MatchPrize {\n        FIRST(1, 6),\n        SECOND(2, 5),\n        THIRD(3, 4),\n        FOURTH(4, 3),\n        FIFTH(5, 2),\n        SIXTH(6, 1);\n\n        private final int rank;\n        private final int matchCount;\n\n        MatchPrize(int rank, int matchCount) {\n            this.rank = rank;\n            this.matchCount = matchCount;\n        }\n\n        private static int findRankByMatchCount(int matchCount) {\n            return Arrays.stream(values())\n                .filter(matchPrize -&gt; matchPrize.matchCount == matchCount)\n                .findFirst()\n                .orElse(SIXTH)\n                .rank;\n        }\n\n    }\n\n}\n\n\n\n\n이러고 나서 보니 코드가 너무 장황하지 않나? 라는 느낌이 들었다.\n\n\n\npublic class Programmers77484 {\n\n    private static final int[] RANK = {6, 6, 5, 4, 3, 2, 1};\n\n    public int[] solution(int[] lottos, int[] winNums) {\n        Set&lt;Integer&gt; lottoSet = stream(lottos)\n            .boxed()\n            .collect(Collectors.toUnmodifiableSet());\n\n        int countOfZero = (int) stream(lottos)\n            .filter(this::isZero)\n            .count();\n\n        int matchCount = (int) stream(winNums)\n            .filter(lottoSet::contains)\n            .count();\n\n        return new int[]{RANK[countOfZero + matchCount], RANK[matchCount]};\n    }\n\n    private boolean isZero(int num) {\n        return num == 0;\n    }\n\n}\n\n\n\n\n코드가 훨씬 간결해지긴 했는데, 가독성이나 확장성 측면에서는 이전 코드가 좀 더 좋다는 느낌이 든다.\n\n이런 미묘한 고민들이 항상 어려운 것 같다.\n\n\n",
      "categories": ["cs","data-structure-algorithm"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/data-structure-algorithm/2021-12-17-programmers-77484/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Could not extract response no suitable HttpMessageConverter found for response type...",
      "date": "2021-12-20 00:00:00 +0000",
      "description": "SpringMVC, OpenFeign 사용 중 발생\n",
      "content": "\n  🚨 문제\n  🚧 원인\n  🚧 재현\n  ✅ 해결\n\n\n\n\n🚨 문제\n\n\n\n회사 서비스를 확장하던 중 발생한 이슈이다.\n\n타 회사의 API에 우리 서비스를 연동해야 하는 상황이었다.\n\n집에 오자마자 데모 프로젝트를 두개 만들어 해당 상황을 재현해봤는데, 재현이 아주 잘 된다.\n\n\n\n2021-12-20 19:39:25.637 ERROR 3936 --- [nio-8080-exec-1] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is feign.codec.DecodeException: Could not extract response: no suitable HttpMessageConverter found for response type [class io.github.shirohoo.client.api.ApiController$Response] and content type [text/html]] with root cause\n\norg.springframework.web.client.UnknownContentTypeException: Could not extract response: no suitable HttpMessageConverter found for response type [class io.github.shirohoo.client.api.ApiController$Response] and content type [text/html]\n\tat org.springframework.web.client.HttpMessageConverterExtractor.extractData(HttpMessageConverterExtractor.java:126) \n\n\n\n\n🚧 원인\n\n\n\n\n  SpringMVC, OpenFeign 사용 중 발생\n  원인: API 서버에서 응답하는 실 데이터는 application/json\n    \n      하지만 Content-Type은 text/html 😒\n      즉, 웹 표준을 지키지 않는 응답으로 인한 문제\n    \n  \n\n\n\n\n🚧 재현\n\n\n\n재현용 데모 프로젝트를 두개 만들었다.\n\n응답 서버에서는 객체를 JSON으로 직렬화해 응답하면서 Content-Type=text/html 으로 헤더를 설정해볼 것이다.\n\n\n  Spring MVC, OpenFeign 프로젝트 = 요청 서버\n  Spring MVC 프로젝트 = 응답 서버\n\n\n\n\n우선 표준을 제대로 지키지 않는 응답서버를 간단하게 하나 구현한다.\n\n\n\n@Slf4j\n@RestController\npublic class FakeResponseController {\n\n    @PostMapping\n    public ResponseEntity&lt;Response&gt; post(@RequestBody Request request) {\n        log.info(\"request={}\", request);\n        HttpHeaders httpHeaders = new HttpHeaders();\n        httpHeaders.setContentType(MediaType.TEXT_HTML);\n        Response httpBody = Response.builder()\n                .responseCode(HttpStatus.OK.value())\n                .responseMessage(HttpStatus.OK.getReasonPhrase())\n                .body(request)\n                .build();\n        log.info(\"httpBody={}\", httpBody);\n\n        return ResponseEntity.status(HttpStatus.OK)\n                .headers(httpHeaders)\n                .body(httpBody);\n    }\n\n    @Data\n    @Builder\n    @NoArgsConstructor\n    @AllArgsConstructor\n    public static class Request {\n\n        private String phoneNumber;\n\n        private long amount;\n\n    }\n\n    @Data\n    @Builder\n    @NoArgsConstructor\n    @AllArgsConstructor\n    public static class Response&lt;T&gt; {\n\n        private int responseCode;\n\n        private String responseMessage;\n\n        private T body;\n\n    }\n\n}\n\n\n\n\n\n그리고 OpenFeign을 이용해 응답서버에 HTTP 요청을 보내야 하므로 이를 구현한다.\n\n\n\n@Slf4j\n@RestController\n@RequiredArgsConstructor\npublic class RequestController {\n\n    private final ApiServerClient client;\n\n    @GetMapping\n    public Response get() {\n        Request request = new Request(\"010-1234-5678\", 50_000);\n        Response response = client.post(request);\n        log.info(\"response={}\", response);\n        return response;\n    }\n\n    @Data\n    @Builder\n    @NoArgsConstructor\n    @AllArgsConstructor\n    public static class Request {\n\n        private String phoneNumber;\n\n        private long amount;\n\n    }\n\n    @Data\n    @Builder\n    @NoArgsConstructor\n    @AllArgsConstructor\n    public static class Response {\n\n        private int responseCode;\n\n        private String responseMessage;\n\n        private Request body;\n\n    }\n\n}\n\n\n\n\n그리고 두 서버를 모두 기동하고 요청을 보냈다.\n\n\n\n\n\n\n\n버그 상황이 재현된 모습\n\n\n\n✅ 해결\n\n\n\nstack trace만 보자면 Content-Type=text/html을 처리해주는 HttpMessageConverter가 없는 것 같다.\n\n이를 직접 구현할까 고민하다, 앞으로 수십개 벤더의 API를 다 연동해야 하는데, 별별 상황이 더 나올 것 같아 gson 의존성을 추가해서 해결해보기로 결정했다.\n\ngson을 프로젝트에 추가하고 Content-Type=text/html 이여도 처리하도록 확장해줄 것이다.\n\n\n\n// file: 'build.gradle'\ndependencies {\n    ...\n    implementation 'com.google.code.gson:gson:2.8.9' // 현 시점 최신 버전을 추가\n    ...\n}\n\n\n\n\n@Component\npublic static class ExpandGsonHttpMessageConverter extends GsonHttpMessageConverter {\n\n    public ExpandGsonHttpMessageConverter() {\n        List&lt;MediaType&gt; types = Arrays.asList(\n                new MediaType(MediaType.TEXT_HTML, DEFAULT_CHARSET),\n                new MediaType(MediaType.TEXT_PLAIN, DEFAULT_CHARSET),\n                new MediaType(MediaType.TEXT_XML, DEFAULT_CHARSET)\n        );\n        super.setSupportedMediaTypes(types);\n    }\n\n}\n\n\n\n\n그리고 두 서버를 모두 재기동한 후 다시 요청을 보내보았다.\n\n응답 서버의 로그\n\n\n\n2021-12-20 20:02:55.853  INFO 30796 --- [nio-8081-exec-1] i.g.s.api.api.FakeResponseController     : request=FakeResponseController.Request(phoneNumber=010-1234-5678, amount=50000)\n2021-12-20 20:02:55.854  INFO 30796 --- [nio-8081-exec-1] i.g.s.api.api.FakeResponseController     : httpBody=FakeResponseController.Response(responseCode=200, responseMessage=OK, body=FakeResponseController.Request(phoneNumber=010-1234-5678, amount=50000))\n\n\n\n\n요청 서버의 로그\n\n\n\n2021-12-20 20:02:55.870  INFO 9108 --- [nio-8080-exec-1] i.g.s.client.api.RequestController       : response=RequestController.Response(responseCode=200, responseMessage=OK, body=RequestController.Request(phoneNumber=010-1234-5678, amount=50000))\n\n\n\n\n문제없이 아주 잘 된다.\n\n내일 출근하면 적용해야겠다.\n\n\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2021-12-20-debugging-14/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "결제 서비스 개발기",
      "date": "2021-12-23 00:00:00 +0000",
      "description": "어떻게 해야 도메인을 보호하면서도 유연한 구조를 만들수 있을까?\n",
      "content": "\n  🙄 무엇을 개발해야 했는가?\n  ✨ 개발 포인트 ?    \n      📜 시나리오        \n          ❌ 조회 실패\n          ❌ 결제 실패\n          ✅ 결제 성공\n        \n      \n    \n  \n  🤔 어떻게 개발할까?    \n      👏 다형성을 이용하자\n      🔗 커맨드 패턴\n      🍗 도우미 클래스\n      🍔 유즈케이스\n    \n  \n  🚀 웹 어댑터\n  😊 후기\n\n\n\n\n이 포스팅에서 나온 코드의 이름들은 제가 실무에서 사용한 이름과 다릅니다.\n\n\n\n🙄 무엇을 개발해야 했는가?\n\n\n\n조금 더 있으면 2021년이 끝남과 동시에 개발자로서 만 1년차가 된다.\n\n이런저런 정리를 하고 있는 와중인데, 이번 포스팅에서는 최근에 진행한, 재미있었던 신규 개발건에 대해 기록하려고 한다.\n\n아주 간단하게 설명하자면 우리 회사 앱에서 내가 만들어야 할 서비스에 결제 요청을 보내면 이를 처리하고 적절한 응답을 반환하면 되는 것이었다.\n\n조금 머리가 아팠던 부분은 수 많은 결제 벤더사를 연동해야하는 부분이었다.\n\n결제 트랜잭션은 다음과 같았다.\n\n\n\n\n  고객이 외부 벤더사에 가입되어있는지 알아야한다\n  연동된 모든 벤더사를 순회하며 가입된 벤더사가 있는지 조회한다\n  가입된 벤더사가 없다면 히스토리를 남기고 결제 트랜잭션을 종료한다\n  가입된 벤더사가 있다면 결제 요청을 보낸다\n  결제 요청에 대한 결과를 히스토리로 남기고 결제 트랜잭션을 종료한다\n\n\n\n\n✨ 개발 포인트 ?\n\n\n\n내가 생각하기에 주요 포인트는 다음과 같았다.\n\n\n\n\n  결제 트랜잭션이 종료되는 시나리오는 총 3개다\n    \n      조회 실패, 결제 실패, 결제 성공\n    \n  \n  멀지 않은 미래에 외부 벤더사가 수십개가 될수도 있다\n    \n      다형성을 최대한 활용하면 좋은 구조를 만들 수 있다\n    \n  \n  \n    각 벤더사별로 요청 &amp; 응답 파라미터가 천차만별이다\n  \n  각 벤더사별로 프로세스가 모두 다르다\n    \n      러프하게 봤을 때 조회, 결제는 모두 동일하나 세세한 프로세스가 다르다\n      예를 들면 어떤 벤더사는 조회 요청을 보내기 전 인증 토큰을 먼저 발급받아야 된다던가 🙄\n    \n  \n  각 벤더사에 요청을 보낼때 요금이 발생하며 이는 각 벤더사마다 다르다\n    \n      따라서 요금이 저렴한 순서대로 조회를 해야한다\n    \n  \n  가장 최근에 결제에 성공한 이력이 있다면 어떤 벤더사에 가입되었는지 일일이 조회해보지 않아도 될 수도 있다\n    \n      조회를 스킵하고 가장 마지막에 결제에 성공했던 벤더사로 결제 요청을 바로 보내서 성공하면 결과적으로 조회를 위한 순회를 스킵할수 있다\n      이는 비용 절감으로 이어진다.\n    \n  \n  \n    JPA를 사용하되, 네이티브 쿼리를 완벽하게 배제하면 DB 벤더에 종속되지 않을 수 있다\n  \n  영속성(Persistence) 인터페이스를 정의하고 이를 구현한 콘크리트 클래스가 JpaRepository를 의존한다면 특정 외부 저장소에 종속되지 않을 수 있다\n    \n      즉, 미래에 파일로 저장하든, RDBMS에 저장하든, NoSQL에 저장하든, 미래에 생길 알지못할 외부 저장소에 저장하든 얼마든지 쉽게쉽게 바꿀 수 있게 된다\n      이는 Mybatis에서 JPA로 마이그레이션하며 느꼈던 지옥같은 고통에서 해방됨을 의미한다.\n    \n  \n\n\n\n\n📜 시나리오\n\n\n\n결제 트랜잭션이 종료되는 시나리오는 총 3가지다.\n\n\n\n❌ 조회 실패\n\n\n\n\n\n\n\n\n\n❌ 결제 실패\n\n\n\n\n\n\n\n\n\n✅ 결제 성공\n\n\n\n\n\n\n\n\n\n🤔 어떻게 개발할까?\n\n\n\n주요 포인트를 쭉 뽑아보니 어떤 구조로 만들어야 할 지 대략 감이 잡혔다.\n\n이는 후술하도록 하고,\n\n\n\n우선 최초 결제 요청이 들어왔을 때 유효한 거래 객체를 만들어내야만 한다.\n\n이후 이 거래 객체의 상태를 변경해가며 프로세스를 진행한다.\n\n이때, 거래 객체를 불변 객체로 설계하고 상태가 변경되는 시점마다 깊은 복사를 통해 새로운 객체를 반환하도록 구성했다.\n\n그리고 이 객체는 주소 참조를 통해 각 메서드들이 공유할 수 있도록 하였다.\n\n이 거래 객체의 이름은 Transaction이라고 하자.\n\n이 객체의 책임은 거래의 상태와 중요 데이터들을 관리하고 기록하는 것인데, 문제는 데이터의 수가 너무 많았다.\n\n일단 이를 다 Transaction에 몰아넣어 만들고 보니 결과적으로 클래스 멤버의 수가 너무 많아 복잡도가 크게 올라가고, 떠돌이 데이터가 많아지는 결과가 나왔다.\n\n\n\n한참을 고민하다 도메인 객체와 자료구조의 경계를 명확하게 구분하기로 결정했다.\n\n이는 스프링 배치의 도메인에서 영감을 얻어 차용했다.\n\n도메인 객체는 Transaction이며, 이 객체는 TransactionContributes라는 객체를 의존하도록 만들었다.\n\n그리고 존재하는 모든 데이터는 TransactionContributes가 관리하도록 하였다.\n\n결과적으로 Transaction은 자신의 상태와 데이터베이스에 기록되어야만 하는 정말 중요한 데이터들만을 집중적으로 관리하면 되게 되었다.\n\n그리고 이 중요한 데이터들은 모두 객체로 포장하고 각종 유효성 검사와 업무 규칙을 처리하도록 해주었다.\n\n\n\n마지막으로 결제 트랜잭션이 종료되는 3가지 시나리오에 대해 Transaction과 TransactionContributes의 모든 데이터를 TransactionEntity로 컨버팅하여 데이터베이스에 히스토리를 남긴 후 트랜잭션을 종료하도록 최종 구성했다.\n\n\n\n👏 다형성을 이용하자\n\n\n\n우선 각 벤더사에서 응답하는 데이터가 천차만별이라, 이 모든 경우의 수를 따져 내가 필요한 데이터들을 골라내야만 했다.\n\n이 때, 벤더사에서 요구하는 데이터도 천차만별이었지만, 이는 결국 추상화할 수 없어 Trasnaction 의 도움을 받아 매번 적절한 요청 객체를 만들어야만 했고, 이 작업은 정말 지루했지만 딱히 좋은 방법이 생각나질 않았다.\n\n다행스럽게도 응답 객체만큼은 추상화를 할 수 있어서 이를 SearchResponse라는 인터페이스로 정의하고 필요한 데이터들을 반환하도록 추상메서드를 선언했다.\n\n\n\n// file: 'src/main/java/payment/application/domain/command/response/SearchResponse.java'\npublic interface SearchResponse {\n    \n    boolean isFound();\n\n    String getA();\n    \n    String getB();\n\n    BigDecimal getC();\n    \n    LocalDateTime getD();\n    \n    // ...\n\n}\n\n\n\n\n결제 요청에 대한 응답인 PaymentResponse라는 인터페이스도 정의해주었다.\n\n\n\n// file: 'src/main/java/payment/application/domain/command/response/PaymentResponse.java'\npublic interface PaymentResponse {\n    \n    boolean isSuccess();\n\n    String getA();\n    \n    String getB();\n\n    BigDecimal getC();\n    \n    LocalDateTime getD();\n    \n    // ...\n\n}\n\n\n\n\n🔗 커맨드 패턴\n\n\n\n각 벤더사별로 미묘하게 프로세스가 다르지만, 러프하게 보면 조회와 결제라는 프로세스는 모두 동일했다.\n\n예를 들면 이렇다.\n\n\n\n\n  A사는 조회를 바로하면 된다\n  B사는 인증토큰을 발급받은 후 조회를 해야 한다\n\n\n\n\n이 부분은 커맨드 패턴을 이용하면 딱 좋을 것 같았다.\n\n우선 간략하게 SearchCommand라는 인터페이스를 하나 정의했다고 가정하자.\n\n\n\n// file: 'src/main/java/payment/application/domain/command/SearchCommand.java'\npublic interface SearchCommand {\n\n    SearchResponse execute(Transaction transaction);\n\n}\n\n\n\n\n조회에 대한 두가지 커맨드 객체를 생성한다.\n\n\n\n// file: 'src/main/java/payment/application/domain/command/ASearchCommand.java'\n@RequiredArgsConstructor\npublic class ASearchCommand {\n    \n    private final AClient client;\n    \n    // 별도의 처리 없이 바로 조회\n    @Override\n    public SearchResponse execute(Transaction transaction){\n        ASearchRequest searchRequest = createSearchRequest(transaction);\n        return client.search(searchRequest);\n    }\n    \n    private ASearchRequest createSearchRequest(Transaction transaction){\n        // do something...\n        return request;\n    }\n\n}\n\n\n\n\n// file: 'src/main/java/payment/application/domain/command/BSearchCommand.java'\n@RequiredArgsConstructor\npublic class BSearchCommand {\n    \n    private final BClient client;\n    \n    // 먼저 인증 토큰을 발급받은 후 조회\n    @Override\n    public SearchResponse execute(Transaction transaction){\n        BTokenRequest tokenRequest = createTokenRequest();\n        String token = client.getToken(tokenRequest);\n        \n        BSearchRequest searchRequest = createSearchRequest(transaction);\n        return client.search(token, searchRequest);\n    }\n    \n    private BTokenRequest createTokenRequest(){\n        // do something...\n        return request;\n    }\n\n    private BSearchRequest createSearchRequest(Transaction transaction){\n        // do something...\n        return request;\n    }\n\n}\n\n\n\n\n결제 요청도 위와 비슷한 방식으로 구성하였다.\n\n이렇게 하니 모든 벤더사들을 나름 깔끔하게 커버할 수 있는 구조가 만들어졌다.\n\n\n\n🍗 도우미 클래스\n\n\n\n주요 처리를 유즈케이스 클래스에서 처리하면 코드가 너무 장황해지고, 의존대상이 너무 늘어나기 때문에 우선 이를 분리했다.\n\n우선 조회에 성공하면 해당 벤더사를 통해 결제 커맨드를 가져올 수 있게끔 동시성 일급 컬렉션을 만들었다.\n\n\n\n// file: 'src/main/java/payment/application/usecase/PaymentCommandConcurrentMap.java'\n@Component\npublic class PaymentCommandConcurrentMap {\n\n    private static final Map&lt;Vendor, PaymentCommand&gt; commandMap = new ConcurrentHashMap&lt;&gt;();\n  \n    @Autowired\n    public PaymentCommandConcurrentMap(\n            APaymentCommand aCommand, \n            BPaymentCommand bCommand\n    ) {\n        commandMap.put(Vendor.A, aCommand);\n        commandMap.put(Vendor.B, bCommand);\n    }\n  \n    public PaymentCommand findByVendor(Vendor vendor) {\n        if (commandMap.containsKey(vendor)) {\n            return commandMap.get(vendor);\n        }\n        throw new IllegalArgumentException(\"Could not find command for \" + vendor);\n    }\n\n}\n\n\n\n\n또한, 여기서 각 벤더사의 API 요금에 따라 API가 호출되는 순서를 결정할 수 있게해줬다.\n\n\n\n// file: 'src/main/java/payment/application/usecase/VendorAdapterComposite.java'\n@Component\npublic class VendorAdapterComposite {\n\n    private final List&lt;SearchCommand&gt; searchCommandList;\n    private final PaymentCommandConcurrentMap paymentConcurrentMap;\n\n    @Autowired\n    public VendorAdapterComposite(\n            PaymentCommandConcurrentMap paymentConcurrentMap,\n            ASearchCommand aCommand, \n            BSearchCommand bCommand\n    ) {\n        this.paymentConcurrentMap = paymentConcurrentMap;\n        \n        // API 호출 요금이 저렴한 순서대로 리스트에 삽입한다\n        this.searchCommandList = new ArrayList&lt;&gt;();\n        searchCommandList.add(aCommand);\n        searchCommandList.add(bCommand);\n    }\n\n    public SearchResponse search(Transaction transaction) throws NotFoundVendorException {\n        for (SearchCommand command : searchCommandList){\n            SearchResponse response = command.execute(transaction);\n            if(response.isFound()){\n                return response;\n            }\n        }\n        throw new NotFoundVendorException();\n    }\n\n    public PaymentResponse payment(Transaction transaction) {\n        TransactionContributes contributes = transaction.getContribute();\n        Vendor vendor = contributes.getVendor();\n        return paymentConcurrentMap.findByVendor(vendor)\n                .execute(transaction);\n    }\n\n}\n\n\n\n\n🍔 유즈케이스\n\n\n\n모든 벤더사에 대한 처리를 테스트코드와 함께 구현하고 보니 이후 작업은 생각보다 쉬웠다.\n\n조회 -&gt; 결제순으로 처리하되 트랜잭션이 종료되어야만 하는 3가지 케이스에 집중하고, 몇가지 예외처리를 해주면 되었다.\n\n\n\n// file: 'src/main/java/payment/application/usecase/PaymentUseCaseImpl.java'\n@Slf4j\n@UseCase\n@RequiredArgsConstructor\npublic class PaymentUseCaseImpl implements PaymentUseCase {\n    \n    private final VendorAdapterComposite adapter;\n    private final TransactionRepository transactionRepository;\n\n    @Override\n    public Transaction paymentUseCase(Transaction transaction) {\n        info(log, \"Create new transaction!\", transaction.getContribute());\n        transaction = search(transactionRepository.save(transaction));\n        \n        if(transaction.isNotFound()){\n            return transaction;\n        }\n        \n        return payment(transaction);\n    }\n\n    private Transaction search(Transaction transaction) {\n        try {\n            SearchResponse response = adapter.search(transaction);\n            return transaction.setFoundVendor(response);\n        } catch (NotFoundVendorException e) {\n            transaction = transaction.setNotFoundVendor();\n            TransactionContributes contribute = transaction.getContribute();\n            error(log, contribute.getStatusMessage(), contribute);\n            return transactionRepository.update(transaction);\n        }\n    }\n\n    private Transaction payment(Transaction transaction) {\n        PaymentResponse response = adapter.payment(transaction);\n        \n        if (response.isSuccess()) {\n            transaction = transaction.setPaymentSuccess(response);\n            TransactionContributes contribute = transaction.getContribute();\n            info(log, contribute.getStatusMessage(), contribute);\n            return transactionRepository.update(transaction);\n        }\n\n        transaction = transaction.setPaymentFail();\n        TransactionContributes contribute = transaction.getContribute();\n        error(log, contribute.getStatusMessage(), contribute);\n        return transactionRepository.update(transaction);\n    }\n\n}\n\n\n\n\n🚀 웹 어댑터\n\n\n\n마지막으로 웹 어댑터를 작성했다.\n\n이 객체는 외부의 요청을 받아 도메인 객체를 만들어낸 후 유즈케이스 클래스에 처리를 위임한다.\n\n그리고 유즈케이스 클래스가 반환한 도메인을 받아 외부에 적절한 응답을 해준다.\n\n\n\n// file: 'src/main/java/payment/adapter/http/PaymentApiController.java'\n@RestController\n@RequiredArgsConstructor\npublic class PaymentApiController {\n    \n    private final PaymentUseCase useCase;\n    \n    @PostMapping\n    public ResponseEntity&lt;Data&lt;?&gt;&gt; payment(@RequestBody PaymentRequest request){\n        transaction = useCase.paymentUseCase(TransactionFactory.convert(request));\n        \n        if(transaction.isNotFound()){\n            return ResponseEntity.status(HttpStatus.NOT_FOUND)\n                .body(Data.of(HttpStatus.NOT_FOUND, transaction.exposure()));\n        }\n\n        if(transaction.isPaymentFail()){\n          return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)\n                  .body(Data.of(HttpStatus.INTERNAL_SERVER_ERROR, transaction.exposure()));\n        }\n  \n        return ResponseEntity.status(HttpStatus.OK)\n                .body(Data.of(HttpStatus.OK, transaction.exposure()));\n    }  \n    \n    @Value\n    @JsonInclude(Include.NON_NULL)\n    private static class Data&lt;T&gt; {\n        int code;\n        String message;\n        T data;\n\n        private static &lt;T&gt; Data&lt;T&gt; of(HttpStatus httpStatus, T data) {\n          return Data.of(httpStatus.value(), httpStatus.getReasonPhrase(), data);\n        }\n  \n        private static &lt;T&gt; Data&lt;T&gt; of(int code, String message, T data) {\n          return new Data&lt;&gt;(code, message, data);\n        }\n    }\n  \n}\n\n\n\n\n😊 후기\n\n\n\n이번 신규 개발건은 그동안 공부한 객체지향과 디자인 패턴에 대해 심도깊게 고민해보고 실무에 적용해볼 수 있는 아주 좋은 기회였다고 생각한다.\n\n최근 📕 클린 아키텍처 와 📕 만들면서 배우는 클린 아키텍처 두 책을 감명깊게 읽었는데, 이 책들에서 본 내용들을 실무에 적용해보고 많은 부분을 깨닫고 체화시킬 수 있었어서 정말 좋았다.\n\n확실히 주먹구구식으로, 절차지향적으로 코드를 작성하던 몇달전과 달리 상대적으로 구조가 깔끔하게 잡히는 것이 매우 흡족했다.\n\n최대한 인터페이스에 대고 코딩하도록 하고, 각 클래스가 변경되어야 하는 이유를 최대한 적게 가져가려고 노력하였는데, 이렇게 하고 보니 테스트 코드를 작성하는것이 매우 수월해짐을 느낄 수 있었다.\n\n테스트코드를 작성하는게 수월해지니 과감한 리팩토링도 계속 시도해볼 수 있었고, 갈수록 코드에서 나쁜 냄새들이 없어지는 긍정적인 연쇄효과가 일어났다.\n\n실제 코드는 훨씬 더 복잡하고 분량이 많았지만, 생각보다 힘들지 않게 요약해서 정리할 수 있게 된것을 보니 기존의 스타일에 비해 복잡도가 상대적으로 많이 낮다는 생각이 들었다. 즉, 구조가 나쁘지 않은 것 같다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2021-12-23-diary-30/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "JPA @OneToOne 슬기롭게 사용하기",
      "date": "2021-12-24 00:00:00 +0000",
      "description": "사용하기 까다로운 @OneToOne ! 어떻게 사용해야 할까?\n",
      "content": "\n  💥 @OneToOne 이슈\n  😁 슬기롭게 사용하기    \n      💡 @MapsId\n    \n  \n  ✅ 결론\n\n\n\n\n💥 @OneToOne 이슈\n\n\n\nJPA(Hibernate)를 실무에서 사용해보신 분이라면 아시겠지만, @OneToOne은 지연로딩 관련 이슈가 존재한다.\n\n따라서 이를 사용하면 N+1 문제가 곧잘 터져나와 사용하기가 여간 까다로운게 아니다.\n\n@OneToOne으로 지연로딩을 하기 위해서는 절대적으로 아래의 조건이 성립해야만 한다\n\n\n\n\n  optional=false 옵션이 있어야 한다 (=NOT NULL)\n\n\n\n\n이 조건이 성립한다면 아래의 경우에 지연로딩이 가능해진다\n\n\n\n\n  @OneToOne 단방향\n  @OneToOne 양방향이지만 관계의 주인쪽에서 조회를 한 경우\n\n\n\n\n즉, 어떻게 해도 양방향 매핑 시 관계의 주인이 아닌곳에서 작업이 들어가면 N+1 문제가 터져나온다.\n\n또한 추가로 관계의 주인이 아닌녀석은 기본적으로 읽기 전용(Read Only)이기 때문에, CUD(Create, Update, Delete)도 제대로 되지 않는 경우가 생길 수 있다.\n\n\n\n확인해보자\n\n\n\n\n@Table\n@Entity\npublic class Member {\n\n    @Id\n    @GeneratedValue\n    private Long id;\n\n    private String name;\n\n    @OneToOne(\n        mappedBy = \"member\",\n        fetch = FetchType.LAZY,\n        cascade = CascadeType.ALL,\n        optional = false\n    )\n    private Locker locker;\n\n    public void setLocker(Locker locker) {\n        if (locker == null) {\n            if (this.locker != null) {\n                this.locker.setMember(null);\n            }\n        }\n        else {\n            locker.setMember(this);\n        }\n        this.locker = locker;\n    }\n\n}\n\n@Table\n@Setter\n@Entity\npublic class Locker {\n\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    private String thing;\n\n    @OneToOne(fetch = FetchType.LAZY)\n    private Member member;\n\n}\n\n\n\n\n관계의 주인은 Locker이다.\n\noptional=false를 명시해주어 매핑된 객체가 NULL일 경우의 수를 배제해주었다.\n\n이는 Hibernate가 EAGER로 동작해 N+1 문제가 발생할 여지를 차단한것과 같은 의미이다.\n\n\n\n관계 매핑에 NOT NULL 조건이 없다면 Hibernate는 데이터베이스에 쿼리해보지 않고서는 매핑된 객체에 프록시를 채워주어야 할지 NULL을 넣어야 할지 알 수 없습니다.\n\n\n\n\n  📜 OneToOne에 대해서\n\n\n\n\n이 상태에서 아주 간단한 테스트를 진행해보자.\n\nLocker가 관계의 주인이므로, Locker를 쿼리하면 N+1 문제가 발생하지 않아야 한다.\n\n따라서 select 쿼리는 단 한번만 발생해야 한다.\n\n\n\n\n@DataJpaTest\n@Rollback(false)\nclass MemberTest {\n\n    @Autowired\n    TestEntityManager em;\n\n    @BeforeEach\n    void setUp() {\n        Locker locker = new Locker();\n        Member member = new Member();\n        member.setLocker(locker);\n        em.persist(member);\n        em.flush(); // insert 두번 발생\n        em.clear();\n    }\n\n    @Test\n    void find() throws Exception {\n        em.find(Locker.class, 1L); // select 한번 발생\n    }\n\n}\n\n\n\n\nHibernate: \n    insert \n    into\n        member\n        (name, id) \n    values\n        (?, ?)\nHibernate: \n    insert \n    into\n        locker\n        (member_id, thing, id) \n    values\n        (?, ?, ?)\nHibernate: \n    select\n        locker0_.id as id1_0_0_,\n        locker0_.member_id as member_i3_0_0_,\n        locker0_.thing as thing2_0_0_ \n    from\n        locker locker0_ \n    where\n        locker0_.id=?\n\n\n\n\nMember와 Locker의 관계는 양방향이며, Member는 관계의 주인이 아니다.\n\n따라서 Member를 통해 쿼리하면 N+1 문제가 발생해야만 한다.\n\n즉, select 쿼리가 두번 발생할 것이다.\n\n\n\n\n@DataJpaTest\n@Rollback(false)\nclass MemberTest {\n\n    @Autowired\n    TestEntityManager em;\n\n    @BeforeEach\n    void setUp() {\n        Locker locker = new Locker();\n        Member member = new Member();\n        member.setLocker(locker);\n        em.persist(member); // insert 두번 발생\n        em.flush();\n        em.clear();\n    }\n\n    @Test\n    void find() throws Exception {\n        // em.find(Locker.class, 1L);\n        em.find(Member.class, 1L); // select 두번 발생\n    }\n\n}\n\n\n\n\nHibernate: \n    insert \n    into\n        member\n        (name, id) \n    values\n        (?, ?)\nHibernate: \n    insert \n    into\n        locker\n        (member_id, thing, id) \n    values\n        (?, ?, ?)\nHibernate: \n    select\n        member0_.id as id1_1_0_,\n        member0_.name as name2_1_0_ \n    from\n        member member0_ \n    where\n        member0_.id=?\nHibernate: \n    select\n        locker0_.id as id1_0_0_,\n        locker0_.member_id as member_i3_0_0_,\n        locker0_.thing as thing2_0_0_ \n    from\n        locker locker0_ \n    where\n        locker0_.member_id=?\n\n\n\n\n@OneToOne에 대해 어느정도 이해하고 있고, 코드를 작성한 당사자는 이러한 문제에서 자유로울수도 있다.\n\n하지만 이러한 속사정을 모르는 동료들은 실수할 가능성이 충분히 높다.\n\n그리고 복잡한 실무환경에서 JPA를 사용하다 보면 코드만 봐서는 정확히 어떤 쿼리가 발생할 것인지 완벽하게 알기가 어렵다.\n\n결국 코드를 실행하면서 모니터링을 해봐야지만 정확히 어떠한 쿼리가 발생하는지를 알 수 있다는 의미이다.\n\n즉, 이러한 문제는 코드리뷰를 해도 사전에 찾아내기가 어렵다.\n\n\n\n그렇다고 @OneToOne을 아예 안쓰기는 어렵다.\n\n아무리 사용을 피하려 해도 간혹가다 사용해야하는 순간이 있을 수 있다.\n\n그러면 어떻게 사용해야 이를 슬기롭게 사용할 수 있을까?\n\n\n\n😁 슬기롭게 사용하기\n\n\n\n우선 위 상황에서 테이블이 어떻게 만들어졌는지 DDL을 확인해보자.\n\n\n\nHibernate: \n    \n    create table locker (\n       id bigint not null,\n        thing varchar(255),\n        member_id bigint,\n        primary key (id)\n    )\nHibernate: \n    \n    create table member (\n       id bigint not null,\n        name varchar(255),\n        primary key (id)\n    )\n\n\n\n\nlocker 테이블에는 pk인 id와 fk인 member_id가 있음을 볼 수 있다.\n\n근데 여기서 과연 pk로 잡혀있는 id컬럼이 필요할까?\n\n필요하지 않다고 생각되는데도 불구하고 인덱스 컬럼을 두개나 잡고 있다.\n\n이는 효율적이지 않다.\n\n그렇다면 어떻게 할 수 있을까?\n\n\n\n💡 @MapsId\n\n\n\njavax.persistence패키지에는 @MapsId라는 어노테이션이 있다.\n\n이는 fk를 pk로 사용할 수 있게 해준다.\n\n두말할 것 없이 적용한 코드와 결과를 보자.\n\n\n\n\n@Table\n@Setter\n@Entity\npublic class Locker {\n\n    // 1: @GeneratedValue 제거\n    @Id\n    private Long id;\n    \n    private String thing;\n\n    @MapsId // 2: @MapsId 추가\n    @OneToOne(fetch = FetchType.LAZY)\n    private Member member;\n\n}\n\n@Table\n@Entity\npublic class Member {\n\n    @Id\n    @GeneratedValue\n    private Long id;\n\n    private String name;\n\n    // 3: 양방향 매핑 -&gt; 단방향 매핑으로 변경됨 (=기존 매핑 제거됨)\n\n}\n\n\n\n\n일단 Entity 클래스의 코드가 대폭 줄어들어 가독성이 크게 늘어났다.\n\n코드에서 주목할 부분들은 다음과 같다.\n\n\n\n\n  1: @GeneratedValue가 제거되었다\n    \n      member 테이블의 pk(id)를 locker 테이블의 pk로 사용할 것이기 때문에 기본키 생성전략이 필요하지 않다\n    \n  \n  2: @MapsId가 추가되었다\n  3: 양방향 매핑에서 단방향 매핑으로 변경되었다 (=기존 매핑 제거됨)\n\n\n\n\n그리고 가장 중요한 테이블에 대한 DDL을 확인해보자.\n\n\n\nHibernate: \n    \n    create table locker (\n       thing varchar(255),\n        member_id bigint not null,\n        primary key (member_id)\n    )\nHibernate: \n    \n    create table member (\n       id bigint not null,\n        name varchar(255),\n        primary key (id)\n    )\nHibernate: \n    \n    alter table locker \n       add constraint FKcwdw46rsk7jstg14ey1ppkb1h \n       foreign key (member_id) \n       references member\n\n\n\n\n우선 locker 테이블에 있던, 불필요하다고 생각되던 인덱스 컬럼이 제거되었다.\n\n그리고 fk였던 member_id를 locker테이블의 pk로 사용하게 되었음을 볼 수 있다.\n\n이제 N+1 문제가 발생하던 코드를 다시 실행해보면 어떻게 될까?\n\n\n\n\n@DataJpaTest\n@Rollback(false)\nclass MemberTest {\n\n    @Autowired\n    TestEntityManager em;\n\n    @BeforeEach\n    void setUp() {\n        Locker locker = new Locker();\n        Member member = new Member();\n        locker.setMember(member);\n        em.persist(locker);\n        em.flush();\n        em.clear();\n    }\n\n    @Test\n    void find() throws Exception {\n        // em.find(Locker.class, 1L);\n        em.find(Member.class, 1L);\n    }\n\n}\n\n\n\n\nHibernate: \n    insert \n    into\n        member\n        (name, id) \n    values\n        (?, ?)\nHibernate: \n    insert \n    into\n        locker\n        (thing, member_id) \n    values\n        (?, ?)\nHibernate: \n    select\n        member0_.id as id1_1_0_,\n        member0_.name as name2_1_0_ \n    from\n        member member0_ \n    where\n        member0_.id=?\n\n\n\n\n아주 깔끔한 쿼리가 발생함을 확인할 수 있다.\n\n\n\n✅ 결론\n\n\n\n이러한 변경을 통해 다음과 같은 이점들을 얻을 수 있었다.\n\n\n\n\n  불필요한 인덱스 컬럼을 제거해 데이터베이스가 최적화되었다\n  JPA 코드의 가독성이 큰 폭으로 개선되었다\n  N+1 문제가 발생할수도 있는 여지를 완벽하게 차단했다\n\n\n\n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2021-12-24-jpa-10/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "프로그래머스 - 숫자 문자열과 영단어",
      "date": "2021-12-25 00:00:00 +0000",
      "description": "프로그래머스 81301번 문제\n",
      "content": "\n\n\n@DisplayName(\"프로그래머스 81301 - 숫자 문자열과 영단어\")\nclass Programmers81301Test {\n    Programmers81301 solve = new Programmers81301();\n\n    @MethodSource\n    @ParameterizedTest\n    void solution(String question, int expected) throws Exception {\n        int actual = solve.solution(question);\n        assertThat(actual).isEqualTo(expected);\n    }\n\n    static Stream&lt;Arguments&gt; solution() {\n        return Stream.of(\n            Arguments.of(\"one4seveneight\", 1478),\n            Arguments.of(\"23four5six7\", 234567),\n            Arguments.of(\"2three45sixseven\", 234567),\n            Arguments.of(\"123\", 123)\n        );\n    }\n}\n\n\n\n\n전형적인 문자열 문제이다.\n\n사용하는 언어의 SDK를 잘 활용한다면 쉽게 풀 수 있을 것 같다.\n\n나는 enum과 정규식을 통해 풀었다.\n\n처음 입력받은 문자열이 오직 숫자로만 이뤄져있다면 별도의 연산이 필요없으므로 즉시 반환한다.\n\n이후 정규식을 사용해 스텝바이 스텝으로 문자를 숫자로 변경하고 문자열에 문자가 없는지를 체크한다.\n\nreplace를 통해 문자를 숫자로 변경하고 보니 문자열에 더이상 문자가 존재하지 않다면 추가적인 연산이 필요하지 않기 때문이다.\n\n\n\n아마 enum을 사용하지 않고 클래스 멤버에 배열을 하드코딩했다면 코드가 훨씬 짧아지긴 했겠지만, 이러면 가독성과 유지보수성이 똥이되므로 선호하지 않는다.\n\n\n\nclass Programmers81301 {\n    int solution(String question) {\n        if (isDigitAll(question)) {\n            return Integer.parseInt(question);\n        }\n\n        for (Numbers number : Numbers.values()) {\n            question = question.replace(number.getRegex(), number.getReplacement());\n            if (isDigitAll(question)) {\n                return Integer.parseInt(question);\n            }\n        }\n        return Integer.parseInt(question);\n    }\n\n    private boolean isDigitAll(String question) {\n        return question.chars()\n            .allMatch(Character::isDigit);\n    }\n\n    private enum Numbers {\n        ZERO(\"0\"),\n        ONE(\"1\"),\n        TWO(\"2\"),\n        THREE(\"3\"),\n        FOUR(\"4\"),\n        FIVE(\"5\"),\n        SIX(\"6\"),\n        SEVEN(\"7\"),\n        EIGHT(\"8\"),\n        NINE(\"9\");\n\n        private final String replacement;\n\n        Numbers(String replacement) {\n            this.replacement = replacement;\n        }\n\n        private String getRegex() {\n            return this.name()\n                .toLowerCase();\n        }\n\n        private String getReplacement() {\n            return replacement;\n        }\n    }\n}\n\n\n\n",
      "categories": ["cs","data-structure-algorithm"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/data-structure-algorithm/2021-12-25-programmers-81301/"
    },{
      "image": "/assets/img/spring/spring-webflux/spring-webflux.jpg",
      "title": "Reactive Programming",
      "date": "2021-12-27 00:00:00 +0000",
      "description": "반응형 프로그래밍에 대한 정리\n",
      "content": "\n  Reactive Programming\n  SSE(Server Sent Events)\n\n\n\n\nReactive Programming\n\n\n\n반응형 프로그래밍의 사전적인 정의를 찾아보면 비동기 데이터 스트림을 이용한 프로그래밍이라고 한다.\n\n역시 이런 전형적인 교과서적인 정의는 잘 이해도 안되고 왠지모를 거부감만 잔뜩 생긴다.\n\n\n\n우선 반응형 프로그램이 무엇인지에 대해 알아보기 전에 이것을 왜 사용해야 하는지, 사용하면 어떤 문제를 해결 할 수 있는지를 알아봤다.\n\n\n\n\n  여러 유저가 보고있는 게시글에 누군가가 좋아요를 누를 경우 해당 게시글을 보고있는 유저들이 새로고침을 하지 않더라도 그들이 보고있는 화면속 좋아요가 동시에 1만큼 증가한다\n  메일이 오면 실시간으로 새로운 메일이 표시된다\n  누군가 댓글을 달면 해당 글을 보고있는 사람들에게 새로운 댓글이 실시간으로 보여진다\n\n\n\n\n이런것들이 가능해진다.\n\n\n\n\n\n이정도면 군침이 싹 돈다.\n\n\n\n자바 개발자들이 주로 사용하는 Spring MVC를 보자.\n\n\n\n\n\n발퀄 그림 ㅈㅅ…\n\n\n\n스프링으로 개발하는 전형적인 웹 어플리케이션의 구조이다.\n\n\n\n\n  브라우저가 서버로 어떤 요청을 보낸다\n  서버는 RDBMS에 쿼리한다\n  데이터가 너무 많고, 쿼리가 비효율적이여서 RDBMS에서 30초가 걸렸다\n  서버는 RDBMS에 요청을 보낸 후 30초동안 놀고있다가 RDBMS의 응답을 받았다\n  서버는 RDBMS에서 받은 응답을 브라우저에 전달했다\n\n\n\n\n이때 문제가 무엇인가?\n\n최소한 두가지의 문제가 있다.\n\n\n\n\n  반드시 먼저 물어봐야만 한다\n  물어봤다면 답이 나올때까지 손가락 빨며 기다려야만 한다\n\n\n\n\n즉, RDBMS에 요청을 보낸 후(물어봄) 기다리는 30초동안 다른 일을 할 수 없다는 것이다.(정확히는 스레드가)\n\n이러한 방식을 동기+블로킹 방식이라고 볼 수 있다.\n\n이러한 방식을 사용할때 위 문제를 해결하기 위해 스레드를 이빠이 만들어놓고(톰캣의 기본 스레드는 200개다) 시분할(Time Sharing) 처리를 한다.\n\n이에 대한 설명은 아래 그림을 보자.\n\n\n\n\n\n\n\n예를 들어 커다란 담벼락을 3분할하여 각각 빨간색, 초록색, 파란색 페인트를 칠해야한다고 가정해보자.\n\n이때 가장 효율적인 방법은 빨간색 페인트를 쭉 칠하고, 페인트를 초록색으로 바꾼다.\n\n이후 초록색을 쭉 칠하고 페인트를 파란색으로 바꾼다.\n\n이렇게 하면 페인트를 단 두번만 교체하면 된다.\n\n그리고 여기서 페인트를 교체하는 작업이 바로 컴퓨터과학에서 말하는 컨텍스트 스위칭(Context Switching)이라고 볼 수 있겠다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n이 개념을 우리가 개발하는 웹 어플리케이션에 그대로 대입해보자.\n\n사용자에게 보여줘야 할 화면이 크게 3분할 (헤더, 바디, 푸터) 돼있다고 가정하면, 사용자는 헤더가 다 그려지기 전까지는 바디와 푸터를 볼수가 없다.\n\n마찬가지로 헤더가 다 그려지고 나면 바디를 그리기 시작할것이므로 푸터를 보기까지 한참이 걸린다.\n\n이러한 것은 사용자 경험(UX)에 굉장히 치명적이다.\n\n사용자님들은 참을성이 부족하기 때문이다.\n\n그래서 이 문제를 아래와 같이 해결했다.\n\n\n\n\n\n\n\n\n\n\n\n…\n\n\n\n\n\n\n\n위에서는 페인트 교체를 2번해서 담벼락을 다 칠했는데, 여기서는 벽을 조금 칠하고 페인트를 바꿔서 다른 벽을 칠하는 식으로 모든 벽을 동시에 칠했다.\n\n그래서 페인트를 14번이나 교체하고서야 벽을 다 칠할수 있었다.\n\n\n\n정말 정신나간 짓이지만, 현대 하드웨어의 정신나간 성능과 조금이라도 더 좋은 사용자 경험을 위해서라면 충분히 할 수 있는 짓이기도 하다.\n\n이것이 현재 Spring MVC가 동작하는 방식이다.\n\n\n\n그럼 비동기 방식의 WebFlux는 어떻게 동작할까?\n\n\n\n\n\n\n\n몇가지 작업이 더 있지만 우선 큰 틀은 위와 같다.\n\n서버는 다른 시스템에 작업을 맡긴 후 해당 작업이 끝날때까지 목빼고 기다리고 있지 않는다.\n\n단지 작업을 맡긴 후 \"작업 다 끝나면 나한테 알려줘. 나는 다른거 하고 있을게.\" 라고 할 뿐이다.\n\n따라서 서버는 다른 시스템에 어떤 작업을 맡겼는지 반드시 기억하고 있어야만 한다.\n\n이러한 작업들을 이벤트(Event)라고 부르며, 이러한 작업들을 저장해놓는 공간을 이벤트 루프(Event Loop) 라고 부른다.\n\n\n\n\n\nRDBMS는 기본적으로 비동기를 지원하지 않는다. 이러한 특징으로 인해 JPA(Hibernate) 역시 비동기를 지원하지 않으며, 이러한 문제를 해결하기 위해 Spring R2DBC 라는것이 나왔다.\n\n\n\n하지만 여기서 문제가 있다.\n\n우리가 사용하는 HTTP 프로토콜은 기본적으로 무상태성(stateless)을 지향하므로, 요청(Request)과 이에 대응되는 응답(Response)이 이루어지면 연결이 끊어진다.\n\n따라서, 위 그림의 플로우가 끝나고 나면 서버가 브라우저에 능동적으로 무언가를 전해줄수가 없게된다.\n\n즉, HTTP 프로토콜이 아닌 다른 방식이 필요해지는 것이다.\n\n\n\nSSE(Server Sent Events)\n\n\n\n\n\n\n\n클라이언트에게 요청을 받으면 서버는 언제든지 클라이언트에 추가적인 응답을 줄 수 있게 응답용 커넥션을 남겨둔다.\n\n단, 이때 클라이언트에서 보내온 요청 커넥션은 끊어버린다.\n\n이를 SSE 프로토콜이라 하며, 콜백이 발생했을 때 클라이언트로 응답을 보내주기 위해 남겨둔 응답용 커넥션을 스트림(흐름, Stream)이라고 부른다.\n\n\n\n소켓과 SSE의 차이라고 할 수 있는 부분이다. 소켓은 요청, 응답 커넥션이 모두 존재한다. 실시간 채팅을 연상하면 조금 더 이해가 수월할 것 같다.\n\n\n\n그리고 이 스트림의 동의어가 바로 Flux이다. (Spring WebFlux의 Flux가 맞다)\n\n또한 Flux와 Mono는 Reactor 에서 정의한 Publisher 인터페이스의 구현체이기도 한데, 두 구현체의 차이는 다음과 같다.\n\n\n\n\n  Flux: 0…N 을 표현\n  Mono: 0…1 을 표현\n\n\n\n\n이렇게 보니 무슨말인지 잘 모르겟다. 코드를 보자.\n\n코드로 보 다음과 같다고 할 수 있다.\n\n일단 단일 객체를 반환하는것을 Mono로 표현할수 있는데 Java 8의 Optional로 비교해보자.\n\n\n\npublic Optional&lt;Person&gt; findById(Long id) {\n    if(map.contains(id)) {\n        return Optional.of(map.get(id));\n    }\n    return Optional.empty();\n}\n\n\n\n\n이를 Mono로 표현하면 다음과 같다.\n\n\n\npublic Mono&lt;Person&gt; findById(Long id) {\n    if(map.contains(id)) {\n        return Mono.just(map.get(id));\n    }\n    return Mono.empty();\n}\n\n\n\n\nFlux는 Collection 혹은 Stream 이라고 볼수 있을 것 같다. (하지만 무한일지도 모르는…?)\n\n역시 코드로 보자.\n\n\n\npublic Stream&lt;Person&gt; findAll() {\n    return Stream.of(\n        new Person(\"james\"),\n        new Person(\"charles)\n    );\n}\n\n\n\n\n이를 Flux로 표현하면,\n\n\n\npublic Flux&lt;Person&gt; findAll() {\n    return Flux.just(\n        new Person(\"james\"),\n        new Person(\"charles)\n    );\n}\n\n\n\n\n일단 기초적인 컨셉은 이렇게 이해를 하였으니, 차차 API도 구성해보면서 더 깊게 알아봐야겠다.\n\n\n",
      "categories": ["spring","spring-webflux"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-webflux/2021-12-27-reactive-programming/"
    },{
      "image": "/assets/img/spring/spring-boot/spring-boot-logo.png",
      "title": "스프링 부트 이벤트 큐 구현",
      "date": "2021-12-31 00:00:00 +0000",
      "description": "Spring Boot에서 간단한 Event Queue를 구현하는 방법\n",
      "content": "\n  이벤트 큐    \n      실행\n      유스케이스\n      스레드풀        \n          ThreadPoolConfig\n        \n      \n      도메인        \n          Transaction\n        \n      \n      이벤트        \n          TransactionEventQueue\n          EventPublisher\n          TransactionEventListener\n          TransactionEventScheduler\n          TransactionEventWorker\n        \n      \n    \n  \n\n\n\n\n이벤트 큐\n\n실행\n\n\n\n📦 GitHub - shirohoo/spring-event-queue\n\n프로젝트를 클론하고 데이터베이스를 설정한다.\n\n기본적으로 H2 인메모리로 설정돼있다.\n\n서버모드를 사용하겠다면 본인이 사용하고있는 머신에 H2 서버모드 설정을 하고 하기의 주석을 변경하라.\n\n애플리케이션이 종료될때 백그라운드 처리가 끝나기 전에 데이터베이스 커넥션이 먼저 닫히지 않도록 ;DB_CLOSE_ON_EXIT=FALSE 옵션을 추가해주었다.\n\n\n\n#application.yaml\nspring:\n  datasource:\n    url: jdbc:h2:mem:testdb;DB_CLOSE_ON_EXIT=FALSE\n    # url: jdbc:h2:tcp://localhost/~/test;DB_CLOSE_ON_EXIT=FALSE\n    username: sa\n    password:\n\n\n\n\n이후 프로젝트를 실행하고 웹 브라우저를 열어 주소창에 localhost:8080/transactions를 입력하라.\n\n기본적으로 위 주소로 접근시 50번의 거래가 발생하도록 설정돼있다.\n\n만약 단건 요청을 하고 싶다면 주소창에 localhost:8080/transaction을 입력하면 된다\n\n서버로 요청을 보낸 후 콘솔창의 로그를 확인하면 다음과 유사한 모습을 볼 수 있을 것이다.\n\n\n\n\n\n\n\n유스케이스\n\n\n\n다음과 같은 유스케이스가 있다고 가정하자\n\n\n\n\n  사용자가 결제를 요청\n  컨트롤러가 결제 요청을 받음\n  사용자 요청의 유효성 검증\n  STANDBY 상태의 유효한 결제거래 생성\n  결제거래를 데이터베이스에 저장\n  이벤트 퍼블리셔가 결제거래 이벤트를 퍼블리싱\n  사용자에게 결제거래 요청에 대한 응답을 보내고 HTTP 통신을 종료\n  발생된 결제거래 이벤트를 이벤트 리스너가 감지하고 결제거래 이벤트에서 결제거래 정보를 추출\n  큐가 꽉 차있지 않다면 결제거래 정보를 큐에 입력하고 결제거래의 상태를 QUEUE로 데이터베이스 업데이트\n  큐가 꽉 차있다면 상태를 QUEUE_WAIT으로 데이터베이스 업데이트\n  백그라운드 스레드에서 큐에 있는 결제거래들을 처리하고 상태를 SUCCESS 혹은 FAILURE로 업데이트\n  결제거래 완료에 대한 후처리를 진행(ex. 결제 결과를 사용자의 앱으로 푸쉬)\n\n\n\n\n이렇게 비동기로 처리하지 않는다고 가정하면, 거래 처리시간이 길어질때 사용자는 거래가 끝날때까지 거래화면을 쳐다보고 있어야만 한다.\n\n따라서 요청을 받자마자 응답하여 사용자와의 커넥션을 빠르게 끊고, 이후 백그라운드에서 처리를 한 후 사용자에게 응답을 주면 사용자 경험이 더 좋아질 것이다.\n\n이 저장소의 코드는 위의 구조를 구축하기 위한 방법이다. (@Async를 사용하면 더 쉽게 할수 있기는 하다.)\n\n\n\n\n\n\n\n스레드풀\n\n\n\nThreadPoolConfig\n\n\n\n스케쥴링을 처리할때 사용할 스레드풀이다.\n\nThreadPoolTaskScheduler를 사용할것이고, 주로 더 범용적으로 사용되는 ThreadPoolTaskExecutor에 대한 설정도 추가해보았다. (이 코드에서 사용하진 않는다)\n\n\n\n@EnableAsync\n@Configuration\n@EnableScheduling\npublic class ThreadPoolConfig {\n    @Bean\n    public ThreadPoolTaskScheduler taskScheduler() {\n        ThreadPoolTaskScheduler taskScheduler = new ThreadPoolTaskScheduler();\n\n        // 스케쥴러 스레드풀의 사이즈. 여기서는 머신의 프로세서 수로 하였다.\n        taskScheduler.setPoolSize(Runtime.getRuntime().availableProcessors());\n\n        // 로그에 찍힐 스케쥴러 스레드의 접두사\n        taskScheduler.setThreadNamePrefix(\"Scheduler-Thread-\");\n\n        // 모든 설정을 적용하고 ThreadPoolTaskScheduler를 초기화\n        taskScheduler.initialize();\n\n        return taskScheduler;\n    }\n\n    @Bean\n    public ThreadPoolTaskExecutor threadPoolTaskExecutor() {\n        ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor();\n\n        // 로그에 찍힐 스레드의 접두사\n        taskExecutor.setThreadNamePrefix(\"Async-Thread-\");\n\n        // 기본적으로 유지할 스레드풀의 사이즈. 설정값은 머신의 프로세서 수로 하였다.\n        taskExecutor.setCorePoolSize(Runtime.getRuntime().availableProcessors());\n\n        // 최대 스레드풀 사이즈\n        taskExecutor.setMaxPoolSize(200);\n\n        // 최대 스레드풀 사이즈만큼 스레드가 생성되면 생성을 대기시킬 스레드의 수\n        taskExecutor.setQueueCapacity(1_000);\n\n        // MaxPoolSize와 QueueCapacity이상으로 스레드가 생성되야 할 경우의 정책\n        // CallerRunsPolicy는 스레드를 생성하고 처리를 위임하려고 한 스레드가 직접 모든 처리를 다하도록 하는 정책\n        taskExecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());\n\n        // 어플리케이션 종료시 동작중이던 스레드가 모든 처리를 완료할때까지 대기한 후 종료한다\n        taskExecutor.setWaitForTasksToCompleteOnShutdown(true);\n\n        // CorePool 스레드의 유휴시간(기본 60s)이 지나면 kill할지 여부.\n        // 기본값은 false이며, true로 설정하면 스레드를 kill한다.\n        taskExecutor.setAllowCoreThreadTimeOut(true);\n\n        // 모든 설정을 적용하고 ThreadPoolTaskExecutor를 초기화\n        taskExecutor.initialize();\n\n        return taskExecutor;\n    }\n}\n\n\n\n\n도메인\n\n\n\nTransaction\n\n\n\n사용자의 요청이 유효하다면 생성시킬 결제거래 객체다.\n\n혹시모를 동시성 이슈를 고려해 불변객체로 설계했다.\n\n\n\n/**\n * 결제거래를 표현하는 클래스.\n */\n@Value(staticConstructor = \"of\")\npublic class Transaction {\n    Long id;\n    TransactionStatus status;\n\n    /**\n     * 새로운 결제거래가 생성되어야 할 경우 호출해야 하는 정적 팩토리 메서드.\n     * @return STANDBY 상태의 인스턴스를 반환\n     */\n    public static Transaction create() {\n        return Transaction.of(null, TransactionStatus.STANDBY);\n    }\n\n    /**\n     * 객체의 상태가 업데이트되야 할 경우 새로운 객체를 생성하여 반환한다\n     * @param status 업데이트되어야 할 상태\n     * @return 상태가 업데이트된 새로운 인스턴스\n     */\n    public Transaction update(TransactionStatus status) {\n        return Transaction.of(id, status);\n    }\n\n    /**\n     * 객체의 상태가 STANDBY 인지?\n     * @return STANDBY라면 true를 반환\n     */\n    public boolean isStandBy(){\n        return status == TransactionStatus.STANDBY;\n    }\n\n    /**\n     * 객체의 상태가 QUEUE_WAIT 인지?\n     * @return QUEUE_WAIT이라면 true를 반환\n     */\n    public boolean isQueueWait() {\n        return status == TransactionStatus.QUEUE_WAIT;\n    }\n\n    /**\n     * 결제 거래의 상태를 나타내는 enum 클래스\n     */\n    public enum TransactionStatus {\n        STANDBY,\n        QUEUE_WAIT,\n        QUEUE,\n        PROGRESS,\n        SUCCESS,\n        FAILURE\n    }\n}\n\n\n\n\n이벤트\n\n\n\nTransactionEventQueue\n\n\n\n결제거래 이벤트가 대기할 큐이다.\n\n구현체는 LinkedBlockingQueue로 결정하였다.\n\n이에 대한 이유가 궁금하다면 아래의 아티클을 확인하라.\n\n\n\n📜 LinkedBlockingQueue vs ConcurrentLinkedQueue\n\n\n\nAPI는 심플하다.\n\n큐에 넣는것(offer), 큐에서 빼내는것(poll)이 있으며, 이벤트가 큐에 들어가면 true를, 그렇지 않다면 false를 반환한다.\n\n여기서 false가 반환됐다는 것은 큐가 가득 찼다는것과 같은 의미이다.\n\n\n\n@Slf4j\npublic class TransactionEventQueue {\n    private final Queue&lt;Transaction&gt; queue;\n    private final int queueSize;\n\n    private TransactionEventQueue(int size) {\n        this.queueSize = size;\n        this.queue = new LinkedBlockingQueue&lt;&gt;(queueSize);\n    }\n\n    public static TransactionEventQueue of(int size) {\n        return new TransactionEventQueue(size);\n    }\n\n    public boolean offer(Transaction transaction) {\n        boolean returnValue = queue.offer(transaction);\n        healthCheck();\n        return returnValue;\n    }\n\n\n    public Transaction poll() {\n        if (queue.size() &lt;= 0) {\n            throw new IllegalStateException(\"No events in the queue !\");\n        }\n        Transaction transaction = queue.poll();\n        healthCheck();\n        return transaction;\n    }\n\n    private int size() {\n        return queue.size();\n    }\n\n    public boolean isFull() {\n        return size() == queueSize;\n    }\n\n    public boolean isRemaining() {\n        return size() &gt; 0;\n    }\n\n    private void healthCheck() {\n        log.info(\"{\\\"totalQueueSize\\\":{}, \\\"currentQueueSize\\\":{}}\", queueSize, size());\n    }\n}\n\n\n\n\n그리고 이벤트 큐를 초기화하여 Bean으로 등록한다.\n\n이때 큐의 사이즈는 1,000으로 설정하였다.\n\n\n\nEventPublisher\n\n\n\n이벤트 객체가 생성되면 이를 publishing해주는 역할을 담당한다.\n\n\n\n@Component\n@RequiredArgsConstructor\npublic class EventPublisher {\n    private final ApplicationEventPublisher publisher;\n\n    public void publish(Transaction transaction) {\n        publisher.publishEvent(transaction);\n    }\n}\n\n\n\n\nTransactionEventListener\n\n\n\nTransactionEvent가 publishing되면 어떤 처리를 담당할 이벤트 리스너이다.\n\n여기서 처리는 아주 심플하다.\n\n\n\n\n  TransactionEventQueue에 이벤트를 집어넣어본다.\n  true가 반환된다면 데이터베이스속 결제거래의 상태를 QUEUE로 변경하고 작업을 종료한다.\n  false가 반환된다면 true가 반환될때까지 계속해서 큐에 이벤트를 집어넣어본다. (=큐에 공간이 남을때까지)\n  이때 이벤트의 상태가 QUEUE_WAIT이 아니라면(=STANDBY라면) QUEUE_WAIT로 데이터베이스를 업데이트한다. 조건문이 있는 이유는 업데이트 쿼리가 계속해서 발생하지 않도록 하기 위함이다.\n\n\n\n\n@Slf4j\n@Component\n@RequiredArgsConstructor\npublic class TransactionEventListener {\n    private final TransactionEventQueue eventQueue;\n    private final TransactionRepository repository;\n\n    @EventListener\n    public void onEvent(Transaction transaction) {\n        if (!transaction.isStandBy()) {\n            log.info(\"Transaction(id:{}) status is not STANDBY!\", transaction.getId());\n            return;\n        }\n\n        while (eventQueue.isFull()) {\n            if (!transaction.isQueueWait()) {\n                transaction = updateStatus(transaction, TransactionStatus.QUEUE_WAIT);\n            }\n        }\n        transaction = updateStatus(transaction, TransactionStatus.QUEUE);\n        eventQueue.offer(transaction);\n    }\n\n    private Transaction updateStatus(Transaction transaction, TransactionStatus status) {\n        TransactionStatus beforeStatus = transaction.getStatus();\n        Transaction updatedTransaction = transaction.update(status);\n        log.info(\"{\\\"transactionId\\\": {},\\\"before\\\":\\\"{}\\\", \\\"after\\\":\\\"{}\\\"}\", transaction.getId(), beforeStatus, status);\n        return repository.update(updatedTransaction);\n    }\n}\n\n\n\n\nTransactionEventScheduler\n\n\n\n큐를 polling 할 스케쥴러이다.\n\n단지 주기적으로 polling만 하며, 모든 처리를 TransactionEventWorker에 위임한다.\n\n\n\n@Component\n@RequiredArgsConstructor\npublic class TransactionEventScheduler {\n    private final TransactionEventQueue eventQueue;\n    private final TransactionRepository repository;\n\n    @Async(\"taskScheduler\")\n    @Scheduled(fixedRate = 100)\n    public void schedule() {\n        new TransactionEventWorker(eventQueue, repository)\n            .run();\n    }\n}\n\n\n\n\nTransactionEventWorker\n\n\n\n이벤트를 처리할 워커이다.\n\n순서는 다음과 같다.\n\n\n\n\n  큐 사이즈가 0보다 작다면 큐에 처리할 이벤트가 없다는 의미이므로 아무것도 하지 않는다.\n  큐 사이즈가 0보다 크다면 큐에서 이벤트를 꺼낸 후 이벤트에서 결제거래 정보를 가져온다.\n  데이터베이스 속 결제거래의 상태를 PROGRESS로 업데이트한다.\n  모종의 처리를 한다. 여기서는 이 처리가 1초(1000ms) 걸린다고 가정하였다.\n  처리가 50:50 의 확률로 성공, 혹은 실패된다. 이때 결과에 따라 데이터베이스 속 결제거래의 상태를 SUCCESS 혹은 FAILURE로 업데이트한다.\n  작업을 종료한다. (여기서 후속 처리를 진행해도 좋다.)\n  3~6 작업 중 예외가 발생한다면 즉시 결제거래의 상태를 FAILURE로 업데이트하고 작업을 종료한다.\n\n\n\n\n중요하게 봐야 할 것은, @Transactional이 선언돼있는 점이다.\n\n작업을 진행할 때 이미 큐에서 할당량을 꺼내온 상태이므로, 예외가 발생한다면 데이터베이스의 상태를 별도로 업데이트하는 부분이 필요해진다.\n\n왜냐하면 @Transactional이 있기 때문에 예외가 발생한다면 롤백이 될 것이다. 즉, PROGRESS로 커밋한게 롤백되어 데이터베이스에는 상태가 PROGRESS가 아닌 QUEUE로 되면서도 큐에 있던 작업은 유실되는 문제가 생길수 있다.\n\n따라서 실무에 사용하려면 이 부분은 별도의 핸들링이 필요하다는 점을 명심하자.\n\n\n\n@Slf4j\n@RequiredArgsConstructor\npublic class TransactionEventWorker implements Runnable {\n    private final TransactionEventQueue eventQueue;\n    private final TransactionRepository repository;\n\n    @Override\n    @Transactional\n    public void run() {\n        if (eventQueue.isRemaining()) {\n            Transaction transaction = eventQueue.poll();\n            try {\n                transaction = updateStatus(transaction, TransactionStatus.PROGRESS);\n                processing(1_000);\n                successOrFailure(transaction);\n            } catch (Exception e) {\n                handlingInCaseOfFailure(transaction);\n                log.error(e.getMessage());\n            }\n        }\n    }\n\n    private void processing(int processingTimeInMs) {\n        try {\n            Thread.sleep(processingTimeInMs);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n    private void successOrFailure(Transaction transaction) {\n        if (Math.random() &lt; 0.5) {\n            updateStatus(transaction, TransactionStatus.SUCCESS);\n        } else {\n            updateStatus(transaction, TransactionStatus.FAILURE);\n        }\n    }\n\n    private void handlingInCaseOfFailure(Transaction transaction) {\n        updateStatus(transaction, TransactionStatus.FAILURE);\n    }\n\n    private Transaction updateStatus(Transaction transaction, TransactionStatus status) {\n        TransactionStatus beforeStatus = transaction.getStatus();\n        Transaction updatedTransaction = transaction.update(status);\n        log.info(\"{\\\"transactionId\\\": {},\\\"before\\\":\\\"{}\\\", \\\"after\\\":\\\"{}\\\"}\", transaction.getId(), beforeStatus, status);\n        return repository.update(updatedTransaction);\n    }\n}\n\n\n\n\n",
      "categories": ["spring","spring-boot"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-boot/2021-12-31-spring-boot-event-queue/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "프로그래머스 - 1차 비밀지도",
      "date": "2022-01-02 00:00:00 +0000",
      "description": "프로그래머스 17681번 문제\n",
      "content": "\n\n\n@DisplayName(\"프로그래머스 17681 - [1차] 비밀지도\")\nclass Programmers17681Test {\n  Programmers17681 solve = new Programmers17681();\n\n  static Stream&lt;Arguments&gt; solution() {\n    return Stream.of(\n            Arguments.of(\n                    5,\n                    new int[]{9, 20, 28, 18, 11},\n                    new int[]{30, 1, 21, 17, 28},\n                    new String[]{\"#####\", \"# # #\", \"### #\", \"#  ##\", \"#####\"}\n            ),\n            Arguments.of(\n                    6,\n                    new int[]{46, 33, 33, 22, 31, 50},\n                    new int[]{27, 56, 19, 14, 14, 10},\n                    new String[]{\"######\", \"###  #\", \"##  ##\", \" #### \", \" #####\", \"### # \"}\n            )\n    );\n  }\n\n  @MethodSource\n  @ParameterizedTest\n  void solution(int n, int[] arr1, int[] arr2, String[] expected) throws Exception {\n    String[] actual = solve.solution(n, arr1, arr2);\n    assertThat(actual).containsExactly(expected);\n  }\n}\n\n\n\n\n밑바닥부터 만드는 컴퓨팅 시스템에서 배운 컴퓨터의 수의 체계가 바로 떠올랐다.\n\n문제를 유심히 보니 이진문자열을 OR연산 해주면 쉽게 풀릴 것 같았다.\n\n풀이는 다음과 같다.\n\n\n\n01001 = 9를 이진수로 변환\n\n11110 = 30을 이진수로 변환\n\n11111 = 두 수를 OR 연산한 결과\n\n\n\n예를 들어 OR연산 결과로 10011이 나왔다고 치자.\n\n이때 0은 공백으로, 1은 #으로 변경해주면 답이된다.\n\n\n\npublic class Programmers17681 {\n  public String[] solution(int n, int[] arr1, int[] arr2) {\n    return IntStream.range(0, n)\n            .mapToObj(i -&gt; String.format(\"%\" + n + \"s\", toBinaryString((arr1[i] | arr2[i])))\n                    .replace('0', ' ')\n                    .replace('1', '#'))\n            .toArray(String[]::new);\n  }\n}\n\n\n\n",
      "categories": ["cs","data-structure-algorithm"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/data-structure-algorithm/2022-01-02-programmers-17681/"
    },{
      "image": "/assets/img/spring/spring-cloud/spring-cloud.png",
      "title": "오픈페인(OpenFeign)",
      "date": "2022-01-04 00:00:00 +0000",
      "description": "혹은 페인 클라이언트(Feign Client)로 불리는 프로젝트\n",
      "content": "\n  Open Feign    \n      의존성\n      기본설정\n      클라이언트        \n          @SpringQueryMap\n        \n      \n      예외 핸들링(디코더)\n      사용\n    \n  \n\n\n\n\n\n  📦 GitHub - shirohoo/spring-cloud-openfeign\n  📦 Spring Cloud OpenFeign Docs\n  📦 우아한 feign 적용기\n  📦 feign 좀더 나아가기\n\n\n\n\nOpen Feign\n\n\n\nMSA환경에서 디스커버리 서비스와 연동하여 각 마이크로 서비스간의 통신을 원활하게 하기위해 탄생한 목적의 프로젝트이다.\n\n하지만 오픈페인은 단독으로도 사용할 수 있으며, 이 경우 RestTemplate, WebClient 등을 대체할 수도 있게 된다.\n\nJPA Repository 와 Spring Controller 를 합쳐놓은 듯한 느낌으로 편안하고 가독성 좋게 사용할 수 있다.\n\n\n\n의존성\n\n\n\n기본적으로 Spring Initializer를 사용하면 아주 쉽게 설정할 수 있다.\n\n\n\n\n\n\n\n직접 설정하려면 다음과 같이 하면 된다.\n\n\n\n// file: 'build.gradle'\ndependencyManagement {\n    imports {\n        mavenBom 'org.springframework.cloud:spring-cloud-dependencies:2020.0.3'\n    }\n}\n\ndependencies {\n    implementation 'org.springframework.cloud:spring-cloud-starter-openfeign'\n}\n\n\n\n\n기본설정\n\n\n\n우선 ObjectMapper때문에 열받는 상황이 종종 생길 수 있으므로 아래 설정을 추가해주면 많이 편해진다.\n\n설정이 좀 과한감이 없지않아 있으니, 최적화를 원한다면 옵션에 대해 찾아보고 디테일하게 설정하도록 하자.\n\n\n\n// file: 'ObjectMapperConfig'\n@Configuration\npublic class ObjectMapperConfig implements Jackson2ObjectMapperBuilderCustomizer {\n    @Override\n    public void customize(Jackson2ObjectMapperBuilder jacksonObjectMapperBuilder) {\n        ObjectMapper objectMapper = new ObjectMapper();\n        objectMapper.registerModule(new JavaTimeModule());\n        objectMapper.setVisibility(PropertyAccessor.FIELD, Visibility.ANY);\n        objectMapper.configure(DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL, false);\n        objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);\n        \n        jacksonObjectMapperBuilder.configure(objectMapper);\n    }\n}\n\n\n\n\n// file: 'OpenFeignConfig'\n@Configuration\n// 페인 클라이언트를 활성화. @SpringBootApplication이 달린 메인 클래스가 아닌 별도의 설정클래스에 추가했으므로 콤포넌트 스캔을 위해 베이스패키지를 지정\n@EnableFeignClients(basePackages = \"io.github.shirohoo.openfeign.client\") \npublic class OpenFeignConfig { \n    // 페인 클라이언트가 제공하는 모든 레벨의 로그를 사용 (자세한건 하기 내용 참고)\n    @Bean\n    public Level feignLoggerLevel() {\n        return Level.FULL; \n    }\n\n    // Error가 발생 할 경우 재시도에 대한 설정\n    // 파라미터는 순서대로 각 시도간의 차이(period), 모든 재시도간의 차이(maxPeriod), 재시도 횟수(maxAttempts) 이다\n    // 만약 HTTP 호출 실패 시 리트라이를 하고싶지 않다면 Retryer.NEVER_RETRY로 설정하자 \n    // 후술할 디코더에서 RetryableException가 발생해야만 동작한다 ! \n    @Bean\n    public Retryer retryer() {\n        return new Default(1_000, 2_000, 3); \n    }\n    \n    // LocalDate, LocalDateTime 핸들링 시 URL 인코딩으로 인해 문제가 생길 수 있다.\n    // 이러한 불편함이 이 설정을 추가함으로서 상당부분 해소될 수 있다\n    @Bean\n    public FeignFormatterRegistrar localDateFeignFormatterRegister() {\n        return registry -&gt; {\n             DateTimeFormatterRegistrar registrar = new DateTimeFormatterRegistrar();\n             registrar.setUseIsoFormat(true);\n             registrar.registerFormatters(registry);\n         };\n    }\n    \n    // 모든 페인 클라이언트가 공통으로 사용할 헤더를 설정할 수 있다\n    @Bean\n    public RequestInterceptor requestInterceptor() {\n        return requestTemplate -&gt; {\n             requestTemplate.header(\"commonHeader\", \"shirohoo\"); // 모든 페인 클라이언트에 적용될 헤더\n             requestTemplate.query(\"commonQueryParam\", \"shirohoo\"); // 모든 페인 클라이언트에 적용될 쿼리스트링\n        };\n    }\n}\n\n\n\n\nOpenFeign이 제공하는 Logger.Level 설정은 다음과 같다\n\n\n  NONE : 로깅을 하지 않는다\n  BASIC : 요청 방법 및 URL, 상태 코드 및 실행 시간만 기록한다\n  HEADERS : 요청 및 응답 헤더와 함께 BASIC의 항목을 기록한다\n  FULL : 요청과 응답 모두에 대한 헤더, 본문 및 메타데이터를 기록한다. (즉, HTTP 메시지를 통째로 다찍는다)\n\n\n\n\n위 설정을 온전히 적용하려면 프로젝트의 로깅 레벨을 DEBUG까지 허용해줘야 한다.\n\napplication.yaml이나 application.properties에서 logging.level.root=debug로 설정하면 된다.\n\n하지만 프로젝트 전체의 로깅 레벨을 DEBUG로 설정하는 것은 무리가 있으므로, 아래와 같이 페인 클라이언트가 몰려있는 특정 패키지의 로깅 레벨만 DEBUG로 적용하는 방식이 주로 사용된다.\n\n\n\n# file: 'application.yaml'\nlogging:\n  level:\n    # 이렇게 FeignClient가 위치한 패키지별로 로깅 레벨을 설정할수도 있다\n    io.github.shirohoo.openfeign.client: DEBUG\n\n\n\n\nOpenFeign이 제공하는 기본 로거 구현체가 찍어주는 로그의 포맷은 다음과 같다.\n\n–&gt;\n\nHTTP Request\n\n–&gt;\n\n&lt;–\n\nHTTP Response\n\n&lt;–\n\n\n\ni.g.s.c.FeignClient - [FeignClient#method] ---&gt; GET https://jsonplaceholder.typicode.com/todos HTTP/1.1\ni.g.s.c.FeignClient - [FeignClient#method] Content-Length: 277\ni.g.s.c.FeignClient - [FeignClient#method] Content-Type: application/json\ni.g.s.c.FeignClient - [FeignClient#method]\ni.g.s.c.FeignClient - [FeignClient#method] {}\ni.g.s.c.FeignClient - [FeignClient#method] ---&gt; END HTTP (277-byte body)\ni.g.s.c.FeignClient - [FeignClient#method] &lt;--- HTTP/1.1 200 200 (737ms)\ni.g.s.c.FeignClient - [FeignClient#method] connection: Keep-Alive\ni.g.s.c.FeignClient - [FeignClient#method] content-type: application/json;charset=UTF-8\ni.g.s.c.FeignClient - [FeignClient#method] date: Fri, 12 Nov 2021 03:51:08 GMT\ni.g.s.c.FeignClient - [FeignClient#method] keep-alive: timeout=5, max=100\ni.g.s.c.FeignClient - [FeignClient#method] server: Apache\ni.g.s.c.FeignClient - [FeignClient#method] transfer-encoding: chunked\ni.g.s.c.FeignClient - [FeignClient#method]\ni.g.s.c.FeignClient - [FeignClient#method] {\"data\":\"data\"}\ni.g.s.c.FeignClient - [FeignClient#method] &lt;--- END HTTP (310-byte body)\n\n\n\n\nHTTP 메시지에 별도의 헤더를 추가하겠다면 Spring MVC Controller에서 사용하듯이 페인 클라이언트 내부에서 @RequestHeader를 사용할 수 있다.\n\n하지만 모든 페인 클라이언트가 공통으로 사용하는 헤더가 있다면 매번 @RequestHeader로 추가하는게 번거롭다.\n\n그럴때 하기 설정을 추가하면 된다.\n\n헤더 뿐만아니고 쿼리스트링, 바디등도 설정할 수 있으니 참고하자 !\n\n\n\n@Bean\npublic RequestInterceptor requestInterceptor() {\n    return requestTemplate -&gt; {\n        requestTemplate.header(\"commonHeader\", \"shirohoo\"); // 모든 페인 클라이언트에 적용될 헤더\n        requestTemplate.query(\"commonQueryParam\", \"shirohoo\"); // 모든 페인 클라이언트에 적용될 쿼리스트링\n    };\n}\n\n\n\n\n클라이언트\n\n\n\n// 필수 속성은 name과 url이며, OpenFeign을 디스커버리 서비스 없이 단독으로 사용 할 경우 name도 크게 신경쓰지 않아도 된다\n// 단, 그래도 name은 필수속성이다\n@FeignClient(\n    name = \"jsonPlaceHolder\",\n    url = \"${feign.client.url.jsonPlaceHolder}\", // application.yaml에 정의한 url을 SpEL을 통해 참조할 수 있다\n    configuration = { // 여러 설정파일을 페인 클라이언트에 탑재할 수 있다\n        // 이전에 설정한 로그, 재시도 관련 설정을 사용하고 싶다면 탑재    \n        // 주로 클라이언트 벤더별로 별도의 Config 클래스를 만들고 각각의 페인 클라이언트에 탑재하는 방식을 사용한다\n        OpenFeignConfig.class,\n            \n        // 별도로 구현한 디코더를 탑재하여 더 디테일한 에러 핸들링도 가능하다\n        // 아무런 디코더를 설정하지 않을 경우 OpenFeign에서 제공하는 기본 디코더가 동작한다\n        CustomErrorDecoder.class \n    }\n)\npublic interface JsonPlaceHolderClient { // JPA Repository와 마찬가지로 인터페이스로 생성한다\n\n    // Spring Controller와 같은 패턴을 사용한다.\n    // Get방식으로 ${feign.client.url.jsonPlaceHolder}/posts에 요청을 보내고 List&lt;Post&gt; 로 응답을 받는다\n    @GetMapping(\"/posts\")\n    List&lt;Post&gt; getPosts();\n\n    @GetMapping(\"/comments\")\n    List&lt;Comment&gt; getComment();\n\n    @GetMapping(\"/albums\")\n    List&lt;Album&gt; getAlbums();\n\n    @GetMapping(\"/photos\")\n    List&lt;Photo&gt; getPhotos();\n\n    @GetMapping(\"/todos\")\n    List&lt;Todo&gt; getTodos();\n\n    @GetMapping(\"/users\")\n    List&lt;User&gt; getUsers();\n\n}\n\n\n\n\nPost나 Put처럼 요청 파라미터가 있는 경우 메서드 파라미터에 추가한다.\n\n@PathVariable, @ReuqestHeader, @RequestBody 등 Spring MVC에서 사용하던 모든 애노테이션을 사용할 수 있다.\n\n이부분이 OpenFeign을 사용하면서 가장 주의해야 할 부분중 하나인데, OpenFeign을 처음 사용하시는 분들이 가장 많이 헤매는 부분이기 때문이다.\n\n예를 들어 하기와 같은 경우에는 String idValue와 시그니처가 일치하지 않기 때문에 (\"id\") 를 생략할 수 없다.\n\n\n\n@GetMapping(\"/api/v1/{id}\")\npublic ResponseEntity&lt;Void&gt; api(@PathVariable(\"id\") String idValue) {\n    // do something...\n}\n\n\n\n\n하지만 하기와 같은 경우에는 시그니처가 일치하기 때문에 생략할 수 있다.\n\n\n\n@GetMapping(\"/api/v1/{id}\")\npublic ResponseEntity&lt;Void&gt; api(@PathVariable String id) {\n    // do something...\n}\n\n\n\n\n하지만 OpenFeign에서는 위처럼 절대 생략할수가 없다\n\n이는 @RequestParam등도 마찬가지이다.\n\n\n\n@PostMapping(\"/users/{id}\")\nvoid getUsers(@PathVariable Long id); // OpenFeign에서는 불가능\n\n@PostMapping(\"/users/{id}\")\nvoid getUsers(@PathVariable(\"id\") Long id); // OpenFeign에서는 이렇게 사용해야만 한다 !\n\n\n\n\nOpenFeign의 경우 많은 애노테이션 속성을 생략할수가 없다. 😂\n\n\n\n@SpringQueryMap\n\n\n\n일반적으로 Get 방식의 요청을 보낼 때 queryString을 자주 사용한다.\n\n이때 일반적으로 @RequestParam을 여러개 추가해서 사용하게 된다.\n\n\n\n@GetMapping(\"/users\")\nList&lt;User&gt; getUsersWithQueryParamsBasic(\n        @RequestParam(\"param1\") String param1,\n        @RequestParam(\"param2\") String param2\n);\n\n\n\n\n@ReuqestParam이 많아지면 코드의 가독성이 매우 안좋아지고, 코드를 작성하기도 지루해진다.\n\n이 때 @SpringQueryMap을 사용할 수 있다.\n\n\n\n@Data\npublic class QueryParams {\n    private String param1;\n    private String param2;\n}\n\n@GetMapping(\"/users\")\nList&lt;User&gt; getUsersWithQueryParams(@SpringQueryMap QueryParams queryParams);\n\n\n\n\ngetUsersWithQueryParams(QueryParams)를 호출하면 다음과 같은 요청이 발생한다.\n\n\n\n[JsonPlaceHolderClient#getUsersWithQueryParams] ---&gt; GET https://jsonplaceholder.typicode.com/users?param1=param1&amp;param2=param2 HTTP/1.1\n\n\n\n\n예외 핸들링(디코더)\n\n\n\n별도의 에러 핸들링이 필요하다면 ErrorDecoder 를 확장한다.\n\n이후 Client 클래스에 구현한 디코더를 탑재하면 된다.\n\n만약 별도의 디코더를 탑재하지 않을 경우 OpenFeign이 제공하는 기본 디코더가 동작한다.\n\n디코더는 기본적으로 HTTP 상태코드가 400~500일 경우에만 동작하며 상태코드에 따라 다음과 같은 예외를 반환한다.\n\n상태코드가 400번대이면 FeignClientException가 반환되며,\n\n상태코드가 500번대이면 FeignServerException가 반환된다.\n\n하지만 Retry는 RetryableException가 반환되어야만 동작하기 때문에, 만약 재시도를 하고싶다면 RetryableException를 반환하도록 해주자.\n\n문서에서는 기본적으로 상태코드가 503(Service Unavailable) 일때 발생한다고 되어있다.\n\n\n\n// FeignClient 가 API 호출 중 발생하는 에러를 처리할 커스텀 클래스. \n// Bean 으로 등록되어 있으면 페인 클라이언트에 탑재하지 않더라도 기본 디코더 대신 동작한다.\n@Slf4j\n@Component\npublic class CustomErrorDecoder implements ErrorDecoder {\n  @Override\n  public Exception decode(String methodKey, Response response) {\n    String requestPayload = new String(response.request().body(), StandardCharsets.UTF_8);\n    int responseStatus = response.status();\n\n    log.info(\"request payload={}, response status={}, response payload={}\", requestPayload, responseStatus, response.body());\n\n    switch (responseStatus) {\n      case 400:\n        return new BadRequestException();\n      case 401:\n        return new UnauthorizedException();\n      case 403:\n        return new ForbiddenException();\n      case 404:\n        return new NotFoundException();\n      case 405:\n        return new MethodNotAllowedException();\n      case 406:\n        return new NotAcceptableException();\n      case 409:\n        return new ConflictException();\n      case 410:\n        return new GoneException();\n      case 415:\n        return new UnsupportedMediaTypeException();\n      case 429:\n        return new TooManyRequestsException();\n      case 422:\n        return new UnprocessableEntityException();\n      case 500:\n        // RetryableException을 던지면 Retry 설정이 동작한다. \n        return new RetryableException(responseStatus, \"to retry\", HttpMethod.GET, null, response.request());\n      default:\n        return FeignException.errorStatus(methodKey, response);\n    }\n  }\n}\n\n\n\n\n사용\n\n\n\n아주 심플하다.\n\n클라이언트를 DI하고 메소드를 호출하면 된다.\n\n본 예제에서는 그냥 인터페이스상태로 사용했지만, 별도의 래퍼 클래스를 만들어 사용하면 효과가 더 좋다.\n\n\n\n@SpringBootTest\nclass JsonPlaceHolderClientTest {\n  @Autowired\n  JsonPlaceHolderClient client;\n\n  @Test\n  void getPosts() throws Exception {\n    List&lt;Post&gt; posts = client.getPosts();\n    assertThat(posts.size()).isEqualTo(100);\n  }\n\n  @Test\n  void getComments() throws Exception {\n    List&lt;Comment&gt; posts = client.getComment();\n    assertThat(posts.size()).isEqualTo(500);\n  }\n\n  @Test\n  void getAlbums() throws Exception {\n    List&lt;Album&gt; posts = client.getAlbums();\n    assertThat(posts.size()).isEqualTo(100);\n  }\n\n  @Test\n  void getPhotos() throws Exception {\n    List&lt;Photo&gt; posts = client.getPhotos();\n    assertThat(posts.size()).isEqualTo(5000);\n  }\n\n  @Test\n  void getTodos() throws Exception {\n    List&lt;Todo&gt; posts = client.getTodos();\n    assertThat(posts.size()).isEqualTo(200);\n  }\n\n  @Test\n  void getUsers() throws Exception {\n    List&lt;User&gt; posts = client.getUsers();\n    assertThat(posts.size()).isEqualTo(10);\n  }\n\n  @Test\n  void getUsersWithQueryParams() throws Exception {\n    // ...given\n    QueryParams queryParams = new QueryParams();\n    queryParams.setParam1(\"param1\");\n    queryParams.setParam2(\"param2\");\n\n    // ...when\n    List&lt;User&gt; posts = client.getUsersWithQueryParams(queryParams);\n\n    // ...then\n    assertThat(posts.size()).isEqualTo(10);\n  }\n}\n\n\n\n",
      "categories": ["spring","spring-cloud"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-cloud/2022-01-04-open-feign/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "405 METHOD_NOT_ALLOWED",
      "date": "2022-01-09 00:00:00 +0000",
      "description": "HTML form 태그 사용시 발생한 문제\n",
      "content": "\n  🚨 문제\n  🚧 원인\n  ✅ 해결\n\n\n\n\n🚨 문제\n\n\n\nSpring WebFlux를 학습하다 마주친 문제이다.\n\n에러 메시지 그대로 해당 URI는 GET 방식의 HTTP 메서드를 지원하지 않는다는 의미이다.\n\n\n\n\n\n\n\nSun Jan 09 18:19:47 KST 2022\n[d6491d4c-11, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:57273] There was an unexpected error (type=Method Not Allowed, status=405).\nRequest method 'GET' not supported\norg.springframework.web.server.MethodNotAllowedException: 405 METHOD_NOT_ALLOWED \"Request method 'GET' not supported\"\n\tat org.springframework.web.reactive.result.method.RequestMappingInfoHandlerMapping.handleNoMatch(RequestMappingInfoHandlerMapping.java:181)\n\tSuppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: \nError has been observed at the following site(s):\n\t*__checkpoint ⇢ org.springframework.boot.web.reactive.filter.OrderedHiddenHttpMethodFilter [DefaultWebFilterChain]\n\t*__checkpoint ⇢ HTTP GET \"/carts/items/61daa8af245e0001a2670b47\" [ExceptionHandlingWebHandler]\nOriginal Stack Trace:\n\t\tat org.springframework.web.reactive.result.method.RequestMappingInfoHandlerMapping.handleNoMatch(RequestMappingInfoHandlerMapping.java:181)\n\n\n🚧 원인\n\n\n\nHTML의 form태그는 GET과 POST만 지원한다고 한다.\n\n헌데, 나는 form태그에 DELETE 메서드를 사용했고, HTML이 이것을 인식하지 못해 결과적으로 DELETE가 아닌 GET으로 요청이 발생했고, 해당 URI로 요청을 받는 컨트롤러는 작성돼있지 않았기 때문에 발생한 문제로 추측된다.\n\nHTML을 만져본지 몇 달 지났더니 아리송하다.\n\n\n\n&lt;form method=\"delete\" th:action=\"@{'/carts/items/'+${item.id}}\"&gt;\n    &lt;input type=\"submit\" value=\"Delete from Cart\"/&gt;\n&lt;/form&gt;\n\n\n\n\n@Controller\n@RequiredArgsConstructor\n@RequestMapping(\"/carts\")\nclass CartController {\n    private final CartManager cartManager;\n\n    @GetMapping\n    public Mono&lt;Rendering&gt; viewCart() {\n        return cartManager.viewCart();\n    }\n\n    @GetMapping(\"/items\")\n    public Mono&lt;Rendering&gt; search(\n        @RequestParam(required = false) String itemName,\n        @RequestParam boolean useAnd\n    ) {\n        return cartManager.viewCart(itemName, useAnd);\n    }\n\n    @PostMapping(\"/items/{itemId}\")\n    public Mono&lt;String&gt; addToCart(@PathVariable String itemId) {\n        return cartManager.addItemToCart(\"MyCart\", itemId)\n            .thenReturn(\"redirect:/carts\");\n    }\n\n    // 문제 발생 부분\n    @DeleteMapping(\"/items/{itemId}\")\n    public Mono&lt;String&gt; deleteFromCart(@PathVariable String itemId) {\n        return cartManager.deleteFromCart(\"MyCart\", itemId)\n            .thenReturn(\"redirect:/carts\");\n    }\n}\n\n\n\n\n✅ 해결\n\n\n\nform 태그의 메서드를 POST로 변경해주고, form 태그 안에 하기와 같은 hidden input 태그를 추가한다.\n\n\n\n&lt;form method=\"post\" th:action=\"@{'/carts/items/'+${item.id}}\"&gt;\n    &lt;input type=\"hidden\" name=\"_method\" value=\"delete\"&gt;\n    &lt;input type=\"submit\" value=\"Delete from Cart\"/&gt;\n&lt;/form&gt;\n\n\n\n\n일반적인 HTML을 사용한다면 여기서 끝날 것 같은데, 나는 타임리프(Thymeleaf)와 웹플럭스(WebFlux)를 사용하였으므로 하기의 설정을 추가해주었다.\n\n\n\n# file: 'application.yaml'\nspring:\n  webflux:\n    hiddenmethod:\n      filter:\n        enabled: true\n\n\n\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2022-01-09-debugging-15/"
    },{
      "image": "/assets/img/spring/spring-data-jpa/hibernate.jpg",
      "title": "Spring Data JPA의 몇가지 유용한 정보",
      "date": "2022-01-11 00:00:00 +0000",
      "description": "공식문서 파헤치기\n",
      "content": "\n  👏 Spring Data JPA    \n      💡 반환 타입으로 Page가 아닌 Slice를 고려하기\n      💡 쿼리 메서드로도 프로젝션이 가능하다        \n          생성자 프로젝션\n          인터페이스 프로젝션\n          제네릭을 이용한 동적 프로젝션(Dynamic Projection)\n        \n      \n      💡 Query By Example API\n    \n  \n\n\n\n\n👏 Spring Data JPA\n\n\n\nSpring Data JPA를 사용하면 Spring Data 프로젝트에서 제공하는 여러가지 유용한 추상화된 API를 사용할 수 있습니다.\n\n특히 쿼리 메서드 기능이 아주 유용하고 강력한데요, 이 쿼리 메서드를 잘 사용하면 정말 대부분의 상황을 이것 하나로 해결할수 있을 정도입니다.\n\n쿼리 메서드로 부족하다면 Example이나 Querydsl등의 사용을 고려해볼 수 있을 것 같습니다.\n\n\n\n쿼리 메서드는 메서드이름을 통해 여러가지 쿼리를 생성해내는 기능입니다.\n\n쿼리 메서드로 할 수 있는 대부분의 롤(ROLE)을 정리해두었으니 궁금하시다면 참고하셔도 좋을 것 같습니다.\n\n\n  📦 SimpleJpaRepository 학습 테스트\n\n\n\n\n이번 포스팅에서는 Spring Data JPA를 사용할 때 몇가지 유용한 팁을 정리하였습니다.\n\n\n\n💡 반환 타입으로 Page가 아닌 Slice를 고려하기\n\n\n\nSpring Data JPA 프로젝트를 사용하면 JpaRepository나 CrudRepository를 extends하여 사용하는 경우가 많습니다.\n\n이때 페이징을 하는 경우 무심코 반환타입에 Page를 사용하는 경우가 많죠.\n\n하지만 Slice라는 타입으로도 반환받을 수 있습니다.\n\n\n\npublic interface ItemRepository extends JpaRepository&lt;Item, Long&gt; {\n    Slice&lt;Item&gt; readAllByNameContaining(String name, Pageable pageable);\n\n    Page&lt;Item&gt; findAllByNameContaining(String name, Pageable pageable);\n}\n\n\n\n\n시그니처를 살펴보면 Page는 Slice를 상속하여 몇가지의 메서드를 더 확장한 인터페이스입니다.\n\n\n\npublic interface Page&lt;T&gt; extends Slice&lt;T&gt; {\n    int getTotalPages();\n    \n    long getTotalElements();\n}\n\n\n\n\n두 반환 타입에는 다음과 같은 명확한 차이가 있습니다.\n\n\n\n\n  Page: 카운트 쿼리를 매번 발생시킵니다.\n    \n      단, 쿼리 메서드를 호출하며 인수로 넘긴 Pageable의 size값보다 반환되는 레코드의 수가 적은 경우에는 카운트 쿼리가 발생하지 않습니다.\n      이 기능은 쿼리한 페이지의 추가적인 상세한 정보들을 포함합니다.\n    \n  \n  Slice: 카운트 쿼리를 아예 발생시키지 않습니다.\n    \n      카운트 쿼리를 사용하지 않고 다음 페이지가 있음을 알 수 있는 원리는 다음과 같습니다.\n      쿼리 메서드를 호출하며 인수로 넘긴 Pageable의 size값보다 +1만큼 더 추가로 조회하여 추가로 반환되는 레코드가 있는 경우에 다음 페이지가 있음을 판단합니다.\n    \n  \n\n\n\n\n즉, 테이블의 레코드가 충분히 많다면 반환타입으로 Page를 선언했을 경우 매번 발생하는 카운트 쿼리가 부담이 될 수 있기 때문에, 이 경우에는 Slice로의 반환을 고려하는게 좋습니다.\n\nPage는 Slice와 다르게 가져온 페이지의 모든 상세한 정보들을 포함하므로 서로간의 trade-off가 분명히 존재합니다.\n\n\n\n두 반환타입의 차이를 확인하기 위해 간단한 테스트 코드를 작성했습니다.\n\n\n\n@DataJpaTest\nclass ItemRepositoryTest {\n    @Autowired\n    ItemRepository itemRepository;\n\n    @BeforeEach\n    void setUp() {\n        List&lt;Item&gt; items = new ArrayList&lt;&gt;();\n        for (int i = 1; i &lt;= 50; i++) {\n            items.add(createItem(i));\n        }\n        itemRepository.saveAll(items);\n    }\n\n    // Returned Page&lt;Item&gt;\n    @Test\n    void findAllByNameContaining() throws Exception {\n        itemRepository.findAllByNameContaining(\"1\", PageRequest.of(1, 3))\n                .forEach(System.out::println);\n    }\n\n    // Returned Slice&lt;Item&gt;\n    @Test\n    void readAllByNameContaining() throws Exception {\n        itemRepository.readAllByNameContaining(\"1\", PageRequest.of(1, 3))\n                .forEach(System.out::println);\n    }\n\n    private Item createItem(int itemName) {\n        return Item.builder()\n                .name(\"item\" + itemName)\n                .description(\"item description\")\n                .createdAt(LocalDateTime.now())\n                .build();\n    }\n}\n\n\n\n\nitemName이 item1 ~ item50 인 아이템 50개를 저장한 후 itemName에 문자열 1이 포함된 아이템들을 쿼리하고, 3개 묶음으로 분할한 후 그 중 1페이지를 가져오도록 하는 쿼리입니다.\n\n1부터 50 사이에 문자열 1이 포함된 수는 분명히 4개 이상이므로 위 설명대로라면 findAllByNameContaining는 카운트 쿼리가 발생할 것이며, readAllByNameContaining는 카운트 쿼리가 발생하지 않을 것입니다.\n\n\n\n\n  findAllByNameContaining 결과 (카운트 쿼리 발생)\n\n\n\n\nHibernate: \n    select\n        item0_.id as id1_4_,\n        item0_.created_at as created_2_4_,\n        item0_.description as descript3_4_,\n        item0_.name as name4_4_ \n    from\n        item item0_ \n    where\n        item0_.name like ? escape ? limit ? offset ?\nHibernate: \n    select // 카운트 쿼리 발생\n        count(item0_.id) as col_0_0_ \n    from\n        item item0_ \n    where\n        item0_.name like ? escape ?\n        \nItem(id=12, name=item12, description=item description, createdAt=2022-01-11T19:06:25.863552900)\nItem(id=13, name=item13, description=item description, createdAt=2022-01-11T19:06:25.863552900)\nItem(id=14, name=item14, description=item description, createdAt=2022-01-11T19:06:25.863552900)\n\n\n\n\n\n  readAllByNameContaining 결과 (카운트 쿼리 발생하지 않음)\n\n\n\n\nHibernate: \n    select\n        item0_.id as id1_4_,\n        item0_.created_at as created_2_4_,\n        item0_.description as descript3_4_,\n        item0_.name as name4_4_ \n    from\n        item item0_ \n    where\n        item0_.name like ? escape ? limit ? offset ?\n        \nItem(id=12, name=item12, description=item description, createdAt=2022-01-11T19:10:14.159593600)\nItem(id=13, name=item13, description=item description, createdAt=2022-01-11T19:10:14.159593600)\nItem(id=14, name=item14, description=item description, createdAt=2022-01-11T19:10:14.159593600)\n\n\n\n\n\n  📜 Spring Data JPA Docs\n\n  The first method lets you pass an org.springframework.data.domain.Pageable instance to the query method to dynamically add paging to your statically defined query. A Page knows about the total number of elements and pages available. It does so \nby the infrastructure triggering a count query to calculate the overall number. As this might be expensive (depending on the store used), you can instead return a Slice. A Slice knows only about whether a next Slice is available, which might be sufficient when walking through a larger result set.\n\n\n\n\n💡 쿼리 메서드로도 프로젝션이 가능하다\n\n\n\nSpring Data JPA의 쿼리 메서드로는 프로젝션이 되지 않기 때문에 Querydsl을 사용해야 한다는 분들이 간혹 계십니다.\n\n📜 Spring Data JPA의 공식문서 를 살펴보시면 분명히 DTO 프로젝션을 지원하고 있음을 알 수 있으며, 훌륭한 DTO 프로젝션 기능에 대해 놀라실지도 모릅니다.\n\n추가로 이 포스팅에서는 List나 Set만을 제한적으로 사용했으나, java.util.Collection 의 하위 타입이나 알맞은 생성자가 있는 단일 클래스는 대부분 제한없이 사용가능합니다.\n\n\n\n생성자 프로젝션\n\n\n\nItem 엔티티는 다음과 같은 필드를 갖습니다.\n\n\n\n@Entity\npublic class Item {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    private String name;\n\n    private String description;\n\n    @CreatedDate\n    private LocalDateTime createdAt;\n}\n\n\n\n\n이중 name과 createdAt 필드만 쏙 뽑아오고 싶다면 다음과 같이 두 필드를 포함하는 DTO를 작성합니다.\n\n이 때 주의해야 할것은, 추출하고자 하는 필드에 대한 생성자가 반드시 선언돼있어야 한다는 것입니다.\n\n\n\n@ToString\n@AllArgsConstructor\npublic class ItemDto {\n    private String name;\n    private LocalDateTime createdAt;\n}\n\n\n\n\n이제 다음과 같은 시그니처를 갖는 추상 메서드를 선언합니다.\n\n반환타입이 Item이 아닌 ItemDto임을 놓치지 마세요.\n\n\n\npublic interface ItemRepository extends JpaRepository&lt;Item, Long&gt; {\n    List&lt;ItemDto&gt; findByNameContaining(String name);\n}\n\n\n\n\n아주 간단한 테스트 코드를 작성하고 어떤 결과가 발생하는지 살펴보겠습니다.\n\nitemName에 문자열 1이 포함돼있는 아이템들의 name과 createdAt만 추출하는 코드입니다.\n\n\n\n@DataJpaTest\nclass ItemRepositoryTest {\n    @Autowired\n    ItemRepository itemRepository;\n\n    @BeforeEach\n    void setUp() {\n        List&lt;Item&gt; items = new ArrayList&lt;&gt;();\n        for (int i = 1; i &lt;= 50; i++) {\n            items.add(createItem(i));\n        }\n        itemRepository.saveAll(items);\n    }\n\n    @Test\n    void findByNameContaining() throws Exception {\n        itemRepository.findByNameContaining(\"1\")\n                .forEach(System.out::println);\n    }\n\n    private Item createItem(int itemName) {\n        return Item.builder()\n                .name(\"item\" + itemName)\n                .description(\"item description\")\n                .createdAt(LocalDateTime.now())\n                .build();\n    }\n}\n\n\n\n\nHibernate: \n    select\n        item0_.name as col_0_0_,\n        item0_.created_at as col_1_0_ \n    from\n        item item0_ \n    where\n        item0_.name like ? escape ?\n        \nItemDto(name=item1, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item10, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item11, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item12, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item13, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item14, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item15, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item16, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item17, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item18, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item19, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item21, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item31, createdAt=2022-01-11T19:00:29.901013)\nItemDto(name=item41, createdAt=2022-01-11T19:00:29.901013)\n\n\n\n\n프로젝션이 아주 잘 되는 모습을 보실 수 있습니다.\n\n\n\n인터페이스 프로젝션\n\n\n\n인터페이스 프로젝션은 객체 참조관계마저도 프로젝션할 수 있습니다.\n\n심지어는 SpEL로 제공되는 target 변수를 이용해 더욱 디테일한 프로젝션이 가능하지만, 이 경우 언더바(_)를 사용하여 코딩 컨벤션이 깨지는 약간의 문제가 있어 저는 선호하지는 않습니다.\n\n하지만 기본적인 인터페이스 프로젝션으로도 충분히 강력하기 때문에 알아두시면 좋을 것 같습니다.\n\n\n\n우선 Item을 참조하는 간단한 CartItem 엔티티를 작성했습니다.\n\n이때 단방향 OneToMany에 cascade를 사용하였는데, 이렇게 하시면 외래키(FK) 지정을 위해 매번 추가적인 update 쿼리가 발생하므로 문제가 있는 코드입니다.\n\n즉, 이것은 단순히 테스트를 조금 더 편하게 하고자함이므로 실제 업무에서 사용하시는 것은 추천드리지 않습니다.\n\n이 경우에는 OneToMany 양방향이나 ManyToMany 사용을 권장드립니다.\n\n\n\n@Entity\n@Getter\n@ToString\n@EntityListeners(AuditingEntityListener.class)\n@NoArgsConstructor(access = AccessLevel.PROTECTED)\npublic class CartItem {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    @OneToMany(cascade = CascadeType.ALL)\n    private Set&lt;Item&gt; items = new HashSet&lt;&gt;();\n\n    private CartItem(Long id, Set&lt;Item&gt; items) {\n        this.id = id;\n        this.items = items;\n    }\n\n    public static CartItem of(Long id, Set&lt;Item&gt; items) {\n        return new CartItem(id, items);\n    }\n\n    public void addItem(Item item) {\n        items.add(item);\n    }\n\n    public boolean isTenBundles() {\n        return items.size() == 10;\n    }\n}\n\n\n\n\n이제 CartItem을 프로젝션하는데 사용할 인터페이스를 정의합니다.\n\n이때 CartItem이 참조하는 Set&lt;Item&gt;도 함께 가져올 것입니다.\n\n\n\npublic interface CartItemProjection {\n    Long getId();\n\n    List&lt;ItemDto&gt; getItems();\n\n    interface ItemDto {\n        Long getId();\n\n        String getName();\n\n        String getDescription();\n    }\n}\n\n\n\n\n그리고 다음과 같은 리파지토리를 작성합니다.\n\n쿼리 메서드를 호출하며 인수로 넘긴 id보다 큰 id를 갖는 CarItem들을 프로젝션합니다.\n\n\n\npublic interface CartItemRepository extends JpaRepository&lt;CartItem, Long&gt; {\n    List&lt;CartItemProjection&gt; findByIdAfter(Long id);\n}\n\n\n\n\n마지막으로 결과 확인을 위한 간단한 테스트를 작성했습니다.\n\n총 100개의 Item을 10개씩 분할해 각각 10개의 CartItem에 넣고 저장했습니다.\n\n이후 id가 5보다 큰 CartItem들을 조회하여 DTO로 프로젝션합니다.\n\n\n\n@DataJpaTest\nclass CartItemRepositoryTest {\n    @Autowired\n    ItemRepository itemRepository;\n\n    @Autowired\n    CartItemRepository cartItemRepository;\n\n    @BeforeEach\n    void setUp() {\n        CartItem cartItem = null;\n        for (int i = 1; i &lt;= 100; i++) {\n            if (cartItem == null) {\n                cartItem = CartItem.of(null, new HashSet&lt;&gt;());\n            }\n            if (cartItem.isTenBundles()) {\n                cartItemRepository.save(cartItem);\n                cartItem = null;\n            }\n            else {\n                cartItem.addItem(createItem(i));\n            }\n        }\n    }\n\n    @Test\n    void findByIdAfter_interface() throws Exception {\n        cartItemRepository.findByIdAfter(5L).forEach(System.out::println);\n    }\n\n    private Item createItem(int itemName) {\n        return Item.builder()\n                .name(\"item\" + itemName)\n                .description(\"item description\")\n                .createdAt(LocalDateTime.now())\n                .build();\n    }\n}\n\n\n\n\nHibernate: \n    select\n        cartitem0_.id as id1_1_ \n    from\n        cart_item cartitem0_ \n    where\n        cartitem0_.id&gt;?\n        \nCartItem(id=6, items=[Item(id=51, name=item60, description=item description, createdAt=2022-01-11T19:21:00.009321), Item(id=52, name=item65, description=item description, createdAt=2022-01-11T19:21:00.009321), Item(id=53, name=item63, description=item description, createdAt=2022-01-11T19:21:00.009321), Item(id=54, name=item56, description=item description, createdAt=2022-01-11T19:21:00.009321), Item(id=55, name=item57, description=item description, createdAt=2022-01-11T19:21:00.009321), Item(id=56, name=item58, description=item description, createdAt=2022-01-11T19:21:00.009321), Item(id=57, name=item64, description=item description, createdAt=2022-01-11T19:21:00.009321), Item(id=58, name=item59, description=item description, createdAt=2022-01-11T19:21:00.009321), Item(id=59, name=item62, description=item description, createdAt=2022-01-11T19:21:00.009321), Item(id=60, name=item61, description=item description, createdAt=2022-01-11T19:21:00.009321)])\n\nCartItem(id=7, items=[Item(id=61, name=item67, description=item description, createdAt=2022-01-11T19:21:00.016323600), Item(id=62, name=item76, description=item description, createdAt=2022-01-11T19:21:00.016323600), Item(id=63, name=item71, description=item description, createdAt=2022-01-11T19:21:00.016323600), Item(id=64, name=item74, description=item description, createdAt=2022-01-11T19:21:00.016323600), Item(id=65, name=item75, description=item description, createdAt=2022-01-11T19:21:00.016323600), Item(id=66, name=item69, description=item description, createdAt=2022-01-11T19:21:00.016323600), Item(id=67, name=item68, description=item description, createdAt=2022-01-11T19:21:00.016323600), Item(id=68, name=item73, description=item description, createdAt=2022-01-11T19:21:00.016323600), Item(id=69, name=item72, description=item description, createdAt=2022-01-11T19:21:00.016323600), Item(id=70, name=item70, description=item description, createdAt=2022-01-11T19:21:00.016323600)])\n\nCartItem(id=8, items=[Item(id=71, name=item82, description=item description, createdAt=2022-01-11T19:21:00.026320800), Item(id=72, name=item86, description=item description, createdAt=2022-01-11T19:21:00.026320800), Item(id=73, name=item83, description=item description, createdAt=2022-01-11T19:21:00.026320800), Item(id=74, name=item85, description=item description, createdAt=2022-01-11T19:21:00.026320800), Item(id=75, name=item80, description=item description, createdAt=2022-01-11T19:21:00.026320800), Item(id=76, name=item81, description=item description, createdAt=2022-01-11T19:21:00.026320800), Item(id=77, name=item87, description=item description, createdAt=2022-01-11T19:21:00.026320800), Item(id=78, name=item84, description=item description, createdAt=2022-01-11T19:21:00.026320800), Item(id=79, name=item79, description=item description, createdAt=2022-01-11T19:21:00.026320800), Item(id=80, name=item78, description=item description, createdAt=2022-01-11T19:21:00.026320800)])\n\nCartItem(id=9, items=[Item(id=81, name=item89, description=item description, createdAt=2022-01-11T19:21:00.037323800), Item(id=82, name=item91, description=item description, createdAt=2022-01-11T19:21:00.038323100), Item(id=83, name=item97, description=item description, createdAt=2022-01-11T19:21:00.038323100), Item(id=84, name=item93, description=item description, createdAt=2022-01-11T19:21:00.038323100), Item(id=85, name=item90, description=item description, createdAt=2022-01-11T19:21:00.038323100), Item(id=86, name=item95, description=item description, createdAt=2022-01-11T19:21:00.038323100), Item(id=87, name=item94, description=item description, createdAt=2022-01-11T19:21:00.038323100), Item(id=88, name=item96, description=item description, createdAt=2022-01-11T19:21:00.038323100), Item(id=89, name=item98, description=item description, createdAt=2022-01-11T19:21:00.038323100), Item(id=90, name=item92, description=item description, createdAt=2022-01-11T19:21:00.038323100)])\n\n\n\n\n큰 부담 없는 깔끔한 쿼리가 발생하였고, 프로젝션이 아주 잘 되는것을 확인할 수 있습니다.\n\n\n\n제네릭을 이용한 동적 프로젝션(Dynamic Projection)\n\n\n\n이것은 그냥 반환타입을 제네릭으로 설정해버리는 방법입니다.\n\n제네릭을 사용 해 다음과 같은 추상 메서드를 작성합니다.\n\n두번째 파라미터는 반환할 타입인데, 이것은 java.util.Collection의 하위타입이거나 알맞은 생성자가 있는 단일 클래스여야 합니다.\n\n저는 위에서 사용한 인터페이스 프로젝션의 코드를 그대로 재사용하겠습니다.\n\n\n\npublic interface CartItemRepository extends JpaRepository&lt;CartItem, Long&gt; {\n    &lt;T&gt; List&lt;T&gt; findByIdAfter(Long id, Class&lt;T&gt; classType);\n}\n\n\n\n\n\n역시 위에서 사용한 테스트코드를 재사용하였습니다.\n\n전체적인 코드는 인터페이스 프로젝션과 큰 차이가 없으나, 쿼리 메서드를 호출하는 부분에서 두번째 인수로 반환타입을 CartItemProjection.class로 넘겨 쿼리 메서드를 호출합니다.\n\n\n\n@DataJpaTest\nclass CartItemRepositoryTest {\n    @Autowired\n    ItemRepository itemRepository;\n\n    @Autowired\n    CartItemRepository cartItemRepository;\n\n    @BeforeEach\n    void setUp() {\n        CartItem cartItem = null;\n        for (int i = 1; i &lt;= 100; i++) {\n            if (cartItem == null) {\n                cartItem = CartItem.of(null, new HashSet&lt;&gt;());\n            }\n            if (cartItem.isTenBundles()) {\n                cartItemRepository.save(cartItem);\n                cartItem = null;\n            }\n            else {\n                cartItem.addItem(createItem(i));\n            }\n        }\n    }\n\n    @Test\n    void findByIdAfter_dynamic() throws Exception {\n        cartItemRepository.findByIdAfter(5L, CartItemProjection.class)\n                .forEach(System.out::println);\n    }\n\n    private Item createItem(int itemName) {\n        return Item.builder()\n                .name(\"item\" + itemName)\n                .description(\"item description\")\n                .createdAt(LocalDateTime.now())\n                .build();\n    }\n}\n\n\n\n\nHibernate: \n    select\n        cartitem0_.id as id1_1_ \n    from\n        cart_item cartitem0_ \n    where\n        cartitem0_.id&gt;?\n        \nCartItem(id=6, items=[Item(id=51, name=item60, description=item description, createdAt=2022-01-11T19:27:54.715796700), Item(id=52, name=item65, description=item description, createdAt=2022-01-11T19:27:54.715796700), Item(id=53, name=item56, description=item description, createdAt=2022-01-11T19:27:54.715796700), Item(id=54, name=item63, description=item description, createdAt=2022-01-11T19:27:54.715796700), Item(id=55, name=item57, description=item description, createdAt=2022-01-11T19:27:54.715796700), Item(id=56, name=item59, description=item description, createdAt=2022-01-11T19:27:54.715796700), Item(id=57, name=item61, description=item description, createdAt=2022-01-11T19:27:54.715796700), Item(id=58, name=item62, description=item description, createdAt=2022-01-11T19:27:54.715796700), Item(id=59, name=item64, description=item description, createdAt=2022-01-11T19:27:54.715796700), Item(id=60, name=item58, description=item description, createdAt=2022-01-11T19:27:54.715796700)])\n\nCartItem(id=7, items=[Item(id=61, name=item67, description=item description, createdAt=2022-01-11T19:27:54.722796), Item(id=62, name=item72, description=item description, createdAt=2022-01-11T19:27:54.722796), Item(id=63, name=item73, description=item description, createdAt=2022-01-11T19:27:54.722796), Item(id=64, name=item68, description=item description, createdAt=2022-01-11T19:27:54.722796), Item(id=65, name=item71, description=item description, createdAt=2022-01-11T19:27:54.722796), Item(id=66, name=item70, description=item description, createdAt=2022-01-11T19:27:54.722796), Item(id=67, name=item76, description=item description, createdAt=2022-01-11T19:27:54.722796), Item(id=68, name=item74, description=item description, createdAt=2022-01-11T19:27:54.722796), Item(id=69, name=item69, description=item description, createdAt=2022-01-11T19:27:54.722796), Item(id=70, name=item75, description=item description, createdAt=2022-01-11T19:27:54.722796)])\n\nCartItem(id=8, items=[Item(id=71, name=item79, description=item description, createdAt=2022-01-11T19:27:54.729795600), Item(id=72, name=item82, description=item description, createdAt=2022-01-11T19:27:54.729795600), Item(id=73, name=item80, description=item description, createdAt=2022-01-11T19:27:54.729795600), Item(id=74, name=item81, description=item description, createdAt=2022-01-11T19:27:54.729795600), Item(id=75, name=item83, description=item description, createdAt=2022-01-11T19:27:54.729795600), Item(id=76, name=item78, description=item description, createdAt=2022-01-11T19:27:54.729795600), Item(id=77, name=item84, description=item description, createdAt=2022-01-11T19:27:54.729795600), Item(id=78, name=item86, description=item description, createdAt=2022-01-11T19:27:54.729795600), Item(id=79, name=item85, description=item description, createdAt=2022-01-11T19:27:54.729795600), Item(id=80, name=item87, description=item description, createdAt=2022-01-11T19:27:54.729795600)])\n\nCartItem(id=9, items=[Item(id=81, name=item93, description=item description, createdAt=2022-01-11T19:27:54.736794200), Item(id=82, name=item97, description=item description, createdAt=2022-01-11T19:27:54.736794200), Item(id=83, name=item98, description=item description, createdAt=2022-01-11T19:27:54.736794200), Item(id=84, name=item89, description=item description, createdAt=2022-01-11T19:27:54.736794200), Item(id=85, name=item90, description=item description, createdAt=2022-01-11T19:27:54.736794200), Item(id=86, name=item96, description=item description, createdAt=2022-01-11T19:27:54.736794200), Item(id=87, name=item91, description=item description, createdAt=2022-01-11T19:27:54.736794200), Item(id=88, name=item94, description=item description, createdAt=2022-01-11T19:27:54.736794200), Item(id=89, name=item92, description=item description, createdAt=2022-01-11T19:27:54.736794200), Item(id=90, name=item95, description=item description, createdAt=2022-01-11T19:27:54.736794200)])\n\n\n\n\n역시 아주 깔끔하게 잘 되는 모습을 보실 수 있습니다.\n\n\n\n💡 Query By Example API\n\n\n\n쿼리 메서드는 매우 강력하지만 치명적인 단점이 하나 있습니다.\n\n바로 조건이 조금만 복잡해지면 메서드이름의 길이가 사용할수 없을정도로 길어진다는 것입니다.\n\nid가 일치하면서, name을 포함하고(like 검색), description도 포함하는(like 검색) 조건을 쿼리 메서드로 작성하면 하기와 같습니다.\n\n너무 길죠?\n\n\n\npublic interface ItemRepository extends JpaRepository&lt;Item, Long&gt; {\n    List&lt;Item&gt; findByIdAndNameContainingAndDescriptionContaining(Long id, String name, String description);\n}\n\n@DataJpaTest\nclass ItemRepositoryTest {\n  @Test\n  void queryMethodLimit() throws Exception {\n    itemRepository.findByIdAndNameContainingAndDescriptionContaining(1L, \"item\", \"desc\") // 너무 장황하다... 🤔\n            .forEach(System.out::println);\n  }\n}\n\n\n\n\nHibernate: \n    select\n        item0_.id as id1_4_,\n        item0_.created_at as created_2_4_,\n        item0_.description as descript3_4_,\n        item0_.name as name4_4_ \n    from\n        item item0_ \n    where\n        item0_.id=? \n        and (\n            item0_.name like ? escape ?\n        ) \n        and (\n            item0_.description like ? escape ?\n        )\n\n\n\n\n이러한 문제를 보완하는게 Example API입니다.\n\n\n\nExample API는 크게 세 부분으로 구성됩니다.\n\n\n\n\n  Probe: 검색을 수행하기 위한 조건을 담은 실제 엔티티 개체\n  ExampleMatcher: 세부적인 검색을 설정하는 개체\n  Example: Probe와 ExampleMatcher로 이루어진 최종 개체\n\n\n\n\n말로만 떠들면 이해하기 힘들 수 있으니 장황한 findByIdAndNameContainingAndDescriptionContaining를 Example API를 사용해 리팩토링 해보겠습니다.\n\n\n\n우선 QueryByExampleExecutor&lt;T&gt; 인터페이스를 추가로 상속해야 합니다.\n\n여기서 T는 검색을 실행할 주체가되는 엔티티입니다.\n\n\n\npublic interface ItemRepository extends JpaRepository&lt;Item, Long&gt;, QueryByExampleExecutor&lt;Item&gt; {\n}\n\n\n\n\n@DataJpaTest\nclass ItemRepositoryTest {\n    @Autowired\n    ItemRepository itemRepository;\n\n    @Test\n    void queryMethodRefactor() throws Exception {\n        Item probe = Item.of(1L, \"item\", \"desc\", null);\n        \n        ExampleMatcher matcher = ExampleMatcher.matching()\n                .withIgnorePaths(\"createdAt\")\n                .withStringMatcher(ExampleMatcher.StringMatcher.CONTAINING);\n\n        Example&lt;Item&gt; example = Example.of(probe, matcher);\n        \n        itemRepository.findAll(example).forEach(System.out::println);\n    }\n}\n\n\n\n\nHibernate: \n    select\n        item0_.id as id1_4_,\n        item0_.created_at as created_2_4_,\n        item0_.description as descript3_4_,\n        item0_.name as name4_4_ \n    from\n        item item0_ \n    where\n        item0_.id=? \n        and (\n            item0_.name like ? escape ?\n        ) \n        and (\n            item0_.description like ? escape ?\n        )\n\n\n\n\n정확히 동일한 쿼리가 발생합니다.\n\n이게 가능한 이유는 QueryByExampleExecutor&lt;T&gt; 인터페이스의 추상 메서드 시그니처를 확인해보면 쉽게 알 수 있습니다.\n\n\n\npublic interface QueryByExampleExecutor&lt;T&gt; {\n\n\t&lt;S extends T&gt; Optional&lt;S&gt; findOne(Example&lt;S&gt; example);\n\n\t&lt;S extends T&gt; Iterable&lt;S&gt; findAll(Example&lt;S&gt; example);\n\n\t&lt;S extends T&gt; Iterable&lt;S&gt; findAll(Example&lt;S&gt; example, Sort sort);\n\n\t&lt;S extends T&gt; Page&lt;S&gt; findAll(Example&lt;S&gt; example, Pageable pageable);\n\n\t&lt;S extends T&gt; long count(Example&lt;S&gt; example);\n\n\t&lt;S extends T&gt; boolean exists(Example&lt;S&gt; example);\n}\n\n\n\n\nExample 타입을 인자로 받아 검색을 수행하고 이에 대한 결과를 반환하고 있음을 확인할 수 있죠.\n\n\n\n어떻게 보면 쿼리 메서드를 사용하는것 이상으로 코드를 많이 작성하긴 합니다만, 검색 조건이 복잡하고 유동적으로 변경되어야 하는 상황이라면 분명히 사용해볼 가치가 있습니다.\n\n우선, 검색 조건을 매우 디테일하게 설정할 수 있으며, 메서드명이 아닌 메서드 자체로 작성되기 때문에 별도의 리파지토리에 캡슐화하여 관리하기도 용이합니다.\n\n검색조건이 변경된다면 ExampleMatcher만 손봐주면 되기 때문입니다.\n\n\n\n아래는 공식 문서에서 소개하는 Example API의 장단점입니다.\n\n\n\n\n  Query by Example은 다음 사례에 적합합니다.\n    \n      일련의 정적 또는 동적 제약 조건을 사용하여 데이터 저장소를 쿼리합니다.\n      기존 쿼리 중단에 대한 걱정 없이 도메인 객체를 자주 리팩토링합니다.\n      기본 데이터 저장소 API와 독립적으로 작업합니다.\n    \n  \n  Query by Example에도 몇 가지 제약 사항이 있습니다.\n    \n      다음과 같이 중첩되거나 그룹화된 속성 제약 조건을 지원하지 않습니다. firstname = ?0 or (firstname = ?1 and lastname = ?2).\n      문자열에 대한 starts(시작부 일치)/contains(문자열 포함)/ends(끝부분만 일치)/regex(정규식) 일치 및 기타 속성 유형에 대한 정확한 일치만 지원합니다.\n    \n  \n\n\n\n\n더 상세한 사용법에 대한 내용은 📜 Spring Data JPA Docs - Query by Example 에 기술되어 있으니 관심이 있으시다면 한번 살펴보시는것도 좋겠습니다.\n\n또한, 쿼리 메서드와 Example API로도 해결이 안된다면 진지하게 Querydsl 사용을 고려해봐야 할 것 같습니다.\n\n\n",
      "categories": ["spring","spring-data-jpa"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-data-jpa/2022-01-11-jpa-11/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "double-quote to start field name",
      "date": "2022-01-19 00:00:00 +0000",
      "description": "Unexpected character … was expecting double-quote to start field name\n",
      "content": "\n  🚨 문제\n  🚧 원인\n  ✅ 해결\n\n\n\n\n🚨 문제\n\n\n\n회사 결제 서비스에서 파트너사의 API를 연동하는 업무를 진행하던 중 발생했다.\n\n대략 아래와 같은 예외 메시지였다.\n\n\n\norg.codehaus.jackson.JsonParseException: \n   Unexpected character ('n' (code 110)): was expecting double-quote to start field name\n   at [Source: java.io.StringReader@7c87c24a; line: 1, column: 3]\n\n\n\n\n🚧 원인\n\n\n\nJSON 필드 네임에 쌍따옴표를 예상했다는 예외 메시지를 보고 파트너사 API의 응답 페이로드를 확인해봤다.\n\nJSON 응답 필드에 홀따옴표가 사용되고 있었다.\n\n근데, 나는 JSON 필드를 쌍따옴표로 쓰긴 하지만 홀따옴표로 사용되는것도 몇 번 봤던 기억이 있어서 당연히 되는건줄 알고 있었기 때문에 이 상황이 잘 이해가 안됐었다.\n\n그래서 처음으로 JSON 공식 홈페이지 에 들어가서 스펙을 확인해봤다.\n\n\n  A value can be a string in double quotes, or a number, or true or false or null, or an object or an array. These structures can be nested.\n\n\nJSON 스펙상으로 홀따옴표가 아닌 쌍따옴표롤 써야 한다고 나와있었다.\n\n즉, 홀따옴표는 비표준이다.\n\n\n\n하지만, 다른 프로젝트에서는 JSON 파서가 홀따옴표로 문제없이 처리해내던 기억이 나서 호기심에 이 부분도 한번 찾아보았다. (굳이 찾아보지 않아도 대략 짐작은 갔지만…)\n\n내가 사용하는 라이브러리는 Jackson이며, ObjectMapper를 주로 사용한다.\n\n📜 jackson.core.JsonParser.Feature.ALLOW_SINGLE_QUOTES\n\n\n\n\n  Feature that determines whether parser will allow use of single quotes (apostrophe, character ‘'’) for quoting Strings (names and String values). If so, this is in addition to other acceptable markers. but not by JSON specification).\n\n  Since JSON specification requires use of double quotes for field names, this is a non-standard feature, and as such disabled by default.\n\n\n\n\n역시나 관련 내용이 있었다.\n\n해당 사항은 표준이 아니기 때문에 때문에 기본적으로 비활성화 해두었다고 명시돼있었다.\n\n아마 JSON 으로 데이터를 주고받을 때 홀따옴표를 사용하면 이를 모두 쌍따옴표로 변환하는 작업이 수반될텐데, 이를 모두 정규식으로 처리하기 때문으로 의심이 갔다.\n\n주고 받는 데이터의 규모가 크다면 이는 불필요한 작업이면서도(애초에 표준을 지켰다면 필요하지 않은 비용이기 때문이다), 무시하기 힘든 비용이 발생할것이기 때문이다.\n\n즉, 표준을 지켜 개발하라는 의미이며 이는 두말할나위 없는 정론이다.\n\n\n\n종국엔 혹시나 표준을 지키지 않는 상황마저 가정해 이러한 옵션을 넣어놓은 개발자들에게 감탄마저 나왔다.\n\n\n\n✅ 해결\n\n\n\n우선 파트너사에 연락하여 위 내용들을 설명함과 동시에 표준을 지켜 개발해달라 요청하였고, 이 요청은 받아들여졌다.\n\n하지만 다른 API도 홀따옴표를 사용하고 있을 수 있고, 파트너사측 개발자분이 수정하실 때 누락될수도 있는 여지가 있기 때문에 ObjectMapper 설정에 홀따옴표를 허용하는 기능을 활성화해주었다.\n\n\n\n@Configuration\npublic class ObjectMapperConfig implements Jackson2ObjectMapperBuilderCustomizer {\n    @Override\n    public void customize(Jackson2ObjectMapperBuilder jacksonObjectMapperBuilder) {\n        jacksonObjectMapperBuilder\n                .modules(new JavaTimeModule())\n                .visibility(PropertyAccessor.FIELD, Visibility.ANY)\n                .featuresToEnable(JsonParser.Feature.ALLOW_SINGLE_QUOTES) // 추가 !\n                .featuresToDisable(DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL)\n                .featuresToDisable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n                .build();\n    }\n}\n\n\n\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2022-01-19-debugging-16/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "소프트웨어 장인",
      "date": "2022-01-19 00:00:00 +0000",
      "description": "The Software Craftsman - Professionalism, Pragmatism, Pride\n",
      "content": "\n  자율성, 통달, 목적의식\n\n\n\n\n\n  산드로 만쿠소 지음, 권오민 옮김, 길벗 출판사\n\n  어떻게 하면 더 나은 프로그래머가 될 수 있을까?\n\n\n\n\n소프트웨어 장인\n\n\n\n결론부터 말하자면, 나에게는 아주 훌륭한 책이었다.\n\n나는 평소 개발자를 장인 혹은 기능공 같은 직업이라고 여기고 있었다. 러프하게 상상해보자면 대장장이나 목공같은?\n\n\n\n\n\n\n\n예를 들어 내가 좋은 의자가 필요해져 어떤 의자 장인에게 좋은 의자를 만들어달라는 의뢰를 맡긴다고 가정하자.\n\n이때 나는 의자에 대해 아무것도 알지 못하기 때문에 그냥 별 생각없이 등받이를 최대한 길고 넓적하고 푹신하게 해달라 요구할 수도 있다. 실제로는 이 요구사항이 내 신체에 좋지 않은 영향을 끼칠수도 있지만 나는 의자에 대한 지식이 전무하기 때문에 이를 알지 못할수도 있다.\n\n훌륭한 장인이라면 이러한 나의 요구사항을 듣자마자 내 신체조건과 의자가 놓일 환경 등을 모두 고려한 다음 그에 대한 전문가로서의 의견을 고객인 나에게 알려줄 것이다.\n\n\n\n나는 개발도 이와 비슷하다고 생각한다.\n\n나에게는 항상 불특정한 누군가가 요구사항들을 전달해온다.\n\n나는 이러한 요구사항들을 받으면 그 요구사항이 정말 우리의 상황에 합당한것인지를 먼저 파악하는데 모든 노력을 기울인다.\n\n우리 일상생활에서 발생하는 문제들을 해결하는 방법은 정말 많다.\n\n애초에 해결할 필요가 없는 문제이지만 문제로 인식하는 경우도 있을 수 있다.\n\n또한 대부분의 문제는 생각보다 쉽게 해결되는 경우도 많다. Simple is best라는 말도 있지 않나?\n\n즉, 요구사항을 무조건 수용하는 것이 아닌, 이러한 사고를 먼저 거친 후 요구사항과 달리 더 좋다고 생각되는 해결방안이 떠오른다면 나의 고객, 나의 상사, 나의 동료들에게 이러한 방안을 역제안 해보는 절차가 반드시 필요하다고 생각하고 있었다.\n\n\n\n나는 왜 이런 가치관을 갖게 됐을까?\n\n\n\n위 질문에 대답하려면 내 인생사를 가볍게 되돌아봐야 한다.\n\n흙수저였던 나는 16살에 군대를 가지 않고 그 시간에 돈을 벌어야겠다는 마음을 먹었었으며, 19살의 어린 나이부터 30살까지 무려 11년동안 쉬지않고 사회생활을 해오고 있다.\n\n그리고 이렇게 열심히 일해 모은 돈으로 최근에는 내 명의의 집도 하나 가질 수 있었다.\n\n이 사건은 장담컨데 내 불우한 인생에서 최고의 업적이다.\n\n나는 평생동안 약 20번에 가까운 이사를 해왔는데, 이러한 경험으로 인해 나만의 집을 가져보는게 너무 절실했었기 때문이다.\n\n어린 나이부터 이렇게 긴 기간동안 일해온 당위성에 대해 설명하기 위해 약간 쓸데없는 말을 좀 했는데, 이러한 삶을 살아온 나는 어느 순간부터 기본적으로 돈을 받고 일을하는 순간부터 프로라는 생각을 가지게 됐다.\n\n아니, 정확히는 이런 마인드가 자연스럽게 생길수밖에 없었다. 내가 겪어온 사회는 가혹했기 때문이다.\n\n세상 물정을 모르는 어린 나이에 악덕 사장에게 임금체불도 당해봤고, 악덕 상사에게 폭언 폭행도 당해봤다. 나는 온실속의 화초가 아닌 온실밖의 잡초였다.\n\n이 가혹한 사회에서 살아남으려면 강한 멘탈, 좋은 마인드, 그리고 무엇보다 누구도 나를 무시할 수 없는, 나를 존중해줄 수 밖에 없는 실력을 키워야 한다는 생각이 나를 점점 지배했다.\n\n\n\n내가 가장 좋아하는 인용구가 있다.\n\n\n\n\n  나무에 앉은 새는 가지가 부러질까 두려워하지 않는다.\n\n\n\n\n새에게는 날개가 있기 때문에 나뭇가지가 부러지면 날아가면 그만이다.\n\n따라서 나뭇가지가 부러지는걸 두려워하지 않는다.\n\n\n\n내가 훌륭한 실력을 갖는다는 것은 사회, 시장에서 나만의 유의미한 경쟁력을 갖는다는 말과 일맥상통한다.\n\n나의 가치가 유의미해진다면 나는 타인의 부당한 압력에 굴할 필요가 없다.\n\n당당해질 수 있다. 왜냐하면 언제든지 다른 선택지를 고를 수 있기 때문이다.\n\n이러한 자신감 넘치는 태도는 내 고객에게 신뢰를 줄 것이고, 고객이 나를 믿는다면 나는 내 일에 더욱 더 집중할 수 있게 된다.\n\n\n\n개발자로서의 커리어는 아직 채 일년이 되지 않았지만, 돌이켜보면 현재 내가 개발하는 모든 것은 우리 사회의 어떤 문제를 해결하고 이를 통해 돈을 벌기위한 일련의 행위들이며, 결과적으로 나는 개발을 해서 돈을 벌기 때문에 개발자로서의 나는 프로다.\n\n이 책은 개발자를 장인 혹은 지식노동자로 표현하고 있으며(즉, 전문가다) 온통 개발자로서의 프로페셔널리즘에 대한 이야기로 가득하다.\n\n그리고 이는 평소 내가 갖고 있던 가치관에 한점의 모호함도 없이 자연스럽게 어울리고 있었다.\n\n그래서 정신없이 몰입하며 읽을 수 있었던 것 같다.\n\n사람마다 좋은 개발자에 대한 정의가 모두 다르겠지만, 이 책이 전달하고자 하는 의미중 대부분은 내가 생각하는 좋은 개발자에 부합했으며, 내가 앞으로 가져야 할 프로로서의 마음가짐과 삶의 태도에 대해 확실히 가이드해주었다.\n\n\n\n자율성, 통달, 목적의식\n\n\n  다니엘 핑크의 저서 원동력: 동기부여에 대한 놀라운 진실에서 돈은 충족되어야 할 기본 조건이고, 지식 노동자를 움직이는 것은 자율성, 통달, 목적의식 이렇게 세 가지라고 이야기하고 있다.\n\n  \n    자율성: 우리가 무엇을, 어떻게, 언제할지 통제할 수 있는 상태를 뜻한다.\n    통달: 더 나은 프로페셔널, 더 나은 인간이 되기 위해 계속 배우고 진화하는 것을 뜻한다.\n    목적의식: 지금 하고 있는 일이 중요하고 무언가를 더 나아지게 하고 있다고 느끼는 것을 뜻한다. 아무런 이해없이 시키는 대로만 일하는 것의 반대 개념이다.\n  \n\n  …\n\n  일에 대한 보상을 받는 프로페셔널이라면 고객에게 가치를 제공할 의무가 있다. 그런데 일에는 금전적 보상보다 더 큰 의미가 있다. 일은 단지 돈을 벌기 위해 참아야 할 고통이 아니다. 일을 선택할 때는 자율성, 통달, 목적의식을 쫓아야 한다. 장인이라면 일을 선택할 때 이 세가지를 반드시 고려해야 한다. 그러한 조건을 만족시켜줄 일 또는 직장을 찾는 것이 쉽지는 않지만 분명히 존재한다. 우리가 그러한 일을 맡을 준비가 덜 된 것일 수도 있다.\n\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-01-19-diary-31/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "JAVA - 프로그래머스 2레벨 - 위장",
      "date": "2022-01-20 00:00:00 +0000",
      "description": "프로그래머스 42578번 문제\n",
      "content": "\n\n\n\n\n\n\n@DisplayName(\"프로그래머스 42578 - 위장\")\nclass Programmers42578Test {\n    Programmers42578 solve = new Programmers42578();\n\n    static Stream&lt;Arguments&gt; solution() {\n        return Stream.of(\n            Arguments.of(new String[][]{\n                {\"yellowhat\", \"headgear\"}, {\"bluesunglasses\", \"eyewear\"}, {\"green_turban\", \"headgear\"}\n            }, 5),\n            Arguments.of(new String[][]{\n                {\"crowmask\", \"face\"}, {\"bluesunglasses\", \"face\"}, {\"smoky_makeup\", \"face\"}\n            }, 3)\n        );\n    }\n\n    @MethodSource\n    @ParameterizedTest\n    void solution(String[][] clothes, int expected) throws Exception {\n        int actual = solve.solution(clothes);\n        assertThat(actual).isEqualTo(expected);\n    }\n}\n\n\n\n\n해쉬맵과 경우의 수를 사용해서 풀 수 있다.\n\n\n\n첫번째 케이스를 보자.\n\n\n  headgear: yellowhat, green_turban\n  eyewear: bluesunglasses\n\n\n\n\n\n  스파이는 하루에 최소 한 개의 의상을 입습니다.\n\n\n\n\n즉, eyewear인 bluesunglasses를 착용했다면, headgear는 아예 착용하지 않을수도 있다.\n\n하지만, 반드시 한개는 착용해야 하므로 headgear와 eyewear 모두를 착용하지 않을수는 없다.\n\n한마디로 의상을 착용하지 않는 경우를 고려해 전체 경우의 수를 구한 후, 모든 의상을 착용하지 않는(맨몸) 경우 단 한가지만 제외해주면 답이 나온다.\n\n위 케이스에서 식은 다음과 같다.\n\n\n  (headgear의 갯수 + 1(=headgear를 아예 착용하지 않는 경우)) * (eyewear의 갯수 + 1(=eyewear를 아예 착용하지 않는 경우)) - 1(맨몸인 경우)\n\n\n\n  (2 + 1) * (1 + 1) - 1 = 5\n\n\n두번째 케이스도 같은 답이 도출된다.\n\n\n  face: crowmask, bluesunglasses, smoky_makeup\n\n\n\n  (3 + 1) - 1 = 3\n\n\n\n\n대체로 PS가 대체로 실무에서 푸는 현실세계의 문제와 무관하면서도 막상 명령형으로 풀고보면 코드도 마음에 안드는게 불편했었다.\n\n왜냐하면 PS에서 제출하는 답안은 패키지 개념이 없어 하나의 파일에 여러개의 TOP 클래스를 작성해야하기 때문이다.\n\n이는 유지보수 관점에서도 좋지 않고, 자바 관례에도 어긋나며, 접근제한자 사용에도 제약이 따른다.\n\n\n\n요즘 실무에 비동기를 적용해보고 모르는걸 공부하면서 자연스레 FP에 대해 관심이 높아졌는데 이 FP를 연습하는데 PS가 생각보다 도움이 꽤 되는 것 같다.\n\n애초에 FP자체가 수학에서 출발해서 그런지, 수학익힘책 느낌이 나는 PS에 적용하기가 아주 적절하다.\n\n\n\n잡설이 좀 있었는데, 구현은 다음과 같다.\n\n인자로 넘어오는 2차원 배열 clothes를 1차원 배열로 풀어헤쳐놓고 보면 0번 인덱스는 의상이고 1번 인덱스는 옷의 카테고리다.\n\n즉, 자바의 스트림을 이용해 1번 인덱스를 키로 그루핑하고 0번 인덱스의 합계를 값으로 매핑하면 적절한 해쉬맵이 만들어진다.\n\n이후 reduce 함수를 사용해 모든 값(옷 카테고리의 갯수)을 위의 식대로 누산해준다.\n\n마지막으로 옷을 아예 입지 않는 맨몸인 경우의 수 1개를 빼주면 답이 나온다.\n\n\n\npublic class Programmers42578 {\n    public int solution(String[][] clothes) {\n        return stream(clothes)\n            .collect(groupingBy(clothe -&gt; clothe[1], mapping(clothe -&gt; clothe[0], counting())))\n            .values()\n            .stream()\n            .reduce(1L, (answer, numberOfClothes) -&gt; answer * (numberOfClothes + 1))\n            .intValue() - 1;\n    }\n}\n\n\n\n\nFP를 잘 익혀두면 우선 비동기, 멀티스레딩이나 근 미래에 사용하게 될 웹플럭스에 도움이 될 것 같다고 생각한다.\n\n그러면서도 이 미래 먹거리를 아무런 리스크 없이, 따분함도 풀어가면서 익히기에 PS만한게 사실 없는 것 같다.\n\n애초에 PS자체가 실무에 아무런 도움이 안된다는 주의였는데, FP를 이렇게 편하게 연습할 수 있다는건 좋은 것 같다.\n\n\n",
      "categories": ["cs","data-structure-algorithm"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/data-structure-algorithm/2022-01-20-programmers-42578/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "JAVA - 프로그래머스 3레벨 - 베스트 앨범",
      "date": "2022-01-23 00:00:00 +0000",
      "description": "프로그래머스 42579번 문제\n",
      "content": "\n\n\n\n\n\n\n@DisplayName(\"프로그래머스 42579 - 베스트앨범\")\nclass Programmers42579Test {\n    Programmers42579 solve = new Programmers42579();\n\n    static Stream&lt;Arguments&gt; solution() {\n        return Stream.of(\n            Arguments.of(\n                new String[]{\"classic\", \"pop\", \"classic\", \"classic\", \"pop\"},\n                new int[]{500, 600, 150, 800, 2500},\n                new int[]{4, 1, 3, 0}\n            )\n        );\n    }\n\n    @MethodSource\n    @ParameterizedTest\n    void solution(String[] genres, int[] plays, int[] expected) throws Exception {\n        int[] actual = solve.solution(genres, plays);\n        assertThat(actual).isEqualTo(expected);\n    }\n}\n\n\n\n\n문제 분류는 해쉬로 돼있는데, 사실상 구현문제에 더 가까운 것 같다.\n\n문제의 요구사항을 모두 구현하되, 해쉬맵을 사용하면 쉽게 풀린다.\n\n코드 자체가 딱히 효율적이진 않지만, 애초에 문제에 효율성 테스트가 없기 때문에 별 문제가 되지 않는 것 같다.\n\n\n\n\n  genres[i]는 고유번호가 i인 노래의 장르입니다.\n  plays[i]는 고유번호가 i인 노래가 재생된 횟수입니다.\n  genres와 plays의 길이는 같으며, 이는 1 이상 10,000 이하입니다.\n  장르 종류는 100개 미만입니다.\n  장르에 속한 곡이 하나라면, 하나의 곡만 선택합니다.\n  모든 장르는 재생된 횟수가 다릅니다.\n\n\n\n\npublic class Programmers42579 {\n    public int[] solution(String[] genres, int[] plays) {\n        return IntStream.rangeClosed(0, genres.length - 1)\n                .mapToObj(toMusic(genres, plays))\n                .collect(groupingBy(Music::getGenre))\n                .entrySet().stream()\n                .sorted(inOrderOfMostPlayedGenre())\n                .flatMap(twoInOrderOfMostPlayed())\n                .mapToInt(Music::getId)\n                .toArray();\n    }\n\n    private IntFunction&lt;Music&gt; toMusic(String[] genres, int[] plays) {\n        return i -&gt; Music.of(i, genres[i], plays[i]);\n    }\n\n    private Comparator&lt;Entry&lt;String, List&lt;Music&gt;&gt;&gt; inOrderOfMostPlayedGenre() {\n        return (entry1, entry2) -&gt; sum(entry2.getValue()) - sum(entry1.getValue());\n    }\n\n    private int sum(List&lt;Music&gt; value) {\n        return value.stream()\n                .mapToInt(Music::getPlayed)\n                .sum();\n    }\n\n    private Function&lt;Entry&lt;String, List&lt;Music&gt;&gt;, Stream&lt;? extends Music&gt;&gt; twoInOrderOfMostPlayed() {\n        return entry -&gt; entry.getValue()\n                .stream()\n                .sorted()\n                .limit(2);\n    }\n\n    private static class Music implements Comparable&lt;Music&gt; {\n        private final int id;\n        private final String genre;\n        private final int played;\n\n        private Music(int id, String genre, int played) {\n            this.id = id;\n            this.genre = genre;\n            this.played = played;\n        }\n\n        private static Music of(int id, String genre, int played) {\n            return new Music(id, genre, played);\n        }\n\n        private int getId() {\n            return id;\n        }\n\n        private String getGenre() {\n            return genre;\n        }\n\n        private int getPlayed() {\n            return played;\n        }\n\n        @Override\n        public int compareTo(Music music) {\n            if (this.played == music.played) {\n                return this.id - music.id;\n            }\n            return music.played - this.played;\n        }\n    }\n}\n\n\n\n",
      "categories": ["cs","data-structure-algorithm"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/data-structure-algorithm/2022-01-23-programmers-42579/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "JDK 17 LTS 정리",
      "date": "2022-01-27 00:00:00 +0000",
      "description": "자바 12 ~ 17사이의 주요 변경사항\n",
      "content": "\n  JDK 17 LTS 정리    \n      주요 변경점        \n          NullPointerExceptions\n          Switch Expression\n          Text Block\n          Record Class\n          Pattern matching for instanceof\n          Number Formatting Support\n          Stream.toList()\n          ZGC\n          Sealed Class\n        \n      \n      12 ~ 17 Features        \n          JDK 12\n          JDK 13\n          JDK 14\n          JDK 15\n          JDK 16\n          JDK 17\n        \n      \n    \n  \n\n\n\n\nJDK 17 LTS 정리\n\n\n\n올해 4분기에 Spring Framework 6, Spring Boot 3이 릴리즈될 예정이며, 현 시점 두 버전 모두 milestone 버전이 이미 출시돼있는 상태이다.\n\n명심해야 할 것은 두 버전 모두 최소 JDK 17을 사용하는것이 필수 조건이라는 것이다.\n\n이번에 Spring Framework 프로젝트에 기여하기 위해 프로젝트 환경설정을 진행했는데, 위 사실에 근거해 JDK 17도 함께 설치해야 했었다.\n\n이러한 상황에 JDK 17을 슬슬 공부해야 할 시기가 다가옴을 직접적으로 체감하였고, JDK 17을 설치하고 2일간 사용해보며 12 ~ 17 까지의 변경사항중 눈에 띄는 부분들을 정리해보았다.\n\n특이사항으로는 JDK 11 + Spring Boot 2 조합에서 JDK 17로 업그레이드하면 하위호환성으로 인한 에러가 많이 발생할 줄 알았는데, 의외로 하위호환성이 매우 훌륭하다고 느꼈다.\n\n필자는 Spring Boot 2.6.3에 JDK 17을 사용했을 경우 별다른 문제없이 잘 돌아가는 것을 확인했는데, 조금 더 크고 복잡한 시스템이라면 어땠을지 또 모르겠다.\n\n\n\n주요 변경점\n\nNullPointerExceptions\n\n\n\n가히 혁명적인 피처가 아닐까 싶다.\n\n기존 자바에서 NullPointerException이 발생하면 대략 다음과 같은 메시지가 출력됐었다.\n\n\n\nException in thread \"main\" java.lang.NullPointerException\n\n\n\n\n그래서 어디서 NullPointerException이 발생했는지 직접 추적해야 했으며, 이 작업이 매우 고통스럽기 때문에 이를 빨리 알아차리기 위해 Objects.requireNonNull()과 같은 메서드가 사용되곤 했다. (fast-fail)\n\n모던자바에서는 어디서 NullPointerException이 발생했는지 직접 알려준다.\n\nNullPointerException이 발생하도록 작성한 다음과 같은 코드가 있다.\n\n\n\n@Test\nvoid nullPointerException() throws Exception {\n    String message = null;\n    printToUpperCase(message);\n}\n\nprivate void printToUpperCase(String message) {\n    System.out.println(\"message = \" + message.toUpperCase());\n}\n\n\n\n\n이를 실행하면 모던자바에서는 이제 다음과 같은 메시지가 출력된다.\n\n\n\nCannot invoke \"String.toUpperCase()\" because \"message\" is null\njava.lang.NullPointerException: Cannot invoke \"String.toUpperCase()\" because \"message\" is null\n\tat io.github.shirohoo.JDK17Tests.nullPointerException(JDK17Tests.java:52)\n\n\n\n\nSwitch Expression\n\n\n\n📜 스위치 JEP 명세\n\n\n\n문(Statement)과 식(Expression)의 차이는 반환값이 있느냐 없느냐인데, JDK 11 LTS까지의 스위치는 문이었다. (스위치문 !)\n\n기존 자바의 스위치문은 다음과 같다.\n\n\n\nswitch (caseType) {\ncase 1:\n\tbreak;\ncase 2:\n\tbreak;\ncase 3:\n\tbreak;\ndefault:\n\tbreak;\n}\n\n\n\n\n마틴 파울러의 Refactoring 책에서는 소프트웨어 설계적인 관점에서 볼 때 이러한 코드를 나쁜냄새가 풍긴다고 표현하였고, 상속구조를 통한 리팩토링을 권장하였다.\n\n하지만 모던자바에서 변경된 스위치식은 좀 다르다.\n\n우선 스위치식 자체가 반환값을 가질 수 있는게 가장 큰 특징이며, 코드의 가독성도 좋아졌다.\n\n스위치가 반환값을 갖지 않을 경우의 코드는 다음과 같다.\n\n-&gt;를 통해 람다식처럼 표현이 가능해졌다.\n\n\n\nprivate void switchEnum(DayOfWeek day) {\n        switch (day) {\n            case MONDAY, FRIDAY, SUNDAY -&gt; System.out.println(6);\n            case TUESDAY -&gt; System.out.println(7);\n            case THURSDAY, SATURDAY -&gt; System.out.println(8);\n            case WEDNESDAY -&gt; System.out.println(9);\n        }\n    }\n\n\n\n\n스위치가 반환값을 갖기 위해서는 default 구문이 반드시 추가되어야만 한다.\n\n아무런 케이스에도 해당하지 않을 경우 반환되어야 할 값이 정의돼야하기 때문이다.\n\n\n\nprivate String switchExpression(int number) {\n        return switch (number) {\n            case 1, 2 -&gt; \"one or two\";\n            case 3, 4 -&gt; \"three or four\";\n            case 5, 6 -&gt; \"five or six\";\n            default -&gt; \"unknown value\";\n        };\n    }\n\n\n\n\n만약 스위치식에서 한줄의 코드가 아닌 여러줄의 코드를 작성해야 한다면 yield 예약어를 사용할 수 있다. (return과 같은역할을 한다)\n\n단 yield는 반드시 블록({}, 중괄호)안에서 사용되어야 하므로, 스위치 케이스가 한줄로 정의될 경우에는 사용할 수 없으며, 사용하면 컴파일 에러가 발생한다.\n\n기존의 콜론(:)을 사용하던 스위치문은 그 자체로 컴파일러에서 블록으로 인식하기 때문에 yield를 사용할 수 있다.\n\n\n\nprivate String switchExpression(int number) {\n        return switch (number) {\n            case 1, 2 -&gt; \"one or two\";\n            case 3, 4 -&gt; \"three or four\";\n            case 5, 6 -&gt; \"five or six\";\n            default -&gt; {\n                System.out.println(\"No matching cases\");\n                yield \"unknown value\";\n            }\n        };\n    }\n\n\n\n\nText Block\n\n\n\n매우 간단하다. 여타 모던 언어에서 지원하는 텍스트 블록과 같다.\n\n가장 마음에 드는 기능중 하나였다.\n\n주의할 점은 텍스트 블록은 \"\"\" ~ \"\"\" 사이에 있는 모든 엔터값을 개행 문자로 인식한다. (첫줄 “”” 다음에 오는 첫번째 개행은 제외하며, 마지막 “\"”앞에있는 개행문자는 인식된다)\n\n\n\n@Test\nvoid stringBlock() throws Exception {\n    // 기존 자바의 방식\n    String beforeString = \"{\\n\" +\n        \"  \\\"name\\\": \\\"shirohoo\\\",\\n\" +\n        \"  \\\"age\\\": 30,\\n\" +\n        \"}\";\n\n    // 모던자바의 텍스트블록으로 표현할 경우 1\n    String afterString = \"\"\"\n        {\n          \"name\": \"shirohoo\",\n          \"age\": 30,\n        }\"\"\"; // 마지막 \"\"\" 앞에 개행문자가 없음을 주의깊게 볼 것!\n\t\n    // 모던자바의 텍스트블록으로 표현할 경우 2\n    String afterString = \"\"\"\n        {\n          \"name\": \"shirohoo\",\n          \"age\": 30,\n        }\n\t\"\"\".stripTrailing(); // 마지막 \"\"\" 앞에 개행문자를 넣었을 경우 이와 같이 처리할수도 있다\n}\n\n\n\n\n그냥 뭐… 압도적이다\n\n다만, 공백관련 문제가 약간 있어 이를 보완하기 위한 몇가지 메서드들이 추가됐다.\n\n더 자세한 사항은 📜 아주 좋은 아티클이 있어 이를 첨부한다.\n\n\n  String.stripIndent(): 텍스트블록에서 생성되는 부수적인 공백들을 제거하는데 사용한다\n  String.translateEscapes(): escape sequences를 번역하는 데 사용된다. (\\b, \\f, \\n, \\t, \\r, \", ', \\ and octal escapes)\n  String.formatted(Object… args): 텍스트 블록에 사용한 Placeholder를 치환한다. (%s, %d와 같은 것들)\n\n\nString output = \"\"\"\n    Name: %s\n    Phone: %s\n    Address: %s\n    Salary: $%.2f\n    \"\"\".formatted(name, phone, address, salary);\n\n\n\n\nRecord Class\n\n\n\n새로 추가된 클래스인데, 자바에서 새로운 타입의 클래스가 추가된 것은 JDK 5에서 추가된 enum 이후 최초라고 한다.\n\n코틀린(Kotlin)의 data class와 같은 기능을 하며, 간단하게 말하자면 읽기전용 불변 최종 클래스가 된다.\n\n클래스를 record로 선언하면 해당 클래스는 final 클래스가 되어 abstract로 선언할 수 없게되며, 모든 클래스 멤버도 final이 된다.\n\n또한, 모든 클래스멤버에 대한 생성자와 public 제한자를 갖는 getter, equals, hashCode, toString 메서드가 자동으로 생성된다.\n\n\n\npublic record Member(String name, int age) {}\n\n\n\n\n위 코드(모던 자바 방식)는 하기 코드(기존 자바 방식)와 정확히 동일하다.\n\n\n\npublic final class Member {\n    private final String name;\n    private final int age;\n\n    public Member(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    public String name() {\n        return name;\n    }\n\n    public int age() {\n        return age;\n    }\n\n    @Override\n    public boolean equals(Object obj) {\n        if (obj == this)\n            return true;\n        if (obj == null || obj.getClass() != this.getClass())\n            return false;\n        var that = (Member) obj;\n        return Objects.equals(this.name, that.name) &amp;&amp;\n            this.age == that.age;\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(name, age);\n    }\n\n    @Override\n    public String toString() {\n        return \"Member[\" +\n            \"name=\" + name + \", \" +\n            \"age=\" + age + ']';\n    }\n}\n\n\n\n\nPattern matching for instanceof\n\n\n\n팩토리 클래스에서 특히 유용할 것 같은 기능이여서 추가한다.\n\n기존 자바에서는 instanceof 키워드를 통해 타입체크를 한 후 타입 캐스팅을 해야만 했다.\n\n\n\nObject o = \"\";\nif(o instanceof String) {\n    String message = (String) o;\n    System.out.println(\"message = \" + message);\n}\n\n\n\n\n위 코드는 이제 다음과 같이 타입 캐스팅과 변수 선언 및 할당을 처리 할 수 있다.\n\n\n\nObject o = \"\";\nif(o instanceof String message) {\n    System.out.println(\"message = \" + message);\n}\n\n\n\n\nNumber Formatting Support\n\n\n\nNumberFormat에 포매팅을 도와주는 정적팩토리 메서드가 생겼다.\n\n다음과 같이 아무런 인수를 주지 않을 경우 사용하고 있는 머신의 Locale을 따라간다.\n\n\n\nNumberFormat fmt = NumberFormat.getCompactNumberInstance();\nSystem.out.println(fmt.format(1000));\nSystem.out.println(fmt.format(100000));\nSystem.out.println(fmt.format(1000000));\n\n\n\n\n1천\n10만\n100만\n\n\n\n\n혹은 별도로 Locale을 할당할수도 있다.\n\nNumberFormat fmt = NumberFormat.getCompactNumberInstance(Locale.ENGLISH, NumberFormat.Style.SHORT);\n\n\n\n\n1K\n100K\n1M\n\n\n\n\nStream.toList()\n\n\n\n기존 자바에서는 Stream에서 List를 반환하도록 하기 위해 다음과 같이 장황한 코드를 작성해야만 했다.\n\n\n\nList&lt;String&gt; strings = Stream.of(\"a\", \"b\", \"c\")\n            .collect(Collectors.toList());\n\n\n\n\n모던 자바에서는 이를 다음과 같이 표현할 수 있다.\n\n\n\nList&lt;String&gt; strings = Stream.of(\"a\", \"b\", \"c\").toList();\n\n\n\n\nZGC\n\n\n\n모던 자바에서 가장 큰 변화라고 하는데, JVM 최적화가 어마어마하게 이루어진 듯 하다.\n\n하지만 필자는 아직 이러한 로우레벨에 대해 완벽하게 이해하고 있지 못하고, GC 튜닝을 해본 경험이 없기 때문에 관련 포스팅을 첨부한다.\n\n\n\n📜 JVM과 Garbage Collection - G1GC vs ZGC\n\n\n\n중요하다고 생각되는 부분은 ZGC가 64bit 컴퓨터에서만 지원되며, G1GC 대비 성능이 매우 좋다는 부분인 듯 하다.\n\n\n\nSealed Class\n\n\n\n📜 JEP 360: Sealed Classes (Preview)\n\n\n\n일견 보기에 상속받을 수 있는 클래스를 제한한다는 내용으로 보이는데, 아직 무슨 내용인지 제대로 이해하지 못한것 같다.\n\n어디에 사용해야 할 지 지금으로서는 잘 모르겠다.\n\n우선 이런것도 있구나 하고 넘어갔다.\n\n\n\n12 ~ 17 Features\n\n12 ~ 17의 전체적인 피처는 하기와 같다.\n\n\n  출처: 📜 JDK Project - Releases\n\n\nJDK 12\n\n  189:    Shenandoah: A Low-Pause-Time Garbage Collector (Experimental)\n  230:    Microbenchmark Suite\n  325:    Switch Expressions (Preview)\n  334:    JVM Constants API\n  340:    One AArch64 Port, Not Two\n  341:    Default CDS Archives\n  344:    Abortable Mixed Collections for G1\n  346:    Promptly Return Unused Committed Memory from G1\n\n\nJDK 13\n\n  350:    Dynamic CDS Archives\n  351:    ZGC: Uncommit Unused Memory\n  353:    Reimplement the Legacy Socket API\n  354:    Switch Expressions (Preview)\n  355:    Text Blocks (Preview)\n\n\nJDK 14\n\n  305:    Pattern Matching for instanceof (Preview)\n  343:    Packaging Tool (Incubator)\n  345:    NUMA-Aware Memory Allocation for G1\n  349:    JFR Event Streaming\n  352:    Non-Volatile Mapped Byte Buffers\n  358:    Helpful NullPointerExceptions\n  359:    Records (Preview)\n  361:    Switch Expressions (Standard)\n  362:    Deprecate the Solaris and SPARC Ports\n  363:    Remove the Concurrent Mark Sweep (CMS) Garbage Collector\n  364:    ZGC on macOS\n  365:    ZGC on Windows\n  366:    Deprecate the ParallelScavenge + SerialOld GC Combination\n  367:    Remove the Pack200 Tools and API\n  368:    Text Blocks (Second Preview)\n  370:    Foreign-Memory Access API (Incubator)\n\n\nJDK 15\n\n  339:    Edwards-Curve Digital Signature Algorithm (EdDSA)\n  360:    Sealed Classes (Preview)\n  371:    Hidden Classes\n  372:    Remove the Nashorn JavaScript Engine\n  373:    Reimplement the Legacy DatagramSocket API\n  374:    Disable and Deprecate Biased Locking\n  375:    Pattern Matching for instanceof (Second Preview)\n  377:    ZGC: A Scalable Low-Latency Garbage Collector\n  378:    Text Blocks\n  379:    Shenandoah: A Low-Pause-Time Garbage Collector\n  381:    Remove the Solaris and SPARC Ports\n  383:    Foreign-Memory Access API (Second Incubator)\n  384:    Records (Second Preview)\n  385:    Deprecate RMI Activation for Removal\n\n\nJDK 16\n\n  338:    Vector API (Incubator)\n  347:    Enable C++14 Language Features\n  357:    Migrate from Mercurial to Git\n  369:    Migrate to GitHub\n  376:    ZGC: Concurrent Thread-Stack Processing\n  380:    Unix-Domain Socket Channels\n  386:    Alpine Linux Port\n  387:    Elastic Metaspace\n  388:    Windows/AArch64 Port\n  389:    Foreign Linker API (Incubator)\n  390:    Warnings for Value-Based Classes\n  392:    Packaging Tool\n  393:    Foreign-Memory Access API (Third Incubator)\n  394:    Pattern Matching for instanceof\n  395:    Records\n  396:    Strongly Encapsulate JDK Internals by Default\n  397:    Sealed Classes (Second Preview)\n\n\nJDK 17\n\n  306:    Restore Always-Strict Floating-Point Semantics\n  356:    Enhanced Pseudo-Random Number Generators\n  382:    New macOS Rendering Pipeline\n  391:    macOS/AArch64 Port\n  398:    Deprecate the Applet API for Removal\n  403:    Strongly Encapsulate JDK Internals\n  406:    Pattern Matching for switch (Preview)\n  407:    Remove RMI Activation\n  409:    Sealed Classes\n  410:    Remove the Experimental AOT and JIT Compiler\n  411:    Deprecate the Security Manager for Removal\n  412:    Foreign Function &amp; Memory API (Incubator)\n  414:    Vector API (Second Incubator)\n  415:    Context-Specific Deserialization Filters\n\n\n\n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2022-01-27-jdk17-lts/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "변성(Variance)",
      "date": "2022-02-01 00:00:00 +0000",
      "description": "변성은 무엇이고, 자바에는 어떻게 적용되는가?\n",
      "content": "\n  변성(Variance)    \n      무공변(invariance)\n      공변(covariance)\n      반공변(contravariance)\n    \n  \n  정리\n  참고\n\n\n\n\n변성(Variance)\n\n\n\n최근 함수형 프로그래밍을 공부하면서 변성이라는 키워드가 나왔는데, 이게 무엇인지 모르겠어서 알아봤다.\n\n쉽게 얘기해보자면 변성(Variance)이란 것은 타입간의 관계에 대한 표현이다.\n\n이를 자바에 대입해 어렵게 얘기하면 기저타입(Base Type)이 같고, 타입 인자(Type Argument)가 다른 경우 두 타입간에 어떠한 관계가 있느냐인데, 자바를 사용하면서 가장 많이 사용하게 되는 제네릭인 List&lt;Integer&gt;와 같은것을 예로 들면, List가 기저타입이고, &lt;Integer&gt;가 타입인자라고 보면 된다.\n\n\n\n\n\n\n\n용어가 좀 거부감들어서 그렇지 조금 더 쉽게 풀어보면 다음과 같다.\n\n\n\n가정: 타입 S가 타입 T의 하위타입일 경우 Box&lt;S&gt;도 Box&lt;T&gt;의 하위 타입인가?\n\n\n  무공변(invariance): 관계없다\n  공변(covariance): 그렇다\n  반공변(contravariance): 오히려 Box&lt;S&gt;가 Box&lt;T&gt;의 상위타입이다\n\n\n\n\n이를 왜 공부해야 할까?\n\n작성하는 프로그램의 유연성과 안전성을 위함이다.\n\n여기서 안정성이라는것은 타입 안정성을 의미하며, 유연성이란 것은 쉽게 확장 혹은 축소 될 수 있음을 의미한다.\n\n\n\n무공변(invariance)\n\n\n\n먼저 알아두어야 할 것은 자바의 배열은 기본적으로 공변이며, 제네릭은 무공변이라는 것이다.\n\n이 말이 무슨 의미이냐?\n\n자바의 자료형은 다음과 같은 계층구조를 따른다는 것을 알 것이다.\n\n\n\n\n\n\n\n무공변이라는 것은 타입 S가 타입 T의 하위타입이지만 Box&lt;S&gt;와 Box&lt;T&gt;간에는 상하 관계가 없다는 것이다.\n\n이를 자바 코드로 풀어보면 다음과 같다.\n\n\n\nList&lt;Number&gt; integers = new ArrayList&lt;Integer&gt;(); // 컴파일 에러 \nList&lt;Number&gt; doubles = new ArrayList&lt;Double&gt;(); // 컴파일 에러 \nList&lt;Number&gt; longs = new ArrayList&lt;Long&gt;(); // 컴파일 에러 \n\n\n\n\nInteger, Double, Long이 Number의 하위타입이지만 List&lt;Number&gt;에 List&lt;Integer&gt;, List&lt;Double&gt;, List&lt;Long&gt;을 할당할 수 없다.\n\n자바의 제네릭은 무공변, 즉 List&lt;Integer&gt;는 List&lt;Number&gt;의 하위타입이 아니기 때문이다.\n\n\n\n공변(covariance)\n\n\n\n자바의 배열은 기본적으로 공변이라 하였다.\n\n공변이라는 것은 타입 S가 타입 T의 하위타입일 경우 Box&lt;S&gt;도 Box&lt;T&gt;의 하위 타입이라는 것이다.\n\nInteger, Double, Long은 Number의 하위타입이기 때문에 Integer[], Double[], Long[]은 모두 Number[]의 하위타입이다.\n\n이를 자바 코드로 풀어보면 다음과 같다.\n\n\n\nNumber[] integers = new Integer[5]; // ok\nNumber[] doubles = new Double[5]; // ok\nNumber[] longs = new Long[5]; // ok\n\n\n\n\n위 코드가 컴파일 에러 없이 아주 잘 작성된다.\n\n\n\n자바의 제네릭은 배열과 다르게 기본적으로 무공변이지만 extends 예약어를 사용하면 공변 혹은 반공변으로 바꿀수도 있다.\n\n\n\nList&lt;? extends Number&gt; integers = new ArrayList&lt;Integer&gt;(); // ok\nList&lt;? extends Number&gt; doubles = new ArrayList&lt;Double&gt;(); // ok\nList&lt;? extends Number&gt; longs = new ArrayList&lt;Long&gt;(); // ok\n\n\n\n\n위 자바 코드는 무리없이 컴파일이된다.\n\n하지만 한 가지 특징이 생긴다.\n\n이렇게 공변으로 빚어낸 제네릭 컬렉션은 읽기전용(read-only)이 돼버린다는 것이다.\n\n\n\nList&lt;? extends Number&gt; integers = new ArrayList&lt;Integer&gt;();\n\nNumber number = integers.get(1); // 읽기 - 정상\nintegers.add(1); // 삽입 - 컴파일 에러\n\n\n\n\n\n\n\n\n컴파일 에러가 발생하는 부분의 인수 타입을 보면 capture of ? extends Number e 라는 문구를 볼 수 있는데, 이 의미는 자바 컴파일러가 ? extends Number e 타입에 대해 캡쳐한 어떤 타입이라는 의미이다.\n\n하지만 결국 이 어떤 타입이라는 캡쳐 타입은 Number의 하위 타입이긴 하지만 정확히 뭔지는 알 수 없는 타입임을 의미한다.\n\n따라서, 정확히 어떤 타입인지를 모르기 때문에 1, 1.0 등을 삽입하려 하면 컴파일 에러가 발생하게 된다.\n\n실제 삽입하려는 타입이 Integer, Double, Long보다도 더 하위의 타입일수도 있기 때문이다.\n\n결국 이렇게 정확히 어떤 타입인지를 알 수 없으니 null을 제외한 그 어떤 타입도 삽입을 하지 못하게 개발자가 강제적으로 막을 수 있게 된다.\n\n반대로 해당 List에 들어있는 모든 원소들은 절대적으로 Number의 하위타입들이기 때문에 Number 타입으로 꺼내어 읽을수는 있는것이다.\n\n\n\n반공변(contravariance)\n\n\n\n반공변이라는 것은 타입 S가 타입 T의 하위타입일 경우 Box&lt;S&gt;가 Box&lt;T&gt;의 상위 타입이라는 것이다.\n\n일단 자바 제네릭에서는 super 예약어를 사용해 무공변인 제네릭을 반공변으로 빚어낼 수 있다.\n\n반공변은 무공변과 다르게 읽기에 제한이 생기며, 오로지 삽입만 원활하게 가능해진다.\n\n일단 코드를 보자.\n\n\n\nList&lt;? super Number&gt; numbers = new ArrayList&lt;&gt;();\n\nnumbers.add(1); // Integer 삽입 - 정상\nnumbers.add(1.0); // Double 삽입 - 정상\nNumber number = numbers.get(1); // 읽기 - 컴파일 에러\nObject someElement = numbers.get(1); // 읽기 - 정상\n\n\n\n\n\n\n\n\n이번엔 컴파일 에러가 난 부분의 반환타입(Provided)을 보면 capture of ? super Number 라는 문구를 볼 수 있는데, 이는 공변에서의 예와 같이 자바 컴파일러가 ? super Number에 대해 캡처한 어떤 타입이라는 의미이다.\n\n즉, 반환 타입이 Number의 상위타입이긴 한데, 정확히 어떤 타입인지를 알수가 없는것이다.\n\n하지만 ? super Number라는 것은 해당 List에 들어있는 모든 원소들은 최소한 Number 타입이라는 것이 절대적으로 보장되기 때문에 Number 타입을 만족한다면 삽입이 되며, 자바의 최상위 타입인 Object로 반환을 하게 한다면 어떻게든 꺼내어 읽을수는 있게 된다. (타입체크 및 타입 캐스팅이 필요해지긴 하지만 !)\n\n\n\n정리\n\n\n\n이제까지 변성이 무엇인지에 대해 대략적인 감을 잡았다.\n\n그래서 언제 extends를 사용해야 하며, 언제 super를 사용해야 하는지에 대한 의문이 들 수 있는데, 📕 이펙티브 자바에서는 이를 PECS라는 용어로 표현하고\n있다.\n\nPECS란 생산자(Producer) - extends, 소비자(Consumer) - super 라는 의미인데 요 부분에서 또 혼란이 크게 왔다.\n\n나는 List에 원소를 집어넣으면 생산자이고, List에서 원소를 꺼내가면 소비자라고 생각하고 코드를 작성했는데, 작성하고 보니 생각한것과 완전 반대로 동작하는 것이었다. 즉, 제대로 이해하지 못한것이었다.\n\n이에 대해 찾아보니 PECS는 오로지 컬렉션 관점에서 생각해야만 하며, 외부에서 List의 원소를 가져갈 경우 컬렉션 관점에서는 자신이 보유하고 있던 원소가 사라진것이기 때문에 이를 생산한다고 표현하고, 외부에서 List에 원소를 삽입하는 경우 컬렉션 관점에서는 자신에게 원소가 하나 생긴것이기 때문에 이를 소비한다고 표현하는 듯 하다 (머리가 어질어질하다… 이게… 영어적인 사고…? 😩)\n\n굉장히 헷갈리고 머리가 아픈데, 그냥 간단하게 생각해서 다른 개발자가 읽기만 안전하게 사용하도록 하고 싶다면 extends를 사용하고, 삽입만 안전하게 사용하도록 하고 싶다면 super를 사용하자고 생각하기로 하였다.\n\n\n\n참고\n\n\n  📕 이펙티브 자바 3/E - 5장 제네릭\n  📜 What is PECS ?\n\n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2022-02-01-variance/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "람다 캡처링(Lambda Capturing)",
      "date": "2022-02-02 00:00:00 +0000",
      "description": "자바 람다 캡처링의 의미와 제약 조건\n",
      "content": "\n  람다 캡처링(Capturing Lambda)\n  참고\n\n\n\n\n람다 캡처링(Capturing Lambda)\n\n\n\npublic class Lambda {\n    public void capturingLambda() {\n        int portNumber = 8080;\n        Runnable runnable = () -&gt; System.out.println(portNumber);\n    }\n}\n\n\n람다 관점에서 봤을 때 위와 같이 람다 파라미터로 넘겨진 변수가 아닌, 람다 외부의 변수(portNumber)들을 자유 변수(Free Variable)라 칭하며, 이러한 자유 변수들을 참조하는 행위를 람다 캡처링(Capturing Lambda)이라고 부른다.\n\n람다는 기본적으로 인스턴스 변수(클래스 멤버 변수)와 정적 변수(static으로 선언된 변수)를 자유롭게 참조할 수 있다.\n\n하지만 지역 변수의 경우에는 약간의 제약이 있다.\n\n\n\n\n  지역변수는 명시적으로 final로 선언되거나, 실질적으로 final로 선언된 변수와 똑같이 사용되어야 한다.\n\n\n\n\nfinal로 선언된 변수와 똑같이 사용되어야 한다는 말은 쉽게 이야기하면 재할당되면 안된다는 말이다.\n\n무슨 말인지 이해가 안된다면 아래 코드를 보자.\n\n\n\npublic class Lambda {\n    public void capturingLambda() {\n        int portNumber = 8080;\n        Runnable runnable = () -&gt; System.out.println(portNumber); // portNumber가 재할당됐으므로 컴파일 에러 발생\n        portNumber = 8081; // 재할당\n    }\n}\n\n\n\n\n인스턴스 변수에는 이런 제약조건이 없는데, 지역 변수에는 이러한 제약 조건이 있는 이유가 뭘까?\n\n프로세스는 운영체제로부터 메모리를 할당받으며, 이 메모리는 Code, Data, Stack, Heap 네개의 구조로 이뤄져있다.\n\n그리고 프로세스 내부의 스레드는 각 스레드별로 고유한 Stack을 가지며 부모 프로세스의 Heap을 공유할 수 있으며, 자바의 인스턴스 변수는 Heap에 저장되고, 지역 변수는 Stack에 저장된다.\n\n즉, Heap에 할당된 인스턴스 변수는 모든 스레드가 자유롭게 공유할 수 있기 때문에 위와 같은 제약이 없다. (final이 아니어도 컴파일 에러가 발생하지 않는다.)\n\n하지만 지역 변수는 Stack에 저장되는데 Stack은 각 스레드별로 고유하기 때문에 스레드들이 공유할수가 없다.\n\n\n\n람다는 함수를 다른 함수에 넘기는 동작 파라미터화이므로 람다는 실제로 자신이 선언된 스레드와 다른 별도의 스레드로 넘겨져 실행될수가 있다.\n\n즉, 원래 지역 변수와 람다를 선언했던 스레드의 모든 작업이 끝나 스레드에 할당된 메모리가 해제되어 해당 스레드의 데이터들이 사라졌지만, 람다는 다른 스레드 넘겨져 살아있을 가능성이 존재하며 이 경우 람다가 이미 메모리가 해제되어 사라진 지역 변수를 참조하려하는 문제가 생길 수 있다.\n\n그래서 이러한 문제가 생기지 않게 람다는 최초 자신을 선언해 넘긴 스레드의 스택에 저장된 지역 변수를 자신이 넘겨질 때 넘겨지는 스레드의 스택으로 복사해온다.\n\n이러한 이유로 람다는 별도의 스레드에 존재하는 지역 변수와 동일한 값을 참조할 수 있으며(실제로는 넘겨질 때 복사해온 값), 원래 스레드가 사라져도 자신이 넘겨진 스레드에서 자신이 해야 할 작업을 문제 없이 수행 할 수 있는 것이다.\n\n\n\n하지만 이렇게 지역 변수를 공유해서 사용할 수 없기 때문에 지역 변수를 복사해와 사용하는데 그 변수의 값이 변경된다면 역시 문제가 생길 수 있기 때문에, 명시적으로 final이거나 final 처럼 사용되어야 한다는 제약이 생긴 것이다.\n\n\n\n참고\n\n\n  📕 모던 자바 인 액션\n  📜 Lambda Expression and Variable Capture\n  📜 Java 8 Lambdas - A Peek Under the Hood\n\n\n\n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2022-02-02-lambda-capturing/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "운영체제(Operating System) 1강",
      "date": "2022-02-07 00:00:00 +0000",
      "description": "반효경 교수님 - System Structure &amp; Program Execution\n",
      "content": "\n  Lecture\n  System Structure &amp; Program Execution    \n      CPU\n      Operating System\n      Memory Controller\n      Mode bit\n      DMA(Direct Memory Access) Controller\n      Timer\n      Device Controller\n      Local Buffer\n      I/O 수행\n      동기식 I/O와 비동기식 I/O\n      절대 주소(물리 주소) 와 상대 주소(논리 주소)\n      저장장치 계층\n    \n  \n\n\n\n\nLecture\n\n\n\n\n  운영체제 - 반효경 교수님\n    \n      System Structure &amp; Program Execution 1\n      System Structure &amp; Program Execution 2\n    \n  \n\n\n\n\nSystem Structure &amp; Program Execution\n\n\n\n이번 챕터는 머릿속에 운영체제의 전체적인 그림을 그리기 위한 챕터로 본 운영체제 강의에서 가장 어려운 부분 중 하나라고 할 수 있다.\n\n\n\n\n\n\n\nCPU\n\n\n\nCPU는 명령어의 인출, 실행을 담당하며, 매 클럭당 프로그램 카운터(PC)가 가리키는 메모리 주소에 위치한 명령어(instruction)를 메모리 컨트롤러(Memory Controller)를 통해 인출하고, 인출 된 명령어를 처리(=연산)한 후 결과를 다시 메모리 컨트롤러에게 알려준다.\n\n또한 CPU는 매번 하나의 명령어를 처리한 후 인터럽트 라인을 체크하여 인터럽트가 있다면 Mode bit를 0으로 변경(커널 모드)하며 CPU의 제어권을 사용자 프로세스에서 운영체제로 넘긴다.\n\n\n\nOperating System\n\n\n\n운영체제도 하나의 프로세스로서 메모리에 올라가며, 컴퓨터에 전원이 인가돼있는 동안 항상 메모리에 상주해야만 하는, 운영체제 프로그램에서 가장 중요한 부분(코드들)을 좁은 의미로서의 커널(Kernel)이라고 부른다. 그리고 이 좁은 의미의 커널이 일반적으로 컴퓨터 과학 전공에서 말하는 운영체제이기도 하다.\n\n운영체제는 어떻게 해야 컴퓨터의 하드웨어 리소스를 가장 효율적으로 사용할 수 있는가를 제 1목적으로 동작한다.\n\n예를 들어 중요한 프로세스가 CPU를 더 많이 점유하고, 상대적으로 덜 중요한 프로세스가 CPU를 더 적게 점유하도록 하는 CPU 스케쥴링(엘리베이터를 연상하자), 실행되는 프로세스들이 메모리를 낭비하지 않고(메모리 단편화) 효율적으로 사용할 수 있게끔 하는 메모리 관리(테트리스와 하드 디스크 조각 모음을 연상하자) 등을 담당한다.\n\n또한, 인터럽트 발생 시 해당 인터럽트가 정확히 어떤 요인에 의해 발생한 인터럽트인지를 파악하고 CPU에게 적절한 처리를 지시해주는 인터럽트 서비스 루틴(ISR, Interrupt Service Routine)을 제공한다.\n\n인터럽트 서비스 루틴은 어려운게 아니고, 코드를 뜯어보면 내부적으로 if 혹은 switch를 통해 구현돼있다.\n\n\n\nMemory Controller\n\n\n\n저장장치에는 물리적으로 임의의 공간에 임의의 데이터가 들어있을 뿐이며, 저장장치 스스로 데이터를 읽고 쓸 수 없다.\n\n따라서 저장장치에 데이터를 읽고 쓰기 위해서는 저장장치의 구조에 대해 빠삭하게 알고 있으면서도 CPU의 요구사항도 이해할 수 있는 중간 계층이 필요한데, 이 중간 계층에 속하는 하드웨어가 메모리 컨트롤러이다.\n\n기본적으로 메모리 컨트롤러는 메모리에 대한 전반적인 관리를 담당하며, 부가적으로 CPU의 요구사항에 맞춰 메모리를 조작하는 역할도 한다.\n\n\n\n\n  메모리가 동작할 수 있게 적당한 전압을 인가한다\n  기본적으로 휘발성인 메모리의 데이터가 사라지지 않도록 주기적으로 refresh 한다\n  메모리에 올라와있는 프로그램의 명령어를 CPU로 인출해준다(읽기)\n  CPU가 메모리에 데이터 쓰기 요청을 해오면 해당 요청을 받아 메모리에 데이터를 저장한다(쓰기)\n\n\n\n\n이를 카페에 비유하자면, 카페에는 계속해서 커피만 내리는 커피머신이 있을 것인데 이 커피머신이 CPU라고 볼 수 있으며, 고객의 요청을 받아 처리하는 직원이 메모리 컨트롤러라고 볼 수 있고, 직원에게 요청을 하는 고객이 메모리에 올라와있는 사용자 프로세스라고 볼 수 있겠다.\n\n메모리는 메모리 컨트롤러에 종속적이기 때문에 메모리의 성능이 아무리 좋더라도, 메모리 컨트롤러의 처리속도나 메인보드 메모리 버스의 대역폭이 따라주지 못한다면 메모리의 성능을 온전히 다 사용할 수 없다.\n\n\n\nMode bit\n\n\n\n현재 CPU를 사용하고 있는 프로세스의 권한을 의미하며, Mode bit가 0이라면 커널 모드, 1이라면 사용자 모드이다.\n\n커널 모드라는 것은 CPU를 운영체제가 제어하고 있다는 의미이며, 커널 모드일 경우 컴퓨터의 모든곳에 접근할 수 있다. (즉, 관리자 권한)\n\n사용자 모드라는 것은 CPU를 운영체제가 아닌 다른 프로세스(일반적으로 사용자 프로세스)가 점유하고 있다는 의미이며, 이 경우 CPU는 사용자 프로세스가 할당받은 메모리에만 접근할 수 있다.\n\n이는 기본적으로 사용자 프로세스를 믿을 수 없기 때문에(악성 프로그램 등) 보안을 위한 조치이다.\n\n\n\nDMA(Direct Memory Access) Controller\n\n\n\n모든 I/O 장치들이 CPU에 직접적으로 인터럽트를 걸어대면 CPU가 자주 방해받아 오버헤드가 커지기 때문에 DMA 컨트롤러가 I/O 장치들의 인터럽트를 받고 데이터를 메모리에 읽고 쓴 다음(메모리 컨트롤러에 요청), CPU에 인터럽트를 한번 발생시킨다.\n\n즉, 일종의 일괄배치 시스템으로, 비유하자면 삽질을 한번 할 때마다 흙을 삽에 올려둔채로 왔다갔다 하면 삽질하는 것보다 왔다갔다 하는데 체력적인 비용이 더 크게 발생하는데 반해, 삽질을 해서 흙을 퍼 올려 수레에 쌓아둔 후 수레가 가득 찼을 때 수레를 끌고 한 번 다녀오면 전자의 경우에 비해 더 삽질에 집중할 수 있게 된다.\n\n\n\nTimer\n\n\n\n우리가 사용하는 컴퓨터는 동시에 여러개의 프로그램이 실행되는 것처럼 보인다.\n\n하지만 실제로 하나의 CPU는 동시간대에 정확히 하나의 일만을 하고있다.\n\n단지, 하는 일을 수시로 바꿔가면서 하고 있을 뿐이며, 이 작업이 너무 빠르기 때문에 동시에 실행되고 있는 것 처럼 보이는 것이다. (동시성)\n\n\n\n\n\n예를 들어 커다란 담벼락을 3분할하여 각각 빨간색, 초록색, 파란색 페인트를 칠해야한다고 가정해보자.\n\n이때 담벼락을 칠해야 하는 작업자 입장에서 가장 효율적인 방법은 다음과 같다.\n\n\n\n\n  빨간색 페인트를 모두 칠하고, 페인트를 초록색으로 바꾼다. (페인트 교체 1회)\n  초록색 페인트를 모두 칠하고 페인트를 파란색으로 바꾼다. (페인트 교체 2회)\n  파란색 페인트를 모두 칠한 후 작업을 종료한다.\n\n\n\n\n이렇게 하면 페인트를 단 두 번만 교체하고도 모든 작업을 끝낼 수 있다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n하지만 위와 같이 처리 할 경우 한가지 문제가 있다.\n\n작업자 입장에서는 페인트를 교체하는 비용이 최대로 적게 들면서 오로지 담벼락을 칠하는데만 집중할 수 있게 되지만, 담벼락을 구경하는 사람 입장에서는 빨간색이 다 칠해지기 전까지는 초록색과 파란색 벽면을 빠르게 볼 수 없다.\n\n심지어 파란색은 빨간색과 초록색이 모두 칠해지기 전까지 볼 수 없다.\n\n이러한 상황을 대입해 생각하면 예를 들어 키보드를 눌렀는데 입력한 값이 10초 후에 화면에 표시되는 상황을 상상할 수 있다. 즉, 사용자 경험이 크게 나빠진다.\n\n이러한 문제를 해결하기 위해 다음과 같은 방식을 사용한다.\n\n\n\n\n  빨간색을 조금 칠한 후 페인트를 초록색으로 바꾼다.\n  초록색을 조금 칠한 후 페인트를 파란색으로 바꾼다.\n  파란색을 조금 칠한 후 페인트를 빨간색으로 바꾼다.\n  1~3을 반복한다.\n\n\n\n\n\n\n\n\n\n\n\n\n…\n\n\n\n\n\n\n\n처음에는 페인트 교체를 단 두 번만 해서 모든 벽을 칠했는데, 여기서는 벽을 조금 칠하고 페인트를 바꿔서 다른 벽을 칠하는 식으로 모든 벽을 동시에 칠했다.\n\n그래서 페인트를 14번이나 교체하고서야 벽을 다 칠할수 있었다.\n\n작업자 입장에서는 참으로 거지같은 상황이지만, 구경하는 사람 입장에서는 담벼락에 모든 색이 칠해지는 광경을 실시간으로 볼 수 있었다.\n\n이러한 방식을 시분할(Time Sharing) 방식이라 하며, 페인트를 교체하는 작업을 컴퓨터 과학에서 말하는 컨텍스트 스위칭(Context Switching)이라고 볼 수 있다.\n\nCPU는 사용자 경험 증대를 위해 매번 하는 작업을 변경하는데, 이렇게 CPU가 매번 작업을 변경 할 경우 이전에 한 작업을 이어서 해야만 하기 때문에 이전에 한 작업을 모두 기억해야만 한다.\n\n때문에 현재까지의 작업 상황을 PCB(Program Controll Block)에 저장해두고 레지스터를 초기화하는 작업을 진행한다.\n\n그리고 나중에 다시 작업을 재개 할 때 PCB를 참고하여 이전에 진행했던 작업 진행 상황들을 다시 불러온 후, 해당 부분부터 작업을 재개하게 된다.\n\n운영체제는 이 시분할 시스템을 위해 사용자 프로세스에게 CPU를 점유할 수 있는 시간을 할당(CPU 스케쥴링)하는데, 사용자 프로세스가 무한 루프등의 이유로 CPU를 반환하지 않고 계속 점유하는 것을 방지하기 위해 타이머를 사용한다.\n\n즉, 사용자 프로세스가 CPU를 점유한 시간이 운영체제가 타이머에 지정한 시간을 넘길 경우 운영체제는 사용자 프로세스에게서 CPU를 강제로 회수해 다른 사용자 프로세스에게 할당해준다.\n\n\n\nDevice Controller\n\n\n\nI/O 디바이스를 제어하는 작은 CPU라고 볼 수 있으며, CPU와 I/O 디바이스 간의 모든 처리는 이 디바이스 컨트롤러가 담당한다.\n\n\n\nLocal Buffer\n\n\n\nI/O 디바이스에게 주어진 작은 저장장치이다.\n\n예를 들어 키보드를 입력하면 입력한 키의 코드 값이 키보드 버퍼에 담기고, 디바이스 컨트롤러가 키보드 버퍼에 쌓인 데이터들을 인터럽트와 함께 CPU를 향해 보낸다. (실제로는 DMA 컨트롤러가 받아 처리할 것으로 예상된다)\n\n\n\nI/O 수행\n\n\n\n모든 I/O 명령은 커널 모드로만 가능하다.\n\n그렇다면 사용자 모드로 실행되는 사용자 프로세스는 어떻게 I/O 작업을 할 수 있을까?\n\n바로, 시스템 콜(System Call)을 활용한다.\n\n시스템 콜은 사용자 프로세스가 인터럽트를 통해 운영체제에게 작업을 대신 처리해줄 것을 요청하는 것을 말한다.\n\n사용자 프로세스는 기본적으로 사용자 모드로 실행되고, 사용자 모드로는 권한이 없어 운영체제 메모리에 직접적으로 접근할 수 없기 때문에, 인터럽트를 통해 운영체제에 정의된 커널 함수를 간접적으로 호출하는 것이다.\n\n즉, 프로그램이 직접 인터럽트를 발생시켜 버리면, CPU는 사용자 프로세스의 명령어를 한 개 처리한 후 인터럽트를 체크 할 것이다.\n\n그리고 CPU는 사용자 프로세스가 발생시킨 인터럽트를 감지하여 다음 명령어를 바로 수행하는 대신 하던 작업을 저장하고 Mode bit를 0으로(커널 모드) 변경한 후 제어권을 운영체제에 넘기게 된다.\n\n그리고 인터럽트에 의해 CPU 제어권을 넘겨받게 된 운영체제는 인터럽트 서비스 루틴(ISR)을 통해 해당 인터럽트가 어떤 경로로 발생했는지를 파악한 후 후속 처리를 진행하게 된다.\n\n\n\n동기식 I/O와 비동기식 I/O\n\n\n\n동기식 I/O(Synchronous I/O)은 사용자 프로세스에서 I/O 작업 요청이 발생하면, 발생한 I/O 작업이 디바이스 컨트롤러에서 완료될 때까지 모든 CPU의 작업 흐름이 멈추고, I/O 작업이 완료됨과 동시에 CPU의 작업 흐름이 재개되는 것을 말한다.\n\n예를 들어 자바로 하드디스크(I/O 디바이스)에 텍스트 파일을 생성하는 프로그램을 작성했고, 이 프로그램이 운영체제로부터 메모리와 CPU를 할당받아 프로세스가 되어 하드디스크에 텍스트 파일을 생성하는 부분의 코드가 실행될 때, 자바 프로세스는 직접 I/O 작업을 할 수 없기 때문에 시스템 콜을 위해 인터럽트를 발생시킬 것이다.\n\n그리고 CPU는 자바 프로세스에서 발생시킨 인터럽트를 감지하여 커널 모드로 변경한 후 운영체제에 자신의 제어권을 넘기고, 운영체제는 자바 프로세스에서 요청한 I/O 작업을 하드디스크 디바이스 컨트롤러에게 위임할 것이다.\n\n그리고 디바이스 컨트롤러가 로컬 버퍼를 통해 모든 작업을 완료하는 동안 자바 프로세스와 CPU는 대기상태에 들어간다.\n\n디바이스 컨트롤러가 모든 작업을 완료하여 인터럽트를 발생시키면 CPU는 다시 사용자 모드로 변경되어 자바 프로세스에 할당 되어 작업 흐름이 돌아가기 시작 할 것이다.\n\n이러한 방식을 다음과 같이 두 가지 방법으로 구현할 수 있다.\n\n\n\n\n  \n    구현 방법 1\n  \n  I/O가 끝날 때까지 기다렸다가, 작업이 끝나 인터럽트가 발생되면 사용자 프로세스에게 CPU의 제어권을 넘긴다.\n  즉, 매 시점 하나의 I/O만 일어날 수 있다.\n  I/O가 끝날 때까지 CPU가 연산할 수 있는 시간을 낭비한다는 커다란 결함이 있다.\n\n\n\n\n\n  \n    구현 방법 2\n  \n  I/O가 완료될 때까지 운영체제는 해당 프로세스에서 CPU의 제어권을 빼앗고 진행상태를 저장한다.\n  다른 사용자 프로세스에게 CPU를 할당한다.\n  현대 동기식 I/O는 보통 이 방법으로 구현한다.\n\n\n\n\n비동기식 I/O(Asynchronous I/O)는 I/O 작업이 시작되면 시작된 I/O 작업이 끝나기를 기다리지 않고 CPU 제어권을 I/O 작업을 요청했던 사용자 프로그램에게 즉시 넘기는 것을 말한다.\n\n즉, 호출자와 피호출자의 작업 싱크가 일치하지 않게 동작하는 것이다.\n\n\n\n\n\n\n\n위 그림은 동기식 I/O와 비동기식 I/O를 비교해 보여 준다.\n\n사용자가 I/O 요청을 하면 동기식 I/O에서는 먼저 운영체제로 CPU의 제어권이 넘어와서 I/O 처리와 관련된 커널 함수가 실행된다.\n\n이때 I/O를 호출한 프로세스의 상태를 Blocked 상태로 바꾸어 I/O가 완료될 때까지 CPU를 다시 할당받지 못하도록 한다.\n\n그리고 I/O가 완료되면 디바이스 컨트롤러가 CPU에게 인터럽트를 발생시켜 I/O가 완료됐음을 알려주고, Blocked 상태인 프로세스의 상태를 복원하여 CPU를 할당받을 수 있는 자격을 준다.\n\n반면 비동기식 I/O에서는 CPU의 제어권이 I/O를 요청한 프로세스에게 곧바로 다시 주어지며, I/O가 완료되는 것과 무관하게 처리 가능한 작업부터 처리한다.\n\n한편 두 방식 모두 I/O 연산이 완료되면 인터럽트를 통해 CPU에게 알려준다.\n\n\n\n절대 주소(물리 주소) 와 상대 주소(논리 주소)\n\n\n\n\n\n\n\n개발자가 프로그래밍 언어로 개발할 때 메모리 주소를 크게 신경쓰지 않고 개발한다.\n\n이게 가능한 이유는 개발자가 개발하는 모든 사용자 프로세스의 시작 메모리 주소는 0x0이라고 가정하기 때문이다.\n\n프로그램이 실행되어 운영체제에게서 메모리를 할당받을 때에서야 랜덤한 시작 메모리 주소가 생겨난다(메모리에 남아있는 공간이 어떻게 되어있을지 모르기 때문에). 그리고 이 랜덤한 시작 메모리 주소를 MMU(Memory Management Unit)가 0x0으로 매핑해준다.\n\n즉, 메모리에 남아있는 영역의 시작 주소가 0x2000이며, 이 주소부터 사용자 프로세스 x가 메모리를 할당받는다고 가정하면, MMU는 사용자 프로세스 x의 실제 시작 메모리 주소를 0x2000으로 저장하고 이를 외부에는 사용자 프로세스 x의 시작 메모리 주소는 0x0이라고 반환해준다.\n\n이후 CPU와 프로그램 카운터에 의해 사용자 프로세스 x의 200번지 주소에 위치한 명령어를 인출해달라는 요청이 들어오면 MMU는 매핑해둔 0x2000을 더해 0x2200라는 주소를 반환해준다.\n\n\n\n저장장치 계층\n\n\n\n\n\n\n\n위로 갈수록 속도가 빠르지만, 단위 공간 당 가격이 비싸고 용량이 적다.\n\n반면 아래로 갈수록 단위 공간 당 가격이 싸고 용량이 많지만, 속도가 느려진다.\n\n또한, CPU는 바이트 단위로 접근 가능한 매체여야 접근이 가능하다.\n\nHDD는 섹터 단위로 접근하기 때문에 CPU에서 직접 접근할 수 없다.\n\n\n\n\n  Primary Storage\n\n\nCPU에서 직접 접근할 수 있는 저장장치를 말하며, Executable(실행 가능한) 라고 부른다. 즉, 해당 저장장치는 바이트 단위로 CPU 접근이 가능하다. Primary 라고 부르며, 전원이 꺼지면 데이터가 사라지는 휘발성 특징을 갖는다. RAM이 대표적이다.\n\n\n\n\n  Secondary Storage\n\n\nCPU가 직접 접근하지 못하는 저장장치를 말한다. 대표적으로 HDD는 섹터 단위를 사용하기 때문에 바이트 단위를 사용하는 CPU가 접근하지 못한다. Secondary 라고 부르며, 해당 저장장치는 전원이 꺼져도 데이터가 보존되는 비휘발성 특징을 갖는다.\n\n\n\n\n  캐시 메모리\n\n\nCPU와 메인 메모리(RAM)간에는 분명한 물리적인 거리가 존재하기 때문에 속도가 크게 저하되며, 이러한 문제를 해결하기 위해 초고성능의 메모리를 CPU에 내장하는데 이것이 캐시 메모리이다.\n\n캐시 메모리는 매우 빠르고 CPU와 물리적으로 가까운곳에 위치하지만, 가격이 비싸 개인용 컴퓨터에는 작은 용량의 캐시 메모리를 사용하기 때문에 RAM에 있는 모든 데이터를 캐시 메모리로 복사 할 수는 없다.\n\n그래서 빈번히 사용되는 데이터를 선별적으로 캐시 메모리에 복사하고 CPU가 RAM이 아닌 캐시 메모리에 접근해 이를 재사용하는 기법(캐싱)을 통해 시스템의 성능을 높일 수 있다.\n\n\n\n간단하게 계산을 해보자.\n\n\n\n\n\n\n\n\n\n\n\n대충 검색을 통해 찾은 1TB HDD의 가격은 52,500이다.\n\n역시, 대충 검색을 통해 찾은 64GB RAM의 가격은 406,930이다.\n\n1TB는 1,024GB이므로, 64GB RAM이 16개 있다면 1TB의 용량이 된다.\n\n즉, HDD로 1TB를 채우면 52,500의 비용이 필요하며, RAM으로 1TB를 채우면 406,930 * 16 = 6,510,880 이라는 천문학적인 비용이 필요하다.\n\n\n",
      "categories": ["cs","operating-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/operating-system/2022-02-07-operating-system/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "코드 카타 - 숫자 야구 게임",
      "date": "2022-02-09 00:00:00 +0000",
      "description": "TDD와 헥사고날 아키텍처 훈련\n",
      "content": "\n  코드카타(Code Kata)    \n      코드 카타, 어떻게 해야 하는가?\n    \n  \n  소프트웨어 개발 3대 원칙\n  숫자 야구 게임    \n      기능 요구 사항\n      실행 결과\n      프로그래밍 요구사항\n      기능 정의 및 책임 할당\n      프로젝트 구성\n    \n  \n  숫자 야구 게임 구현\n\n\n\n\n코드카타(Code Kata)\n\n\n  📜 CodeKata - Because experience is the only teacher\n\n\n\n\n(주의… 의역이 심합니다 😅)\n\n어떻게 하면 훌륭한 음악가가 될 수 있을까요?\n\n우선, 일단 이론을 알면 악기의 역학을 이해하는데 분명 도움이 됩니다.\n\n하지만 궁극적으로 훌륭한 실력은 이렇게 이론만 알아서 되는것이 아닌, 지속적이고 반복적인 훈련에서 나온다는 것을 깨달아야 합니다.\n\n반복적인 훈련에 이론을 계속 적용하며 결과를 얻고, 결과에 대한 피드백도 얻는다면 결과는 계속해서 좋아질 것입니다.\n\n\n\n위대한 스포츠 선수가 되려면 어떻게 해야 할까요?\n\n체력과 같은 선천적인 재능들은 분명히 큰 도움이 됩니다.\n\n그러나 이러한 재능들과 별개로 모든 위대한 스포츠 선수들은 보이지 않는 곳에서 매일 긴 시간 동안의 피나는 훈련을 했음을 알아야 합니다.\n\n\n\n일반적으로 소프트웨어 산업현장에서 우리는 이론만 훈련받은 개발자들을 데려와 프로젝트에 투입시키고, 프로젝트가 잘 돌아가길 원합니다.\n\n이것은 건강한 아이들을 몇 모으면 워싱턴 커맨더스를 이길 수 있다고 말하는 것과 다르지 않습니다.\n\n\n\n즉, 우리는 직장에서 훈련을 하기 때문에 실수를 하는 것입니다.\n\n따라서, 우리는 일과 훈련을 분리하는 방법을 찾고 지속적으로 훈련해 성장해야만 합니다.\n\n\n\n코드 카타, 어떻게 해야 하는가?\n\n\n\n\n  \n    누구에게도 방해받지 않는 시간이 필요하며, 가볍게 시도해보고 싶은 단순한 주제가 필요합니다.\n  \n  \n    필요하거나 만족스러울 만큼 여러 번 쉽게 시도하고, 무엇보다 실수를 하는 것이 두렵지 않고 편안해야만 합니다.\n  \n  \n    개선을 위해 노력할 수 있도록 매번 피드백을 찾아야 합니다.\n  \n  \n    외부의 압력이 없어야 합니다. 심신이 편안해야 합니다. 그리하여 오로지 훈련에만 몰입 할 수 있어야 합니다.\n  \n\n\n\n\n이것이 프로젝트 환경에서 성장하기 어렵고, 실수가 잦아지는 이유입니다.\n\n\n\n카타는 한 형태를 여러 번 반복하면서 조금씩 개선되는 가라데의 훈련입니다.\n\n코드 카타의 의도는 가라데의 카타와 비슷합니다.\n\n둘 모두 단순히 짧은 반복 훈련입니다.\n\n\n\n카타를 처음 하면 지루할수도 있지만, 계속해서 반복 할 수록 코드가 점점 더 좋아지는 것을 보고 느끼게 될 것이기 때문에 하면 할 수록 이 훈련이 아주 좋다는 것을 스스로 인식하게 될 것입니다.\n\n결과적으로, 스스로가 성장한다는 것을 직접적으로 느낄 수 있기 때문에 카타는 개발에 재미를 느끼는 데에도 큰 도움이 됩니다.\n\n\n\n누군가는 카타를 하며 단순히 코딩하는 것을 떠나 설계까지 고려 할 겁니다.\n\n또 누군가는 카타를 진행하며 프로그래밍 이면의 문제에 대한 고민을 할 겁니다.\n\n즉, 카타에는 정답이 없습니다.\n\n\n\n원하는 훈련을 하고 원하는 공예에 충분한 시간을 투자하세요.\n\n카타의 요점은 정답이 없다는 것이며, 설령 정답이 있다고 하더라도 그 정답이 중요하지 않을 것이라는 점입니다.\n\n중요한 것은 결과가 아닌 카타를 진행하며 고민하는 과정 그 자체입니다.\n\n\n\n소프트웨어 개발 3대 원칙\n\n\n\n나는 최대한 소프트웨어 개발 3대 원칙과 객체지향 5대 원칙(SOLID)을 고민하면서 훈련에 임할 것이다.\n\n\n  KISS(Keep It Simple Stupid): 최대한 단순하게 해라\n  YAGNI(You Ain’t Gonna Need It): 필요한 것만 해라\n  DRY(Do not Repeat Yourself): 같은 것을 반복하지 마라\n\n\n숫자 야구 게임\n\n\n\n\n\n\n  📜 NextStep - 숫자 야구 게임 저장소\n\n\n\n\n기능 요구 사항\n\n\n\n기본적으로 1부터 9까지 서로 다른 수로 이루어진 3자리의 수를 맞추는 게임이다.\n\n\n  같은 수가 같은 자리에 있으면 스트라이크, 다른 자리에 있으면 볼, 같은 수가 전혀 없으면 포볼 또는 낫싱이란 힌트를 얻고, 그 힌트를 이용해서 먼저 상대방(컴퓨터)의 수를 맞추면 승리한다.\n    \n      e.g. 상대방(컴퓨터)의 수가 425일 때, 123을 제시한 경우 : 1스트라이크, 456을 제시한 경우 : 1볼 1스트라이크, 789를 제시한 경우 : 낫싱\n    \n  \n  위 숫자 야구 게임에서 상대방의 역할을 컴퓨터가 한다. 컴퓨터는 1에서 9까지 서로 다른 임의의 수 3개를 선택한다. 게 임 플레이어는 컴퓨터가 생각하고 있는 3개의 숫자를 입력하고, 컴퓨터는 입력한 숫자에 대한 결과를 출력한다.\n  이 같은 과정을 반복해 컴퓨터가 선택한 3개의 숫자를 모두 맞히면 게임이 종료된다.\n  게임을 종료한 후 게임을 다시 시작하거나 완전히 종료할 수 있다.\n\n\n\n\n실행 결과\n\n\n\n숫자를 입력해 주세요 : 123\n1볼 1스트라이크\n숫자를 입력해 주세요 : 145\n1볼\n숫자를 입력해 주세요 : 671\n2볼\n숫자를 입력해 주세요 : 216\n1스트라이크\n숫자를 입력해 주세요 : 713\n3스트라이크\n3개의 숫자를 모두 맞히셨습니다! 게임 종료\n게임을 새로 시작하려면 1, 종료하려면 2를 입력하세요.\n1\n숫자를 입력해 주세요 : 123\n1볼 1스트라이크\n…\n\n\n\n\n프로그래밍 요구사항\n\n\n\n\n  자바 코드 컨벤션을 지키면서 프로그래밍한다.\n    \n      기본적으로 Google Java Style Guide을 원칙으로 한다.\n      단, 들여쓰기는 ‘2 spaces’가 아닌 ‘4 spaces’로 한다.\n    \n  \n  indent(인덴트, 들여쓰기) depth를 2가 넘지 않도록 구현한다. 1까지만 허용한다.\n    \n      예를 들어 while문 안에 if문이 있으면 들여쓰기는 2이다.\n    \n  \n  else 예약어를 쓰지 않는다.\n  모든 로직에 단위 테스트를 구현한다. 단, UI(System.out, System.in) 로직은 제외\n  핵심 로직을 구현하는 코드와 UI를 담당하는 로직을 구분한다.\n  3항 연산자를 쓰지 않는다.\n  함수(또는 메소드)가 한 가지 일만 하도록 최대한 작게 만들어라.\n\n\n\n\n기능 정의 및 책임 할당\n\n우선 꼭 필요하다고 생각되는 기능들을 정의해야한다.\n\n구현 중간에 세세하게 바뀔수는 있겠지만 거시적으로 보면 크게 변하지는 않을 것이다.\n\n\n  콘솔로 숫자를 입력받을 수 있어야 한다 (ConsoleInput)\n  콘솔로 재시작 여부를 입력받을 수 있어야 한다(ConsoleInput)\n  콘솔에 정보를 출력할 수 있어야 한다(ConsoleOutput)\n  1~9사이의 중복되지 않는 랜덤한 수 3개를 생성할 수 있어야 한다(NumbersGenerativeStrategy)\n  생성된 랜덤수와 사용자가 입력한 수를 비교하여 볼, 스트라이크 카운트를 판별할 수 있어야 한다(Referee)\n\n\n\n\n프로젝트 구성\n\n\n\n일단 다음과 같이 패키지 구조를 잡았다\n\n\n\n\n\n\n\n의존성 설정을 할 것인데, 자바 17을 사용할 것이며, 빌드툴은 Gradle을 사용한다.\n\n테스트를 원활하게 하기 위해 AssertJ와 JUnit5를 추가했다.\n\n\n\n// file: 'build.gradle'\nplugins {\n    id 'java'\n}\n\ngroup 'io.github.shirohoo'\n\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    testImplementation 'org.assertj:assertj-core:3.22.0'\n    testImplementation 'org.junit.jupiter:junit-jupiter-params:5.8.2'\n    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.8.2'\n    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.8.2'\n}\n\ntest {\n    useJUnitPlatform()\n}\n\njava {\n    toolchain {\n        languageVersion = JavaLanguageVersion.of(17)\n    }\n}\n\n\n\n\n숫자 야구 게임 구현\n\n\n\n\n  📦 숫자 야구 게임 구현 코드 저장소\n\n\n\n\n우선 이 게임에서 가장 중요한 객체인 숫자를 구현해야겠다.\n\n게임에서 사용하는 숫자를 표현 할 클래스 이름은 Numbers라고 명명하였고, 구현의 유연함을 위해 외부에서 생성 전략을 주입받아 생성되도록 구성할 것이다.\n\n\n\nclass NumbersTests {\n    @Test\n    void from() {\n        assertThatCode(() -&gt; {\n            Numbers randomNumbers = Numbers.from(() -&gt; \"123\");\n        }).doesNotThrowAnyException();\n    }\n}\n\n\n\n\n먼저 테스트 케이스를 정의해주고 스터빙을 한다.\n\n\n\npublic interface NumbersGenerativeStrategy {}\n\npublic class RandomNumbersGenerativeStrategy implements NumbersGenerativeStrategy {}\n\npublic class Numbers {\n    public static Numbers from(NumbersGenerativeStrategy randomStrategy) {\n        return null;\n    }\n}\n\n\n\n\n다시 테스트를 실행해본다.\n\n\n\n\n\n\n\n테스트 케이스를 추가한다.\n\nnull이 입력되면 NPE가 발생하는지 검증하도록 한다.\n\n\n\nclass NumbersTests {\n    @Test\n    void from() {\n        assertThatCode(() -&gt; {\n            Numbers randomNumbers = Numbers.from(() -&gt; \"123\");\n        }).doesNotThrowAnyException();\n    }\n\n    @Test\n    void createExceptionWhenInNull() {\n        assertThatThrownBy(() -&gt; {\n            Numbers randomNumbers = Numbers.from(null);\n        }).isInstanceOf(NullPointerException.class);\n    }\n}\n\n\n\n\nExpecting code to raise a throwable.\n\tat io.github.shirohoo.baseball.app.domain.NumbersTests.createExceptionWhenInNull(NumbersTests.java:18)\n\n\n\n\n테스트가 실패하였다.\n\n구현을 해야 하는데, 일단 Numbers는 여기서 손 떼고 Numbers 생성을 책임지는 전략쪽으로 선회하는게 조금 더 편할 것 같다.\n\nNumbersGenerativeStrategy는 숫자를 생성하는 전략이다.\n\nRandomNumbersGenerativeStrategy는 1~9사이의 중복되지 않는 숫자 세개를 생성해야만 한다.\n\n검증은 어떻게 해야 할까?\n\n\n  우선 생성된 세 숫자의 중복을 제거하고도 숫자의 수가 3개여야 할 것이다.\n  1~9사이의 중복되지 않는 숫자 3개가 나오므로 최소로 나올 수 있는 수는 123이며, 최대로 나올 수 있는 수는 789이다. 따라서 세 숫자의 합 x는 6 &lt;= x &lt;= 24 여야 한다.\n  1,2번 테스트 케이스로도 충분히 검증은 될 것 같지만, 아무래도 랜덤수이다 보니 조금 더 신뢰성을 확보하기 위해 테스트를 100번 반복해야겠다.\n\n\n\n\nclass RandomNumbersGenerativeStrategyTests {\n    @RepeatedTest(100)\n    void generate() {\n        RandomNumbersGenerativeStrategy strategy = new RandomNumbersGenerativeStrategy();\n        String randomNumbers = strategy.generate();\n\n        assertThat(distinctCount(randomNumbers)).isEqualTo(3L);\n        assertThat(sum(randomNumbers)).isGreaterThanOrEqualTo(6).isLessThanOrEqualTo(24);\n    }\n\n    private long distinctCount(String randomNumbers) {\n        return stream(randomNumbers.split(\"\"))\n            .distinct()\n            .count();\n    }\n\n    private int sum(String randomNumbers) {\n        return stream(randomNumbers.split(\"\"))\n            .mapToInt(Integer::valueOf)\n            .sum();\n    }\n}\n\n\n\n\n스터빙을 하고 테스트를 실행하면 구현은 아예 없기 때문에 당연히 테스트는 실패한다.\n\n바로 구현에 들어간다.\n\n위 테스트만 만족하면 RandomNumbersGenerativeStrategy는 유효하다고 볼 수 있을 것 같다.\n\n구현 할 때 자바 17에 포함되어 릴리즈된 새로운 의사난수 생성기(RandomGenerator)를 사용해봤다.\n\n\n\npublic class RandomNumbersGenerativeStrategy implements NumbersGenerativeStrategy {\n    private static final RandomGenerator RANDOM_GENERATOR = RandomGenerator.getDefault();\n\n    public String generate() {\n        return RANDOM_GENERATOR.ints(1, 10)\n            .distinct()\n            .limit(3)\n            .mapToObj(String::valueOf)\n            .collect(joining());\n    }\n}\n\n\n\n\n다시 테스트를 실행한다.\n\n\n\n\n\n\n\n100번의 반복동안 모든 케이스가 한번도 실패하지 않았다.\n\n이정도면 충분히 검증이 되었다고 믿어도 될 것 같다.\n\n이제 Numbers가 NumbersGenerativeStrategy를 받아 인스턴스를 생성하는 부분을 구현할건데, 코드를 보니 Numbers는 내부적으로 문자열을 포함해야 할 것 같다.\n\n객체지향 프로그래밍을 할 때 중요한 것은 항상 데이터 -&gt; 행동이 아닌, 행동 -&gt; 데이터 순으로 생각해야만 한다는 것이다.\n\n데이터 중심적인 사고를 버리고 책임,역할과 행동 중심적인 사고를 길러야 한다 !\n\n\n\npublic class Numbers {\n    private final String numbers;\n\n    private Numbers(String numbers) {\n        this.numbers = numbers;\n    }\n\n    public static Numbers from(NumbersGenerativeStrategy strategy) {\n        return new Numbers(strategy.generate());\n    }\n}\n\n\n\n\n구현하고 다시 Numbers 테스트를 실행했다.\n\n\n\n\n\n\n\n아주 잘 된다.\n\n이제보니 리팩토링 할 건덕지가 보인다.\n\nNumbers를 record 클래스로 변경해도 좋을 것 같다.\n\n변경하고 다시 테스트를 실행해보자.\n\n\n\npublic record Numbers(String numbers) {\n    public static Numbers from(NumbersGenerativeStrategy strategy) {\n        return new Numbers(strategy.generate());\n    }\n}\n\n\n\n\n\n\n\n\n사용자가 3개의 숫자를 입력해올 것인데, 이 숫자도 1~9사이의 중복되지 않는 랜덤한 수인지를 판별할 수 있게 정적 팩토리 메서드를 하나 열어봐야겠다는 생각이 들었다.\n\n우선 테스트 케이스를 추가한다.\n\n사용자 입력이 null, empty, 4자리 이상, 중복되는 수 포함, 0이 포함된 경우 예외가 발생되도록 할 것이다.\n\n\n\nclass NumbersTests {\n\n    ...\n    \n    @ParameterizedTest\n    @NullAndEmptySource\n    @ValueSource(strings = {\"012\", \"890\", \"111\", \"112\", \"1234\", \"1111\"})\n    void createExceptionWhenNot3NonOverlappingNumbersForUserInput(String userInput) {\n        assertThatThrownBy(() -&gt; {\n            Numbers randomNumbers = Numbers.nonOverlapping3digits(userInput);\n        }).isInstanceOf(IllegalArgumentException.class);\n    }\n}\n\n\n\n\n새로 추가한 테스트를 실행하면 모든 케이스가 실패한다.\n\n\n\n\n\n\n\n구현하자.\n\n\n\npublic record Numbers(String numbers) {\n    public static Numbers from(NumbersGenerativeStrategy strategy) {\n        return new Numbers(strategy.generate());\n    }\n\n    public static Numbers nonOverlapping3digits(String userInput) {\n        if (userInput == null || userInput.isBlank()) {\n            throw new IllegalArgumentException(\"'userInput' must not be null or empty\");\n        }\n\n        if (userInput.contains(\"0\")) {\n            throw new IllegalArgumentException(\"'userInput' must not be contain '0'\");\n        }\n\n        long count = stream(userInput.split(\"\")).distinct().count();\n        if (count != 3) {\n            throw new IllegalArgumentException(\"'userInput' must be three non-overlapping numbers\");\n        }\n\n        int sum = stream(userInput.split(\"\")).mapToInt(Integer::valueOf).sum();\n        if (sum &lt; 6 || sum &gt; 24) {\n            throw new IllegalArgumentException(\"sum of 'userInput' must be 6 &lt;= x &lt;= 24\");\n        }\n        return new Numbers(userInput);\n    }\n}\n\n\n\n\n다시 테스트를 실행해봤다.\n\n\n\n\n\n\n\n이제 랜덤하게 생성된 Numbers와 사용자의 입력을 받아 생성된 Numbers 를 비교하여 볼, 스트라이크 카운트를 반환해주는 심판(Referee) 객체를 구현 할 것이다.\n\n심판은 오로지 두개의 숫자(Numbers)를 비교하여 판정(decision)하고 판정 결과(DecisionResult)를 반환 할 것이다.\n\n그리고 심판이 반환한 판정 결과에는 볼, 스트라이크 카운트가 포함돼있을 것이다.\n\n테스트 코드를 작성 할 때, 볼과 스트라이크가 나올 수 있는 경우의 수를 최대한 고려해 테스트 케이스에 추가했다.\n\n\n\nclass RefereeTests {\n    @MethodSource\n    @ParameterizedTest\n    void decision(Numbers userNumbers, DecisionResult expected) {\n        Referee referee = new Referee();\n        Numbers computerNumbers = Numbers.nonOverlapping3digits(\"123\");\n\n        DecisionResult decisionResult = referee.decision(computerNumbers, userNumbers);\n\n        assertThat(decisionResult).isEqualTo(expected);\n    }\n\n    static Stream&lt;Arguments&gt; decision() {\n        return Stream.of(\n            Arguments.of(Numbers.nonOverlapping3digits(\"123\"), DecisionResult.of(0, 3)),\n            Arguments.of(Numbers.nonOverlapping3digits(\"124\"), DecisionResult.of(0, 2)),\n            Arguments.of(Numbers.nonOverlapping3digits(\"145\"), DecisionResult.of(0, 1)),\n            Arguments.of(Numbers.nonOverlapping3digits(\"135\"), DecisionResult.of(1, 1)),\n            Arguments.of(Numbers.nonOverlapping3digits(\"132\"), DecisionResult.of(2, 1)),\n            Arguments.of(Numbers.nonOverlapping3digits(\"345\"), DecisionResult.of(1, 0)),\n            Arguments.of(Numbers.nonOverlapping3digits(\"234\"), DecisionResult.of(2, 0)),\n            Arguments.of(Numbers.nonOverlapping3digits(\"789\"), DecisionResult.of(0, 0))\n        );\n    }\n}\n\n\n\n\n우선 DecisionResult를 record 클래스로 하나 생성했다.\n\n\n\npublic record DecisionResult(int ballCount, int strikeCount) {\n    public static DecisionResult of(int ballCount, int strikeCount) {\n        return new DecisionResult(ballCount, strikeCount);\n    }\n}\n\n\n\n\n이제 심판이 판정 후 DecisionResult를 반환할 것인데, 두개의 Numbers를 비교하는 알고리즘을 구현해야 한다.\n\n해보자.\n\n\n\npublic class Referee {\n    public DecisionResult decision(Numbers computerNumbers, Numbers userNumbers) {\n        int ballCount = 0;\n        int strikeCount = 0;\n        for (int i = 0; i &lt; computerNumbers.numbers().length(); i++) {\n            ballCount += ifBallIncreaseByOne(i, computerNumbers, userNumbers);\n            strikeCount += ifStrikeIncreaseByOne(i, computerNumbers, userNumbers);\n        }\n        return DecisionResult.of(ballCount, strikeCount);\n    }\n\n    private int ifBallIncreaseByOne(int i, Numbers computerNumbers, Numbers userNumbers) {\n        if (computerNumbers.numbers().charAt(i) != userNumbers.numbers().charAt(i) &amp;&amp;\n            userNumbers.numbers().contains(Character.toString(computerNumbers.numbers().charAt(i)))\n        ) {\n            return 1;\n        }\n        return 0;\n    }\n\n    private int ifStrikeIncreaseByOne(int i, Numbers computerNumbers, Numbers userNumbers) {\n        if (computerNumbers.numbers().charAt(i) == userNumbers.numbers().charAt(i)) {\n            return 1;\n        }\n        return 0;\n    }\n}\n\n\n\n\n알고리즘의 시간복잡도는 O(N)으로 썩 훌륭하진 않지만, 더 좋은 방법이 생각나지 않아 일단 이렇게 구현했다.\n\n어차피 N이 최대 3이라 이정도만 해도 아무 문제 없을 것 같기도 하고…\n\n이제 테스트 코드를 실행해보자.\n\n\n\n\n\n\n\n정의한 모든 케이스가 통과되는 것을 확인했다.\n\n이쯤에서 도메인 구현은 얼추 끝이 난 것 같다.\n\n\n\n\n\n\n\n이제 유스케이스를 하나 구현할것인데, 게임이 시작되면 3스트라이크가 될 때까지 사용자의 입력이 도메인에 계속 들어와야 한다.\n\n이를 유저가 숫자 야구 게임(BaseBall)을 한번 시도했음으로 표현해야겠다.\n\n경험상 유스케이스는 이미 테스트 코드로 검증된 도메인 객체들을 갖다 사용하므로 바로 구현에 들어가도 무방하다.\n\n이미 테스트 된 것은 다시 테스트하지 말라는 말이 있기 때문이다. (DRY 원칙)\n\n유스케이스가 생성될 때 심판과 컴퓨터의 랜덤수를 포함하고, 사용자 입력을 받아 계속 결과를 반환하도록 작성해보자.\n\n\n\npublic interface BaseBall {\n    DecisionResult action(String input);\n}\n\n\n\n\npublic class BaseBallImpl implements BaseBall {\n    private final Referee referee;\n    private final Numbers computerNumbers;\n\n    private BaseBallImpl(Referee referee, Numbers computerNumbers) {\n        this.referee = referee;\n        this.computerNumbers = computerNumbers;\n    }\n\n    public static BaseBall of(Referee referee, NumbersGenerativeStrategy strategy) {\n        return new BaseBallImpl(referee, Numbers.create(strategy));\n    }\n\n    @Override\n    public DecisionResult action(String input) {\n        return referee.decision(computerNumbers, Numbers.nonOverlapping3digits(input));\n    }\n}\n\n\n\n\n여기까지 하고 보니, 애플리케이션 외부에서 String을 직접적으로 받는게 마음에 들지 않는다.\n\n이러면 유저가 입력하는 데이터의 타입을 외부에 직접적으로 노출하게 되어 외부에서는 항상 String으로만 입력할 수 밖에 없게 된다.\n\n모든 구현이 이 정의에 종속되기 때문이다.\n\n\n\n따라서, 이를 UserInput으로 추상화 하고, Numbers.nonOverlapping3digits()에 있던 유효성 검사 코드를 모두 UserInput으로 옮겨와야겠다.\n\n굉장히 많은 구조 변경이 예상되지만, 걱정할 것은 없다.\n\n여지껏 작성한 테스트 코드가 보호해줄 것이다.\n\n과감하게 구조 변경에 들어간다.\n\n우선 모든 테스트 코드를 적절하게 옮기고 더이상 필요하지 않은 코드들은 제거하는 작업들을 해 주었다.\n\n\n\nclass NumbersTests {\n    @Test\n    void from() {\n        assertThatCode(() -&gt; {\n            Numbers randomNumbers = Numbers.from(() -&gt; \"123\");\n        }).doesNotThrowAnyException();\n    }\n}\n\n\n\n\nclass RefereeTests {\n    @MethodSource\n    @ParameterizedTest\n    void decision(UserInput userInput, DecisionResult expected) {\n        Referee referee = new Referee();\n        Numbers computerNumbers = Numbers.from(\"123\");\n\n        DecisionResult decisionResult = referee.decision(computerNumbers, userInput.createNumbers());\n\n        assertThat(decisionResult).isEqualTo(expected);\n    }\n\n    static Stream&lt;Arguments&gt; decision() {\n        return Stream.of(\n            Arguments.of(UserInput.nonOverlapping3digits(\"123\"), DecisionResult.of(0, 3)),\n            Arguments.of(UserInput.nonOverlapping3digits(\"124\"), DecisionResult.of(0, 2)),\n            Arguments.of(UserInput.nonOverlapping3digits(\"145\"), DecisionResult.of(0, 1)),\n            Arguments.of(UserInput.nonOverlapping3digits(\"135\"), DecisionResult.of(1, 1)),\n            Arguments.of(UserInput.nonOverlapping3digits(\"132\"), DecisionResult.of(2, 1)),\n            Arguments.of(UserInput.nonOverlapping3digits(\"345\"), DecisionResult.of(1, 0)),\n            Arguments.of(UserInput.nonOverlapping3digits(\"234\"), DecisionResult.of(2, 0)),\n            Arguments.of(UserInput.nonOverlapping3digits(\"789\"), DecisionResult.of(0, 0))\n        );\n    }\n}\n\n\n\n\n그리고 UserInputTests 를 새로 만들어 Numbers의 테스트 케이스를 여기로 옮겼다.\n\n\n\nclass UserInputTests {\n    @ParameterizedTest\n    @NullAndEmptySource\n    @ValueSource(strings = {\"012\", \"890\", \"111\", \"112\", \"1234\", \"1111\"})\n    void createExceptionWhenNot3NonOverlappingNumbersForUserInput(String userInput) {\n        assertThatThrownBy(() -&gt; {\n            UserInput userNumbers = UserInput.nonOverlapping3digits(userInput);\n        }).isInstanceOf(IllegalArgumentException.class);\n    }\n\n    @Test\n    void createNumbers() {\n        UserInput userInput = UserInput.nonOverlapping3digits(\"123\");\n        assertThat(userInput.createNumbers()).isEqualTo(Numbers.from(\"123\"));\n    }\n}\n\n\n\n\n모든 테스트 케이스가 통과할 수 있게 Numbers와 UserInput간의 책임을 재분배해준다.\n\n\n\npublic record Numbers(String numbers) {\n    public static Numbers from(NumbersGenerativeStrategy strategy) {\n      return new Numbers(strategy.generate());\n    }\n\n    public static Numbers from(String input) {\n      return new Numbers(input);\n    }\n}\n\n\n\n\npublic class UserInput {\n    private final String userInput;\n\n    private UserInput(String input) {\n        if (input == null || input.isBlank()) {\n            throw new IllegalArgumentException(\"'userInput' must not be null or empty\");\n        }\n\n        if (input.contains(\"0\")) {\n            throw new IllegalArgumentException(\"'userInput' must not be contain '0'\");\n        }\n\n        long count = stream(input.split(\"\")).distinct().count();\n        if (count != 3) {\n            throw new IllegalArgumentException(\"'userInput' must be three non-overlapping numbers\");\n        }\n\n        int sum = stream(input.split(\"\")).mapToInt(Integer::valueOf).sum();\n        if (sum &lt; 6 || sum &gt; 24) {\n            throw new IllegalArgumentException(\"sum of 'userInput' must be 6 &lt;= x &lt;= 24\");\n        }\n        this.userInput = input;\n    }\n\n    public static UserInput nonOverlapping3digits(String input) {\n        return new UserInput(input);\n    }\n\n    public Numbers createNumbers(){\n        return Numbers.from(userInput);\n    }\n}\n\n\n\n\n변경된 코드에 맞춰 BaseBallImpl도 수정해주자.\n\n\n\npublic class BaseBallImpl implements BaseBall {\n    private final Referee referee;\n    private final Numbers computerNumbers;\n\n    private BaseBallImpl(Referee referee, Numbers computerNumbers) {\n        this.referee = referee;\n        this.computerNumbers = computerNumbers;\n    }\n\n    public static BaseBall of(Referee referee, NumbersGenerativeStrategy strategy) {\n        return new BaseBallImpl(referee, Numbers.from(strategy));\n    }\n\n    @Override\n    public DecisionResult action(UserInput input) {\n        return referee.decision(computerNumbers, input.createNumbers());\n    }\n}\n\n\n\n\n\n다시 테스트를 실행하면…\n\n\n\n\n\n\n\n\n\n\n\n여기까지의 패키지 구조는 다음과 같다.\n\n\n\n\n\n\n\n이제 마지막으로 콘솔 입력과 콘솔 출력을 구현하고, 콘솔 애플리케이션을 구현 할 차례다.\n\n이부분은 요구사항에 의거하여 테스트 코드를 작성하지 않아도 되므로 구현에 집중하도록 하자.\n\n사실 굳이 요구사항이 아니더라도 외부의 입력은 도메인에서 신경 쓸 필요가 없다고 생각한다.\n\n단지 도메인 스스로 유효성 검사만 잘 하면 될 뿐이다.\n\n\n\npublic class ConsoleInput {\n    private final Scanner scanner;\n\n    public ConsoleInput() {\n        this.scanner = new Scanner(System.in);\n    }\n\n    public UserInput trys() {\n        return UserInput.nonOverlapping3digits(scanner.nextLine());\n    }\n\n    public boolean restartIntentions() {\n        int intentions = scanner.nextInt();\n        if (intentions == 1) {\n            return true;\n        }\n        if (intentions == 2) {\n            return false;\n        }\n        throw new IllegalArgumentException(String.format(\"'%s' is unknown.\", intentions));\n    }\n}\n\n\n\n\npublic class ConsoleOutput {\n    private static final String ENTER_NUMBER_MESSAGE = \"숫자를 입력해 주세요 : \";\n    private static final String BALL_MESSAGE = \"볼\";\n    private static final String STRIKE_MESSAGE = \"스트라이크\";\n    private static final String NOTHING_MESSAGE = \"낫싱\";\n    private static final String COMPLETE_MESSAGE = \"3개의 숫자를 모두 맞히셨습니다! 게임 종료\";\n    private static final String RESTART_MESSAGE = \"게임을 새로 시작하려면 1, 종료하려면 2를 입력하세요.\";\n\n    public void enterNumberMessage() {\n        print(ENTER_NUMBER_MESSAGE);\n    }\n\n    public void resultMessage(DecisionResult result) {\n        if (result.ballCount() == 0 &amp;&amp; result.strikeCount() == 0) {\n            println(NOTHING_MESSAGE);\n        }\n        if (result.ballCount() &gt; 0 &amp;&amp; result.strikeCount() == 0) {\n            println(result.ballCount() + BALL_MESSAGE);\n        }\n        if (result.ballCount() == 0 &amp;&amp; result.strikeCount() &gt; 0) {\n            println(result.strikeCount() + STRIKE_MESSAGE);\n        }\n        if (result.ballCount() &gt; 0 &amp;&amp; result.strikeCount() &gt; 0) {\n            println(String.format(\"%s%s %s%s\",\n                result.ballCount(), BALL_MESSAGE,\n                result.strikeCount(), STRIKE_MESSAGE\n            ));\n        }\n        if (result.strikeCount() == 3) {\n            println(COMPLETE_MESSAGE);\n        }\n    }\n\n    public void restartMessage() {\n        println(RESTART_MESSAGE);\n    }\n\n    private void print(String message) {\n        System.out.print(message);\n    }\n\n    private void println(String message) {\n        System.out.println(message);\n    }\n}\n\n\n\n\npublic class ConsoleBaseBallApp {\n    public static void main(String[] args) {\n        Runner.init().run();\n    }\n\n    private static class Runner {\n        private static Runner init() {\n            return new Runner();\n        }\n\n        private void run() {\n            ConsoleInput input = new ConsoleInput();\n            ConsoleOutput output = new ConsoleOutput();\n            BaseBall game = BaseBallImpl.of(new Referee(), new RandomNumbersGenerativeStrategy());\n\n            DecisionResult result;\n            do {\n                output.enterNumberMessage();\n                result = game.action(input.trys());\n                output.resultMessage(result);\n            } while (result.strikeCount() != 3);\n\n            output.restartMessage();\n            if (input.restartIntentions()) {\n                run();\n            }\n            System.exit(0);\n        }\n    }\n}\n\n\n\n\n출력 메시지를 결정하는 코드가 별로 마음에 안든다.\n\nDecisionResult 내부의 구현을 모조리 외부로 노출하고 있기 때문이다.\n\n모든 경우의 수를 스스로 판별하도록 위임해야겠다.\n\n항상 그랬듯이 우선 테스트 케이스를 작성한다.\n\n\n\nclass DecisionResultTests {\n    @Test\n    void isBallAndStrike() {\n        DecisionResult result = DecisionResult.of(1, 1);\n        assertThat(result.isBallAndStrike()).isTrue();\n        assertThat(result.isNothing()).isFalse();\n        assertThat(result.isOnlyBall()).isFalse();\n        assertThat(result.isOnlyStrike()).isFalse();\n        assertThat(result.isStrikeOut()).isFalse();\n    }\n\n    @Test\n    void isNothing() {\n        DecisionResult result = DecisionResult.of(0, 0);\n        assertThat(result.isBallAndStrike()).isFalse();\n        assertThat(result.isNothing()).isTrue();\n        assertThat(result.isOnlyBall()).isFalse();\n        assertThat(result.isOnlyStrike()).isFalse();\n        assertThat(result.isStrikeOut()).isFalse();\n    }\n\n    @Test\n    void isOnlyBall() {\n       DecisionResult result = DecisionResult.of(1, 0);\n        assertThat(result.isBallAndStrike()).isFalse();\n        assertThat(result.isNothing()).isFalse();\n        assertThat(result.isOnlyBall()).isTrue();\n        assertThat(result.isOnlyStrike()).isFalse();\n        assertThat(result.isStrikeOut()).isFalse();\n    }\n\n    @Test\n    void isOnlyStrike() {\n       DecisionResult result = DecisionResult.of(0, 1);\n        assertThat(result.isBallAndStrike()).isFalse();\n        assertThat(result.isNothing()).isFalse();\n        assertThat(result.isOnlyBall()).isFalse();\n        assertThat(result.isOnlyStrike()).isTrue();\n        assertThat(result.isStrikeOut()).isFalse();\n    }\n\n    @Test\n    void isStrikeOut() {\n        DecisionResult result = DecisionResult.of(0, 3);\n        assertThat(result.isBallAndStrike()).isFalse();\n        assertThat(result.isNothing()).isFalse();\n        assertThat(result.isOnlyBall()).isFalse();\n        assertThat(result.isOnlyStrike()).isTrue();\n        assertThat(result.isStrikeOut()).isTrue();\n    }\n}\n\n\n\n\n\n\n\n\n이제 모든 테스트 케이스가 통과하도록 구현을 해주자.\n\n\n\npublic record DecisionResult(int ballCount, int strikeCount) {\n    public static DecisionResult of(int ballCount, int strikeCount) {\n        return new DecisionResult(ballCount, strikeCount);\n    }\n\n    public boolean isBallAndStrike() {\n        return ballCount() &gt; 0 &amp;&amp; strikeCount() &gt; 0;\n    }\n\n    public boolean isNothing() {\n        return ballCount() == 0 &amp;&amp; strikeCount() == 0;\n    }\n\n    public boolean isOnlyBall() {\n        return ballCount() &gt; 0 &amp;&amp; strikeCount() == 0;\n    }\n\n    public boolean isOnlyStrike() {\n        return ballCount() == 0 &amp;&amp; strikeCount() &gt; 0;\n    }\n\n    public boolean isStrikeOut() {\n        return strikeCount == 3;\n    }\n}\n\n\n\n\n이제 다시 테스트를 실행하면…\n\n\n\n\n\n\n\n\n\n\n\n이제 새로 작성한 메서드들로 기존 코드들을 리팩토링 해준다.\n\n\n\npublic class ConsoleOutput {\n    private static final String ENTER_NUMBER_MESSAGE = \"숫자를 입력해 주세요 : \";\n    private static final String BALL_MESSAGE = \"볼\";\n    private static final String STRIKE_MESSAGE = \"스트라이크\";\n    private static final String NOTHING_MESSAGE = \"낫싱\";\n    private static final String COMPLETE_MESSAGE = \"3개의 숫자를 모두 맞히셨습니다! 게임 종료\";\n    private static final String RESTART_MESSAGE = \"게임을 새로 시작하려면 1, 종료하려면 2를 입력하세요.\";\n\n    public void enterNumberMessage() {\n        print(ENTER_NUMBER_MESSAGE);\n    }\n\n    public void resultMessage(DecisionResult result) {\n        if (result.isBallAndStrike()) {\n            println(result.ballCount() + BALL_MESSAGE + \" \" + result.strikeCount() + STRIKE_MESSAGE);\n            return;\n        }\n\n        if (result.isNothing()) {\n            println(NOTHING_MESSAGE);\n            return;\n        }\n\n        if (result.isOnlyBall()) {\n            println(result.ballCount() + BALL_MESSAGE);\n            return;\n        }\n\n        if (result.isOnlyStrike()) {\n            println(result.strikeCount() + STRIKE_MESSAGE);\n            if (result.isStrikeOut()) {\n                println(COMPLETE_MESSAGE);\n            }\n        }\n    }\n\n    public void restartMessage() {\n        println(RESTART_MESSAGE);\n    }\n\n    private void print(String message) {\n        System.out.print(message);\n    }\n\n    private void println(String message) {\n        System.out.println(message);\n    }\n}\n\n\n\n\n빠른 리턴을 통해 앞의 조건문이 충족됐다면 후속 조건문은 런타임에 실행되지 않도록 약간의 최적화를 곁들여줬다.\n\n\n\nConsoleBaseBallApp도 리팩토링 해주자.\n\n\n\npublic class ConsoleBaseBallApp {\n    public static void main(String[] args) {\n        Runner.init().run();\n    }\n\n    private static class Runner {\n        private static Runner init() {\n            return new Runner();\n        }\n\n        private void run() {\n            ConsoleInput input = new ConsoleInput();\n            ConsoleOutput output = new ConsoleOutput();\n            BaseBall game = BaseBall.create(new Referee(), new RandomNumbersGenerativeStrategy());\n\n            DecisionResult result;\n            do {\n                output.enterNumberMessage();\n                result = game.action(input.trys());\n                output.resultMessage(result);\n            } while (!result.isStrikeOut()); // &lt;--- 요기 !\n\n            output.restartMessage();\n            if (input.restartIntentions()) {\n                run();\n            }\n            System.exit(0);\n        }\n    }\n}\n\n\n\n\n여기까지 전체적인 패키지 구조는 다음과 같다.\n\n\n\n\n\n\n\n이제 게임을 실행해보자.\n\n\n\n\n\n\n\n잘 된다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-02-09-diary-32/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "운영체제(Operating System) 2강",
      "date": "2022-02-13 00:00:00 +0000",
      "description": "반효경 교수님 - Process &amp; Thread\n",
      "content": "\n  Lecture\n  Process    \n      Context        \n          Hardware context\n          Process memory\n          Process-related kernel data structures\n        \n      \n      State of the process        \n          State diagram of the process\n          Example of a process state transition\n        \n      \n      Process Control Block (PCB)\n      Context Switch        \n          시스템 콜이나 인터럽트가 발생하면 항상 문맥 교환이 일어나는가?\n        \n      \n      Ready Queue &amp; various Device Queue        \n          Job Queue\n          Ready Queue\n          Device Queues\n        \n      \n      CPU Scheduler        \n          Long-Term Scheduler (장기 스케줄러 or Job scheduler)\n          Short-Term Scheduler (단기 스케줄러 or CPU scheduler)\n          Medium-Term Scheduler (중기 스케줄러 or Swapper)\n        \n      \n      State diagram of the process with Suspended added\n    \n  \n  Thread    \n      정의\n      구성\n      The part that one thread shares with other threads\n      장점        \n          응답성 (Responsiveness)\n          자원 공유 (Resource Sharing)\n          경제성 (Economy)\n          멀티 프로세서 아키텍처에서의 이용성 (Utilization of MP Architectures)\n        \n      \n    \n  \n\n\n\n\nLecture\n\n\n\n\n  운영체제 - 반효경 교수님\n    \n      Process 1\n      Process 2\n      Process 3\n    \n  \n\n\n\n\nProcess\n\n\n\n프로그램은 보조기억장치에 저장돼있는 코드 덩어리이며, 프로세스는 메모리에 올라간 프로그램이다.\n\n보조기억장치에 실행 파일 형태로(exe, jar 등) 존재하던 프로그램이 메모리에 올라가면 비로소 CPU를 할당받을 수 있는 자격을 얻게된다.\n\n\n\nContext\n\n\n\n프로세스가 실행돼서 종료될 때까지 항상 CPU에서 명령을 처리하면 좋겠지만, 여러 프로세스가 함께 수행되는 시분할 환경에서는 각 프로세스들이 CPU를 자주 빼앗기고 획득하게 된다.\n\n따라서 CPU를 다시 획득해 명령의 수행을 재개하는 시점이 되면, CPU를 빼앗기기 전에 어느 부분까지 명령을 수행했는지 정확한 프로세스의 상태를 재현할 필요가 있다.\n\n이때 정확한 재현을 위해 필요한 정보가 바로 프로세스의 문맥(Context)이다.\n\n즉, 프로세스의 문맥은 프로세스의 메모리(Stack, Data, Code)를 비롯해 CPU 레지스터에 저장된 데이터, 시스템 콜을 통해 커널에서 수행한 작업들의 현황, 프로세스에 대해 커널이 관리하고 있는 각종 정보 등을 포함하게 된다.\n\n프로세스의 문맥은 3가지로 나눌 수 있다.\n\n\n\n\n\n\n\nHardware context\n\n\n\nCPU에 저장된 여러 데이터들을 의미한다. (프로그램 카운터, 레지스터 등등등)\n\n\n\nProcess memory\n\n\n\nStack, Data, Code에 들어 있는 데이터들을 의미한다.\n\n\n\nProcess-related kernel data structures\n\n\n\nPCB (Process Control Block)\n\nPCB는 운영 체제가 프로세스에 대한 관리를 위해 프로세스의 모든 정보를 저장하는 자료구조이다.\n\nPCB는 운영 체제의 메모리에 위치한다.\n\n\n\nState of the process\n\n\n\n프로세스의 상태는 계속해서 변경된다.\n\n\n\n\n  실행 (Running)\n    \n      CPU를 할당받아 명령이 처리되고 있는 상태\n    \n  \n  준비 (Ready)\n    \n      메모리에 프로그램이 올라가 있으며, CPU를 할당받기 위해 대기하고 있는 상태\n    \n  \n  봉쇄 (Blocked, Wait, Sleep)\n    \n      메모리에 프로그램이 올라가 있지만, CPU를 할당받더라도 당장 명령을 실행할 수 없는 상태\n      프로세스가 요청한 이벤트(I/O 등)가 완료 되지 않아 이를 기다리는 상태\n    \n  \n  시작 (New)\n    \n      프로세스가 생성 중인 상태\n    \n  \n  완료 (Terminated)\n    \n      프로세스가 종료되는 상태\n    \n  \n\n\n\n\n추후 중기 스케쥴러가 등장하며 Suspended 상태가 추가된다.\n\n\n\nState diagram of the process\n\n\n\n\n\n\n  프로세스가 생성되면 New 에서 Ready 가 된다.\n  Ready 에서 CPU를 할당받으면 Running 이 된다.\n  CPU 얻은 상태에서 내려 놓는 경우\n    \n      Running → Terminated : 본인의 역할을 다하면 종료됨\n      Running → Waiting : I/O 같은 작업을 하면, CPU가 Blocking 되어 명령을 수행할 수 없으므로 Waiting 이 된다.\n      Running → Ready : Timer에 지정 된 CPU 사용시간이 끝나면 Ready 가 된다.\n    \n  \n\n\n\n\nExample of a process state transition\n\n\n\n\n\n\n\n놀이동산에서 기구별로 줄 서서 타는것을 생각하면 이해가 편하다.\n\n즉, 사람이 프로세스이며 각 장치들이 놀이동산 기구라고 생각하면 된다.\n\n\n\nProcess Control Block (PCB)\n\n\n\n\n\n\n\nPCB란 운영 체제가 프로세스들을 관리하기 위해 각 프로세스들의 정보를 담는 커널 내의 자료구조이다.\n\n\n\nContext Switch\n\n\n\n문맥 교환이란 하나의 사용자 프로세스로부터 다른 사용자 프로세스로 CPU의 제어권을 넘겨주는 과정으로, CPU의 현재 상태, 프로세스의 현재 상태들을 모두 정리하여 PCB에 저장한 후 캐시 메모리를 비우는 작업이 진행된다.\n\n즉, 오버헤드가 무지막지하게 크게 발생하기 때문에 프로그램 개발 시 이것으로 인해 성능 저하가 매우 크게 일어나므로 아주 중요한 개념이라고 생각된다.\n\n\n\n\n\n\n\n사용자 프로세스가 CPU를 할당 받고 실행되던 중에 타이머 인터럽트가 발생하면 CPU의 제어권이 운영체제에게 넘어가게 된다.\n\n운영 체제는 ISR을 통해 타이머 인터럽트 처리를 시작하며, 직전까지 수행 중이던 프로세스의 모든 상태를 PCB에 저장하고 Ready 상태의 프로세스에게 CPU의 제어권을 넘긴다.\n\n이 과정에서 원래 수행 중이던 프로세스는 Running-&gt;Ready등의 상태로 바뀌고 새롭게 CPU를 할당 받은 프로세스는 Ready-&gt;Running 상태가 된다.\n\n문맥 교환 중 원래 CPU를 할당받았던 프로세스는 자신의 모든 상태를 자신의 PCB에 저장하고, 새롭게 CPU를 할당 받은 프로세스는 예전에 저장했던 자신의 상태를 자신의 PCB로부터 불러오는 과정을 거친다.\n\n\n\n시스템 콜이나 인터럽트가 발생하면 항상 문맥 교환이 일어나는가?\n\n\n\n아니다\n\n\n\n\n\n\n\n1번의 경우는 프로세스가 Running 상태일 때 시스템 콜이나 인터럽트가 발생하여 CPU의 제어권이 운영 체제로 넘어가 프로세스가 잠시 멈추고 운영 체제의 함수가 실행된 경우다.\n\n이 경우에도 프로세스의 문맥 중 일부를 PCB에 저장한다.\n\n하지만, 프로세스는 계속 Running인 상태에 Mode bit를 통해 실행 모드가 사용자 모드에서 커널 모드로 바뀌는 것일 뿐이고, CPU를 점유하는 프로세스가 다른 사용자 프로세스로 변경되는 것이 아니므로 이는 문맥 교환이 아니다.\n\n2번의 경우는 타이머 인터럽트가 발생하거나 프로세스가 Blocked 상태가 된 경우다.\n\n이 때는 운영 체제의 관리를 통해 다른 사용자 프로세스에게 CPU의 제어권을 넘기게 되므로 문맥 교환이 발생한다.\n\n\n\nReady Queue &amp; various Device Queue\n\n\n\n\n\n\n\nJob Queue\n\n\n\n현재 시스템 내에 있는 모든 프로세스 집합으로 Ready Queue 와 Device Queues를 모두 포함하는 개념이다.\n\n\n\nReady Queue\n\n\n\n상태가 Ready인 프로세스의 집합이다.\n\n\n\nDevice Queues\n\n\n\n상태가 Blocked인 프로세스의 집합이다.\n\n\n\nCPU Scheduler\n\n\n\n스케줄러란 어떤 프로세스에게 CPU를 할당할지를 결정하는 운영 체제 함수를 의미한다.\n\n스케줄러에는 3가지 스케줄러가 존재한다.\n\n\n\nLong-Term Scheduler (장기 스케줄러 or Job scheduler)\n\n\n\n\n  New 상태의 프로세스들 중 어떤 것들을 Ready Queue로 보낼지 결정한다.\n  프로세스에 메모리를 할당하는 문제에 관여한다.\n  degree of Multiprogramming을 제어. 메모리에 프로세스가 10개 올라가있다면 degree of Multiprogramming 는 10이다.\n  degree of Multiprogramming이 너무 낮아도 CPU 효율이 제대로 안나오고(CPU가 놀아서), 너무 높아도 효율이 안나온다(컨텍스트 스위칭 등).\n  현대의 시분할 시스템에는 보통 장기 스케줄러가 없다. New 상태의 프로세스는 전부 Ready Queue에 삽입한다.\n\n\n\n\nShort-Term Scheduler (단기 스케줄러 or CPU scheduler)\n\n\n\n\n  어떤 프로세스를 다음 번에 Running 할지 결정\n  프로세스에 CPU를 주는 문제\n  충분히 빨라야 한다. (ms 단위)\n\n\n\n\nMedium-Term Scheduler (중기 스케줄러 or Swapper)\n\n\n\n\n  메모리 여유 공간 마련을 위해 프로세스를 통째로 디스크의 스왑 영역으로 밀어낸다. (Swap Out)\n  장기 스케쥴러가 없는 시스템(현대의 컴퓨터 시스템)에서 degree of Multiprogramming을 제어\n  주로 Blocked 상태에 있는 프로세스들을 Swap out하고, 그래도 메모리 공간이 부족하면 Ready Queue 후반부에 있는 프로세스들을 Swap out한다.\n\n\n\n\nState diagram of the process with Suspended added\n\n\n\n중기 스케줄러의 등장으로 인해 프로세스의 상태에는 New, Ready, Running, Blocked, Terminated 외에 하나의 상태가 더 추가된다.\n\n외부적인 이유로 프로세스의 수행이 정지된 상태를 나타내는 중지(Suspended or Stopped) 상태가 바로 그것이다.\n\n중지 상태에 있는 프로세스는 외부에서 재개해야만 다시 활성화될 수 있다.\n\n이 중지 상태의 프로세스는 메모리를 조금도 할당받지 못한 swap out된 프로세스라고 생각하면 된다.\n\n\n\n\n\n\n\n중지 상태는 중지 준비 상태와 중지 봉쇄 상태로 세분화할 수 있다.\n\nReady 상태에 있던 프로세스가 중기 스케줄러에 의해 디스크로 swap out되면 이 프로세스의 상태는 중지 준비 상태가 된다.\n\n이에 비해 Blocked 상태에 있던 프로세스가 중기 스케줄러에 의해 swap out되면 이 프로세스의 상태는 중지 봉쇄 상태가 된다.\n\n참고로 중지 봉쇄 상태이던 프로세스가 봉쇄되었던 조건을 만족하게 되면 중지 준비 상태로 바뀐다.\n\n\n\nThread\n\n\n\n정의\n\n프로세스 내에서 실행 되는 작업 흐름의 단위, 혹은 프로세스가 할당 받은 자원을 이용하는 실행 흐름의 단위를 뜻한다.\n\n구성\n\n\n\n\n\n각 스레드마다 각자 CPU 관련 정보들을 가지고 있다.\n\n\n\nThe part that one thread shares with other threads\n\n\n\n\n\n\n\n\n  Code section\n  Data section\n  OS resources\n\n\n각 스레드는 프로세스의 Data, Code 영역을 공유하며, Stack은 스레드 별로 별도로 할당 받는다.\n\nPCB에서는 프로그램 카운터와 레지스터 셋을 제외한 프로세스 관련 정보를 모두 공유한다.\n\n여기서 스레드들이 공유하는 부분인 Code section, Data section, OS resources를 task라고 한다.\n\n그래서 전통적인 개념의 heavyweight process는 하나의 스레드를 가지고 있는 task라고 볼 수 있다.\n\n\n\n장점\n\n\n  \n    응답성 (Responsiveness)\n  \n\n\n멀티 스레드로 구성된 프로세스에서 하나의 스레드가 Blocked 상태인 동안에도 동일한 프로세스내의 다른 스레드가 실행되어 프로세스간의 문맥 교환 없이 즉시 처리가 가능하다.\n\n예를 들어 웹 브라우저가 스레드를 여러 개 가지고 있을 때, 하나의 스레드는 이미지등의 데이터를 받기 위해 서버에 I/O 요청을 걸어서 Blocked 된 후, 다른 스레드가 이미 받아 놓은 HTML을 화면에 출력할 수 있다.\n\n이렇게 멀티 스레딩을 통한 NIO를 통해 응답성을 높일 수 있다.\n\n\n\n\n  \n    자원 공유 (Resource Sharing)\n  \n\n\n하나의 프로세스 안에 여러 스레드를 두게 되면 스레드 간 Code, Data, Resource 를 공유하여 효율적으로 자원 활용이 가능하다.\n\n즉, 한 프로세스 내에서 I/O 작업을 하더라도 프로세스간의 문맥 교환을 일으키지 않으면서 연속적으로 작업을 처리할 수 있다.\n\n\n\n\n  \n    경제성 (Economy)\n  \n\n\n동일한 일을 수행하는 여러 스레드가 협력하여 높은 처리율(throughput)과 성능 향상을 얻을 수 있다.\n\n또한, 새로운 스레드를 만드는 것은 새로운 프로세스 하나를 만드는 것 보다 훨씬 오버헤드가 적다.\n\n그리고, 스레드 끼리는 프로세스의 Code, Data, Resource 영역을 공유하므로 각자 Stack 영역만 처리하면 되고, 하나의 스레드가 I/O 작업으로 인해 Blocked 되더라도 다른 스레드가 CPU를 할당받아 작업을 진행하면 되기 때문에 I/O 작업시 발생하는 비싼 비용의 프로세스 문맥 교환도 일어나지 않으며, 이 때 발생하는 CPU의 캐시 메모리를 초기화할 필요도 없어진다.\n\n즉, 캐시도 훨씬 더 효율적으로 사용할 수 있게 된다. (캐시 히트율)\n\n\n\n\n  \n    멀티 프로세서 아키텍처에서의 이용성 (Utilization of MP Architectures)\n  \n\n\n각각의 스레드가 서로 다른 CPU를 할당받아 병렬적으로 작업을 진행해 더 빠르게 작업을 수행할 수 있다.\n\n\n  단점\n    \n      자원의 공유로 인한 동시성 문제가 발생할 수 있다.\n      절차적이지 않기 때문에 디버깅이 어렵다.\n      작업량이 너무 적거나 작업을 쪼개기 어려운 경우 포크&amp;조인으로 인한 오버헤드가 더 커져 오히려 더 느려질수도 있다.\n    \n  \n\n\n\n",
      "categories": ["cs","operating-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/operating-system/2022-02-13-process-thread/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "코드 카타 - 문자열 계산기",
      "date": "2022-02-14 00:00:00 +0000",
      "description": "TDD와 헥사고날 아키텍처 훈련\n",
      "content": "\n  코드카타(Code Kata)    \n      코드 카타, 어떻게 해야 하는가?\n    \n  \n  소프트웨어 개발 3대 원칙\n  문자열 계산기    \n      요구사항\n      프로그래밍 요구사항\n      기능 정의 및 책임 할당\n      프로젝트 구성\n    \n  \n  문자열 계산기 구현\n\n\n\n\n코드카타(Code Kata)\n\n\n  📜 CodeKata - Because experience is the only teacher\n\n\n\n\n(주의… 의역이 심합니다 😅)\n\n어떻게 하면 훌륭한 음악가가 될 수 있을까요?\n\n우선, 일단 이론을 알면 악기의 역학을 이해하는데 분명 도움이 됩니다.\n\n하지만 궁극적으로 훌륭한 실력은 이렇게 이론만 알아서 되는것이 아닌, 지속적이고 반복적인 훈련에서 나온다는 것을 깨달아야 합니다.\n\n반복적인 훈련에 이론을 계속 적용하며 결과를 얻고, 결과에 대한 피드백도 얻는다면 결과는 계속해서 좋아질 것입니다.\n\n\n\n위대한 스포츠 선수가 되려면 어떻게 해야 할까요?\n\n체력과 같은 선천적인 재능들은 분명히 큰 도움이 됩니다.\n\n그러나 이러한 재능들과 별개로 모든 위대한 스포츠 선수들은 보이지 않는 곳에서 매일 긴 시간 동안의 피나는 훈련을 했음을 알아야 합니다.\n\n\n\n일반적으로 소프트웨어 산업현장에서 우리는 이론만 훈련받은 개발자들을 데려와 프로젝트에 투입시키고, 프로젝트가 잘 돌아가길 원합니다.\n\n이것은 건강한 아이들을 몇 모으면 워싱턴 커맨더스를 이길 수 있다고 말하는 것과 다르지 않습니다.\n\n\n\n즉, 우리는 직장에서 훈련을 하기 때문에 실수를 하는 것입니다.\n\n따라서, 우리는 일과 훈련을 분리하는 방법을 찾고 지속적으로 훈련해 성장해야만 합니다.\n\n\n\n코드 카타, 어떻게 해야 하는가?\n\n\n\n\n  \n    누구에게도 방해받지 않는 시간이 필요하며, 가볍게 시도해보고 싶은 단순한 주제가 필요합니다.\n  \n  \n    필요하거나 만족스러울 만큼 여러 번 쉽게 시도하고, 무엇보다 실수를 하는 것이 두렵지 않고 편안해야만 합니다.\n  \n  \n    개선을 위해 노력할 수 있도록 매번 피드백을 찾아야 합니다.\n  \n  \n    외부의 압력이 없어야 합니다. 심신이 편안해야 합니다. 그리하여 오로지 훈련에만 몰입 할 수 있어야 합니다.\n  \n\n\n\n\n이것이 프로젝트 환경에서 성장하기 어렵고, 실수가 잦아지는 이유입니다.\n\n\n\n카타는 한 형태를 여러 번 반복하면서 조금씩 개선되는 가라데의 훈련입니다.\n\n코드 카타의 의도는 가라데의 카타와 비슷합니다.\n\n둘 모두 단순히 짧은 반복 훈련입니다.\n\n\n\n카타를 처음 하면 지루할수도 있지만, 계속해서 반복 할 수록 코드가 점점 더 좋아지는 것을 보고 느끼게 될 것이기 때문에 하면 할 수록 이 훈련이 아주 좋다는 것을 스스로 인식하게 될 것입니다.\n\n결과적으로, 스스로가 성장한다는 것을 직접적으로 느낄 수 있기 때문에 카타는 개발에 재미를 느끼는 데에도 큰 도움이 됩니다.\n\n\n\n누군가는 카타를 하며 단순히 코딩하는 것을 떠나 설계까지 고려 할 겁니다.\n\n또 누군가는 카타를 진행하며 프로그래밍 이면의 문제에 대한 고민을 할 겁니다.\n\n즉, 카타에는 정답이 없습니다.\n\n\n\n원하는 훈련을 하고 원하는 공예에 충분한 시간을 투자하세요.\n\n카타의 요점은 정답이 없다는 것이며, 설령 정답이 있다고 하더라도 그 정답이 중요하지 않을 것이라는 점입니다.\n\n중요한 것은 결과가 아닌 카타를 진행하며 고민하는 과정 그 자체입니다.\n\n\n\n소프트웨어 개발 3대 원칙\n\n\n\n나는 최대한 소프트웨어 개발 3대 원칙과 객체지향 5대 원칙(SOLID)을 고민하면서 훈련에 임할 것이다.\n\n\n  KISS(Keep It Simple Stupid): 최대한 단순하게 해라\n  YAGNI(You Ain’t Gonna Need It): 필요한 것만 해라\n  DRY(Do not Repeat Yourself): 같은 것을 반복하지 마라\n\n\n문자열 계산기\n\n\n\n\n\n\n  📖 NextStep - 문자열 계산기\n\n\n\n\n요구사항\n\n\n\n\n  사용자가 입력한 문자열 값에 따라 사칙연산을 수행할 수 있는 계산기를 구현해야 한다.\n  문자열 계산기는 사칙연산의 계산 우선순위가 아닌 입력 값에 따라 계산 순서가 결정된다. 즉, 수학에서는 곱셈, 나눗셈이 덧셈, 뺄셈 보다 먼저 계산해야 하지만 이를 무시한다.\n  예를 들어 2 + 3 * 4 / 2와 같은 문자열을 입력할 경우 2 + 3 * 4 / 2 실행 결과인 10을 출력해야 한다.\n\n\n\n\n프로그래밍 요구사항\n\n\n  모든 로직을 TDD로 구현한다. 단, UI(System.out, System.in) 로직은 제외\n  자바 코드 컨벤션을 지키면서 프로그래밍한다.\n    \n      기본적으로 Google Java Style Guide을 원칙으로 한다.\n      단, 들여쓰기는 ‘2 spaces’가 아닌 ‘4 spaces’로 한다.\n    \n  \n  indent(인덴트, 들여쓰기) depth를 2가 넘지 않도록 구현한다. 1까지만 허용한다.\n    \n      예를 들어 while문 안에 if문이 있으면 들여쓰기는 2이다.\n    \n  \n  else 예약어를 쓰지 않는다.\n  핵심 로직을 구현하는 코드와 UI를 담당하는 로직을 구분한다.\n  3항 연산자를 쓰지 않는다.\n  함수(또는 메소드)가 한 가지 일만 하도록 최대한 작게 만들어라.\n\n\n\n\n기능 정의 및 책임 할당\n\n우선 꼭 필요하다고 생각되는 기능들을 정의해야한다.\n\n구현 중간에 세세하게 바뀔수는 있겠지만 거시적으로 보면 크게 변하지는 않을 것이다.\n\n\n  콘솔로 수식을 입력받을 수 있어야 한다 (ConsoleInput)\n  콘솔에 계산 결과를 출력할 수 있어야 한다(ConsoleOutput)\n  숫자와 사칙연산자로 이뤄지고 공백으로 분리된 올바른 수식을 판별해야 한다(Expression)\n  순차적으로 사칙연산이 되어야 한다(StringCalculator)\n\n\n\n\n프로젝트 구성\n\n\n\n일단 다음과 같이 패키지 구조를 잡았다\n\n\n\n\n\n\n\n의존성 설정을 할 것인데, 자바 17을 사용할 것이며, 빌드툴은 Gradle을 사용한다.\n\n테스트를 원활하게 하기 위해 AssertJ와 JUnit5를 추가했다.\n\n\n\n// file: 'build.gradle'\nplugins {\n    id 'java'\n}\n\ngroup 'io.github.shirohoo'\n\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    testImplementation 'org.assertj:assertj-core:3.22.0'\n    testImplementation 'org.junit.jupiter:junit-jupiter-params:5.8.2'\n    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.8.2'\n    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.8.2'\n}\n\ntest {\n    useJUnitPlatform()\n}\n\njava {\n    toolchain {\n        languageVersion = JavaLanguageVersion.of(17)\n    }\n}\n\n\n\n\n문자열 계산기 구현\n\n\n\n\n  📦 문자열 계산기 구현 코드 저장소\n\n\n\n\n우선 수식과 연산이 가장 중요하다고 생각하므로 둘을 먼저 타겟으로 잡고 수식에 대한 테스트 코드를 먼저 작성했다.\n\n\n\n@DisplayName(\"수식 테스트\")\nclass ExpressionTests {\n    @ParameterizedTest\n    @NullAndEmptySource\n    @ValueSource(strings = {\n        \"2+4-7*1/0\", \"5+7\", \"1 + +\", \"+\", \"-\", \"/\", \"*\", \"1 + +\", \"1 - -\", \"1 / /\", \"1 * *\"\n    })\n    @DisplayName(\"유효하지 않은 수식이 입력되면 예외가 발생해야 한다\")\n    void validate(String expr) {\n        assertThatThrownBy(() -&gt; {\n            Expression expression = Expression.from(expr);\n        }).isInstanceOf(IllegalArgumentException.class);\n    }\n}\n\n\n\n\n예외 케이스는 비정상적인 수식인 경우(1++ 같은), 정상적인 수식이지만 공백으로 분리되지 않은 경우다.\n\n후자는 공백이 포함되지 않아도 파싱하도록 해보려 했는데, 공백으로 분리가 안되면 2+55 같은 입력이 들어올 때 분리하기가 힘들 것 같아서 일단 보류했다.\n\n규식이형을 좀 더 잘 알았다면 어떻게 해볼 수 있었을 것 같기도 한데…\n\n어쨌든 일단 이정도로 해두고 테스트 코드 통과를 위한 약간의 구현을 했다.\n\n\n\npublic class Expression {\n    private static final Pattern PATTERN = Pattern.compile(\"^([0-9]*)|[0-9]*(\\\\s[+\\\\-*/]\\\\s[0-9].*)$\");\n\n    private final String expr;\n\n    private Expression(String expr) {\n        if (expr == null || expr.isBlank() || !PATTERN.matcher(expr).matches()) {\n            throw new IllegalArgumentException(\"Expression must be space-separated and must be valid. for example, you cannot enter a expression such as 1 + +.\");\n        }\n        this.expr = expr;\n    }\n\n    public static Expression from(String expr) {\n        return new Expression(expr);\n    }\n}\n\n\n\n\n여기서도 규식이형에 대해 할 말이 참 많은데, 처음에는 수식을 공백으로 분리해서 배열방의 홀수는 숫자, 짝수는 연산자로 검사를 하려고 했다.\n\n\n\n\n\n\n\n근데 그렇게 코드를 작성하고 보니 너무 장황한 것 같아서 규식이형을 사용하기로 노선을 변경했는데, 이게 이번 카타에서 가장 많은 시간을 빼앗아갔다 (-ㅅ-)\n\n알량한 지식을 갖고 주먹구구식으로 만들어낸 규식이형을 보니 뭔가 매우 구린거 같아서 썩 마음에 들진 않는데, 이게 지금의 내가 할 수 있는 최선인 것 같아서 받아들이기로했다…\n\n\n\n\n\n\n\n보면 볼수록 규식이형이 문자열 처리에서 치트키인데 요상하게 난해해서 우선순위가 계속 밀렸던 것 같다… 어쨌든 조만간 규식이형을 한번 각잡고 정복해야겠다는 생각이 들어 책을 한권 주문하게 되는 계기가 됐다.\n\n\n\nPattern.compile을 private static final로 작성한 이유는, 이렇게 정적 멤버로 선언하지 않고 생성자에서 매번 Pattern 인스턴스를 새로 만들면, 생성자가 종료될때마다 Pattern 인스턴스가 가비지 컬렉션 대상이 되기 때문이다.\n\n\n\n다음으로 수식을 분리하는 테스트 코드를 작성했다.\n\n\n\n@DisplayName(\"수식 테스트\")\nclass ExpressionTests {\n    ...\n  \n    @Test\n    @DisplayName(\"수식을 공백단위로 분리할 수 있어야 한다\")\n    void split() {\n        // ...given\n        String expr = \"2 + 4 - 7 * 1 / 0\";\n        String[] expected = {\"2\", \"+\", \"4\", \"-\", \"7\", \"*\", \"1\", \"/\", \"0\"};\n\n        // ...when\n        Expression expression = Expression.from(expr);\n\n        // ...then\n        assertThat(expression.split()).isEqualTo(expected);\n    }\n}\n\n\n\n\n이번 구현은 아주 쉽다.\n\n\n\npublic class Expression {\n    private static final Pattern PATTERN = Pattern.compile(\"^([0-9]*)|[0-9]*(\\\\s[+\\\\-*/]\\\\s[0-9].*)$\");\n    \n    private final String expr;\n    \n    private Expression(String expr) {\n        if (expr == null || expr.isBlank() || !PATTERN.matcher(expr).matches()) {\n            throw new IllegalArgumentException(\"Expression must be space-separated and must be valid. for example, you cannot enter a expression such as 1 + +.\");\n        }\n        this.expr = expr;\n    }\n    public static Expression from(String expr) {\n        return new Expression(expr);\n    }\n\n    public String[] split() {\n        return expr.split(\" \");\n    }\n}\n\n\n\n\n몇가지 테스트 케이스를 더 추가해준다.\n\n수식 객체에 대한 최종적인 테스트 코드는 하기와 같다.\n\n\n\n@DisplayName(\"수식 테스트\")\nclass ExpressionTests {\n    @ParameterizedTest\n    @NullAndEmptySource\n    @ValueSource(strings = {\n        \"2+4-7*1/0\", \"5+7\", \"1 + +\", \"+\", \"-\", \"/\", \"*\", \"1 + +\", \"1 - -\", \"1 / /\", \"1 * *\"\n    })\n    @DisplayName(\"유효하지 않은 수식이 입력되면 예외가 발생해야 한다\")\n    void validate(String expr) {\n        assertThatThrownBy(() -&gt; {\n            Expression expression = Expression.from(expr);\n        }).isInstanceOf(IllegalArgumentException.class);\n    }\n\n    @Test\n    @DisplayName(\"수식을 공백단위로 분리할 수 있어야 한다\")\n    void split() {\n        // ...given\n        String expr = \"2 + 4 - 7 * 1 / 0\";\n        String[] expected = {\"2\", \"+\", \"4\", \"-\", \"7\", \"*\", \"1\", \"/\", \"0\"};\n\n        // ...when\n        Expression expression = Expression.from(expr);\n\n        // ...then\n        assertThat(expression.split()).isEqualTo(expected);\n    }\n\n    @Test\n    @DisplayName(\"수식이 단순 숫자 한개일 경우 분리할 수 없음을 알려준다\")\n    void isSplit() {\n        Expression expression = Expression.from(\"1\");\n        assertThat(expression.isSplit()).isFalse();\n    }\n\n    @Test\n    @DisplayName(\"수식이 단순 숫자 한개일 경우 수식을 바로 반환 할 수 있다\")\n    void export() {\n        Expression expression = Expression.from(\"1\");\n        assertThat(expression.export()).isEqualTo(1);\n    }\n\n    @Test\n    @DisplayName(\"수식이 단순 숫자 한개일 경우 수식을 바로 반환 할 수 없다\")\n    void exportException() {\n        Expression expression = Expression.from(\"1 + 2\");\n        assertThatThrownBy(expression::export).isInstanceOf(IllegalStateException.class);\n    }\n}\n\n\n\n\n최종적인 구현은 다음과 같다.\n\n\n\npublic class Expression {\n    private static final Pattern PATTERN = Pattern.compile(\"^([0-9]*)|[0-9]*(\\\\s[+\\\\-*/]\\\\s[0-9].*)$\");\n\n    private final String expr;\n\n    private Expression(String expr) {\n        if (expr == null || expr.isBlank() || !PATTERN.matcher(expr).matches()) {\n            throw new IllegalArgumentException(\"Expression must be space-separated and must be valid. for example, you cannot enter a expression such as 1 + +.\");\n        }\n        this.expr = expr;\n    }\n\n    public static Expression from(String expr) {\n        return new Expression(expr);\n    }\n\n    public String[] split() {\n        return expr.split(\" \");\n    }\n\n    public boolean isSplit() {\n        return expr.length() &gt; 1;\n    }\n\n    public double export() {\n        if (!isSplit()) {\n            return Double.parseDouble(split()[0]);\n        }\n        throw new IllegalStateException(\"Current expression is not a single number\");\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n다음은 계산기를 구현할 차례다.\n\n항상 그랬듯이 테스트 코드의 시작은 초기화 테스트부터다.\n\n\n\n@DisplayName(\"문자열 계산기 테스트\")\nclass StringCalculatorTests {\n    @Test\n    @DisplayName(\"정상적인 수식이 입력되면 초기화에 성공한다\")\n    void from() {\n        Expression expression = Expression.from(\"2 + 4 - 7 * 1 / 0\");\n\n        assertThatCode(() -&gt; {\n            StringCalculator calculator = StringCalculator.from(expression);\n        }).doesNotThrowAnyException();\n    }\n\n    @Test\n    @DisplayName(\"비정상적인 수식이 입력되면 초기화에 실패한다\")\n    void fromException() {\n        assertThatThrownBy(() -&gt; {\n            StringCalculator calculator = StringCalculator.from(null);\n        }).isInstanceOf(NullPointerException.class);\n    }\n}\n\n\n\n\npublic class StringCalculator {\n    private final Expression expression;\n\n    private StringCalculator(Expression expression) {\n        this.expression = Objects.requireNonNull(expression);\n    }\n\n    public static StringCalculator from(Expression expression) {\n        return new StringCalculator(expression);\n    }\n}\n\n\n\n\n이미 수식에 대한 검증은 모두 마쳤으므로 계산기는 오로지 계산에만 집중하면 된다.\n\n수식 객체가 null로 들어오는지만 검증하도록 하고 바로 계산기 구현에 들어간다.\n\n항상 유효한 상태로 초기화되도록 검증된 수식 객체가 들어올 것이기 때문에 입력이 null만 아니면 된다.\n\n우선 요구사항대로 상식적인 순서의 사칙연산이 아닌 순차적인 순서의 사칙연산을 거친 결과가 나오도록 테스트 케이스들을 정의한다.\n\n\n\n@DisplayName(\"문자열 계산기 테스트\")\nclass StringCalculatorTests {\n    @Test\n    @DisplayName(\"정상적인 수식이 입력되면 초기화에 성공한다\")\n    void from() {\n        Expression expression = Expression.from(\"2 + 4 - 7 * 1 / 0\");\n\n        assertThatCode(() -&gt; {\n            StringCalculator calculator = StringCalculator.from(expression);\n        }).doesNotThrowAnyException();\n    }\n\n    @Test\n    @DisplayName(\"비정상적인 수식이 입력되면 초기화에 실패한다\")\n    void fromException() {\n        assertThatThrownBy(() -&gt; {\n            StringCalculator calculator = StringCalculator.from(null);\n        }).isInstanceOf(NullPointerException.class);\n    }\n\n    @MethodSource\n    @ParameterizedTest\n    @DisplayName(\"수식에 대한 순차적인 연산 결과를 반환한다\")\n    void calculate(String expr, double expected) {\n        // ...given\n        Expression expression = Expression.from(expr);\n        StringCalculator calculator = StringCalculator.from(expression);\n\n        // ...when\n        double result = calculator.calculate();\n\n        // ...then\n        assertThat(result).isEqualTo(expected);\n    }\n\n    static Stream&lt;Arguments&gt; calculate() {\n        return Stream.of(\n            Arguments.of(\"1\", 1),\n            Arguments.of(\"5 - 1\", 4),\n            Arguments.of(\"0 - 1\", -1),\n            Arguments.of(\"2 + 4 - 1 * 5 / 5\", 5),\n            Arguments.of(\"2 + 4 - 1 * 5 / 10\", 2.5),\n            Arguments.of(\"100 + 100 - 5 * 2 / 3\", 130),\n            Arguments.of(\"100 + 100 - 5 * 2 / 4\", 97.5)\n        );\n    }\n\n    @Test\n    @DisplayName(\"0으로 나누려 하는 경우 예외가 발생한다\")\n    void calculateDividedByZero() {\n        Expression expression = Expression.from(\"5 / 0\");\n        StringCalculator calculator = StringCalculator.from(expression);\n        assertThatThrownBy(calculator::calculate).isInstanceOf(ArithmeticException.class);\n    }\n}\n\n\n\n\n0으로 나누려 하는 경우는 무한루프가 발생할 수 있기 때문에 이에 대한 예외 처리를 해준다.\n\n이에 대해 약간 설명을 해보자면, 컴퓨터는 오로지 덧셈밖에 못한다. 그럼 덧셈을 제외한 다른 연산은 어떻게 하냐는 의문이 들 수 있다.\n\n곱셈은 덧셈을 반복하며, 뺄셈은 보수를 구해 더하는 식으로 동작한다.\n\n즉, 프로그래밍에서 2-2는 2+(-2)이다.\n\n그리고 마지막으로 나눗셈은 위의 뺄셈 작업을 반복하게 된다.\n\n예를 들어 10을 2로 나눈다고 가정하면 뺄셈해서 나온 결과가 2보다 작을 때까지 계속해서 빼게 되므로 다섯 번을 뺄 것이고, 이 경우 몫은 5, 나머지는 0이 된다.\n\n이를 수학적인 용어로는 피제수에서 제수를 뺀다고 표현한다.\n\n그럼 이제 예외 처리를 해야하는 어떤 값을 0으로 나누는 경우를 생각해보자.\n\n위에서 언급한대로 동작하면 결국 피제수에서 0을 뺀 결과가 0보다 작을 때까지 반복하게 되는데, 피제수에서 0을 빼 봐야 피제수는 항상 같다.\n\n즉, 프로그래밍에서 10 / 0은 10+(-0)+(-0)+(-0)+(-0)+(-0)+(-0)+(-0)... (무한반복)이 되는 것이다.\n\n\n\n연산에 대한부분은 구현이 좀 긴데, 일단 누산기를 생각해 구현했다.\n\n일단 수식을 공백으로 분리해 나온 배열에는 수와 연산자가 들어있다.\n\n여기에 연산에 사용할 스택을 한개 만들고, 배열의 크기 만큼 반복하며 스택에 수와 연산자를 집어넣는다.\n\n집어넣다가 스택의 사이즈가 3이 되면 3개를 모두 꺼냈을 때 가장 먼저 pop된 수는 제수고, 두번째로 pop된 수는 연산자, 세번째로 pop 된 수는 피제수이다.\n\n즉, 그림으로 보면 다음과 같다.\n\n수식 2 + 5 / 1이 입력됐다고 가정하자.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n이렇게 N번 순회하고 스택에 남아있는 최종 결과를 반환하면 원하는 값이 나올 것이다.\n\n더 우아한 방법이 있는지는 잘 모르겠지만 일단 이게 내가 생각해낼 수 있는 최선의 솔루션인 것 같다.\n\n\n\npublic class StringCalculator {\n    private final Stack&lt;String&gt; accumulator;\n    private final Expression expression;\n\n    private StringCalculator(Expression expression) {\n        this.accumulator = new Stack&lt;&gt;();\n        this.expression = Objects.requireNonNull(expression);\n    }\n\n    public static StringCalculator from(Expression expression) {\n        return new StringCalculator(expression);\n    }\n\n    public double calculate() {\n        if (!expression.isSplit()) {\n            return expression.export();\n        }\n\n        accumulator.clear();\n        for (String expr : expression.split()) {\n            accumulateIfEqualSize3();\n            pushIfLessThanSize3(expr);\n        }\n        return Double.parseDouble(accumulate());\n    }\n\n    private void accumulateIfEqualSize3() {\n        if (accumulator.size() == 3) {\n            accumulate();\n        }\n    }\n\n    private String accumulate() {\n        double right = Double.parseDouble(accumulator.pop());\n        String operator = accumulator.pop();\n        double left = Double.parseDouble(accumulator.pop());\n\n        return accumulator.push(\n            ArithmeticCalculator.findBy(operator)\n                .applyAsDouble(left, right)\n        );\n    }\n\n    private void pushIfLessThanSize3(String expr) {\n        if (accumulator.size() &lt; 3) {\n            accumulator.push(expr);\n        }\n    }\n\n    private enum ArithmeticCalculator {\n        ADDITION(\"+\", (x, y) -&gt; x + y),\n        SUBTRACTION(\"-\", (x, y) -&gt; x - y),\n        MULTIPLICATION(\"*\", (x, y) -&gt; x * y),\n        DIVISION(\"/\", (x, y) -&gt; x / y);\n\n        private static final Map&lt;String, ArithmeticCalculator&gt; MAP = stream(values())\n            .collect(toMap(ArithmeticCalculator::operator, identity()));\n\n        private final String operator;\n        private final DoubleBinaryOperator function;\n\n        ArithmeticCalculator(String operator, DoubleBinaryOperator function) {\n            this.operator = operator;\n            this.function = function;\n        }\n\n        private static ArithmeticCalculator findBy(String operator) {\n            if (MAP.containsKey(operator)) {\n                return MAP.get(operator);\n            }\n            throw new NoSuchElementException(\"'%s' is not operator or not supported operator.\".formatted(operator));\n        }\n\n        private String applyAsDouble(double left, double right) {\n            if (isDivideByZero(right)) {\n                throw new ArithmeticException(\"It cannot be divided by zero.\");\n            }\n            return String.valueOf(function.applyAsDouble(left, right));\n        }\n\n        private boolean isDivideByZero(double right) {\n            return this == DIVISION &amp;&amp; right == 0;\n        }\n\n        private String operator() {\n            return operator;\n        }\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n최종적인 도메인 구현은 여기서 끝났고, 이번 카타에서 콘솔 입출력은 너무 간단하기 때문에 스킵했다.\n\n만들고 보니 굳이 스택사이즈가 3이 될때까지 push하지 않고 사이즈 2까지만 확인했어도 될 것 같긴하다.\n\n그리고 StringCalculator의 클래스 멤버인 Stack&lt;String&gt; accumulator 도 일급 컬렉션으로 포장했으면 더 좋았을 것 같다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-02-14-diary-33/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "운영체제(Operating System) 3강",
      "date": "2022-02-16 00:00:00 +0000",
      "description": "반효경 교수님 - Process Management\n",
      "content": "\n  Lecture\n  Process Management    \n      Process creation\n      Process termination\n      System Call        \n          fork()\n          exec()\n          wait()\n          exit()\n          abort()\n        \n      \n      Collaboration between processes        \n          독립적 프로세스 (Independent process)\n          협력 프로세스 (Cooperating process)\n          프로세스 간 협력 메커니즘 (IPC: Interporcess Communication)\n          메시지 전달 방식 (Message Passing)\n          직접 통신 (Direct Communication)\n          간접 통신 (Indirect Communication)\n          공유 메모리 방식 (Shared Memory)\n        \n      \n    \n  \n\n\n\n\nLecture\n\n\n\n\n  운영체제 - 반효경 교수님\n    \n      Process Management 1\n      Process Management 2\n    \n  \n\n\n\n\nProcess Management\n\n\n\nProcess creation\n\n\n\n컴퓨터가 부팅되어 운영체제가 실행된 후 최초의 프로그램을 실행할 때 다음과 같은 과정이 발생한다. (단순 예시임 !)\n\n\n\n\n  컴퓨터를 부팅한다.\n  아무것도 하지 않고 즉시 바탕화면에 있는 League of Legends.exe를 더블클릭한다.\n  운영체제는 메모리에 League of Legends의 Data, Code영역을 로딩하고, 빈 Stack을 생성한 후 PCB를 하나 새로 만들어 초기화한다.\n  금방 실행한 최초의 프로세스는 0번 프로세스이다.\n\n\n\n\n위의 과정은 컴퓨터가 부팅 된 후 최초의 프로세스를 생성할 때 단 한번만 진행된다.\n\n이후부터 생성되는 프로세스는 0번 프로세스를 복사하여 생성된다.\n\n이 이유는 프로세스를 새로 만드는 것보다 기존의 것을 복사하는게 더 비용이 적게 소모되기 때문이다.\n\n\n\n\n  Diablo 2.exe를 실행한다.\n  이미 실행중인 League of Legends를 대상으로 운영체제의 fork() 함수를 호출해 복사한다.\n  복사된 프로세스의 부모 프로세스는 League of Legends이며, League of Legends의 자식 프로세스는 Diablo 2이다.\n  복사된 Diablo 2는 League of Legends의 데이터들을 갖고 있으므로, 운영체제는 Diablo 2를 대상으로 exec()함수를 호출해 Diablo 2.exe의 모든 데이터를 덮어쓴다.\n  이후부터 Diablo 2는 League of Legends와 다르게 동작하기 시작한다.\n\n\n\n\n위 내용들은 대략적인 예시이며, 실제로 리그오브레전드를 실행할 때 저런 과정이 발생하는것도 아니며, 리그오브레전드를 복사해서 디아블로를 실행한다는 것도 아니다.\n\n분명 리그오브레전드나 디아블로를 실행하기 위해 복사하는 상위의 어떤 프로세스가 있을것이라는 의미이다.\n\n위 과정을 리눅스 터미널에서 새로운 프로세스를 생성하는 것을 대입해 연상하면 조금 더 이해가 쉬울 것 같다.\n\n정리하면 대략 다음과 같다.\n\n\n  새로운 프로세스를 생성할 때, 이미 존재하는 프로세스를 복제한다. 이때 기존 프로세스를 부모 프로세스라 하고, 복제 생성된 프로세스를 자식 프로세스라고 부른다.\n  프로세스의 계층 구조는 트리로 형성된다.\n  모든 프로세스들은 컴퓨터 자원을 필요로 한다.\n    \n      운영체제에게 컴퓨터 자원을 받는다.\n      프로세스는 자원을 부모와 공유할 수 있다.\n    \n  \n  프로세스간 자원 공유 모델은 러프하게 다음과 같다.\n    \n      부모와 자식이 모든 자원을 공유하는 모델\n      일부를 공유하는 모델\n      전혀 공유하지 않는 모델\n      부모와 자식이 공존하며 수행하는 모델 (이때는 부모자식간에 CPU를 획득하기 위한 경쟁이 일어날 수 있음)\n      자식이 종료(Terminate)될 때까지 부모가 기다리는(Wait) 모델\n    \n  \n\n\n\n\nProcess termination\n\n\n\n\n  자식 프로세스가 부모 프로세스에게 exit() 함수를 통해 종료 신호를 보낸다.\n  부모 프로세스는 자식 프로세스의 종료 신호를 인지하고 자식 프로세스를 종료시킨다.\n  종료된 프로세스의 자원들이 운영체제에 반납된다.\n  부모 프로세스가 abort() 함수를 통해 자식 프로세스를 강제로 종료하는 경우도 있다.\n    \n      자식 프로세스가 사용하는 자원이 할당된 자원의 한계치를 넘어서는 경우\n      자식에게 할당된 작업이 더 이상 필요하지 않은 경우\n      부모 프로세스가 종료되는 경우\n    \n  \n\n\n만약 부모 프로세스가 비정상적으로 종료되거나, 자식 프로세스가 비정상적으로 종료되 exit()신호를 부모 프로세스에게 주지 못한 경우, 이 프로세스는 정상종료 되지 못하고 컴퓨터의 자원만 점유하며 남아있는 경우가 발생 할 수 있다.\n\n이를 좀비 프로세스(Zombie Process)라 부르며, 컴퓨터를 오래 켜두면 느려지는 이유 중 하나가 바로 이 좀비 프로세스가 많아지는 것 때문이기도 하다.\n\nexit() 는 프로세스가 종료 될 때 운영체제에게 자신의 작업이 끝났음을 알리는 자발적 종료(Non-Preemptive, 비선점)에 해당하는 시스템 콜이다.\n\n그리고, abort() 는 부모 프로세스가 자식 프로세스를 강제로 종료하는 것이기에, 비자발적 종료(Preemptive, )에 해당하는 시스템 콜이다.\n\n여기서 Preemptive와 Non-Preemptive 라는 용어는 앞으로도 자주 나올 것이기 때문에 잘 기억해두자.\n\n\n\nSystem Call\n\nfork()\n\n\n\n\n  운영체제는 효율적인 프로세스의 생성을 위해 fork() 시스템 콜을 제공한다.\n  프로세스가 해당 시스템 콜을 호출하면 CPU의 제어권이 커널로 넘어가고, 커널은 fork() 를 호출한 프로세스를 복제하여 자식 프로세스를 생성한다.\n  fork() 를 수행하면 부모 프로세스의 주소 공간을 비롯해 각종 레지스터의 현재 상태, PCB 등의 모든 문맥을 그대로 복제해 자식 프로세스의 문맥으로 형성한다.\n  따라서 자식 프로세스는 부모 프로세스의 처음부터 수행하지 않고, 부모 프로세스가 현재 수행해야 할 시점부터 수행하게 된다.\n  다만 운영체제가 프로세스를 관리해야 하기 때문에 자식 프로세스와 부모 프로세스의 식별자(PID)는 다르다.\n\n\n\n\n\n\n\n\n\n  부모 프로세스가 메인 함수의 첫 번째 줄부터 한 줄씩 코드를 수행하다가 fork() 라인에 이르면 자신과 똑같은 프로세스를 하나 생성한다.\n  이때 fork() 라인까지 수행했다는 기억조차도 똑같은 자식 프로세스가 생성된다. 즉, 금방 생성된 자식 프로세스는 여지껏 부모 프로세스가 수행한 작업을 자신이 한 것으로 알고있음이다.\n  그래서 복제된 프로세스는 자기가 복제본이 아니라 원본이며, 자기를 복제해서 다른 복제본을 생성했다는 기억을 갖고 있다.\n  다만 이 자식 프로세스가 복제된 프로세스라는 사실을 알 수 있는 단서가 있는데, 진짜 부모 프로세스는 fork()의 반환값으로 0보다 큰 값을 반환하고, 자식 프로세스는 fork() 의 반환값으로 값으로 0을 반환한다.\n\n\n\n\nexec()\n\n\n\n\n  fork() 만으로는 같은 코드에 대해 조건을 분기하는 정도로 밖에 사용할 수 없다.\n  자식 프로세스에게 부모 프로세스와는 독자적인 작업을 수행할 수 있게 하는 시스템 콜이 바로 exec() 이다.\n  이 시스템 콜은 프로세스의 메모리에 새로운 프로그램의 데이터를 덮어 씌운 후, 덮어 씌운 새로운 프로그램의 첫 부분부터 다시 실행하도록 한다.\n  즉, 새로운 프로그램을 수행하기 위해서는 fork() 로 자식 프로세스를 생성한 뒤, exec() 로 해당 프로세스의 주소 공간을 새롭게 수행하려는 프로세스의 주소 공간으로 덮어 씌우면 된다.\n\n\n\n\n\n\n\n\n\n  execlp() 라인에 이르면 새로운 프로그램으로 덮어 씌운다.\n\n\n\n\nwait()\n\n\n\n\n\n\n\n\n  자식 프로세스가 종료되기를 기다리며 부모 프로세스가 Wait 상태에 머무르도록 할 때 사용한다.\n  부모 프로세스가 fork() 후에 wait() 을 호출하면 자식 프로세스가 종료될 때까지 부모 프로세스를 Wait 상태에 머무르게 하고, 자식 프로세스가 종료되면 부모 프로세스를 Ready 상태로 변경한다.\n\n\n\n\nexit()\n\n\n\n\n\n\n\n\n  프로세스를 자발적으로 종료할 때 사용한다.\n  프로그램에 명시적으로 적어주지 않아도 프로세스의 main 함수가 리턴되는 위치에 컴파일러가 자동으로 넣어준다.\n\n\n\n\nabort()\n\n\n\n\n  프로세스를 비자발적으로 종료할 때 사용한다.\n  부모 프로세스가 자식 프로세스를 강제로 종료한다.\n    \n      자식 프로세스가 한계를 넘어서는 자원을 요청하는 경우\n      자식에게 할당된 작업이 더 이상 필요하지 않은 경우\n    \n  \n  터미널에서 kill, break 등의 명령어를 입력한 경우\n  부모가 종료하는 경우\n    \n      부모 프로세스가 종료하기 전에 자식들이 먼저 종료됨.\n      dontKillMe 옵션을 주면 자식 프로세스는 종료되지 않는다.\n    \n  \n\n\n\n\nCollaboration between processes\n\n독립적 프로세스 (Independent process)\n\n\n\n프로세스는 각자의 메모리를 가지고 동작하므로 원칙적으로 하나의 프로세스는 다른 프로세스의 수행에 영향을 미치지 못한다. (메모리 관리자가 프로세스간의 메모리 침범을 허용하지 않는다.)\n\n\n\n협력 프로세스 (Cooperating process)\n\n\n\n\n  프로세스 협력 메커니즘을 통해 하나의 프로세스가 다른 프로세스의 수행에 영향을 미칠 수도 있다.\n\n\n\n\n프로세스 간 협력 메커니즘 (IPC: Interporcess Communication)\n\n\n\n\n\n\n  IPC는 프로세스들 간의 통신과 동기화를 이루기 위한 메커니즘을 의미한다.\n  크게 메시지 전달 방식과 공유 메모리 방식이 있다.\n  TCP 등의 프로토콜을 사용한 프로세스간의 통신도 IPC의 일종이며, 소켓 통신이라고도 불린다.\n\n\n\n\n메시지 전달 방식 (Message Passing)\n\n\n\n\n\n\n\n\n  \n    직접 통신 (Direct Communication)\n    \n      통신하려는 프로세스의 이름을 명시적으로 표시한다.\n      각 쌍의 프로세스에게는 오직 하나의 링크만 존재한다.\n    \n  \n\n\n\n\n\n  \n    간접 통신 (Indirect Communication)\n    \n      메시지를 메일 박스 또는 포트로부터 전달받는다.\n      각 메일 박스에는 고유의 ID가 있으며 메일 박스를 공유하는 프로세스만 통신할 수 있다.\n      하나의 링크가 여러 프로세스에게 할당될 수 있다.\n    \n  \n\n\n\n\n공유 메모리 방식 (Shared Memory)\n\n\n\n\n\n\n\n\n  공유 메모리 방식은 프로세스들이 주소 공간의 일부(Heap 등)를 공유한다.\n  동시성으로 인해 데이터 정합성 문제가 발생할 수 있다.\n  따라서 프로세스 간 동기화(synchronization) 문제를 스스로 책임져야 한다.\n\n\n\n",
      "categories": ["cs","operating-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/operating-system/2022-02-16-process-management/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "Hibernate 5.6 - @Comment",
      "date": "2022-02-16 00:00:00 +0000",
      "description": "JPA 사용 시 테이블 컬럼에 컬럼 설명 작성하기\n",
      "content": "\n  @Comment\n  Reference\n\n\n\n\n@Comment\n\n\n\nHibernate 저장소에 끝내주는 PR이 하나 들어와 있었습니다.\n\n바로 @Comment를 소개한다는 내용의 PR 이었는데요.\n\n일단 이 기능은 현재 최신 안정버전인 Hibernate 5.6+부터 사용하실 수 있으며, Spring Boot 2.6부터 Hibernate 5.6을 의존합니다.\n\nSpring Data JPA에서 사용하는 Hibernate는 원래 테이블 컬럼에 대한 코멘트 자동 작성을 정식으로 지원하지 않았습니다.\n\n대신 다음과 같이 JPA 자체 스펙인 columnDefinition을 통해 작성할수는 있었으나, 하드코딩을 해야 한다는 문제(오탈자 위험도 높음), 특정 DB 벤더에 종속되는 문제 등이 있었습니다.\n\n즉, columnDefinition는 일반적으로 거의 사용하지 않는 옵션입니다.\n\n\n\n@Entity\npublic class Member {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    @Column(columnDefinition = \"varchar(10) not null comment 'this is name'\")\n    private String name;\n}\n\n\n\n\nHibernate: \n    drop table if exists member\nHibernate: \n    create table member (\n       id bigint not null auto_increment,\n        name varchar(10) not null comment 'this is name',\n        primary key (id)\n    ) engine=InnoDB\n\n\n\n\n그리고 위의 이유 때문만은 아니지만, 일반적으로 DDL은 너무 중요하기 때문에 따로 작성하여 관리하기도 하고요.\n\n그럼에도 불구하고 저는 초창기 개발환경에서 ddl-auto: create, create-drop, update 등의 옵션을 사용하는것을 매우 선호하기 때문에 이 부분이 약간 아쉽긴 했었습니다.\n\n\n\n이번에 Hibernate 5.6에 들어온 @Comment는 다음과 같은 기능을 지원합니다.\n\n\n\n@Entity\npublic class Member {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    @Comment(\"this is name\")\n    @Column(length = 10, nullable = false)\n    private String name;\n}\n\n\n\n\nHibernate: \n    drop table if exists member\nHibernate: \n    create table member (\n       id bigint not null auto_increment,\n        name varchar(10) not null comment 'this is name',\n        primary key (id)\n    ) engine=InnoDB\n\n\n\n\n\n\n@Comment로 생성된 컬럼 코멘트\n\n\n\n인수는 컬럼에 대한 설명인 value 밖에 없는 아주 단순한 어노테이션입니다.\n\n보시다시피 @Comment를 사용하면 ddl-auto를 사용할 때 ColumnBuilder가 생성되는 DDL에 코멘트를 끼워넣어 주게 됩니다.\n\n\n\nReference\n\n\n\n\n  HHH-4369 Introduce @Comment for comment on column #3611\n  HHH-4369 Support @Comment or column attribute on @Table and @Column\n  Spring Boot Releases Note - v2.6.0\n  Spring Boot PR - Upgrade to Hibernate 5.6.1.Final #28574\n\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-02-16-diary-34/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "Comparable & Comparator",
      "date": "2022-02-18 00:00:00 +0000",
      "description": "자바에서 정렬시 객체를 비교하는 기준\n",
      "content": "\n  비교 기준    \n      Comparator\n      Comparable\n    \n  \n\n\n\n\n비교 기준\n\n\n\nComparable, Comparator 는 자바에서 객체 비교를 하는 방법을 제공하는 인터페이스입니다.\n\n\n\n쉽게 생각해봅시다.\n\n두 숫자 3과 5가 있습니다. 어떤 수가 더 클까요?\n\n당연히 5가 더 큽니다. 이견의 여지가 없죠?\n\n\n\n자 그럼 학생1과 학생2가 있습니다.\n\n두 학생 중 어느 학생이 더 클까요?\n\n이 질문에는 즉답을 할 수가 없습니다.\n\n왜냐하면 두 학생간 크다 작다를 어떤 기준으로 판별할지에 대한 정보가 제공되지 않았기 때문입니다.\n\n키로 비교를 할 것인지, 머리의 길이로 비교를 할 것인지, 몸무게로 비교를 할 것인지 등이요.\n\n\n\n즉, 자바의 원시 타입(primitive)간의 비교는 어떤것이 더 크다 작다가 명백하지만, 객체간의 비교에서는 어떤 기준으로 비교 할 것인가에 대한 정의가 필요해지게 됩니다.\n\n\n\n그리고 바로 이러한 기준을 제공해주는것이 Comparable &amp; Comparator 인터페이스입니다.\n\n그리고 두 인터페이스간에는 사용 방법이라는 명확한 차이가 존재합니다.\n\n\n\nComparator\n\n\n\nComparator는 이름대로 비교기입니다.\n\n이 인터페이스의 명세를 먼저 살펴보겠습니다.\n\n인터페이스가 아주 많은데, 중요한것은 compare 단 하나뿐입니다.\n\ncompare와 equals를 제외한 다른 추상메서드들은 default거나 static으로 선언돼있기 때문에 기본적으로 신경쓰지 않아도 무방하며, equals는 핵심인 객체간의 비교와는 상관이 없기 때문에 역시 신경쓰지 않아도 됩니다. (서로 다른 Comparator간의 비교를 의미합니다. 정확한 것은 javadoc을 참고하세요.)\n\n\n\n@FunctionalInterface\npublic interface Comparator&lt;T&gt; {\n    int compare(T o1, T o2);\n}\n\n\n\n\n\n  Compares its two arguments for order. Returns a negative integer, zero, or a positive integer as the first argument is less than, equal to, or greater than the second. The implementor must ensure that signum(compare(x, y)) == -signum(compare(y, x)) for all x and y. (This implies that compare(x, y) must throw an exception if and only if compare(y, x) throws an exception.)\nThe implementor must also ensure that the relation is transitive: ((compare(x, y)&gt;0) &amp;&amp; (compare(y, z)&gt;0)) implies compare(x, z)&gt;0. Finally, the implementor must ensure that compare(x, y)==0 implies that signum(compare(x, z))==signum(compare(y, z)) for all z.\n\n\n\n\n뭔가 설명이 많은데 중요한것은 아래 단 한 줄입니다.\n\n\n\n\n  두 인수를 비교합니다. 첫 번째 인수가 두 번째 인수보다 작다면 음의 정수, 같다면 0, 크다면 양의 정수를 반환합니다.\n\n\n\n\n일단 코드를 봅시다.\n\n\n\npublic record Student(Integer id) {}\n\n\n\n\nclass StudentTests {\n    List&lt;Student&gt; students;\n\n    @BeforeEach\n    void setUp() {\n        students = IntStream.rangeClosed(1, 50)\n                .mapToObj(Student::new)\n                .toList();\n\n        Collections.shuffle(students);\n    }\n\n    @Test\n    void comparator() {\n        Collections.sort(students, (o1, o2) -&gt; 1); // Comparator 사용 (람다식)\n    }\n}\n\n\n\n\nComparator는 이렇게 위와 같이 정렬에 사용됩니다.\n\n위 코드에서는 자바 컬렉션을 정렬할 때 사용하는 Collections 클래스를 사용하였으며, 마찬가지로 자바 배열을 정렬할 때 사용하는 Arrays.sort에도 Comparator를 인수로 하는 메서드가 오버로딩 되어 있습니다.\n\n도입부에서도 언급한바와 같이, 정렬을 할 때 대상이 객체인 경우 명확한 기준을 통해 객체간의 비교가 되어야지만 정렬을 할 수가 있는데, 이 객체를 어떤 기준으로 비교 할 것인가라는 책임을 동작 파라미터화한 것이 Comparator와 Comparable이라고 정의 할 수 있습니다.\n\n즉, 정렬 구현체들은 정렬만 하고, 정렬을 위한 객체 비교는 Comparator와 Comparable에 위임하는 것입니다.\n\n\n\n따라서 개발자들은 Comparator와 Comparable를 오버라이딩하여 객체끼리 어떻게 비교 할 것인지를 정해주기만 하면 됩니다.\n\n여기서 Student에는 id라는 속성이 있기 때문에 저는 Student끼리 비교할 때 id를 기준으로 비교하도록 하겠습니다.\n\n정렬 구현체 입장에서는 간단합니다.\n\nComparator.compare에 정의된 javadoc과 정확히 동일한데, Comparator.compare(student1, student2)라고 호출했을 때,\n\n\n\n\n  결과로 -1이 나왔다면 첫번째 인수인 student1이 student2보다 작다는 것입니다.\n  결과로 0이 나왔다면 첫번째 인수인 student1과 student2는 같다는 것입니다.\n  결과로 1이 나왔다면 첫번째 인수인 student1이 student2보다 크다는 것입니다.\n\n\n\n\n그리고 정렬 구현체는 Comparator가 내린 이러한 판단을 근거로 정렬을 할 수 있게 됩니다.\n\n실제 사용 코드는 다음과 같이 됩니다.\n\n\n\nclass StudentTests {\n    List&lt;Student&gt; students;\n\n    @BeforeEach\n    void setUp() {\n        students = IntStream.rangeClosed(1, 50)\n            .mapToObj(Student::new)\n            .toList();\n\n        Collections.shuffle(students);\n    }\n\n    @Test\n    void comparator() {\n        Collections.sort(students, (s1, s2) -&gt; s1.id() - s2.id());\n    }\n}\n\n\n\n\n\n여기서 알아야 할 것이 한가지 있습니다.\n\n대부분의 컴퓨팅 시스템은 기본적으로 오름차순(ASC)을 기준으로 구현이 돼있습니다.\n\n이는 자바에 구현된 수많은 정렬 구현체들도 동일합니다.\n\n한가지 예를 들어보겠습니다.\n\n\n\n{5,2,1} 이라는 정수형 배열이 있습니다.\n\n버블 정렬을 기준으로 설명드리자면, 버블 정렬은 기본적으로 왼쪽에서 오른쪽으로 두 원소를 비교해나가면서 정렬이 이뤄지기 때문에 처음에는 5와 2를 비교할 것입니다.\n\n따라서, 버블 정렬 구현체는 내부적으로 Comparator.compare(5, 2)를 호출하고, 이에 대한 결과는 첫번째 인수인 5에서 두번째 인수인 2를 뺀 양의 정수 3이 반환됩니다.\n\n즉, Comparator의 명세대로라면 배열의 선행 원소인 5가 후행 원소인 3보다 크다는 의미와 동일합니다.\n\n그리고 기본적인 정렬 방식은 오름차순이기 때문에 버블 정렬 구현체는 5와 2의 위치를 바꾸어 더 큰 수인 5가 오른쪽으로 가도록 할 것입니다.\n\n따라서 비교 결과는 {2,5,1}이 됩니다.\n\n\n\n감이 잡히시나요?\n\n다시 원래 코드를 봅시다.\n\n\n\n위 코드에서 저는 두 객체의 id값의 차이를 반환하도록 하였습니다.\n\ns1.id = 5이고, s2.id = 2라고 가정하고 코드를 보면 5 - 2 = 3이므로, 양의 정수인 3이 반환됩니다.\n\n이는 s1이 s2보다 크다는 말과 같습니다.\n\n즉, 정렬 구현체는 s1을 s2보다 크다고 판단하여 s1을 오른쪽으로 옮길것입니다.\n\n\n\n그렇다면 만약 내림차순(DESC)으로 정렬을 하고 싶다면 어떻게 해야 할까요?\n\n아주 간단합니다.\n\n\n\nclass StudentTests {\n    List&lt;Student&gt; students;\n\n    @BeforeEach\n    void setUp() {\n        students = IntStream.rangeClosed(1, 50)\n            .mapToObj(Student::new)\n            .toList();\n\n        Collections.shuffle(students);\n    }\n\n    @Test\n    void comparator() {\n        Collections.sort(students, (s1, s2) -&gt; s2.id() - s1.id()); // s2에서 s1을 빼도록 위치 변경\n    }\n}\n\n\n\n\ns1과 s2의 위치를 바꾸면 됩니다.\n\n\n\nComparable\n\n\n\nComparable은 문자 그대로 비교 가능한입니다.\n\n역시 인터페이스에 정의된 사양을 먼저 봅시다.\n\n\n\npublic interface Comparable&lt;T&gt; {\n    public int compareTo(T o);\n}\n\n\n\n\n\n  Compares this object with the specified object for order. Returns a negative integer, zero, or a positive integer as this object is less than, equal to, or greater than the specified object.\n\n\n\n  이 객체를 지정된 객체(compareTo)와 비교하여 순서를 지정합니다. 이 객체(this)가 지정된 객체보다 작다면 음의 정수, 같다면 0, 크다면 양의 정수를 반환합니다.\n\n\n\n\n마찬가지로 음의 정수, 0, 양의 정수를 반환하므로 본질적인 비교 방법에 대해서는 Comparator와 차이가 없습니다.\n\n다만, Comparator는 비교하려는 객체 두개를 인수로 받지만, Comparable은 비교하려는 객체에 서브타이핑을 통해 다른 객체를 입력받아 자기 자신과 비교한다는 사용방법의 차이가 있을 뿐입니다.\n\n\n\n\n  서브타이핑: 인터페이스 상속\n\n  서브클래싱: 구현 상속\n\n\n\n\n실제 사용 예는 다음과 같습니다.\n\n\n\npublic record Student(Integer id) implements Comparable&lt;Student&gt;{ // 서브타이핑\n    @Override\n    public int compareTo(Student o) {\n        return this.id - o.id;\n    }\n}\n\n\n\n\n만약 정렬 방식을 내림차순으로 바꾸고 싶다면 역시 다음과 같이 구현하면 되겠죠?\n\n\n\npublic record Student(Integer id) implements Comparable&lt;Student&gt;{\n    @Override\n    public int compareTo(Student o) {\n        return o.id - this.id;\n    }\n}\n\n\n\n\n이러한 이유들로 인해 자바에서 사용되는 객체간의 모든 정렬에는 Comparator 혹은 Comparable가 반드시 필요합니다.\n\n그리고 반대로, 두 인터페이스 중 하나라도 정렬 구현체에 제공해줄수만 있다면 객체간의 정렬이 가능해지게 됩니다.\n\n\n\n자바의 자료형들은 전부 내부적으로 Comparator 혹은 Comparable를 구현해두었습니다.\n\n자주 사용하는 String(문자열)의 비교 코드를 한번 보죠.\n\n내부적으로 메서드 추출 리팩토링이 많이 되어있지만, 중요한 부분은 다음 코드입니다.\n\n\n\npublic static int compareToCI(byte[] value, byte[] other) {\n    int len1 = value.length;\n    int len2 = other.length;\n    int lim = Math.min(len1, len2);\n    for (int k = 0; k &lt; lim; k++) {\n        if (value[k] != other[k]) {\n            char c1 = (char) CharacterDataLatin1.instance.toUpperCase(getChar(value, k));\n            char c2 = (char) CharacterDataLatin1.instance.toUpperCase(getChar(other, k));\n            if (c1 != c2) {\n                c1 = Character.toLowerCase(c1);\n                c2 = Character.toLowerCase(c2);\n                if (c1 != c2) {\n                    return c1 - c2;\n                }\n            }\n        }\n    }\n    return len1 - len2;\n}\n\n\n\n\n문자열 두개를 입력받아, 두 문자열의 길이를 먼저 비교합니다.\n\n문자열 abcd와 abc가 입력됐다고 가정합시다.\n\nMath.min 메서드를 통해 두 문자열의 길이 중 작은 값을 얻어낸 후 얻어낸 길이만큼만 for문을 돌며 대문자로 변경 후 비교 -&gt; 소문자로 변경 후 비교를 하고 있습니다.\n\n그리고 사전순으로 앞서는 값을 반환하도록 하고 있네요.\n\n그러면 abcd와 abc가 입력됐을 경우 abc가 abcd보다 사전순으로 더 앞서므로 abc, abcd순으로 정렬이 될 것임을 짐작해볼 수 있습니다.\n\n\n\npublic class StringSortTest {\n    @Test\n    void sort() {\n        String[] strings = {\"abcd\", \"abc\"};\n        Arrays.sort(strings);\n        assertThat(Arrays.asList(strings).toString()).isEqualTo(\"[abc, abcd]\"); // 테스트 통과\n    }\n}\n\n\n\n\n마지막으로 이 내용은 본문과는 크게 상관없는 내용이지만, 자바의 정렬은 정렬 메서드에 넘어간 배열의 사이즈에 따라 다른 정렬 알고리즘이 선택되어 사용됩니다.\n\n참고해두시면 도움이 될 것 같습니다.\n\n\n\n\n\n\n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2022-02-18-comparable-comparator/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "운영체제(Operating System) 4강",
      "date": "2022-02-19 00:00:00 +0000",
      "description": "반효경 교수님 - CPU Scheduling\n",
      "content": "\n  Lecture\n  CPU burst &amp; I/O burst    \n      CPU burst\n      I/O burst\n      CPU bound process &amp; I/O bound process\n    \n  \n  CPU Scheduling    \n      CPU Scheduler        \n          CPU 스케쥴러가 필요한 경우\n          Dispatcher\n        \n      \n      Scheduling Criteria        \n          시스템 측면\n          프로세스 측면\n          중국집으로 비유한 스케쥴링 성능 척도\n        \n      \n      CPU Scheduling Algorithms        \n          FCFS (First-Come First-Served)\n          SJF (Shortest-Job-First)\n          Priority Scheduling\n          RR (Round Robin)\n          Multi-Level Queue\n          Multi-Level Feedback Queue\n        \n      \n      Multi-Processor Scheduling        \n          Real-time Scheduling\n          Thread Scheduling\n        \n      \n      Scheduling Algorithmic Evaluation        \n          Queuing Model\n          Implementation &amp; Measurement\n          Simulation\n        \n      \n    \n  \n\n\n\n\nLecture\n\n\n\n\n  운영체제 - 반효경 교수님\n    \n      CPU Scheduling 1\n      CPU Scheduling 2\n    \n  \n\n\n\n\nCPU burst &amp; I/O burst\n\n\n\n프로세스의 작업은 크게 두가지로 나뉘는데, 결과를 화면에 출력하거나, 다른 파일에 접근하여 데이터를 읽어오거나, 다른 컴퓨터와 통신하는 등의 I/O 작업과, 어떤 결과를 도출해내기 위한 CPU 연산 작업으로 이뤄져있다.\n\n\n\n\n\n\n\nCPU burst\n\n\n\nCPU 버스트는 사용자 프로세스가 CPU를 할당받아 명령어들을 빠르게 수행하는 단계이다.\n\n이 때, 사용자 프로세스는 CPU 내에서 일어나는 명령(연산)이나 메모리에 접근하는 일반 명령(읽기, 쓰기)을 수행 할 수 있다.\n\n\n\nI/O burst\n\n\n\nI/O 버스트는 사용자 프로세스가 시스템 콜을 통해 운영체제에 작업을 위탁한 후 운영체제에 의해 I/O 작업을 진행하는 단계이다.\n\n이 단계에서 모든 I/O 작업은 커널 모드로 수행되기 때문에 오로지 운영체제를 통해서만 수행된다.\n\n이처럼 사용자 프로그램이 수행되는 과정은 CPU 버스트와 I/O 버스트의 반복으로 구성된다.\n\n\n\nCPU bound process &amp; I/O bound process\n\n\n\n각 사용자 프로세스는 CPU 버스트와 I/O 버스트의 비율이 다르다.\n\n사용자 입출력이 많은 프로세스는 I/O 버스트가 CPU 버스트에 비해 많은 비율을 차지하겠지만, 사용자 입출력이 거의 없이 오로지 연산만 하는 경우는 CPU 버스트의 비율이 더 높게 나타난다.\n\n이러한 기준에서 프로세스는 CPU bound process와 I/O bound process로 나눌 수 있다.\n\n\n\n\n\n\n\n프로세스 수행 구조를 보면 I/O bound process는 짧은 CPU 버스트를 많이 가지고 있는 반면, CPU bound process는 소수의 긴 CPU 버스트로 구성되고 있는 것을 볼 수 있다.\n\n\n\nCPU Scheduling\n\n\n\n컴퓨터 시스템 내에서 수행되는 프로세스들의 CPU 버스트를 분석해보면 대부분의 프로세스가 짧은 CPU 버스트를 가지며, 극히 일부분의 프로세스만 긴 CPU 버스트를 갖는다.\n\n이는 다시 말해서 CPU를 한 번에 오래 사용하기보다는 잠깐 사용하고 I/O 작업을 수행하는 프로세스가 많다는 것이다.\n\n즉, 사용자와의 대화형 작업(인터랙션)을 많이 수행한다고 볼 수 있는데, 사용자에 대한 빠른 응답을 위해서는 해당 프로세스에게 우선적으로 CPU를 할당하는 것이 바람직하다. 왜냐하면, 만약 CPU 바운드 프로세스에게 먼저 CPU를 할당한다면 그 프로세스가 CPU를 다 사용할 때까지 수많은 I/O 바운드 프로세스는 기다려야할 것이다. 이는 사용자 경험측면에서 봤을 때 컴퓨터의 응답이 느려진다는 치명적인 결과로 이어진다.\n\n이러한 이유로 어떤 프로세스에게 CPU를 더 먼저 할당해줄지를 결정하는 CPU 스케쥴링이 필요해졌다.\n\n\n\nCPU Scheduler\n\n\n\nCPU 스케쥴러는 준비 상태에 있는 프로세스들 중 어떠한 프로세스에게 CPU를 할당할 지 결정하는 운영체제의 코드이다.\n\n즉, 단순히 운영체제 코드에 정의된 어떤 함수일 뿐이며, 이를 범용적으로 CPU 스케쥴러라고 부르는 것이다.\n\n이 코드는 당장 깃허브에 리눅스 프로젝트를 검색해 들어가면 볼 수 있다.\n\n\n\nCPU 스케쥴러가 필요한 경우\n\n\n\nCPU 스케쥴링이 필요한 경우는 프로세스에게 다음과 같은 상태 변화가 있는 경우이다.\n\n\n\n\n  Running -&gt; Blocked (예: I/O 요청하는 시스템 콜)\n  Running -&gt; Ready (예: 할당 시간 만료로 타이머 인터럽트 발생)\n  Blocked -&gt; Ready (예: I/O 완료 후 인터럽트)\n  Terminated (예: 프로세스 종료)\n\n\n\n\n1, 4번째의 스케쥴링은 강제로 빼앗지 않고 자진 반납하는 non-preemptive(비선점, 자발적인) 방식이고, 그 외의 스케쥴링은 CPU를 강제로 빼앗는 preemptive(선점, 강제적인) 방식이다.\n\n\n\nDispatcher\n\n\n\nCPU를 누구한테 누구한테 줄 지 결정했으면 해당 프로세스에게 넘겨야 하는데, 디스패처가 이 역할을 수행한다. 이 과정이 Context Switch에 해당한다.\n\n참고로, 디스패처는 관제탑에서 여러 비행기들에게 지시하는 사람을 의미한다.\n\n\n\n\n\n\n\nScheduling Criteria\n\n\n\n\n\n\n\n시스템 측면\n\n\n\n시스템 측면에서의 성능 척도라는 것은 CPU 하나를 가지고 최대한 일을 많이 시키면 좋은 것이다.\n\n따라서 다음 두개의 지표를 본다.\n\n\n\n\n  CPU utilization (CPU 이용률)\n    \n      전체 시간 중에서 CPU가 놀지 않고 일을 한 시간의 비율\n      keep the CPU as busy as possible (가능한 바쁘게 일을 시켜야 한다)\n    \n  \n  Throughput (처리량, 산출량)\n    \n      주어진 시간동안 몇개의 작업을 완료했는가\n      CPU를 원하는 프로세스 중 몇 개가 원하는 만큼의 CPU를 사용하고 있고, 이번 CPU 버스트를 끝내어 레디큐를 떠났는지 측정한 것\n      더 많은 프로세스들이 CPU 작업을 완료하기 위해서는 CPU 버스트가 짧은 프로세스에게 우선적으로 CPU를 할당하는 것이 유리할 것\n    \n  \n\n\n\n\n프로세스 측면\n\n\n\n프로세스 측면에서의 성능 척도라는 것은 자신이 CPU를 빨리 얻어서 해야 할 작업을 빨리 끝내면 좋은 것이다.\n\n따라서 다음 세가지의 지표를 본다.\n\n\n\n\n  Turnaround time (소요 시간, 반환 시간)\n    \n      프로세스가 CPU를 사용하기 위해 레디큐에 들어와서, CPU를 다 사용하고 나갈 때까지 걸린 시간을 의미\n      즉, Turnaround time = Waiting time + 실제로 CPU를 사용한 시간\n    \n  \n  Waiting time (대기 시간)\n    \n      CPU 버스트 중 프로세스가 레디큐에서 CPU를 얻기 위해 기다린 시간의 총 합을 의미\n      시분할 시스템의 경우 CPU를 강제적으로 계속 빼앗길 수 있기 때문에, 한 번의 CPU 버스트 중에도 레디큐에서 기다리는 시간이 여러 번 발생할 수 있다\n    \n  \n  Response time (응답 시간)\n    \n      프로세스가 준비 큐에 들어온 후 첫 번째 CPU를 획득하기까지 기다린 시간을 뜻한다\n      응답 시간은 대화형 시스템에 적합한 성능 척도로서, 사용자 입장에서 가장 중요한 성능 척도라고 할 수 있다\n    \n  \n\n\n\n\n중국집으로 비유한 스케쥴링 성능 척도\n\n\n\n중국집에 주방장 한명과 여러 손님이 있다.\n\n중국집 입장에서는 주방장한테 일을 많이 시키는게 좋다.\n\n\n  CPU utilization: 전체 시간 중 주방장이 일을 한 시간의 비율. 당연히 높으면 좋을 것\n  Throughput: 정해진 시간 동안 주방장이 몇명의 손님에게 요리를 만들어 주었는가. 당연히 높으면 좋을 것\n\n\n\n\n손님 입장에서는 중국집에 밥을 먹으러 들어가서 밥을 먹고 나오는 시간이 짧으면 짧을수록 좋다.\n\n\n  Turnaround time: 손님이 중국집에 들어와 음식을 주문하고, 주문한 음식을 다 먹고 나가기까지 소요된 총 시간\n  Waiting time: 음식을 먹은 시간을 제외한 순수하게 기다린 시간 (코스요리 처럼 음식이 여러 번 나누어져 나오는 경우 중간중간 기다린 시간을 모두 다 합쳐야 한다)\n  Response time: 최초의 음식이 나오기까지 손님이 기다린 시간\n\n\n\n\nCPU Scheduling Algorithms\n\n\n\nFCFS (First-Come First-Served)\n\n\n\n\n  먼저 온 순서대로 처리하는 방식 (non-preemptive)\n  버스트 타임이 긴 프로세스와 짧은 프로세스들이 있는 상황에, 버스트 타임이 가장 긴 프로세스가 가장 먼저 도착하면 버스트 타임이 짧은 프로세스들은 앞의 프로세스가 끝날때까지 대기해야만 한다\n  마트 계산대로 비유하자면, 나는 아이스크림 하나만 결제하고 나가면 되는데, 앞에 카트를 통째로 채워온 손님이 먼저 도착하여 계산을 하고 있는 경우와 같다\n\n\n\n\n\n\n\n\n\n  위 사진처럼 어떤 프로세스가 먼저 CPU를 할당받느냐에 따라 전체 대기 시간에 상당한 영향을 미침\n    \n      1번\n        \n          대기 시간: P1 = 0, P2 = 24, P3 = 27\n          평균 대기 시간: (0 + 24 + 27) / 3 = 17\n        \n      \n      2번\n        \n          대기 시간: P1 = 6, P2 = 0, P3 = 3\n          평균 대기 시간: (6 + 0 + 3) / 3 = 3\n        \n      \n    \n  \n  긴 프로세스 하나 때문에 짧은 프로세스 여러 개가 기다리는 현상을 Convoy effect 라 부른다\n\n\n\n\nSJF (Shortest-Job-First)\n\n\n\n\n\n\n\n\n  버스트 타임이 가장 짧은 프로세스에게 가장 먼저 CPU를 할당하는 방식\n  평균 대기 시간을 가장 짧게 가져가는 알고리즘 (minimum average wating time)\n\n\n\n\n\n\n\n\n\n\n\n\n\n  문제점\n    \n      Starvation (기아): 버스트 타임이 짧은 프로세스가 계속해서 들어오면 버스트 타임이 상대적으로 긴 프로세스가 영원히 CPU를 할당받지 못할 수도 있다\n      정확한 버스트 타임을 미리 알 수 없고, 과거 버스트 타임을 통해 추정만 할 수 있다\n    \n  \n\n\n\n\n\n\n\n\nPriority Scheduling\n\n\n\n\n  우선 순위가 제일 높은 프로세스에게 CPU를 할당\n  일반적으로 우선 순위 값(priority number)이 작을 수록 높은 우선 순위를 갖는다. (정수형)\n  non-preemptive (비선점형)\n    \n      일단 CPU를 할당 받으면, 더 높은 우선 순위를 가진 프로세스가 들어와도 CPU 버스트가 완료될 떄까지 CPU를 빼앗기지 않는다\n    \n  \n  preemptive (선점형)\n    \n      CPU를 할당받아 작업중이더라도 더 높은 우선 순위를 가진 프로세스가 들어오면 CPU를 빼앗긴다\n    \n  \n  SJF는 버스트 타임을 우선순위로 사용하는 우선 순위 스케쥴링의 일종이라고 볼 수 있다\n  문제점\n    \n      Starvation (기아): 우선 순위가 낮은 프로세스가 지나치게 오래 기다리거나, 혹은 영원히 CPU를 할당 받지 못할 수도 있다\n    \n  \n  해결 방안\n    \n      Aging (노화): 우선 순위가 낮은 프로세스에 대해 기다린 시간만큼 비례하여 우선 순위를 높여주는 기법\n    \n  \n\n\n\n\nRR (Round Robin)\n\n\n\n\n  각 프로세스는 동일한 크기의 할당 시간(time quantum) 을 가진다\n  할당 시간이 지나면 프로세스는 CPU를 빼앗기고 레디큐 맨 뒤에 가서 줄을 선다\n  사용자에게 짧은 응답 시간을 보장함\n    \n      CPU를 줬다 뺏었다를 반복하기 때문에 CPU를 최초로 얻기까지 걸리는 시간이 짧다\n      n개의 프로세스가 레디큐에 있고, 할당 시간이 q인 경우 어떤 프로세스도 (n - 1) * q 이상 기다리지 않는다\n      CPU를 할당받기 위해 기다리는 시간이 CPU 버스트에 비례한다\n    \n  \n  성능\n    \n      q가 커질 수록 FCFS에 가까워진다\n      q가 작을 수록 Context Switch로 인한 오버헤드가 증가한다\n    \n  \n  일반적으로 SJF보다 평균 Turnaround time이 길지만, 응답 시간은 짧다\n  시간이 오래 걸리는 프로세스와 짧게 걸리는 프로세스가 섞여 있을 때는 효율적이지만, 시간이 동일한 프로세스만 있을 때는 비 효율적이다.\n\n\n\n\n\n\n\n\n위와 같이 RR은 정해진 할당 시간(20) 만큼만 공평하게 CPU를 사용한다.\n\n\n\nMulti-Level Queue\n\n\n\n\n\n\n\n\n\n\n\n\n  우선 순위에 따라 여러개의 레디큐를 둔다\n    \n      사용자에게 빠른 응답을 줘야하는 대화형 작업은 우선순위가 높은 전위큐에 넣는다\n        \n          전위큐에서는 주로 RR 스케쥴링 기법을 사용한다\n        \n      \n      계산 위주의 작업은 우선순위가 낮은 후위큐에 넣는다\n        \n          후위큐에서는 주로 FCFS 스케쥴링 기법을 사용한다\n        \n      \n    \n  \n  멀티 레벨 큐 자체에 대한 스케쥴링이 필요하다\n    \n      고정 우선순위 방식 (Fixed Priority Scheduling)\n        \n          전위큐에 있는 프로세스에게 우선적으로 CPU가 할당되고, 전위큐가 비어 있는 경우에만 후위큐에 있는 프로세스에게 CPU가 할당된다\n          Starvation (기아) 가능성이 존재한다\n        \n      \n      타임 슬라이스 방식 (Time Slice)\n        \n          각 큐에 CPU 사용 시간을 적절한 비율로 할당한다.\n          예: 80%는 전위큐, 20%는 후위큐\n        \n      \n    \n  \n\n\n\n\nMulti-Level Feedback Queue\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  현대에 와서, 대다수의 컴퓨터들이 채택하고 있는 CPU 스케쥴링 기법이다\n  프로세스가 여러 개로 분할된 레디큐 내에서 다른 큐로 이동이 가능하다\n  멀티 레벨 피드백 큐를 이용하여 Aging (노화) 기법을 구현할 수 있다\n    \n      Aging 기법은 프로세스가 우선 순위가 낮은 큐에서 오래 기다리면, 우선 순위가 높은 큐로 승격하는 방식이다\n    \n  \n  멀티 레벨 피드백 큐를 정의하는 요소\n    \n      큐의 수\n      각 큐의 스케쥴링 알고리즘\n      프로세스를 상위큐로 승격하는 기준\n      프로세스를 하위큐로 강등하는 기준\n      프로세스가 도착했을 때 들어갈 큐를 결정하는 기준\n        \n          일반적으로 처음 들어온 프로세스는 CPU 할당 시간을 짧게 하여 우선 순위가 가장 높은 전위큐에 배치한다\n          만약 주어진 할당 시간 안에 작업을 완료하지 못하면 CPU 할당 시간을 조금 더 주되, 우선 순위가 한 단계 낮은 큐로 강등한다\n          이 과정을 반복하다가 최하위큐에 배치가 된다\n        \n      \n    \n  \n\n\n\n\nMulti-Processor Scheduling\n\n\n\n은행으로 비유하자면, 행원 한명과 은행 창구 하나만 있던 상황에서, 행원과 은행 창구가 여러명으로 늘어난 것과 같은 상황이다.\n\n이렇게 되어도 근본적인 CPU 스케쥴링에는 큰 차이가 없으나 몇가지 특이한 상황이 발생할 수 있다.\n\n\n\n\n\n\n\nReal-time Scheduling\n\n\n\n정해진 시간 안에 반드시 실행이 되어야 하는, 즉 프로세스에 데드라인이 있는 경우 사용하는 기법이다.\n\n\n\n\n  Hard real-time systems\n    \n      정해진 시간 안에 반드시 작업이 끝나도록 스케쥴링해야 한다\n      미사일 발사 버튼같은 것들을 생각해볼 수 있다\n    \n  \n  Soft real-time systems\n    \n      데드라인이 존재하기는 하지만 지키지 못했다고 해서 위험한 상황이 생기지는 않는다\n      일반 프로세스에 비해 높은 우선 순위를 갖도록 한다\n    \n  \n\n\n\n\nThread Scheduling\n\n\n\n\n  Local Scheduling\n    \n      운영체제가 스레드의 존재를 모르는 것을 유저 레벨 스레드라고 한다\n      OS가 아닌 사용자 프로세스가 직접 어느 스레드한테 CPU를 줄 것인지 결정한다\n      대표적으로 구버전 JVM의 스레드 스케쥴링이 있다\n    \n  \n  Global Scheduling\n    \n      커널 레벨 스레드의 경우 일반 프로세스처럼 운영체제의 단기 스케쥴러가 어떤 스레드를 스케쥴할 지 결정한다\n    \n  \n\n\n\n\nScheduling Algorithmic Evaluation\n\nQueuing Model\n\n\n\n\n  주로 이론가들이 수행하는 방식\n  확률 분포로 주어지는 도착율(Arrival Rate)과 처리율(Service Rate)등을 통해 각종 성능 지표를 계산한다\n\n\n\n\nImplementation &amp; Measurement\n\n\n\n\n  주로 구현가들이 수행하는 방식으로, 실측을 의미한다\n  실제 시스템에 알고리즘을 구현하여 실제 작업에 대해서 성능을 측정하여 비교한다\n  예를 들어 새로운 CPU 스케쥴링 알고리즘을 개발했다고 가정하면, 리눅스의 스케쥴링 함수를 직접 개발한 알고리즘으로 수정한 후 컴파일 하여 컴파일된 리눅스를 직접 돌려 성능 지표를 뽑아낸 후 기존 리눅스와 비교하는 방식이라고 생각하면 되겠다\n\n\n\n\nSimulation\n\n\n\n\n  알고리즘을 모의 프로그램으로 작성한 후 trace(실제 시스템에서 추출한 입력값)를 입력으로 하여 결과를 비교한다\n\n\n\n",
      "categories": ["cs","operating-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/operating-system/2022-02-19-cpu-scheduling/"
    },{
      "image": "/assets/img/ide/Intellij.png",
      "title": "Translation",
      "date": "2022-02-20 00:00:00 +0000",
      "description": "젯브레인이 공식 지원하는 번역 플러그인\n",
      "content": "\n  Translation\n\n\nTranslation\n\n\n\n현 시점 최신 버전의 젯브레인 툴(인텔리제이, 웹스톰 등)을 설치하게 되면 한국어가 지원이 되고 있습니다.\n\n이는 Translation이라는 번역 플러그인 덕분입니다.\n\n즉, 현재 젯브레인 툴을 설치하면 이 번역 플러그인도 같이 설치되어있을 확률이 높습니다.\n\nTranslation은 현재 젯브레인에서 공식적으로 후원하고 있는 플러그인으로, 지원이 쉽게 중단되지는 않을거라고 생각하고 있습니다.\n\n이 플러그인에는 단순히 툴 자체의 언어를 통으로 바꿔주는 것 뿐만 아니라 유용한 기능이 다수 포함돼있는데요, 그 중 제가 주로 사용하는 기능 몇가지를 공유하려고 합니다.\n\n\n\n우선 Translation 플러그인을 설치해야합니다.\n\n다만, 최신 툴을 사용하시는 분들은 이미 설치돼있을 확률이 높습니다.\n\n\n\n\n\n\n\n설치를 완료했다면 Settings - Keymap 으로 진입하여 다음 두개의 기능에 편한 단축키를 등록해줍니다.\n\n기능이 여러가지 있지만, 이 중 가장 자주 사용하게 되는 기능은 Translate, Translate and Replace 입니다.\n\n저는 각각 Alt + Shift + 2와 Ctrl + Shift + X로 설정해주었습니다.\n\n젯브레인 툴은 워낙 단축키가 많아, 기존의 단축키와 중복되지 않으면서도 편한 단축키를 찾는게 생각보다 어려울 수 있습니다.\n\n\n\n\n\n\n\n여담이지만, Settings - Tools - Translation 에서 여러가지 설정을 만질 수 있습니다만, 기본적으로는 별로 건들게 없었습니다.\n\n제 기준으로는 별다른 설정을 해주지 않더라도 한국어 - 영어로 세팅이 되어있긴 했는데, 혹시 다를 수도 있으니 한번 확인해보시기 바랍니다.\n\n\n\n\n\n\n\n하기 이미지는 Translate에 등록한 단축키인 Alt + Shift + 2를 입력하였을 때 발생하는 액션입니다.\n\n번역을 원하는 단어를 하이라이팅 한 후 단축키를 입력하면 아래와 같이 여러가지 정보들이 출력됩니다.\n\n저는 주로 모르는 단어가 나오면 이 기능을 사용하게 되는 것 같습니다.\n\n이미지에서는 영어 -&gt; 한국어로 번역하였으나 반대로도 가능합니다.\n\n\n\n\n\n\n\n하기 이미지는 Translate and Replace에 등록한 단축키인 Ctrl + Shift + X를 입력했을 때의 모습입니다.\n\n단어를 번역하고 치환해줍니다.\n\n저는 주로 마땅한 변수명이 생각나지 않을 경우 이 기능을 사용하게 되는 것 같습니다.\n\n마찬가지로 이미지에서는 한국어 -&gt; 영어로 번역하였으나 반대로도 가능합니다.\n\n\n\n\n\n\n\n개발을 하다 보면 공식문서를 참고해야 할 일이 많습니다.\n\n자바는 코드 베이스에 javadoc이라는 주석으로 된 문서가 기본적으로 많이 작성돼있는데요, 이 javadoc도 한국어로 통번역이 가능합니다.\n\n반대로도 가능하며, 생각보다 번역 퀄리티도 훌륭합니다.\n\n아래와 같이 javadoc에 우클릭을 한 후 Translate Documentation을 클릭하면…\n\n\n\n\n\n\n\n다음과 같이 번역됩니다.\n\n\n\n\n\n\n",
      "categories": ["ide","intellij"],
      "tags": [],
      
      "collection": "posts",
      "url": "/ide/intellij/2022-02-20-translation/"
    },{
      "image": "/assets/img/backend/test-logo.png",
      "title": "컨트롤러 테스트를 최적화해보기",
      "date": "2022-02-22 00:00:00 +0000",
      "description": "Spring 환경에서 컨트롤러 테스트를 더욱 깔끔한 구조로, 더욱 빠르게 실행되게 작성해보기\n",
      "content": "\n  컨트롤러 테스트시 문제점?\n  솔루션\n\n\n\n\n컨트롤러 테스트시 문제점?\n\n\n\n저는 주로 HTTP 계층 테스트 + API 문서화 용도로 Spring Rest Docs를 사용합니다.\n\n그리고 위 목적을 이루기 위해 컨트롤러 테스트를 필수적으로 작성하게 됩니다.\n\n\n\n\n  Swagger는 이쁘고 사용하기 편리하지만, 테스트 코드가 없어도 문서를 작성할 수 있다는 특징으로 인해, 실제 API 스펙과 API 문서의 스펙이 다른 문제가 발생할 수 있고, 컨트롤러에 Swagger 코드가 침투한다는 점으로 인해 제가 선호하지 않습니다.\n\n\n\n\nSpring Rest Docs를 사용하는 경우, 보통 @SpringBootTest를 사용하여 통합 테스트를 진행하거나, HTTP 계층만 테스트하기 위해 슬라이싱 테스트인 @WebMvcTest를 사용하게 됩니다.\n\n저 같은 경우엔 @WebMvcTest를 사용하고 있었습니다.\n\n왜냐하면 @SpringBootTest를 사용해 통합 테스트를 진행하게 되면 테스트에서 영속성 계층에 의존성이 생겨 골치아파지는 경우가 많았기 때문입니다.\n\n즉, 저는 HTTP 계층, 서비스 계층, 영속성 계층을 모두 따로 테스트하는것을 선호하며, 그중에서도 영속성 계층은 Spring Data JPA 프로젝트에 이미 테스트 코드가 매우 잘 작성돼있기 때문에, JPA를 사용하는 경우에는 이마저도 잘 테스트하지 않고, 쿼리가 실제로 어떻게 발생하는지 궁금할때만 작성해보는 편입니다.\n\n\n\n아무튼, 위와 같은 이유들로 슬라이싱 테스트를 매우 선호하는데, 슬라이싱 테스트를 하는 경우에는 계층간의 의존성을 끊어내기 위해 @MockBean을 사용하게 되는 경우가 많습니다.\n\n\n\n문제는, 이렇게 Mocking하는것이 과도하게 많아지게 되면 컨텍스트를 매번 새롭게 로딩하게 되기 때문에 테스트가 심각하게 느려지게 됩니다.\n\n그리고 또 이러한 문제를 해결하기 위해(🤣) 컨텍스트 재사용을 위한 추상 클래스를 하나 작성하게 됩니다.\n\n이 경우 추상 클래스는 대략 다음과 같은 모양새가 나오게 됩니다.\n\n\n\n@AutoConfigureRestDocs\n@ExtendWith(RestDocumentationExtension.class)\n@WebMvcTest(controllers = {\n    SomeController1.class,\n    SomeController2.class,\n    SomeController3.class\n    // ... 컨트롤러 계속 추가 ...\n})\npublic class RestDocsSpecification {\n    @Autowired\n    protected MockMvc mockMvc;\n\n    @Autowired\n    protected ObjectMapper objectMapper;\n\n    @MockBean\n    protected SomeService1 someService1;\n\n    @MockBean\n    protected SomeService2 someService2;\n\n    @MockBean\n    protected SomeService3 someService3;\n    \n    // ... MockBean 계속 추가 ...\n\n    protected static OperationRequestPreprocessor documentRequest() {\n        return Preprocessors.preprocessRequest(prettyPrint());\n    }\n\n    protected static OperationResponsePreprocessor documentResponse() {\n        return Preprocessors.preprocessResponse(prettyPrint());\n    }\n}\n\n\n\n\n이때 심각한 문제가 발생하는데, 매번 테스트 케이스가 추가될때마다 그에 해당하는 Controller와 @MockBean을 계속해서 함께 추가해줘야만 한다는 것입니다.\n\n즉, 새로운 테스트를 작성할 때 이러한 작업이 누락될 가능성이 충분히 높습니다.\n\n부차적으로 코드가 매우 지저분하기도 하고요.\n\n\n\n그렇다면 이러한 구조적인 문제도 해결하면서, 테스트 속도를 더 빠르게 가져갈 수 있는 방법이 무엇이 있을까 고민해보았는데, @WebMvcTest를 사용하지 않고 컨트롤러 인스턴스를 자체적으로 생성해 테스트한다면 어떨까 싶었습니다.\n\n즉, 컨트롤러 테스트를 일반적인 유닛 테스트 하듯이 하는 것이죠.\n\n\n\n공식문서에서 관련 내용을 찾아보니 MockMvc를 standaloneSetup으로 셋업하면 가능할 것 같았습니다.\n\n\n\n@WebMvcTest를 사용하게 되면 기본적으로 MockMvc, Controller, Filter, Interceptor등의, 컨트롤러 계층에 관련된 모든 Spring Bean을 등록해주는데, 사실 이러한 것들이 과연 내가 하는 테스트에 모두 필요한가? 라는 의문을 가져볼 수 있습니다.\n\n저같은 경우는 주로 JSON을 사용하는 API 서버를 개발하기 때문에 HTTP Body를 파싱해주는 HttpMessageConverter, 그중에서도 JSON을 파싱해주는 MappingJackson2HttpMessageConverter 하나만 있어도 무방하거든요.\n\n그렇습니다.\n\n유닛 테스트를 하는데 너무 과도한 설정을 하게되고, 이로인해 테스트 시간이 불필요하게 늘어난다는 문제가 생긴다는 것입니다.\n\n\n\n솔루션\n\n\n\n제가 사용하던 기존 방식의 코드는 다음과 같습니다.\n\n\n\n@AutoConfigureRestDocs\n@ExtendWith(RestDocumentationExtension.class)\n@WebMvcTest(controllers = {EmployeeController.class})\npublic abstract class RestDocsSpecification {\n    @Autowired\n    protected MockMvc mockMvc;\n\n    @Autowired\n    protected ObjectMapper objectMapper;\n\n    @MockBean\n    protected EmployeeService employeeService;\n\n    protected static OperationRequestPreprocessor documentRequest() {\n        return Preprocessors.preprocessRequest(prettyPrint());\n    }\n\n    protected static OperationResponsePreprocessor documentResponse() {\n        return Preprocessors.preprocessResponse(prettyPrint());\n    }\n}\n\n\n\n\n@WebMvcTest가 만들어주는, 제 기준으로 과도한 설정이 추가된 MockMvc와 각종 Bean, MockBean들을 모두 셋업합니다.\n\n즉, 매 테스트마다 스프링 컨텍스트를 로딩하는 과정이 발생합니다.\n\n\n\n21:59:55.016 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating CacheAwareContextLoaderDelegate from class [org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate]\n21:59:55.023 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating BootstrapContext using constructor [public org.springframework.test.context.support.DefaultBootstrapContext(java.lang.Class,org.springframework.test.context.CacheAwareContextLoaderDelegate)]\n21:59:55.062 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating TestContextBootstrapper for test class [com.example.restdocs.v1.EmployeeControllerTests] from class [org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper]\n21:59:55.074 [main] INFO org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper - Neither @ContextConfiguration nor @ContextHierarchy found for test class [com.example.restdocs.v1.EmployeeControllerTests], using SpringBootContextLoader\n21:59:55.077 [main] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [com.example.restdocs.v1.EmployeeControllerTests]: class path resource [com/example/restdocs/v1/EmployeeControllerTests-context.xml] does not exist\n21:59:55.077 [main] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [com.example.restdocs.v1.EmployeeControllerTests]: class path resource [com/example/restdocs/v1/EmployeeControllerTestsContext.groovy] does not exist\n21:59:55.078 [main] INFO org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [com.example.restdocs.v1.EmployeeControllerTests]: no resource found for suffixes {-context.xml, Context.groovy}.\n21:59:55.078 [main] INFO org.springframework.test.context.support.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [com.example.restdocs.v1.EmployeeControllerTests]: EmployeeControllerTests does not declare any static, non-private, non-final, nested classes annotated with @Configuration.\n21:59:55.138 [main] DEBUG org.springframework.test.context.support.ActiveProfilesUtils - Could not find an 'annotation declaring class' for annotation type [org.springframework.test.context.ActiveProfiles] and class [com.example.restdocs.v1.EmployeeControllerTests]\n21:59:55.205 [main] DEBUG org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider - Identified candidate component class: file [D:\\sample\\restdocs\\out\\production\\classes\\com\\example\\restdocs\\RestdocsApplication.class]\n21:59:55.212 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration com.example.restdocs.RestdocsApplication for test class com.example.restdocs.v1.EmployeeControllerTests\n21:59:55.220 [main] DEBUG org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper - @TestExecutionListeners is not present for class [com.example.restdocs.v1.EmployeeControllerTests]: using defaults.\n21:59:55.221 [main] INFO org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.boot.test.autoconfigure.webservices.client.MockWebServiceServerTestExecutionListener, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.event.ApplicationEventsTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.test.context.event.EventPublishingTestExecutionListener]\n21:59:55.233 [main] DEBUG org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper - Skipping candidate TestExecutionListener [org.springframework.test.context.transaction.TransactionalTestExecutionListener] due to a missing dependency. Specify custom listener classes or make the default listener classes and their required dependencies available. Offending class: [org/springframework/transaction/interceptor/TransactionAttributeSource]\n21:59:55.235 [main] DEBUG org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper - Skipping candidate TestExecutionListener [org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener] due to a missing dependency. Specify custom listener classes or make the default listener classes and their required dependencies available. Offending class: [org/springframework/transaction/interceptor/TransactionAttribute]\n21:59:55.236 [main] INFO org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@51acdf2e, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@6a55299e, org.springframework.test.context.event.ApplicationEventsTestExecutionListener@2f1de2d6, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@4eb386df, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@79517588, org.springframework.test.context.support.DirtiesContextTestExecutionListener@3a0baae5, org.springframework.test.context.event.EventPublishingTestExecutionListener@7ac0e420, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@289710d9, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@5a18cd76, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@3da30852, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@403f0a22, org.springframework.boot.test.autoconfigure.webservices.client.MockWebServiceServerTestExecutionListener@503ecb24, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@4c51cf28]\n21:59:55.252 [main] DEBUG org.springframework.test.context.support.AbstractDirtiesContextTestExecutionListener - Before test class: context [DefaultTestContext@4b14918a testClass = EmployeeControllerTests, testInstance = [null], testMethod = [null], testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@6d1ef78d testClass = EmployeeControllerTests, locations = '{}', classes = '{class com.example.restdocs.RestdocsApplication}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper=true}', contextCustomizers = set[org.springframework.boot.test.autoconfigure.OverrideAutoConfigurationContextCustomizerFactory$DisableAutoConfigurationContextCustomizer@6ea2bc93, org.springframework.boot.test.autoconfigure.actuate.metrics.MetricsExportContextCustomizerFactory$DisableMetricExportContextCustomizer@3224a577, org.springframework.boot.test.autoconfigure.filter.TypeExcludeFiltersContextCustomizer@8fa62a15, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@31ca6936, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@11bb571c, [ImportsContextCustomizer@1a6c1270 key = [@org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureWebMvc(), @org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureMockMvc(webDriverEnabled=true, print=DEFAULT, webClientEnabled=true, addFilters=true, printOnlyOnFailure=true), @org.springframework.boot.test.autoconfigure.properties.PropertyMapping(value=\"spring.test.mockmvc\", skip=NO), @org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest(useDefaultFilters=true, excludeFilters={}, controllers={com.example.restdocs.controller.EmployeeController.class}, excludeAutoConfiguration={}, value={}, includeFilters={}, properties={}), @org.springframework.boot.test.autoconfigure.core.AutoConfigureCache(cacheProvider=NONE), @org.springframework.boot.autoconfigure.ImportAutoConfiguration(value={}, exclude={}, classes={}), @org.springframework.context.annotation.Import(value={org.springframework.boot.autoconfigure.ImportAutoConfigurationImportSelector.class}), @org.springframework.context.annotation.Import(value={org.springframework.boot.test.autoconfigure.restdocs.RestDocumentationContextProviderRegistrar.class}), @org.springframework.boot.test.autoconfigure.restdocs.AutoConfigureRestDocs(uriScheme=\"http\", outputDir=\"\", uriPort=8080, value=\"\", uriHost=\"localhost\"), @org.springframework.boot.test.autoconfigure.filter.TypeExcludeFilters(value={org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTypeExcludeFilter.class}), @org.springframework.boot.test.autoconfigure.properties.PropertyMapping(value=\"spring.test.restdocs\", skip=NO), @org.springframework.test.context.BootstrapWith(value=org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTestContextBootstrapper.class), @org.springframework.boot.test.autoconfigure.OverrideAutoConfiguration(enabled=false)]], org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@7cbd9d24, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@1b45c0e, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@91577190, org.springframework.boot.test.context.SpringBootTestArgs@1, org.springframework.boot.test.context.SpringBootTestWebEnvironment@0], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map[[empty]]], class annotated with @DirtiesContext [false] with mode [null].\n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::                (v2.6.3)\n\n2022-02-22 21:59:55.703  INFO 16876 --- [           main] c.e.restdocs.v1.EmployeeControllerTests  : Starting EmployeeControllerTests using Java 11.0.11 on DESKTOP-Q76TMR6 with PID 16876 (started by hch41 in D:\\sample\\restdocs)\n2022-02-22 21:59:55.703  INFO 16876 --- [           main] c.e.restdocs.v1.EmployeeControllerTests  : No active profile set, falling back to default profiles: default\n2022-02-22 21:59:57.048  INFO 16876 --- [           main] o.s.b.t.m.w.SpringBootMockServletContext : Initializing Spring TestDispatcherServlet ''\n2022-02-22 21:59:57.048  INFO 16876 --- [           main] o.s.t.web.servlet.TestDispatcherServlet  : Initializing Servlet ''\n2022-02-22 21:59:57.049  INFO 16876 --- [           main] o.s.t.web.servlet.TestDispatcherServlet  : Completed initialization in 1 ms\n2022-02-22 21:59:57.091  INFO 16876 --- [           main] c.e.restdocs.v1.EmployeeControllerTests  : Started EmployeeControllerTests in 1.785 seconds (JVM running for 2.906)\n\n\n\n\n테스트 코드는 다음과 같습니다.\n\n\n\n@ExtendWith(MockitoExtension.class)\nclass EmployeeControllerTests extends RestDocsSpecification {\n    @Test\n    void save() throws Exception {\n        Employee request = Employee.builder()\n            .name(\"employee1\")\n            .email(\"employee1@mail.com\")\n            .phone(\"010-1234-5678\")\n            .build();\n\n        Employee response = Employee.builder()\n            .id(UUID.randomUUID())\n            .name(\"employee1\")\n            .email(\"employee1@mail.com\")\n            .phone(\"010-1234-5678\")\n            .build();\n\n        given(employeeService.save(any())).willReturn(response);\n\n        mockMvc.perform(post(\"/api/v1/employee\")\n                .contentType(MediaType.APPLICATION_JSON)\n                .content(objectMapper.writeValueAsString(request)))\n            .andExpect(status().isCreated())\n            .andDo(document(\"employee\",\n                documentRequest(),\n                documentResponse(),\n                requestFields(\n                    fieldWithPath(\"name\").description(\"이름\"),\n                    fieldWithPath(\"email\").description(\"이메일\"),\n                    fieldWithPath(\"phone\").description(\"휴대폰번호\")\n                ),\n                responseFields(\n                    fieldWithPath(\"id\").description(\"식별자\"),\n                    fieldWithPath(\"name\").description(\"이름\"),\n                    fieldWithPath(\"email\").description(\"이메일\"),\n                    fieldWithPath(\"phone\").description(\"휴대폰번호\")\n                )\n            ));\n    }\n}\n\n\n\n\n@MockBean을 사용했기 때문에 필연적으로 Mockito를 사용하게 되며, 따라서 테스트 코드 상단부에 Mocking을 하기 위한 코드들이 상당수 추가됩니다.\n\n그리고 이러한 코드들은 테스트 코드가 무엇을 검증하고 있는지 눈에 잘 안들어오게 방해합니다.\n\n\n\n개선된 코드는 다음과 같습니다.\n\n\n\n@AutoConfigureRestDocs\n@ExtendWith({RestDocumentationExtension.class, ObjectMapperResolver.class})\npublic abstract class RestDocsSpecification {\n    protected ObjectMapper objectMapper;\n    private RestDocumentationContextProvider contextProvider;\n\n    @BeforeEach\n    private void setUp(ObjectMapper objectMapper, RestDocumentationContextProvider contextProvider) {\n        this.objectMapper = objectMapper;\n        this.contextProvider = contextProvider;\n    }\n\n    protected MockMvc mockMvc(Object controller) {\n        return MockMvcBuilders.standaloneSetup(controller)\n            .setMessageConverters(jackson2HttpMessageConverter())\n            .apply(documentationConfiguration(contextProvider))\n            .build();\n    }\n\n    private MappingJackson2HttpMessageConverter jackson2HttpMessageConverter() {\n        MappingJackson2HttpMessageConverter converter = new MappingJackson2HttpMessageConverter();\n        converter.setObjectMapper(objectMapper);\n        return converter;\n    }\n\n    protected static OperationRequestPreprocessor documentRequest() {\n        return Preprocessors.preprocessRequest(prettyPrint());\n    }\n\n    protected static OperationResponsePreprocessor documentResponse() {\n        return Preprocessors.preprocessResponse(prettyPrint());\n    }\n}\n\n\n\n\npublic class ObjectMapperResolver implements ParameterResolver {\n    @Override\n    public boolean supportsParameter(ParameterContext parameterContext, ExtensionContext extensionContext) throws ParameterResolutionException {\n        return parameterContext.getParameter().getType() == ObjectMapper.class;\n    }\n\n    @Override\n    public Object resolveParameter(ParameterContext parameterContext, ExtensionContext extensionContext) throws ParameterResolutionException {\n        return Jackson2ObjectMapperBuilder.json()\n            .modules(new JavaTimeModule())\n            .visibility(PropertyAccessor.FIELD, Visibility.ANY)\n            .featuresToDisable(DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL)\n            .featuresToDisable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n            .build();\n    }\n}\n\n\n\n\nprotected MockMvc mockMvc(Object controller)에서 컨트롤러 인스턴스를 받아 MockMvc에 셋업합니다.\n\n그리고 위에서 언급했듯, 제게 필요한 MappingJackson2HttpMessageConverter 인스턴스를 하나 생성하여 넣어줍니다.\n\n위 코드의 세팅은 단순히 HTTP Body에 들어있는 JSON이 정상인지 테스트하기 위한 목적이기 때문에, 만약 @RestControllerAdvice 등을 별도로 만들어 사용하고 계신다면 빌더에 인스턴스를 만들어 넣어주셔야만 합니다.\n\n\n\n테스트 코드는 다음과 같습니다.\n\n\n\nclass EmployeeControllerTests extends RestDocsSpecification {\n    @Test\n    void save() throws Exception {\n        mockMvc(new EmployeeController(new EmployeeService()))\n            .perform(post(\"/api/v1/employee\")\n                .contentType(MediaType.APPLICATION_JSON)\n                .content(objectMapper.writeValueAsString(Employee.builder()\n                    .name(\"employee1\")\n                    .email(\"employee1@mail.com\")\n                    .phone(\"010-1234-5678\")\n                    .build())))\n            .andExpect(status().isCreated())\n            .andDo(document(\"employee\",\n                documentRequest(),\n                documentResponse(),\n                requestFields(\n                    fieldWithPath(\"name\").description(\"이름\"),\n                    fieldWithPath(\"email\").description(\"이메일\"),\n                    fieldWithPath(\"phone\").description(\"휴대폰번호\")\n                ),\n                responseFields(\n                    fieldWithPath(\"id\").description(\"식별자\"),\n                    fieldWithPath(\"name\").description(\"이름\"),\n                    fieldWithPath(\"email\").description(\"이메일\"),\n                    fieldWithPath(\"phone\").description(\"휴대폰번호\")\n                )\n            ));\n    }\n}\n\n\n\n\n기존의 코드와 다르게, 컨트롤러 인스턴스를 직접 생성하여 슈퍼 클래스에 넘겨주고, 슈퍼 클래스에서는 넘겨받은 컨트롤러 인스턴스를 MockMvc에 탑재한 후 반환해주고 있습니다.\n\n이 경우엔 단순 예제이기 때문에 서비스 클래스에 별도의 의존성이 없도록 하였으나, 실무에서는 보통 인터페이스를 두어 결합도를 느슨하게 가져가기 때문에 익명 클래스를 넘겨 Mockito를 대신할 수도 있습니다.\n\n혹은 구조 문제로 인해 위와 같은 방식을 시도할 수 없다면 Mockito를 사용할수도 있겠죠. (별로 좋다고 생각되진 않습니다.)\n\n\n\n두 테스트를 실행하면 다음과 같은 결과가 나옵니다.\n\n\n\n\n\n\n\nv1이 기존의 방식이며, v2는 standaloneSetup을 사용한 개선된 방식입니다.\n\nv2의 경우 실제로 스프링 컨텍스트를 로딩하는 과정 자체가 스킵되기 때문에 실 체감상으로도 테스트 속도가 매우 빨라짐을 느낄 수 있으며(과장 조금 보태 버튼 누르자마자 완료되는 수준으로 POJO로 작성된 유닛 테스트보다 약간 느린 정도 입니다), 테스트 리포트 상으로도 약 10배에 가까운 속도차이가 발생하고 있음을 확인 할 수 있습니다.\n\n\n",
      "categories": ["backend","test"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/test/2022-02-22-rest-docs-optimization/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "함수형 프로그래밍의 작은 깨달음",
      "date": "2022-02-27 00:00:00 +0000",
      "description": "모나드 ? 🤔\n",
      "content": "\n  함수형 프로그래밍\n\n\n\n\n함수형 프로그래밍\n\n\n\n최근 함수형 프로그래밍에 대한 관심이 높아지고 있다.\n\n나는 기본적으로 객체지향으로 코딩을 하고 있지만, 이런저런 개발 방법론을 접할 때마다 그들의 철학에 매료된다.\n\n객체지향이 아닌 다른 방식들을 객체지향에 접목하면 더 좋은 코드를 작성할 수 있을 것만 같기 때문이다.\n\n\n\n단박에 느껴지는 함수형 프로그래밍의 메리트는 부수효과가 없다는 것이다.\n\n이로 인해 에러가 줄어들고, 무엇보다 병렬성을 크게 끌어올릴 수 있다.\n\n아무튼, 함수형 프로그래밍 서적을 보는데 함수형 프로그래밍의 함수에 대한 정의에서 한 가지 의문이 들었었다.\n\n함수형 프로그래밍 속 함수의 정의는 다음과 같다.\n\n\n\n\n  수학에서 말하는 함수와 같다\n  함수는 0개 이상의 입력값을 가지며, 1개 이상의 반환값을 가져야 한다\n  부수효과(Side-Effect)가 없어야 한다. 즉, 같은 입력이 들어오면 항상 같은 값이 반환되어야 한다\n\n\n\n\n여기서 의문이 들었는데, 그렇다면 함수 내부에서 예외(Exception)가 발생한다면 어떻게 해야하는가? 라는 의문이었다.\n\n예외가 발생한다면 일반적인 자바 프로그래밍에서는 예외를 캐치하여 처리하거나 던질것이다.\n\n하지만 이렇게 하면 함수의 정의에 벗어난다.\n\n예외를 던지면 값을 반환하지 못하는 것이며, 예외 처리를 하여 예외를 던지지 않고 임의의 값을 반환한다면? 이 역시도 애매하다.\n\n같은 입력에 대해 언제나 같은 값이 출력된다고 보장하기 힘들 것 같았다.\n\n\n\n예를 들어, 나누기를 하는 함수가 있다고 가정하자.\n\n\n\npublic double divide(double x, double y) {\n    return x / y; \n}\n\n\n\n\n근데 x가 임의의 실수이고, y가 0이라면 어떻게 해야할까?\n\n무한루프가 발생할 것이므로, 일반적인 자바 스타일의 코딩을 한다면 적절한 예외처리를 해주어야만 한다.\n\n\n\n이러한 경우를 함수형 프로그래밍에서는 어떻게 해결하는지 궁금해져 질문을 했더니, 모나드요 ! 라는 답변이 돌아왔다.\n\n결론적으로는 다음과 같다.\n\n\n\npublic Optional&lt;Double&gt; divide(double x, double y) {\n    if(y == 0) {\n        return Optional.empty();\n    }\n    return Optional.of(x / y); \n}\n\n\n\n\n반환값 자체를 반환값이 있을수도 있고, 없을수도 있다는 범주로 묶는 것이다.\n\n이러면 예외상황에도 항상 같은 값(Optional)을 반환할 수 있게 된다.\n\n이러한 개념을 함수형 프로그래밍에서는 모나드라고 부르는 것 같은데, 이게 함수형 프로그래밍에서 아주 어려운 개념인 듯 하다.\n\n그렇다면 Optional도 일종의 모나드인가? 아직 잘 모르겠다.\n\n아무튼 신기한 해결방식에 흥미가 생겼고, 모나드가 무엇인지 이해하고 싶다는 생각이 들게되는 계기가 되었다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-02-27-diary-35/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "운영체제(Operating System) 5강",
      "date": "2022-02-28 00:00:00 +0000",
      "description": "반효경 교수님 - Process Synchronization\n",
      "content": "\n  Lecture\n  임계구역(Critical section)    \n      프로그램적 해결법의 충족 조건        \n          문제 해결 알고리즘            \n              Algorithm 1\n              Algorithm 2\n              Algorithm 3(Peterson`s Algorithm)\n            \n          \n          Synchronization Hardware\n        \n      \n      Semaphores        \n          Semaphores Examples\n          Block &amp; Wakeup Implementation\n          Type of Semaphore\n        \n      \n      Deadlock &amp; Starvation        \n          Deadlock\n          Starvation\n          Deadlock vs Starvation\n        \n      \n    \n  \n  Producer-Consumer Problem    \n      Synchronization Problem\n      Uses of semaphores\n      Solution example using semaphore\n    \n  \n  Readers-Writers Problem    \n      Solution\n    \n  \n  Dining-Philosophers Problem    \n      Example\n      Solution\n      세마포어 예제\n    \n  \n  Monitor    \n      The problem with semaphores\n      Concept        \n          Producer-Consumer Problem\n        \n      \n      Dining-Philosopher Problem\n    \n  \n\n\n\n\nLecture\n\n\n\n\n  운영체제 - 반효경 교수님\n    \n      Process Synchronization 1\n      Process Synchronization 2\n      Process Synchronization 3\n      Process Synchronization 4\n    \n  \n\n\n\n\n임계구역(Critical section)\n\n\n\n\n  n 개의 프로세스가 공유 자원을 동시에 사용하기를 원하는 경우, 공유 자원에 접근하려 하는 코드 블럭을 의미\n  A프로세스에서 공유자원 c의 값을 1만큼 증가시키고, B프로세스에서는 동시에 c의 값을 1만큼 감소시킨다면 어떤 현상이 발생하는가?\n  이러한 경우 발생할 수 있는 문제들을 해결하기 위해 동기화(synchronization)가 필요하다\n\n\n\n\n프로그램적 해결법의 충족 조건\n\n\n\nMutual Exclusion (상호 배제)\n\n\n  프로세스가 임계구역 부분을 수행 중이면 다른 모든 프로세스들은 그들의 임계구역에 들어갈 수 없다\n\n\nProgress (진행)\n\n\n  아무 프로세스도 임계구역에 있지 않는 상태에서 임계구역에 들어가고자 하는 프로세스가 생긴다면 즉시 임계구역에 들어가게 해줘야한다\n\n\nBounded Waiting (유한 대기)\n\n\n  프로세스가 임계구역에 들어가려고 요청한 후 부터 그 요청이 허용될 때까지 다른 프로세스들이 임계구역에 들어가는 횟수에 한계가 있어야 한다\n\n\n\n\n문제 해결 알고리즘\n\n\n\n다음과 같이 가정한다.\n\n\n  모든 프로세스의 수행 속도는 0보다 크다\n  프로세스들 간의 상대적인 수행 속도는 가정하지 않는다\n\n\n\n\nAlgorithm 1\n\n\n\n\n\ndo {\n    while (turn != 0)\n    critical section\n    turn = 1;\n    remainder section\n} while (1);\n\n\n\n\nturn이라는 변수를 가지고 자기 차례에만 임계구역에 들어가게 강제한다.\n\n\n\n상호배제를 만족하지만, 프로세스 간의 임계구역에 들어가야하는 횟수가 다르다면 문제가 생길 수 있다.\n\n\n  프로세스 1은 임계구역에 한 번만 들어가도 되고, 프로세스 2는 임계구역에 여러 번 들어가야 되는 상황이다\n  코드가 한 번 작동한 이후, 프로세스 1이 더이상 들어갈 일이 없게 되기 때문에 프로세스 2에게는 자신의 차례가 돌아오지 않게 되버린다\n  즉, Progress(진행) 조건을 만족하지 못한다\n\n\n\n\nAlgorithm 2\n\n\n\n\n\ndo {\n    flag[i] = true;\n    while(flag[j]);\n    critical section\n    flag[i] = false;\n    remainder section\n} while(1);\n\n\n\n\nflag라는 boolean 변수를 가지고 임계구역에 들어갈 상태를 표현한다.\n\n\n  다른 프로세스의 flag를 체크하고, 프로세스의 flag가 true라면 양보, false라면 자신이 들어간다\n\n\n이 또한 상호배제는 만족하므로 얼핏 보기에는 문제가 없어 보이지만, 선점 문제가 발생 할 수있다.\n\n\n  프로세스 1이 임계구역에 들어가기 위해 flag를 true로 만들어 둔 상태에서 CPU를 뺏기게 된다\n  프로세스 2도 임계구역에 들어가기 위해 flag를 true로 만들고 들어가려하는데, 다른 프로세스의 flag가 이미 true이기에 양보를 하게된다\n  프로세스 1에게 다시 CPU가 넘어와 임계구역에 들어가려하는데, 다른 프로세스의 flag가 true이므로 프로세스1도 마찬가지로 양보를 하게되버린다\n  즉, 서로 무한정으로 양보하는 상황이 발생한다 (데드락)\n\n\n\n\nAlgorithm 3(Peterson`s Algorithm)\n\n\n\n\n\ndo {\n    flag[i]= true;\n    turm = j;\n    while(flag[j] &amp;&amp; turn == j);\n    critical section\n    flag[i] = false;\n    remainder section\n} while(1);\n\n\n\n\nflag 변수와 turn 변수를 둘 다 사용하는 방법으로, 프로그램적 해결법의 충족 조건을 모두 만족하게 된다.\n\n하지만 Busy Waiting(Spin Lock)문제가 발생한다.\n\nBusy Waiting은 계속 CPU와 Memory를 사용하며 wait하고 있는 상태를 의미하며, 코드상으로 while문을 계속해서 돌고있는 상태이다.\n\n\n\nSynchronization Hardware\n\n\n\n하드웨어적으로 Test &amp; modify를 atomic 하게 수행할 수 있도록 지원하는 경우 앞의 문제는 간단히 해결 가능하다.\n\n\n  lock을 걸고 푸는 작업을 하나의 명령어(논리)로 처리하기 때문에, 문제를 손 쉽게 해결 할 수 있다.\n\n\n\n\nSynchronization variable;\n    boolean lock = false;\n\ndo {\n    while(Test_and_Set(losk));\n    critical section\n    lock = false;\n    remainder section\n}\n\n\n\n\nSemaphores\n\n\n\n\n  앞의 방식들을 추상화 시킨 것\n  앞서 보았던 잠금을 걸고, 푸는 작업을 대신 해준다. (공유 자원을 획득하고, 다시 반납하는 작업)\n\n\n\n\nP(S) - 잠금을 거는 연산\n\n\n\nwhile (S&lt;=0) do no-op;\nS--;\n\n\n\n\nV(S) - 잠금을 푸는 연산\n\n\n\nS++;\n\n\n\n\nSemaphores Examples\n\n\n\nSynchronization variable:\nsemaphore mutex; // 1로 초기화\n\ndo{\n\tP(mutex);\n\t/* critical section */\n\tV(mutex); \n} whlile (1);\n\n\n\n\n프로그래머는 위처럼 세마포어를 이용해서 더 간단하게 프로그램을 작성할 수 있다.\n\n\n\nBlock &amp; Wakeup (Sleep Lock) 방식의 구현을 이용한다.\n\n\n  임계구역의 길이가 긴 경우 적당하다.\n\n\nBusy-wait (Spin Lock)\n\n\n  임계구역의 길이가 매우 짧은 경우 오버헤드가 비교적 더 작다.\n  그렇기 때문에 일반적으로 Block &amp; Wakeup 방식이 더 효율적으로 사용할 수 있다.\n\n\nBlock &amp; Wakeup Implementation\n\n\n\n세마포어는 다음과 같이 정의 할 수있다.\n\n\n\ntypedef struct\n{\n\tint value; // 세마포어 변수\n\tstruct process *L; // 세마포어를 사용하기 위한 대기 큐\n}semaphore;\n\n\n\n\n\n\n\n\n\n  block()\n    \n      커널은 block을 호출한 프로세스를 suspend하고, 이 프로세스의 PCB를 세마포어의 대기큐에 넣는다\n    \n  \n  wakeup(P)\n    \n      block된 프로세스를 wake up하고, 이 프로세스의 PCB를 레디큐에 넣는다\n    \n  \n\n\n\n\n세마포어 연산은 다음과 같이 정의 및 구현한다\n\n\n  P(S):\n\n  세마포어 변수 S를 무조건 1 줄이고, 그 변수의 값이 음수면 해당 프로세스를 대기큐로 보낸 후 Block 상태로 만든다.\n\n\n\n\n// P(S)\nS.value--;\nif (S.value &lt; 0)\n{\n    add this process to S.L;\n    block();\n}\n\n\n\n\n\n  V(S):\n\n  세마포어 변수 S를 무조건 1 늘리고, 그 변수의 값이 0보다 작거나 같으면 이미 기다리고 있는 프로세스가 있으므로 프로세스를 대기큐에서 꺼내 레디큐로 보낸다. 세마포어 변수 S 값이 양수면 아무나 임계 구역에 들어 갈 수 있으므로 별다른 추가 연산을 하지 않는다. V 연산은 특정 프로세스가 공유 데이터를 반납한 후 임계 구역에서 나가는 연산이다.\n\n\n\n\n// V(S)\nS.value++;\nif (S.value &lt;= 0)\n{\n    remove a process P from S.L;\n    wakeup(P);\n}\n\n\n\n\n\n  block()\n    \n      커널은 block을 호출한 프로세스를 대기 시킨다.\n      이 프로세스의 PCB를 세마포어를 위한 대기 큐에 넣는다.\n    \n  \n  wakeup(P)\n    \n      block 된 프로세스 P를 wakeup 시킨다.\n      이 프로세스의 PCB를 준비 큐로 옮긴다.\n    \n  \n\n\n\n\nType of Semaphore\n\n\n\n\n  Counting Semaphore\n    \n      도메인이 0이상인 임의의 정수값\n      여러 개의 공유 자원을 상호 배제\n      주로 resource counting에 사용\n    \n  \n\n\n-Binary Semaphore\n\n  0 또는 1값만 가질 수 있는 세마포어\n  한 개의 공유 자원을 상호 배제\n  mutex와 유사하나 완전히 같지는 않다\n\n\n\n\nDeadlock &amp; Starvation\n\nDeadlock\n\n\n\n둘 이상의 프로세스가 서로 상대방에 의해 충족될 수 있는 event를 무한히 기다리는 현상으로, 예시는 다음과 같다.\n\n\n\nS와 Q가 1로 초기화된 세마포어라 하자.\n\n\n\n\n\nP0이 CPU를 얻어 P(S) 연산까지 수행하여 S 자원을 얻었다고 가정 한다. 이 때,  P0의 CPU 점유 시간이 끝나 Context Switch가 발생하고 P1에게 CPU 제어권이 넘어갔다.\n\nP1은 P(Q) 연산을 수행하여 Q 자원을 얻었으나 또 다시 CPU 점유 시간이 끝나 Context Switch가 발생하여 P0에게 CPU 제어권이 넘어갔다.\n\nP0은 P(Q) 연산을 통해 Q 자원을 얻고 싶지만, 이미 Q 자원은 P1이 갖고 있는 상태이므로 Q 자원을 가져올 수가 없다.\n\n마찬가지로 P1도 P(S) 연산을 통해 S 자원을 얻고 싶지만, 이미 S 자원은 P0이 갖고 있는 상태이므로 S 자원을 가져올 수 없다.\n\n이렇게 P0와 P1은 영원히 서로의 자원을 가져올 수 없고, 이러한 상황을 Deadlock이라고 한다.\n\n\n\n이러한 현상을 해결하는 방법 중 하나로, 자원의 획득 순서를 정해주어 해결하는 방법이 있다.\n\nS를 획득해야만 Q를 획득할 수 있게끔 순서를 정해주면 프로세스 A가 S를 획득했을 때 프로세스 B가 Q를 획득할 일이 없다.\n\n\n\nStarvation\n\n\n\nindefinite blocking(무기한적인 차단)으로, 프로세스가 자원을 얻지 못하고 무한히 기다리는 현상을 의미한다.\n\n\n\nDeadlock vs Starvation\n\n\n\n언뜻 보기에 둘 다 자원을 가져오지 못하고 무한히 기다리니까 같은 단어라고 혼동할 수 있다.\n\nDeadlock은 P0 프로세스가 A 자원을 보유하고 있고, P1 프로세스가 B 자원을 보유하고 있을 때 서로의 자원을 요구하여 무한히 기다리는 현상이다.\n\n반면 Starvation은 프로세스가 자원 자체를 얻지 못하고 무한히 기다리는 현상이다. SJF 알고리즘을 생각하면 이해가 쉬울 수 있다.\n\n\n\nProducer-Consumer Problem\n\n\n\n\n\n\n\n\n  주황색: Full buffer\n  회색: Empty buffer\n\n\n\n\n\n  Producer\n    \n      empty buffer가 있는지 확인하고 없다면 기다린다\n      공유 데이터에 lock을 건다\n      empty buffer에 데이터를 입력한다\n      lock을 푼다\n      full buffer가 하나 증가한다\n    \n  \n\n\n\n\n\n  Consumer\n    \n      full buffer가 있는지 확인하고 없다면 기다린다\n      공유 데이터에 lock을 건다\n      full buffer에서 데이터를 꺼낸다\n      lock을 푼다\n      empty buffer가 하나 증가한다\n    \n  \n\n\n\n\nSynchronization Problem\n\n\n\n\n  공유 버퍼이기 때문에 여러 생산자가 동시에 한 버퍼에 데이터를 입력 할 수 있다\n  마찬가지로 여러 생산자가 동시에 한 버퍼의 데이터를 꺼내가려 할 수 있다\n\n\n\n\nUses of semaphores\n\n\n\n\n  공유 데이터의 상호배제를 위해 이진 세마포어가 필요\n  가용 자원의 갯수를 세기 위해 계수 세마포어가 필요\n\n\n\n\nSolution example using semaphore\n\n\n\n\n\n\n  Producer\n    \n      P 연산을 통해 empty buffer가 있는지 확인하고 없다면 대기한다\n      P 연산을 통해 empty buffer가 있다면 mutex를 0으로 만들고 임계 구역에 진입한다\n      empty buffer에 데이터를 입력한다\n      V 연산을 통해 mutex 값을 1로 만든다\n      V 연산을 통해 full buffer를 1 증가하고 임계 구역에서 빠져나온다\n    \n  \n\n\n\n\n\n  Consumer\n    \n      P 연산을 통해 full buffer가 있는지 확인하고 없다면 대기한다\n      P 연산을 통해 full buffer가 있다면 mutex를 0으로 만들고 임계 구역에 진입한다\n      full buffer에서 데이터를 빼 간다\n      V 연산을 통해 mutex 값을 1로 만든다\n      V 연산을 통해 empty buffer를 1 증가하고 임계 구역에서 빠져나온다\n    \n  \n\n\n\n\nReaders-Writers Problem\n\n\n\n\n  한 프로세스가 DB에 쓰기 중일 때 다른 프로세스가 접근하면 안 된다\n  읽기는 동시에 여러 명이 해도 된다\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\n이진 세마포어 두 개를 사용한다\n\n\n  semaphore mutex = 1\n    \n      상호 배제를 보장해야 하므로 각각의 세마 포어 값은 1로 지정하며, 다수의 Reader들이 readCount에 동시 접근하면 데이터 불일치의 위험이 있으므로 mutex를 정의\n    \n  \n  db = 1\n    \n      db는 Reader와 Writer가 공통 데이터베이스에서 서로 상호 배제를 보장해야하므로 정의\n    \n  \n\n\n\n\n\n  Reader\n    \n      readCount도 공유 변수이기 때문에 P(mutex) 연산을 통해 readCount를 상호 배제 처리하고 값을 1 증가시킨다 (readCount++)\n      Reader가 없고, Reader가 오로지 본인 혼자라면 (if(readCount == 1)) db에 lock을 건다 (P(db))\n      V(mutex) 연산을 통해 임계 구역에서 빠져 나온다\n      db를 원하는 만큼 읽는다\n      P(mutex) 연산을 통해 readCount 상호 배제 처리하고 값을 1 감소시킨다 (readCount–)\n      마지막으로 read를 그만하고 나가려는 프로세스가 나 하나라면 (if(readCount == 0)) db의 lock을 해제한다 (V(db))\n      V(mutex) 연산을 통해 임계 구역에서 빠져나온다.\n    \n  \n\n\n\n\n\n  Wrtier\n    \n      P(db) 연산을 통해 db에 lock이 걸려있는지 확인한다\n      lock이 걸려 있지 않으면 db에 lock을 걸고 임계 구역에 진입한다\n      쓰기 작업이 끝나면 V(db) 연산을 통해 db의 lock을 해제하고 임계 구역에서 빠져 나온다\n    \n  \n\n\n\n\n\n  문제점\n    \n      Writer가 쓰기 작업을 하고 싶어도 무조건 Read 하고 있는 프로세스인 Reader가 없어야 한다\n      만약 Reader가 무한히 read 작업을 실행한다면 Writer는 영영 임계 구역에 진입 하지 못하는 Startvation에 빠질 수도 있다\n    \n  \n\n\n\n\nDining-Philosophers Problem\n\n\n\n철학자 다섯이서 원형 식탁에 둘러앉아 생각에 빠져있다가, 배가 고파지면 밥을 먹는다.\n\n그들의 양쪽엔 각각 젓가락 한 짝씩 놓여있고, 밥을 먹으려 할 땐 다음의 과정을 따른다.\n\n\n  왼쪽 젓가락부터 집어든다. 다른 철학자가 이미 왼쪽 젓가락을 쓰고 있다면 그가 내려놓을 때까지 생각하며 대기한다\n  왼쪽을 들었으면 오른쪽 젓가락을 든다. 들 수 없다면 1번과 마찬가지로 들 수 있을 때까지 생각하며 대기한다\n  두 젓가락을 모두 들었다면 일정 시간동안 식사를 한다\n  식사를 마쳤으면 오른쪽 젓가락을 내려놓고, 그 다음 왼쪽 젓가락을 내려놓는다\n  다시 생각하다가 배고프면 1번으로 돌아간다\n\n\n\n\nExample\n\n\n\ndo {\n    P(chopstick[i]);\n    P(chopstick[(i + 1) % 5]);\n    ...\n    eat();\n    ...\n    V(chopstick[(i + 1) % 5]);\n    V(chopstick[i]);\n    ...\n    think();\n    ...\n} while (1);\n\n\n\n\n모두가 동시에 왼쪽 젓가락을 드는 순간부터 환형대기에 빠져 다 같이 오른쪽 젓가락을 들 수 없으므로 Deadlock이 발생할 수 있다\n\nDeadlock의 필요 조건은 다음과 같으며, 아래의 조건이 단 하나라도 만족하지 않는다면 Deadlock은 발생하지 않는다.\n\n  상호 배제\n  비선점\n  점유와 대기\n  원형 대기\n\n\n\n\nSolution\n\n\n\n\n  4명의 철학자만 테이블에 동시에 앉을 수 있게 한다\n  젓가락을 두 개 모두 집을 수 있을 때만 젓가락을 집을 수 있게 한다\n  비대칭\n    \n      짝수(홀수) 철학자는 왼쪽(오른쪽) 젓가락부터 집도록 방향을 정해준다\n    \n  \n\n\n\n\n세마포어 예제\n\n\n\nenum {thinking, hungry, earting} state[5]; // 5명의 철학자들이 가질 수 있는 상태\nsemaphore self[5] = 0; // 5명의 철학자들이 젓가락 2개를 모두 들 수 있는 지를 판단 (0이면 불가, 1이면 가능)\nsemaphore mutex = 1; // 5명의 철학자들이 state에 동시에 접근하지 못하도록 상호 배제\n\ndo {\n    pickup(i); // 젓가락을 든다\n    eat(); // 먹는다\n    putdown(i); // 젓가락을 내린다\n    think(); // 생각한다\n} while (1);\n\nvoid pickup(int i) {\n    P(mutex); // state에 lock을 걸고 임계구역에 진입\n    state[i] = hungry; // 철학자의 상태를 hungry로 변경\n    test(i); // 젓가락 2개를 들 수 있는지 확인하고 가능하면 상태를 eating으로 변경한다\n    V(mutex); // state의 lock을 풀고 임계 구역을 빠져나옴\n    P(self[i]); // 젓가락 2개를 들 수 없는 상태로 변경\n}\n\nvoid putdown(int i) {\n    P(mutex); // state에 lock을 걸고 임계구역에 진입\n    state[i] = thinking; // 철학자의 상태를 thinking으로 변경\n    test((i + 4) % 5); // 양 옆 철학자가 식사할 수 있는 상태인지 확인하고\n    test((i + 1) % 5); // 식사할 수 있는 상태라면 상태를 eating으로 변경해줌 \n    V(mutex); // state의 lock을 풀고 임계 구역을 빠져나옴\n}\n\nvoid test(int i) {\n    if (state[(i + 4) % 5] != eating &amp;&amp; state[i] == hungry &amp;&amp; state[(i + 1) % 5] != eating) {\n        state[i] = eating;\n        V(self[i]); // 젓가락 2개를 들 수 있는 상태로 변경\n    }\n}\n\n\n\n\nMonitor\n\nThe problem with semaphores\n\n\n\n\n\n\n\nConcept\n\n\n\n모니터는 동시 수행중인 프로세스 사이에서 추상 데이터 타입의 안전한 공유를 보장하기 위한 고수준의 동기화 도구이다.\n\n\n\nmonitor monitor-name\n{\n    shared variable declarations\n    procedure body P1 (...) {\n        ...\n    }\n    procedure body P2 (...) {\n        ...\n    }\n    procedure body Pn (...) {\n        ...\n    }\n    {\n        initialization code\n    }\n}\n\n\n\n\n프로세스가 공유 데이터에 접근하기 위해서는 위와 같이 모니터 내부의 프로시저를 통해서만 공유 데이터를 접근할 수 있도록 설계한다.\n\n\n\n\n\n\n\n예를 들어 공유 데이터들이 있으면 밖에서 아무나 접근할 수 있는 것이 아니라 모니터 내부에 공유 데이터에 접근하는 프로시저를 정의해 놓고 이 프로시저를 통해서만 접근할 수 있게 제어한다.\n\n모니터가 내부에 있는 프로시저는 동시에 여러 개가 실행되지 않도록 통제하는 권한을 준다.\n\n즉, 모니터 내에서는 한 번에 하나의 프로세스만이 활동이 가능하도록 제어하므로 프로그래머 입장에서 lock을 임의로 걸 필요가 없다는 장점이 있다.\n\n\n\n\n\n\n\nProducer-Consumer Problem\n\n\n\n\n\n\n\n\n  Producer\n    \n      empty buffer가 없으면 empty buffer를 기다리는 큐에서 대기\n      empty buffer가 있다면 empty buffer에 데이터를 집어넣는다\n      작업이 끝나면 full.signal()을 통해 full buffer를 기다리는 큐에 프로세스 하나를 깨우라고 알림\n    \n  \n\n\n\n\n\n  Consumer\n    \n      full buffer가 없으면 full buffer를 기다리는 큐에서 대기\n      full buffer가 있다면 full buffer의 데이터를 꺼내서 *x에 값을 저장한다\n      작업이 끝나면 empty.signal()을 통해 empty buffer를 기다리는 큐에 프로세스 하나를 깨우라고 알림\n    \n  \n\n\n\n\nDining-Philosopher Problem\n\n\n\nmonitor dining_philosopher\n{\n    enum {thinking, hungry, eating} state[5]; // 5명의 철학자들이 가질 수 있는 상태\n    condition self[5]; // 5명의 철학자들이 젓가락 2개를 모두 들 수 있는 지를 판단\n\n    void pickup(int i) {\n        state[i] = hungry; // 철학자 자신의 상태를 hungry로 변경\n        test(i); // 철학자 자신에게 식사할 수 있는 기회를 준다 (test 함수 참고)\n        \n        // 식사를 하지 못했다면 상태가 eating으로 변경되지 않았음을 의미한다\n        // 따라서 wait 큐에서 대기한다\n        if (state[i] != eating) {\n            self[i].wait();\n        }\n    }\n\n    void putdown(int i) {\n        state[i] = thinking; // 식사를 마쳤으므로 상태를 thinking으로 변경한다\n        test[(i + 4) % 5]; // 자신의 왼쪽 철학자에게 식사할 수 있는 기회를 준다 (test 함수 참고)\n        test[(i + 1) % 5]; // 자신의 오른쪽 철학자에게 식사할 수 있는 기회를 준다 (test 함수 참고)\n    }\n\n    void test(int i) {\n        // 자신의 왼쪽 젓가락과 오른쪽 젓가락을 모두 들 수 있는지 확인\n        if ((state[(i + 4) % 5] != eating) &amp;&amp; (state[i] == hungry) &amp;&amp; (state[(i + 1) % 5] != eating) {\n            // 모두 들 수 있다면 수행\n            state[i] = eating; // 상태를 eating으로 변경한다 \n            self[i].signal(); // wait 큐에서 자신을 깨운다\n        }\n    }\n}\n\nEach Philosopher:\n{\n    pickup(i);\n    eat();\n    putdown(i);\n    think();\n} while (1)\n\n\n\n",
      "categories": ["cs","operating-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/operating-system/2022-02-28-process-synchronization/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "운영체제(Operating System) 6강",
      "date": "2022-03-01 00:00:00 +0000",
      "description": "반효경 교수님 - Deadlocks\n",
      "content": "\n  Lecture\n  Deadlock    \n      Deadlock’s Requirements\n      Resource-Allocation Graph (자원 할당 그래프)\n      Deadlock Resolution        \n          Deadlock Prevention (데드락 예방)\n          Deadlock Avoidance (데드락 회피)            \n              Resource Allocation Graph Algorithm (자원 할당 그래프 알고리즘)\n              Banker’s Algorithm (은행원 알고리즘)\n            \n          \n          Deadlock Detection and recovery (데드락 탐지 및 회복)\n          Deadlock Ignorance (데드락 무시)\n        \n      \n    \n  \n  Deadlock implemented in Java\n\n\n\n\nLecture\n\n\n\n\n  운영체제 - 반효경 교수님\n    \n      Deadlocks 1\n      Deadlocks 2\n    \n  \n\n\n\n\nDeadlock\n\n\n\n\n\n\n\n일련의 프로세스들이 서로가 가진 자원을 기다리며 block된 상태\n\n\n\n\n  Resource\n    \n      하드웨어, 소프트웨어 등을 포함하는 개념\n        \n          I/O device, CPU cycle, memory space, semaphore etc.\n        \n      \n      프로세스가 자원을 사용하는 절차\n        \n          Request, Allocate, Use, Release\n        \n      \n    \n  \n  Example\n    \n      Example 1\n        \n          시스템에 2개의 tape drive가 있다\n          P1과 P2가 각각이 하나의 tape drive를 보유한 채 다른 하나를 기다리고 있다\n        \n      \n      Example 2\n        \n          이진 세마포어 A와 B가 있다\n          P1이 A를 얻은 상태에서 Context Switch가 발생했다\n          P2에게 CPU 제어권이 넘어갔고, P2가 B를 얻었다\n          다시 Context Switch가 발생하여 P1에게 CPU 제어권이 넘어갔다\n          P1이 B를 얻고 싶어하지만 이미 P2가 B를 가지고 있기 때문에 P1은 P2가 B를 내놓기를 기다린다\n          다시 Context Switch가 발생하여 P2에게 CPU 제어권이 넘어갔다\n          마찬가지로 P2가 A를 얻고 싶어하지만 이미 P1이 A를 가지고 있기 때문에 P2는 P1이 A를 내놓기를 기다린다\n          무한히 서로를 기다린다\n        \n      \n    \n  \n\n\n\n\nDeadlock’s Requirements\n\n\n\n데드락은 하기의 4가지 조건이 모두 만족될 때 발생한다.\n\n반대로 생각하면 단 하나라도 조건을 만족하지 않는다면 데드락은 절대 발생하지 않는다.\n\n\n\n\n  Mutual Exclusion (상호 배제)\n    \n      매 순간 하나의 프로세스만이 공유 자원을 점유 할 수 있다\n    \n  \n  No preemption (비선점)\n    \n      프로세스는 공유 자원을 자발적으로 내어 놓을 뿐 강제로 빼앗기지는 않는다\n    \n  \n  Hold and wait (점유와 대기)\n    \n      공유 자원을 점유한 프로세스가 다른 공유 자원을 기다릴 때 보유한 공유 자원을 내어 놓지 않고 계속 가지고 있는다\n    \n  \n  Circular wait (순환 대기)\n    \n      공유 자원을 기다리는 프로세스간에 순환 대기가 형성되어야 한다\n      프로세스 P0, P1, … , Pn이 있을 때\n        \n          P0은 P1이 가진 자원을 기다린다\n          P1은 P2가 가진 자원을 기다린다\n          P(n-1)은 Pn이 가진 자원을 기다린다\n          Pn은 P0이 가진 자원을 기다린다\n        \n      \n    \n  \n\n\n\n\nResource-Allocation Graph (자원 할당 그래프)\n\n\n\n\n\n\n\nP(동그라미)는 프로세스를 의미하며, R(사각형)은 자원을 의미한다.\n\n화살표는 두 가지가 있다.\n\n\n  자원 -&gt; 프로세스\n    \n      자원이 프로세스에 점유되어있다\n    \n  \n  프로세스 -&gt; 자원\n    \n      프로세스가 자원 점유를 요청하였으나 획득하지는 못하였다\n    \n  \n\n\n\n\n데드락은 다음과 같이 판단한다.\n\n\n\n\n\n\n\n\n  그래프에 사이클(순환 대기)이 없으면 데드락이 아니다\n  그래프에 사이클이 있으면,\n    \n      자원 하나에 하나의 인스턴스만 있다면 데드락이다\n      자원 하나에 여러 인스턴스가 존재한다면 데드락 가능성이 있다\n    \n  \n\n\n\n\n\n  왼쪽 그래프\n    \n      P1에게 R2 1개가 점유되고 있고, P2에게 R2 1개가 점유되고 있는 상황이다\n      이 때 P3이 R2를 요구한다\n      P2는 R3 1개를 요청하지만, R3은 이미 P3가 가지고 있다\n      이 때 P1은 R1을 요청하지만, 이것은 P2가 가지고 있다. 즉, 사이클이 존재한다\n      사이클이 존재하며, 자원 하나에 프로세스 하나씩 할당돼있기 때문에 데드락이다.\n    \n  \n\n\n\n\n\n  오른쪽 그래프\n    \n      P1에게 R2가 할당되어 있다\n      P4에게 R2가 할당되어 있다\n      P3가 R2를 요구하면 P4가 R2 자원을 반납하면 된다\n      즉, 사이클이 없다\n      따라서 데드락이 아니다\n    \n  \n\n\n\n\nDeadlock Resolution\n\n\n\n데드락을 해결하기 위한 방법들은 다음과 같다.\n\n\n\nDeadlock Prevention (데드락 예방)\n\n\n\n\n  자원 할당 시 데드락의 4가지 필요 조건 중 어느 하나를 만족되지 않도록 하는 것\n  Mutual exclusion (상호 배제)\n    \n      공유해서는 안되는 자원의 경우 반드시 성립해야 하므로 건들지 않는다\n    \n  \n  Hold and wait (점유와 대기)\n    \n      프로세스가 자원을 요청할 때 다른 어떤 자원도 가지고 있지 않아야 한다\n      방법 1 - 프로세스 시작 시 필요한 모든 자원을 할당받게 한다\n      방법 2 - 자원이 필요할 경우 보유 자원을 모두 내어 놓은 후 요청 한다\n    \n  \n  No preemption (비선점)\n    \n      프로세스가 어떤 자원을 기다려야 하는 경우 이미 보유한 자원이 선점된다\n      모든 필요한 자원을 얻을 수 있을 때 그 프로세스는 다시 시작된다\n      상태를 쉽게 저장하고 불러올 수 있는 자원에서 주로 사용한다\n    \n  \n  Circular wait (순환 대기)\n    \n      모든 자원 유형에 할당 순서를 정하여서 정해진 순서대로만 자원을 할당한다\n    \n  \n\n\n데드락 예방 방법을 선택하면, 생길지 안생길지 모르는 데드락을 막을려고 사전에 많은 제약을 걸어두기 때문에, 이용률 저하, 시스템 성능 감소, Starvation 등의 문제가 발생할 수 있다.\n\n즉, 효율성이 떨어진다.\n\n\n\nDeadlock Avoidance (데드락 회피)\n\n\n\n\n  자원 요청에 대한 부가 정보를 이용해서 자원 할당이 데드락으로부터 안전(Safe)한지를 동적으로 조사해서 안전한 경우에만 할당\n  가장 단순하고 일반적인 모델은 프로세스들이 필요로 하는 각 자원별 최대 사용량을 미리 선언하도록 하는 방법임\n  시스템이 안전 상태에 있으면 데드락이 아니며, 불안전 상태에 있으면 데드락의 가능성이 있다고 볼 수 있다\n  데드락 회피는 시스템이 불안전 상태에 들어가지 않는 것을 보장한다\n    \n      자원 유형 당 1개의 인스턴스만 존재\n        \n          Resource Allocation Graph Algorithm (자원 할당 그래프 알고리즘)\n        \n      \n      자원 유형 당 여러 개의 인스턴스 존재\n        \n          Banker’s Algorithm (은행원 알고리즘)\n        \n      \n    \n  \n\n\n\n\n\n\n\n\nResource Allocation Graph Algorithm (자원 할당 그래프 알고리즘)\n\n\n\n\n\n\n\n\n  Claim edge(점선)\n    \n      프로세스가 자원을 미래에 요청할 수 있음을 뜻한다\n    \n  \n  Request edge(실선)\n    \n      프로세스가 해당 자원 요청 시 실선으로 바뀐다\n    \n  \n  데드락 회피는 데드락이 위험성이 있으면 자원을 할당하지 않는다\n    \n      위에서 3번째 이미지는 데드락의 위험성이 있기 때문에 자원이 할당되지 않는다\n    \n  \n\n\n\n\nBanker’s Algorithm (은행원 알고리즘)\n\n\n\n은행에서 사람들에게 돈을 대출해주는 것에서 착안한 알고리즘으로, 현재 사용할 수 있는 자원과 필요로 하는 자원들을 계산하여, 데드락의 위험성이 있는지 검증한다.\n\n\n\n\n\n\n\n\n\n\n\n\n  A는 10개, B는 5개, C는 7개가 존재\n  Allocation은 현재 각 프로세스에 할당된 자원의 수를 의미\n  Max는 각 프로세스마다 최대로 할당 받고 싶은 자원의 수를 의미\n  Available은 각 자원이 프로세스에게 추가로 할당 할 수 있는 가용 자원의 수를 의미\n  Need는 각 프로세스가 현재 최대로 필요로 하는 자원의 수를 뜻하며, Max에서 Allocation을 뺀 값\n  자원은 현재 가용 자원을 보고, Need만큼 자원을 줄 수 있는 프로세스를 하나도 찾지 못하면 불안전한 상태가 됨\n    \n      자원을 줄 수 있는 프로레스가 있다면 해당 프로세스에게 자원을 주고난 후, 프로세스가 끝날 때 모든 자원을 가져온다\n      이 과정을 반복하면 &lt;P1, P3, P4, P2, P0&gt;라는 안전 순서열을 만들 수 있다\n    \n  \n\n\n\n\n데드락 회피 또한, 데드락을 막기 위해 사전에 많은 제한을 걸게 되므로 비효율적이다\n\n\n\nDeadlock Detection and recovery (데드락 탐지 및 회복)\n\n\n\n데드락이 발생할 때 까지 아무런 조치를 하지 않다가, 데드락이 발생하면 조치를 취한다\n\n\n  Deadlock Detection (데드락 탐지)\n    \n      자원 당 인스턴스가 하나인 경우 == 자원할당 그래프의 사이클이 곧 데드락을 의미\n    \n  \n  Deadlock recovery (데드락 회복)\n    \n      Process termination\n        \n          방법 1 - 데드락에 연관된 모든 프로세스를 죽인다\n          방법 2 - 데드락에 연관된 프로세스를 하나씩 죽이다 데드락이 풀리면 그만둔다\n        \n      \n      Resource Preemption\n        \n          비용을 최소화할 희생양을 선정하여, 그 프로세스로 부터 자원을 빼앗아온다\n        \n      \n    \n  \n\n\n\n\nDeadlock Ignorance (데드락 무시)\n\n\n\n\n  데드락이 일어나지 않는다고 가정 아무런 조치도 취하지 않는다\n    \n      데드락이 애초에 매우 드물게 발생하므로 데드락에 대한 조치 자체가 더 큰 오버헤드일 수 있다\n      만약 시스템에 데드락이 발생한 경우 시스템이 비정상적으로 작동하는 것을 사람이 느낀 후 직접 프로세스를 죽이는 등의 방법으로 대처한다\n      UNIX, Windows 등 대부분의 OS에서 채택하였다\n    \n  \n\n\n\n\nDeadlock implemented in Java\n\n\n\npublic class Deadlock {\n    private static final Logger logger = Logger.getLogger(Deadlock.class.getName());\n\n    public static void main(String[] args) {\n        Integer lock1 = 1;\n        Integer lock2 = 2;\n\n        Thread t1 = new Thread(() -&gt; {\n            synchronized (lock1) {\n                logger.info(\"t1 got lock1. now going to try to get a lock2\");\n                synchronized (lock2) {\n                    logger.info(\"t1 got lock2\");\n                }\n                logger.info(\"If this message is printed, it means that t1 has acquired lock2\");\n            }\n        });\n\n        Thread t2 = new Thread(() -&gt; {\n            synchronized (lock2) {\n                logger.info(\"t2 got lock2. now going to try to get a lock1\");\n                synchronized (lock1) {\n                    logger.info(\"t2 got lock1\");\n                }\n                logger.info(\"If this message is printed, it means that t2 has acquired lock1\");\n            }\n        });\n\n        t1.start();\n        t2.start();\n    }\n}\n\n\n\n\nINFO: t1 got lock1. now going to try to get a lock2\nINFO: t2 got lock2. now going to try to get a lock1\n\n\n\n",
      "categories": ["cs","operating-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/operating-system/2022-03-01-deadlock/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "대체 스레드 종류는 뭐가 이렇게 많나? 😡",
      "date": "2022-03-04 00:00:00 +0000",
      "description": "많은 방황과 삽질 끝에 정리한 스레드의 종류\n",
      "content": "\n  스레드(Thread)    \n      사전 지식\n      하드웨어 스레드(Hardware Thread)\n      커널 스레드(Kernel Thread)\n      유저 스레드(User Thread)\n      그린 스레드(Green Thread)\n    \n  \n  Reference\n\n\n\n\n스레드(Thread)\n\n\n\n이번에 알았지만 컴퓨터 과학에서 스레드라는 용어는 굉장히 범용적으로 사용되고 있었다.\n\n실제로 스레드는 여러 종류가 존재하기 때문에 글의 문맥에 따라 어떤 스레드를 말하는지를 유추할 수 있어야 하는데, 나 같은(노베이스 비전공자) 사람이 이런 상황을 마주하면 굉장히 힘들어진다.\n\n자바 고급 서적들(JVM 레벨의…)을 보다보면 커널 스레드, 유저 스레드, 그린 스레드, 혹은 그냥 접두사 다 떼 놓은 스레드 같은 용어들이 미친듯이 나오는데, 기본기가 없으니 이게 대체 무슨말들을 하는건지 알아들을수가 있어야지…\n\n\n\n\n\n\n\n비유하자면, 나는 코딩을 처음 시작할 때 API가 뭔지 엄청 헷갈려했었는데, 이것과 굉장히 비슷한 느낌이었다. (API도 굉장히 범용적으로 사용되는 용어이므로…)\n\n아무튼, 이러한 이유로 이번에 운영체제 과목을 공부하게 됐는데, 까먹으면 내가 나중에 다시 볼 거기도 하고, 나 같은 분들(노베이스 비전공자)께 조금이나마 도움이 되길 바라기도 하며 나름대로 정리한 내용들을 기록해본다.\n\n우선 이 글은 스레드가 뭔지 궁금해 한번쯤 검색을 해 사전적인 정의라도 찾아봤다는 가정하에 기록한다.\n\n\n\n사전 지식\n\n\n\n\n  프로그램(Program)\n    \n      코드로 작성된 실행될 수 있는 애플리케이션. 하지만 메모리(RAM)를 할당받지 못하고 하드디스크에 저장돼있는 것\n    \n  \n  프로세스(Process)\n    \n      프로그램이 운영체제로부터 메모리를 할당받아 실행된 것. 즉, 실행 된 프로그램\n    \n  \n  스레드(Thread)\n    \n      프로세스의 실행 단위. 하나의 프로세스는 최소한 하나 이상의 스레드를 포함한다\n    \n  \n  멀티 프로그래밍(Multi Programming) or 멀티 프로세스(Multi Process)\n    \n      메모리에 동시에 여러개의 프로세스가 올라가는 것. MPD(Multi-Programming Degree or Degree of Multi programming mpd) 라는 키워드가 있다\n    \n  \n  멀티 태스킹(Multi Tasking)\n    \n      CPU가 여러개의 프로세스를 동시에 처리하는 것. CPU가 프로세스1을 조금 작업하고 정지한 후 프로세스2를 작업하러 가는 것\n    \n  \n  시분할(Time Sharing) or 시분할 시스템(TSS, Time Sharing System)\n    \n      멀티 태스킹을 위해 각 프로세스가 CPU를 점유할 수 있는 시간을 강제해둔 시스템\n    \n  \n  멀티 프로세싱(Multi Processing)\n    \n      프로그램이 여러개의 코어를 활용하는 것. 병렬 프로그래밍이라고도 불린다\n    \n  \n  멀티 스레딩(Multi Threading)\n    \n      하나의 프로세스가 여러개의 스레드를 갖는 것. 멀티스레딩을 활용하면 동시성을 보장할 수 있다\n    \n  \n  동시성(Concurrency)\n    \n      CPU가 동 시간대에는 단 하나의 작업을 처리하지만, 여러개의 작업을 조금씩 번갈아가며 처리하면 이 작업이 인간 입장에선 너무 빠르기 때문에 여러개의 작업이 동시에 처리되는 것 처럼 느낀다. 이를 동시성이라고 부른다\n    \n  \n  병렬성(Parallel)\n    \n      CPU가 동 시간대에 여러개의 작업을 처리하고 있는 것. 즉, 코어 1이 프로세스 1을 처리하고, 코어 2가 프로세스 2를 처리하면 동 시간대에 정확히 두개의 작업을 처리하고 있는 것이다. 이를 병렬성이라고 부른다\n    \n  \n\n\n\n\n\n\n동시성과 병렬성의 차이\n\n\n\n\n\n\n스레드 개념도\n\n\n\n하드웨어 스레드(Hardware Thread)\n\n\n\n우선 누구라도 듀얼 코어, 4코어 4스레드, 4코어 8스레드 어쩌고 하는 말들을 들어본 적이 있을 것이다.\n\n여기서 말하는 스레드가 하드웨어 스레드이다.\n\n누군가는 CPU 스레드라고 부르기도 하는 것 같다.\n\n\n\n모든 코드(Instruction Set, 명령어)는 메모리에서 CPU로 옮겨진 후 실행(연산)되고, 이러한 결과는 다시 메모리에 반영된다.\n\n하지만 CPU의 연산 속도에 비해 메모리에서 CPU로 코드를 옮겨오거나, CPU에서 메모리로 코드를 옮기는 속도는 상대적으로 매우매우매우 느리다.\n\n즉, 하드웨어가 발전함에 따라 CPU가 일하는 속도가 너무 빨라졌기 때문에, 역설적으로 CPU가 할 일이 없어 손가락을 빨며 대기하는 상황이 생긴다는 것이다.\n\n\n\n\n\n\n\n위 그림대로라면, CPU는 코드를 메모리로 옮기거나, 메모리에서 CPU로 가져오는 동안에는 연산 작업을 하지 못하게 된다.\n\n즉, CPU의 성능을 온전하게 활용하지 못하고 클럭을 낭비하게 되는 것이다.\n\n\n\n\n\nCPU의 상태\n\n\n\n상황이 이러하니 나온 것이, CPU 내부에서 일을 하는 친구를 하나 더 만들자는 것.\n\n즉, 인텔에서는 HT(하이퍼 스레딩)라 부르고, AMD에서는 SMT라고 부르는 기술이 탄생한다.\n\n그림으로 보자면 하기와 같다.\n\n\n\n\n\n\n\n여담이지만, CPU와 프로세서는 대부분 이음동의어로 사용되며, 코어라는 것은 CPU 내부에 존재하는 ALU와 같은 핵심 부품들을 통틀어 의미한다.\n\n\n\n\n\n\n\nHT/SMT는 실제로 물리적인 코어는 하나만 있지만, 운영체제에게는 코어가 두개인 것처럼 속이는 기술이다.\n\n따로 찾아보면 파이프라이닝이니 뭐니 해서 굉장히 내용이 깊고 심오하니, 한번쯤은 꼭 찾아보길 바란다 !\n\n\n\n\n\n\n\n커널 스레드(Kernel Thread)\n\n\n\n프로그래밍을 제외한 대부분의 매체에서 말하는 스레드는 이 커널 스레드라고 봐도 무방하다.\n\n실제로, 프로그래밍 관련 서적에서도 커널 스레드가 가장 많이 나오기도 한다.\n\n이 커널 스레드가 가장 헷갈렸는데, 커널 스레드를 부르는 다른 이름이 진절머리나게 많았기 때문이다.\n\n이 커널 스레드를 어떤 이름으로 부르는지, 내가 본 용어들을 정리하자면 다음과 같고, 더 있을수도 있다.\n\n\n\n\n  네이티브 스레드(Native Thread)\n  운영체제 스레드(OS Thread)\n  커널 레벨 스레드(Kernel Level Thread)\n  운영체제 레벨 스레드(OS Level Thread)\n\n\n\n\n이것들이 모두 같은걸 의미하는 용어라는걸 확신할 수 없는 상황(노베이스 비전공 -ㅅ-)에서 온갖 글들을 보고있으면 머리만 더 아파지는 것이다. (예를 들자면… 엥? 이건 또 뭐야? 같은 느낌?)\n\n이제와서 나는 대부분의 상황에서 커널 스레드를 위의 용어들과 동일하다고 생각하며 보고 있으며, 실제로 그렇게 봐도 이해하는데 지장이 없었다.\n\n\n\n\n\n\n\n운영체제도 하나의 프로그램으로서 하드디스크에 저장되어있고, 컴퓨터에 전원을 공급하면 운영체제가 실행되며 메모리(RAM)에 올라가 프로세스가 된다.\n\n그리고 메모리에 항상 상주하는, 운영체제의 핵심적인 부분(코드)들이 바로 커널이라고 할 수 있다.\n\n즉, 커널은 일반적으로 운영체제의 이음동의어다.\n\n\n\n운영체제도 일단 프로그램이기 때문에, 내부적으로 최소한 한개 이상의 스레드를 가진다.\n\n운영체제가 프로그램으로서 갖는 스레드를 바로 커널 스레드(혹은 위에 나열한 용어들...)라고 부르며, 운영체제 코드에 작성 된 CPU 스케쥴링같은 코드들에 직접적으로 영향을 받아 하드웨어 스레드를 점유하거나 여타 하드웨어들을 제어하는 것이 바로 이 커널 스레드이다.\n\n즉, 4코어 8스레드 컴퓨터에서는 동시간대에 정확히 8개의 커널 스레드가 동작할 수 있는 것이다.\n\n따라서 멀티코어 파워를 온전히 활용해야 하는 병렬 프로그래밍에 있어 매우 중요한 개념이라고 볼 수 있겠다.\n\n\n\n유저 스레드(User Thread)\n\n\n\n유저 스레드는 사용자 스레드, 혹은 유저 레벨 스레드(User Level Thread)라고 불리기도 하며, 이는 프로그래밍 언어에서 제공하는 스레드를 의미한다.\n\n프로그래밍 언어로 프로그램을 개발하면, 내부적으로 최소한 한개 이상의 스레드를 갖게 되는데, 이렇게 추가적인 스레드를 만들고 제어하는 것들을 대부분의 프로그래밍 언어에서 지원하고 있다.\n\n그리고 기본적으로 커널에서는 이 유저 스레드들의 존재를 모르며, 오직 프로세스를 대상으로 일련의 작업들을 진행한다. (커널은 프로세스인 줄 알았지만, 그게 실제로는 유저 스레드인 셈…)\n\n그러니까 실제적으로 유저 스레드가 작업을 하려면 커널 스레드와 반드시 매핑이 되어야만 하며(하드웨어 스레드가 커널 스레드를 바라보므로), 커널 스레드와 매핑되지 않은 유저 스레드는 아무런 작업도 할 수 없는 상태가 된다.\n\n\n\n여기서 약간 의문이 생겼고, 나름의 답을 내렸는데 이게 정답인지는 나도 잘 모르겠다.\n\n위에서는 운영체제도 프로그램이라 하였다.\n\n그리고, 현재 대부분의 운영체제는 C언어로 작성돼있다.\n\n즉, 위에서 말한 커널 스레드도 C언어에서 제공하는 스레드 관련 코드로 작성됐을 것이라는 생각이 들었는데, 그렇다면 커널 스레드도 유저 스레드의 일종이라고 볼 수 있지 않을까? 라는 의문이 들었었다.\n\n내 결론은 커널 스레드도 유저 스레드의 일종이며, 운영체제도 프로그램이긴 하지만, 아주 특별한 프로그램이기 때문에 마찬가지로 운영체제의 유저 스레드에 커널 스레드라는 특별한 이름을 붙여 부르게 된 것이 아닐까 싶다. (정확히 아시는분은 알려주세요 😭)\n\n\n\n잡담이 길었는데, 내가 사용하는 자바에도 물론 유저 스레드를 지원하기 때문에 Thread라는 클래스와, 이에 관련 된 여러가지 클래스들이 존재한다.\n\n\n\npublic class Thread implements Runnable {\n  // ...이하 생략\n\n  public synchronized void start() {\n    if (threadStatus != 0)\n      throw new IllegalThreadStateException();\n\n    group.add(this);\n\n    boolean started = false;\n    try {\n      start0();\n      started = true;\n    } finally {\n      try {\n        if (!started) {\n          group.threadStartFailed(this);\n        }\n      } catch (Throwable ignore) {\n                /* do nothing. If start0 threw a Throwable then\n                  it will be passed up the call stack */\n      }\n    }\n  }\n\n  private native void start0();\n  \n  // ...이하 생략\n}\n\n\n\n\n모던 자바의 스레드는 특이한데, Thread.start()가 호출되면 start0() 이라는 JNI(Java Native Interface)를 통해 운영체제의 시스템 콜(System Call)을 호출하고, 이는 결과적으로 커널 스레드를 직접적으로 생성하여 유저 스레드(여기선 자바 스레드)와 매핑하게 된다.\n\n즉, 모던 자바의 모든 유저 스레드는 커널을 직접 만들어 다이렉트로 연결되므로, 하나도 남김없이 커널의 CPU 스케쥴링에 직접적으로 영향을 받게 된다.\n\n또한, 하나의 커널 스레드가 여러개의 유저 스레드를 관리하고, 하나의 유저 스레드가 여러개의 커널 스레드의 관리를 받는 Many-To-Many 모델을 채택해 멀티코어 파워를 온전히 활용할 수 있게 됐다.\n\n정리하자면 모던 자바는 병렬 프로그래밍에 많은 최적화가 되어있는 셈이다. (모든 코어를 균등하게 잘 갈굴 수 있다…!)\n\n\n\n\n\n모던 자바의 Thread 모델\n\n\n\n그린 스레드(Green Thread)\n\n\n\n\n\n자바 최적화 中\n\n\n\n극 초창기 자바인 버전 1.2이전의 자바 스레드를 의미한다.\n\n극 초창기의 자바는 위와 다르게, 하나의 커널 스레드에 여러개의 유저 스레드가 매핑되는 Many-To-One 모델이었다고 한다.\n\n\n\n\n\n자바 1.2 이전의 Thread 모델 -\n\n\n\n즉, 동시성은 지원하지만, 병렬성은 지원 할 수 없는 모델이었기 때문에 멀티코어 파워를 온전히 활용 할 수 없었고, 이로 인한 성능 이슈로 인해 자바 커뮤니티에서 굉장히 많은 비판을 받았던 것 같다.\n\n아무튼 모던 자바에서는 사용되지 않고 있는 것 같지만, 자바 고급 서적들에서는 의외로 자주 나오는 용어이기 때문에 추가하였다.\n\n\n\nReference\n\n\n\n\n  📕 운영체제 10판\n  📕 자바 최적화\n  📕 자바 성능 튜닝\n  📕 자바 병렬 프로그래밍\n  📕 JVM Performance Optimizing 및 성능분석 사례\n  📜 Oracle Docs - 멀티스레딩\n  📜 자바 스레드와 OS 스레드의 차이점\n  📜 LASS - 스레드, 스케줄링 및 동기화\n  📜 유저 레벨 스레드 / 커널 레벨 스레드\n  📜 Stackoverflow - CPU 스레드, 커널 스레드, OS 스레드, 유저 스레드의 차이점\n  📜 Stackoverflow - 자바의 네이티브 스레드와 JVM 이해하기\n  📜 Stackoverflow - 자바 스레드는 유저 또는 커널 공간에서 생성되나요?\n  📜 나무위키 - SMT/HT\n\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-03-04-diary-36/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "GitHub - Pull Request File Tree",
      "date": "2022-03-05 00:00:00 +0000",
      "description": "GitHub - Feature preview\n",
      "content": "\n  Feature preview - Pull Request File Tree\n\n\n\n\nFeature preview - Pull Request File Tree\n\n\n\n깃허브에 새로운 베타 기능이 들어왔다.\n\nPR을 트리구조로 보여주는 기능인데, Octotree와 비슷하다.\n\n베타버전이기 때문에 활성화를 해 주어야 한다.\n\n\n\n\n  깃허브에 로그인하여 우상단 프로필을 클릭한 후 Feature preview를 클릭한다.\n\n\n\n\n\n\n\n\n\n  Pull Request File Tree - Enable을 클릭해 기능을 활성화 해준다.\n\n\n\n\n\n\n\n\n\n  아무 프로젝트나 들어가 Pull Request 탭을 누른 후 File changed 탭을 클릭하면 좌측에 파일 트리가 나타난다.\n\n\n\n\n\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-03-05-diary-37/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "운영체제(Operating System) 7강",
      "date": "2022-03-10 00:00:00 +0000",
      "description": "반효경 교수님 - Memory Management\n",
      "content": "\n  Lecture\n  Memory    \n      Logical Address vs Physical Address        \n          Address Binding\n        \n      \n      MMU(Memory Management Unit)\n      Memory Terminology        \n          Dynamic Loading\n          Overlay\n          Swapping\n          Dynamic Linking\n        \n      \n      Allocation Of Physical Memory        \n          Contiguous Allocation            \n              Dynamic Storage Allocation Problem\n              Compaction\n            \n          \n          Non-Contiguous Allocation\n        \n      \n      Paging        \n          Address Translation Architecture\n          Implementation Of Page Table\n          TLB\n          Hierarchical Paging            \n              Two-Level Page Table\n            \n          \n        \n      \n    \n  \n  Paging    \n      Multilevel Paging and Performance\n      Memory Protection\n      Inverted Page Table\n      Shared Page\n    \n  \n  Segmentation    \n      Segmentation Architecture\n      Segmentation Hardware        \n          Protection\n          Sharing\n          Allocation of Physical Memory\n        \n      \n      Advantages and Disadvantages of Segmentation\n    \n  \n  Paged Segmentation\n\n\n\n\nLecture\n\n\n\n\n  운영체제 - 반효경 교수님\n    \n      Memory Management 1\n      Memory Management 2\n      Memory Management 3\n      Memory Management 4\n    \n  \n\n\n\n\nMemory\n\n\n\n각 프로세스는 독립적인 메모리를 점유한다 하였다.\n\n이번에는 운영체제가 메모리를 어떻게 관리하는지 알아 볼 것이다.\n\n\n\nLogical Address vs Physical Address\n\n\n\n\n\n\n\nAddress Binding\n\n\n\n프로세스의 논리적 주소를 물리적 메모리 주소로 연결하는 작업을 말한다.\n\n\n  Symbolic Address -&gt; Logical Address (바로 이 시점) -&gt; Physical Address\n\n\nSymbolic Address는 프로그래머 입장에서 사용하는 것이며, 프로그래머는 데이터를 메모리 몇 번지에 저장하라고 코딩하지 않고, 문자로 된 변수명을 사용한다.\n\n마찬가지로, 함수도 메모리 몇 번지로 jump하라고 코딩하지 않고, 문자로 된 함수명을 사용한다.\n\n이를 Symbolic하다고 표현하며, 주소 바인딩 방식은 프로그램이 적재되는 물리적 메모리의 주소가 결정되는 시기에 따라 세 가지로 분류할 수 있다.\n\n\n\n\n\n\n\n\n  Compile Time Binding\n    \n      프로그램을 컴파일할 때 물리적 메모리 주소가 결정되는 주소 바인딩 방식\n      컴파일 하는 시점에 해당 프로그램이 물리적 메모리의 몇 번지에 위치할 것인지를 이미 결정하므로 프로그램이 절대 주소로 적재된다는 뜻에서 절대 코드를 생성하는 바인딩 방식이라고도 부른다\n      프로그램이 올라가 있는 물리적 메모리의 위치를 변경하고 싶다면 컴파일을 다시 해야 한다\n      멀티프로그래밍이 없던 시절에는 사용됐으나, 현대의 시분할 컴퓨팅 환경에서 거의 사용하지 않는다\n    \n  \n\n\n\n\n\n  Load Time Binding\n    \n      프로그램이 실행 될 때 물리적 메모리 주소가 결정되는 주소 바인딩 방식\n      Loader의 관리 하에 물리적 메모리 주소가 결정되며 프로그램이 종료될 때까지 물리적 메모리 상의 위치가 고정된다\n        \n          Loader는 사용자 프로그램을 메모리에 적재하는 프로그램이다\n        \n      \n      컴파일러가 재배치 가능 코드를 생성한 경우에만 가능하다\n    \n  \n\n\n\n\n\n  Execution Time Binding or Runtime Binding\n    \n      프로그램이 실행된 후에도 프로그램이 위치한 물리적 메모리 주소가 변경 될 수 있는 바인딩 방식\n      CPU가 주소를 참조할 때마다 해당 데이터가 어느 물리주소에 위치에 존재하는지 확인해야하는데, 이때 MMU(Memory Management Unit)의 주소 매핑 테이블을 사용한다\n        \n          MMU는 논리적 주소와 물리적 주소를 매핑해주는 하드웨어 장치이다 (데이터베이스 매핑 테이블을 연상하라)\n        \n      \n      MMU, 기준 레지스터, 한계 레지스터 등과 같은 하드웨어적인 자원이 필요하다\n      현대의 시분할 컴퓨팅 환경에서 사용되는 방식\n    \n  \n\n\n\n\nMMU(Memory Management Unit)\n\n\n\n\n\n\n\n\n\n\n\n\n  Relocation Register (Base Register)\n    \n      사용자 프로세스의 논리적 주소 0번지에 매핑된 물리적 주소를 의미\n      사용자 프로세스는 항상 자신의 시작 주소가 0번지라고 생각하지만, 이는 논리 주소일 뿐이며, 실제 물리 주소는 0번지가 아닐 수 있다\n      위 그림에서 P1은 CPU를 통해 논리 주소 346번지의 데이터를 요청했으나, 실제로 이 사용자 프로세스가 할당받은 물리 시작 주소는 14,000번지로 MMU에 저장돼있으므로 MMU는 14,000에 346을 더한 14,346번지의 주소를 반환한다\n    \n  \n  Limit Register\n    \n      사용자 프로세스에게 할당된 메모리의 최대 크기를 저장하는 레지스터\n      운영체제가 사용자 프로세스에게 할당한 메모리를 넘어 바깥의 메모리를 침범하면, 이 프로세스는 악의적인 프로세스(바이러스 등)일 가능성이 있으므로 이를 차단해야 한다\n      위 그림에서 운영체제가 P1에게 할당한 메모리의 크기는 3,000이며, 물리 주소는 14,000~17,000 이다\n    \n  \n\n\n\n\n\n\n\n\nMemory Terminology\n\nDynamic Loading\n\n\n\n\n  프로세스 전체를 메모리에 미리 다 올리는 것이 아니라 해당 루틴이 불려질 때 메모리에 올리는 것\n  메모리를 더 효율적으로 사용할 수 있게 된다\n  가끔씩 사용되는 많은 양의 코드의 경우, 예를 들자면 오류 처리 루틴같은 것들에 유용하다\n  운영체제의 특별한 지원 없이 프로그램 자체에서 구현이 가능하며, 운영체제가 라이브러리를 통해 지원할 수도 있다\n\n\n\n\nOverlay\n\n\n\n\n  메모리에 프로세스의 부분 중 실제 필요한 정보만을 올리는 기법으로 Dynamic Loading와 비슷하여 헷갈릴 수 있다\n  초창기 컴퓨터 시스템은 메모리가 매우 작아 하나의 프로세스조차도 메모리에 한꺼번에 올릴 수 없었다\n  프로세스의 주소 공간을 분할해 당장 필요한 부분만을 메모리에 올려 실행하고 해당 부분에 대한 실행이 끝난 후에 나머지 부분을 올려 실행하는 기법\n  프로세스의 크기가 메모리보다 클 때 유용하다\n  작은 공간의 메모리를 사용하던 초창기 시스템에서 운영체제의 지원 없이 수작업으로 프로그래머가 구현하였다. 즉, 현재는 일반적으로 사용되지 않는다\n    \n      프로그래밍이 상당히 복잡하다.\n    \n  \n  Dynamic Loading과의 차이점\n    \n      Dynamic Loading: 멀티프로그래밍 환경에서 메모리에 더 많은 프로세스를 동시에 올려놓고 실행하기 위한 용도. 운영체제의 도움을 받는다\n      Overlay: 단일 프로세스만을 메모리에 올려놓는 환경에서 메모리 용량보다 큰 프로세스를 올리기 위한 용도. 운영체제의 도움을 받지 않는다\n    \n  \n\n\n\n\nSwapping\n\n\n\n\n  메모리에 올라온 프로세스를 디스크의 Backing Store로 쫓아내는 것\n    \n      Backing Store는 Swap Area라고도 부르며, 디스크 내에 파일 시스템과는 별도로 존재하는, 많은 사용자 프로세스를 담을 만큼 충분히 빠르고 큰 저장 공간이다\n    \n  \n  디스크에서 메모리로 올리는 작업을 Swap In, 메모리에서 디스크로 내리는 작업을 Swap Out라고 부른다\n  Swap이 일어나는 과정\n    \n      일반적으로 중기 스케줄러(Swapper)가 Swap Out할 프로세스를 선정한다\n        \n          주로 우선 순위 기반 CPU 스케줄링을 사용한다\n          우선 순위가 높은 프로세스를 Swap In\n          우선 순위가 낮은 프로세스를 Swap Out\n        \n      \n      만약 컴파일 타임 바인딩 혹은 로드 타임 바인딩 방식이 사용되고 있다면, Swap Out되었다가 Swap In이 되면 원래 존재하던 메모리 위치로 다시 올라가야만 한다\n      반면 런타임 바인딩 방식이 사용되고 있다면, 추후 빈 메모리 영역 아무 곳에나 프로세스를 올릴 수 있으므로 Swapping에 적합하다\n    \n  \n  Swap Time은 디스크의 탐색 시간이나 회전 지연 시간 보다는 디스크 섹터에서 실제 데이터를 읽고 쓰는 전송 시간(transfer time)이 대부분을 차지한다\n    \n      디스크는 물리적으로 움직이는 시간이 존재하기 때문에, 전기적 신호로 동작하는 메모리에 비해 심각하게 느리다\n    \n  \n\n\n\n\nDynamic Linking\n\n\n\n\n  연결(Linking)이란, 개발자가 작성한 소스 코드를 컴파일하여 생성된 목적 파일(object file)과 이미 컴파일된 라이브러리 파일들을 묶어 하나의 실행 파일을 생성하는 과정이다\n  Dynamic Linking은 컴파일을 통해 생성된 목적 파일과 라이브러리 파일 사이의 연결을 프로그램의 실행 시점까지 지연하는 기법이다.\n  Static Linking\n    \n      외부 라이브러리가 프로그램의 실행 파일에 포함된다\n      실행 파일의 크기가 커진다\n      동일한 라이브러리를 각각의 프로세스가 메모리에 올리므로 메모리 낭비가 심하다\n    \n  \n  Dynamic Linking\n    \n      실행 파일에 라이브러리 코드가 포함되지 않으며, 프로그램이 실행되면서 라이브러리 함수를 호출할 때가 되어서야 라이브러리에 대한 연결이 이루어진다\n      라이브러리 호출 부분에 라이브러리 루틴의 위치를 찾기 위한 Stub이라는 작은 코드를 둔다\n      라이브러리가 이미 메모리에 있으면 그 루틴의 주소로 가고, 없으면 디스크에서 읽어 온다\n      운영 체제의 도움이 필요하다\n    \n  \n\n\n\n\nAllocation Of Physical Memory\n\n\n\n\n  물리적 메모리는 운영체제 상주 영역(커널)과 사용자 프로세스 영역으로 나뉨\n    \n      운영체제 상주 영역은 인터럽트 벡터와 함께 낮은 주소 영역을 사용한다 (주로 물리적 메모리의 0번지)\n      사용자 프로세스 영역은 운영체제보다 높은 주소 영역을 사용\n    \n  \n\n\n\n\nContiguous Allocation\n\n\n\n\n  각각의 프로세스가 연속적인 메모리 공간에 적재되도록 하는 것\n  고정 메모리 분할 방식과 가변 메모리 분할 방식이 존재\n  고정 분할 방식은 외부 조각과 내부 조각이 동시에, 가변 분할 방식은 외부조각이 발생할 수 있다\n    \n      외부 조각 (External Fragmentation)\n        \n          프로그램의 크기보다 파티션의 크기가 작은 경우 해당 파티션이 비어있는 데도 불구하고 프로그램을 적재하지 못하기 때문에 생기는 메모리 공간을 의미\n        \n      \n      내부 조각 (Internal Fragmentation)\n        \n          프로그램의 크기보다 파티션의 크기가 큰 경우 해당 파티션에 프로그램을 적재하고 남는 메모리 공간을 의미\n        \n      \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDynamic Storage Allocation Problem\n\n\n\n\n  가변 분할 방식에서 주소 공간의 크기가 n인 프로세스를 메모리에 올릴 때 물리적 메모리 내의 가용 공간 중 어느 위치에 올릴 것인지 결정하는 문제\n  First-fit\n    \n      size가 n 이상인 것 중 최초로 찾아지는 hole에 할당\n    \n  \n  Best-fit\n    \n      size가 n 이상인 가장 작은 hole을 찾아 할당\n      hole 리스트가 크기 순으로 정렬되지 않은 경우 모든 hole을 탐색해야 함\n      많은 수의 아주 작은 hole이 생성 됨\n    \n  \n  Worst-fit\n    \n      가장 큰 hole에 할당 해야 함\n      역시 hole을 탐색해야 함\n      상대적으로 아주 큰 hole이 생성 됨\n    \n  \n  First-fit과 Best-fit이 Worst-fit보다 속도와 공간 이용률 측면에서 효과적\n\n\n\n\nCompaction\n\n\n\n\n  외부 조각 문제를 해결하는 방법 중 하나\n  물리적 메모리 중에서 프로세스에 의해 사용 중인 메모리를 한 쪽으로 밀고, 가용 공간들을 다른 한쪽으로 몰아서 하나의 큰 가용 공간을 만드는 방법이다 (디스크 조각모음?, 가비지 컬렉션?)\n  매우 비용이 많이 드는 방법이다\n  최소한의 메모리 이동으로 압축하는 방법은 매우 복잡한 문제이다\n  압축은 프로세스의 주소가 실행 시간에 동적으로 재배치가 가능한 런타임 바인딩 방식을 지원하는 환경에만 가능하다\n\n\n\n\nNon-Contiguous Allocation\n\n\n\n\n  하나의 프로세스가 메모리의 여러 영역에 분산되어 적재 되는 것\n  Paging, Segmentation, Paged Segmentation 방식이 존재\n  현대의 컴퓨팅 시스템은 Non-Contiguous Allocation 방식의 Paging 기법을 주로 사용한다\n\n\n\n\nPaging\n\n\n\n\n  프로세스의 주소 공간을 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 페이지를 저장하는 방식\n  각 프로세스의 주소 공간 전체를 메모리에 한꺼번에 올릴 필요가 없고, 일부는 Backing Storage, 일부는 메모리에 혼재하는 것이 가능해진다\n  메모리를 페이지와 같은 동일한 크기의 프레임으로 미리 나누어 둔다. 이를 페이지 프레임(Page Frame) 이라 칭한다\n  메모리에 올리는 단위가 동일한 크기의 페이지 단위이므로 외부 조각이 발생하지 않고, 동적 메모리 할당 문제도 고려할 필요가 없어진다\n  주소 매핑을 기존 MMU의 레지스터 두개로는 처리할 수 없고, 페이지 테이블이라는 것을 사용하여 논리적 주소를 물리적 주소로 변환하는 작업이 필요해진다\n  프로그램의 크기가 항상 페이지 크기의 배수가 된다는 보장이 없으므로 프로세스의 주소 공간 중 제일 마지막에 위치한 페이지에서는 내부 조각이 발생할 수 있다\n\n\n\n\n\n\n\n\nAddress Translation Architecture\n\n\n\n\n\n\n\n\n  페이징에서는 CPU가 사용하는 논리적 주소를 페이지 번호(p)와 페이지 오프셋(d)으로 나누어 주소 변환에 사용\n  페이지 번호는 각 페이지별 주소 변환 정보를 담고 있는 페이지 테이블 접근 시 인덱스로 사용되고, 해당 인덱스의 항목에는 그 페이지의 물리적 메모리 상의 기준 주소, 즉 시작 위치가 저장 됨\n  프로세스의 p번째 페이지의 물리적 메모리의 시작 위치를 알고 싶다면 해당 프로세스의 페이지 테이블에서 p번째 항목을 찾으면 됨\n  페이지 오프셋은 하나의 페이지 내에서의 변위(offset)를 알려 줌\n  기준 주소 값에 변위를 더함으로써 요청된 논리적 주소에 매핑되는 물리적 주소를 얻을 수 있다\n  위 그림에서 f (물리적 주소의 시작 위치) + d를 취하면 처음에 CPU가 요청한 논리적 주소에 매핑되는 물리적 주소가 나온다\n\n\n\n\nImplementation Of Page Table\n\n\n\n\n  페이지 테이블은 페이징 기법에서 주소 변환을 하기 위한 자료 구조로, 메모리에 항상 상주한다\n  현재 CPU에서 실행 중인 프로세스의 페이지 테이블에 접근하기 위해 운영체제는 2개의 레지스터를 사용한다\n    \n      Page-Table Base Register\n        \n          메모리 내에서 페이지 테이블의 시작 위치를 가리킨다\n        \n      \n      Page-Table Length Register\n        \n          페이지 테이블의 크기를 보관\n        \n      \n    \n  \n  페이징에서 모든 메모리 접근 연산은 총 2번씩 필요\n    \n      주소 변환을 위해 페이지 테이블에 접근\n      변환된 주소에서 실제 데이터에 접근\n      이러한 오버헤드를 줄이고 메모리의 접근 속도를 향상하기 위해 TLB(Translation Lock-aside Buffer) 라고 불리는 주소 변환용 고속 하드웨어 캐시를 사용\n    \n  \n\n\n\n\nTLB\n\n\n\n\n  TLB는 가격이 매우 비싸기 때문에 빈번히 참조되는 페이지에 대한 주소 변환 정보만 담게 된다\n  요청된 페이지 번호가 TLB에 존재한다면 곧바로 대응하는 물리적 메모리의 프레임 번호를 얻을 수 있지만, TLB에 존재하지 않는 경우에는 메인 메모리에 있는 페이지 테이블에 접근 해 프레임 번호를 알아내야 한다\n  페이지 테이블에는 페이지 번호가 주어지면 해당 페이지에 대응하는 프레임 번호를 얻을 수 있지만, TLB에는 페이지 번호와 프레임 번호 쌍을 가지고 있으므로 특정 페이지 번호가 있는지 TLB 전체를 찾아봐야 한다\n    \n      이때 TLB 풀 스캔 시간이 오래 걸리므로 병렬적으로 탐색이 가능한 연관 레지스터를 사용한다\n    \n  \n  TLB는 Context Switching 시, 이전 프로세스의 주소 변환 정보를 담고 있는 내용이 전부 지워진다\n\n\n\n\n\n\n\n\nHierarchical Paging\n\n\n\n\n  현대의 컴퓨터는 하드웨어의 발달로 메모리를 크게 잡아먹는 프로그램을 지원\n    \n      예를 들어 32bit 주소 체계를 사용하는 컴퓨터에서는 4GB의 주소 공간을 갖는 프로그램을 지원\n        \n          페이지 사이즈가 4K라면, 한 프로세스당 페이지 테이블을 위해 1M 크기의 페이지 테이블 메모리 공간이 필요\n          그러나 대부분의 프로그램은 4G의 주소 공간 중 지극히 일부분만 사용하므로 페이지 테이블 공간이 심하게 낭비 됨\n          이러한 공간 낭비를 막기 위해 페이지 테이블 자체를 페이지로 구성하는 다단계 페이징 기법을 사용\n        \n      \n    \n  \n\n\n\n\nTwo-Level Page Table\n\n\n\n\n\n\n\n\n  주소 변환을 위해 외부 페이지 테이블과 내부 페이지 테이블로 나뉜 2단계 페이지 테이블을 사용\n  사용하지 않는 주소 공간에 대해서는 외부 페이지 테이블의 항목을 null로 설정, 이에 대응하는 내부 페이지 테이블을 생성하지 않음\n  페이지 테이블을 위해 사용되는 메모리 공간을 줄이지만, 페이지 테이블의 수가 증가하므로 약간의 시간적인 성능 손해가 발생한다 (trade-off)\n\n\n\n\n\n\n\n\n\n  프로세스의 논리적 주소를 두 종류의 페이지 번호(P1, P2)와 페이지 오프셋(d)으로 구분\n    \n      P1은 외부 페이지 테이블의 인덱스이고, P2는 내부 페이지 테이블의 인덱스이다\n      따라서, 논리적 주소를 &lt;P1, P2, d&gt; 형태로 표시할 수 있게 된다\n    \n  \n  외부 페이지 테이블로부터 P1만큼 떨어진 위치에서 내부 페이지 테이블의 주소를 얻게 되고, 내부 페이지 테이블로부터 P2만큼 떨어진 위치에서 요청된 페이지가 존재하는 프레임의 위치를 얻은 후, 해당 프레임으로부터 d만큼 떨어진 곳이 찾으려는 물리적 주소임\n\n\n\n\nPaging\n\n\n\nMultilevel Paging and Performance\n\n\n\n\n  프로세스의 주소 공간이 커질수록 페이지 테이블의 크기도 커지므로 주소 변환을 위한 메모리 공간 낭비가 심해진다\n  이 때, 다단계 페이지 테이블을 사용하면 페이지 테이블을 위해 사용되는 메모리 공간의 소모를 줄일 수 있지만, 메모리 접근 시간이 늘어난다\n  이 문제를 다시 TLB를 통해 메모리 접근 시간을 줄일 수 있다. 즉 현대의 컴퓨팅 시스템에서 TLB는 필연이다\n  4단계 페이지 테이블을 사용하는 경우\n    \n      메모리 접근 시간 = 100ns, TLB 접근 시간 = 20ns\n      요청된 페이지에 대한 주소 변환 정보가 TLB에 존재할 확률 98%\n      평균 메모리 접근 시간 (EAT) = 0.98 x 120 + 0.02 x 520 = 128ns\n        \n          TLB hit이 성공할 때 - TLB 접근 시간과 메모리 접근 시간의 합인 120ns\n          TLB hit이 실패할 때 - TLB 접근 시간과 메모리 접근 시간 x 5의 합인 520ns\n        \n      \n      결과적으로 주소 변환을 위해서만 28ns가 소요됨\n    \n  \n\n\n\n\nMemory Protection\n\n\n\n\n  페이지 테이블의 각 항목에는 주소 변환 정보 외에 메모리 보호를 위한 보호 비트와 유효-무효 비트(Valid (v) / Invalid (i))가 존재\n  보호 비트는 각 페이지에 대해 읽기-쓰기/읽기 전용 등의 접근 권한을 설정하는 데 사용\n  유효-무효 비트는 해당 페이지의 내용이 유효한지에 대한 내용을 포함\n    \n      유효-무효 비트가 유효 인 경우 - 해당 메모리 프레임에 해당 페이지가 존재. 따라서 접근 허용\n      유효-무효 비트가 무효 인 경우 - 해당 페이지가 물리적 메모리에 올라와 있지 않고, Backing Store에 존재하여 해당 메모리 프레임에 접근 불가\n    \n  \n\n\n\n\n\n\nInverted Page Table\n\n\n\n\n\n\n\n\n\nShared Page\n\n\n\n\n  공유 코드(Shared Code)는 메모리 공간의 효율적인 사용을 위해 여러 프로세스가 공통적으로 사용 할  수 있도록 작성된 코드를 의미\n    \n      재진입 가능 코드, 순수 코드라고도 불리며, 읽기 전용(Read Only)의 특성을 가짐\n    \n  \n  공유 페이지(Shared Page)는 공유 코드를 담고 있는 페이지를 의미\n    \n      공유 페이지는 여러 프로세스에게 공유되는 페이지이므로 물리적 메모리에 하나만 적재되어 메모리를 효율적으로 사용할 수 있음\n    \n  \n  예를 들어 문서 편집기 프로그램을 공유 페이지를 사용해서 작성한 경우, 이 프로세스를 여러 개 수행하더라도 공유 코드를 담은 페이지는 메모리에 하나만 올라감\n    \n      공유 코드는 읽기 전용의 성질을 가져야 하고 모든 프로세스의 논리적 주소 공간에서 동일한 위치에 존재해야 한다\n    \n  \n  사유 페이지는 프로세스들이 공유하지 않고, 프로세스 별로 독자적으로 사용하는 페이지를 의미\n    \n      사유 페이지는 해당 프로세스의 논리적 주소 공간 중 어떠한 위치에 있어도 무방\n    \n  \n  ed1, ed2, ed3은 공유 페이지, data1, data2, data3은 사유 페이지\n\n\n\n\n\n\n\n\nSegmentation\n\n\n\n\n  프로그램은 의미 단위인 여러 개의 세그먼테이션으로 구성\n    \n      작게는 프로그램을 구성하는 하나 하나를 세그먼트로 정의\n      크게는 프로그램 전체를 하나의 세그먼트로 정의 가능\n      일반적으로는 code, data, stack 부분이 각각 하나의 세그먼트로 정의됨\n    \n  \n  세그먼트는 다음과 같은 logical unit들임\n    \n      main()\n      function\n      global variables\n      stack\n      symbol table\n      arrays\n    \n  \n\n\n\n\nSegmentation Architecture\n\n\n\n\n  논리 주소는 &lt;세그먼트 번호(s), 오프셋(d)&gt; 두 가지로 구성됨\n    \n      s는 해당 논리 주소가 프로세스 주소 공간 내에서 몇 번째 세그먼트에 속하는지를 나타냄\n      d는 세그먼트 내에서 얼마만큼 떨어져 있는 지에 대한 정보를 나타냄\n    \n  \n  세그먼트 테이블 사용\n    \n      기준점(base)과 한계점(limit)을 가진다\n      기준점은 물리 메모리에서 그 세그먼트의 시작 위치를 나타낸다\n      한계점은 물리 메모리에서 그 세그먼트의 길이를 나타낸다\n    \n  \n  세그먼트 테이블 기준 레지스터(STBR)와 세그먼트 테이블 길이 레지스터(STLR)을 사용\n    \n      STBR은 현재 CPU에서 실행 중인 프로세스의 세그먼트 테이블이 메모리의 어느 위치에 있는지 그 시작 주소를 담고 있다\n      STLR은 그 프로세스의 주소 공간이 총 몇 개의 세그먼트로 구성되는지, 즉 세그먼트의 개수를 나타낸다\n    \n  \n\n\n\n\nSegmentation Hardware\n\n\n\n\n\n\n\n\n  논리적 주소를 물리적 주소로 변환하기 전에 두 가지 사항을 확인\n    \n      요청된 세그먼트 번호(s)가 STLR에 저장된 값보다 작은 값 인지?\n        \n          아니라면, 존재하지 않는 세그먼트에 대한 접근 시도이므로 예외 발생\n        \n      \n      논리적 주소의 오프셋(d)이 그 세그먼트의 길이(limit)보다 작은 값 인지?\n        \n          아니라면, 세그먼트 길이를 넘어서는 오프셋 위치이므로 예외 발생\n        \n      \n    \n  \n\n\n\n\nProtection\n\n\n\n\n  각 세그먼트별로 보호 비트(Protection Bit)가 있다\n    \n      보호 비트는 각 세그먼트에 대해 읽기/쓰기/실행 등의 권한이 있는지를 의미\n    \n  \n  각 세그먼트 별로 유효 비트(Valid Bit)가 있다\n    \n      유효 비트는 각 세그먼트의 주소 변환 정보가 유효한지를 의미\n      즉, 해당 세그먼트가 현재 물리 메모리에 적재되어 있는지를 의미\n    \n  \n\n\n\n\nSharing\n\n\n\n\n  여러 프로세스가 특정 세그먼트를 공유하여 사용하는 개념\n  공유 세그먼트는 이 세그먼트를 공유하는 모든 프로세스의 주소 공간에서 동일한 논리적 주소에 위치해야 함\n\n\n\n\n\n\n\n\n\n\nAllocation of Physical Memory\n\n\n\n\n\n\n\nAdvantages and Disadvantages of Segmentation\n\n\n\n\n  Advantages\n    \n      주소 공간의 일부를 공유하거나 특정 주소 공간에 읽기 전용 등의 접근 권한 제어를 하고자 할 경우, 이는 단순히 크기 단위가 아닌 어떤 의미 단위로 이루어질 때가 많음\n      이 때, 세그먼트는 의미 단위로 나누어져 있기 때문에 공유와 보안의 측면에서 페이징 기법에 비해 훨씬 효과적\n    \n  \n\n\n\n\n\n  Disadvantages\n    \n      세그먼테이션 기법에서는 프로그램을 의미 단위로 나누기 때문에 세그먼트의 길이가 균일하지 않음\n      메모리 관리에서 외부 단편화가 발생하게 되며, 연속 할당 메모리 관리의 가변 분할 방식에서의 동일한 문제점이 발생\n    \n  \n\n\n\n\nPaged Segmentation\n\n\n\n\n\n\n  페이지드 세그먼테이션 기법은 프로그램을 의미 단위의 세그먼트로 나누되, 세그먼트가 동일한 크기 페이지의 집합으로 구성 됨\n    \n      페이지드 세그먼테이션 기법에서는 하나의 세그먼트 크기를 페이지 크기의 배수가 되도록 함으로써 세그먼테이션 기법에서 발생하는 외부 조각의 문제를 해결\n      세그먼트 단위로 프로세스 간의 공유나 프로세스 내의 접근 권한 보호가 이루어지도록 함으로써 페이징 기법의 문제를 해결\n    \n  \n  주소 변환을 위해 외부의 세그먼트 테이블과 내부의 페이지 테이블, 이렇게 두 단계의 테이블을 이용\n    \n      하나의 세그먼트가 여러 개의 페이지로 구성되므로 각 세그먼트마다 페이지 테이블을 가지게 됨\n      즉, 2단계 페이지 테이블과 유사한 구조\n    \n  \n  &lt;세그먼트 번호(s), 오프셋(d)&gt;으로 구성된 논리 주소를 물리 주소로 변환하는 과정\n    \n      논리 주소의 상위 비트인 s를 통해 세그먼트 테이블의 해당 항목에 접근\n        \n          이 세그먼트 항목에는 세그먼트 길이와 그 세그먼트의 페이지 테이블 시작 주소가 포함된다\n        \n      \n      d를 세그먼트 내에서의 페이지 번호(p), 페이지 내에서의 변위(d’)로 사용하도록 분리\n      p와 d’를 이용하여 물리 메모리에 접근\n    \n  \n\n\n\n",
      "categories": ["cs","operating-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/operating-system/2022-03-10-memory-management/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "운영체제(Operating System) 8강",
      "date": "2022-03-10 00:00:00 +0000",
      "description": "반효경 교수님 - Virtual Memory\n",
      "content": "\n  Lecture\n  Virtual Memory    \n      Demand Paging\n      Page Fault        \n          Performance of Demand Paging\n        \n      \n      Page Replacement\n      Page Replacement Algorithm        \n          Optimal Algorithm\n          FIFO (First-In-First-Out)\n          LRU (Least Recently Used)\n          LFU (Least Frequently Used)\n        \n      \n      다양한 캐싱 환경        \n          페이징 시스템에서 LRU, LFU 가능한가?\n        \n      \n      Clock Algorithm\n      Page Frame Allocation\n      Global vs Local Replacement\n      Thrashing\n      Working-Set        \n          PFF (Page-Fault Frequency)\n          Page Size 결정\n        \n      \n    \n  \n\n\n\n\nLecture\n\n\n\n\n  운영체제 - 반효경 교수님\n    \n      Virtual Memory 1\n      Virtual Memory 2\n    \n  \n\n\n\n\nVirtual Memory\n\n\n\nDemand Paging\n\n\n  페이지가 실제로 필요할 때 메모리에 올리기에 다음과 같은 장점이 있다\n    \n      I/O 감소\n      메모리 사용량 감소\n      빠른 응답 시간\n      더 많은 사용자 수용\n    \n  \n  Valid/Invalid Bit\n    \n      Invalild의 의미\n        \n          사용되지 않는 주소 영역인 경우\n          페이지가 물리 메모리에 없는 경우\n        \n      \n      최초에는 모든 page entry가 Invalid로 초기화 됨\n    \n  \n\n\n\n\n\n\n\n\n\n  0, 2, 5 (A, C, F) 는 당장 필요한 부분이기 때문에,\n물리 메모리에 올라가 있고 Valid로 마킹 되어있다\n  1, 3, 4 (B, D, E) 는 논리 메모리에는 올라가 있지만 당장 사용되지 않고 있는 부분이기 때문에 Invalid로 마킹 되어있다\n  6, 7 (G, H) 같은 경우에는 페이지가 물리 메모리에 없는 상태이기 때문에,\nInvalid로 마킹 되어있다\n  Invalid Bit이 설정되어 있으면, Page Fault 인터럽트가 발생하며, 쉽게 얘기하자면 물리 메모리에 페이지가 존재하지 않으니 확인해보라는 의미이다\n\n\n\n\nPage Fault\n\n\n\n\n  Invalid Page에 접근하면 MMU가 interrupt를 발생시킨다 (page fault trap)\n  커널 모드로 전환 후 Page Fault Handler가 호출 된다\n  Page Fault 처리 순서\n    \n      Invalid 를 참조\n      빈 Page Frame을 가져오는데, 없으면 뺏어온다 (Page Replace)\n      해당 페이지를 디스크에서 메모리로 읽어온다 (swap in)\n      디스크 읽기/쓰기 작업이 끝날 때 까지 프로세스가 blocked된다\n      디스크 읽기가 끝나면 PTE(Page Table Entry)를 기록하고,\nValid/Invalid Bit을 Valid로 바꾼다.\n      Ready Queue에 프로세스를 넣는다\n      이 프로세스가 CPU를 점유하여 다시 running\n      아까 중단되었던 Instruction을 재개\n    \n  \n\n\n\n\nPerformance of Demand Paging\n\n\n\n\n  페이지 부재의 발생 빈도가 성능에 가장 큰 영향을 미친다.\n  유효 접근 시간(요청한 페이지를 참조하는 데 걸리는 시간)\n    \n      (1 - P) x 메모리 접근 시간 + P x M\n      페이지 부재 발생 비율(P) → 0 ≤ P ≤ 1\n        \n          P = 0: 페이지 부재가 한 번도 일어나지 않은 경우\n          P = 1: 모든 참조 요청에서 페이지 부재가 발생한 경우\n        \n      \n      M (각종 오버헤드)\n        \n          페이지 부재 발생 처리 오버헤드\n          메모리에 빈 프레임이 없는 경우 swap out 오버헤드\n          요창된 페이지의 swap in 오버헤드\n          프로세스의 재시작 오버헤드\n          위 오버헤드의 총합\n        \n      \n    \n  \n  쉽게 얘기하면 Page Fault가 발생했을때의 오버헤드는 매우 값 비싸다\n\n\n\n\nPage Replacement\n\n\n\n\n  Page Fault가 발생하여 요청된 페이지를 디스크에서 메모리로 읽어오려고 하는데, 물리 메모리에 빈 공간이 없을 수 있다\n  이때 이미 메모리에 올라와 있는 페이지 중 하나를 디스크로 쫓아내(swap out) 물리 메모리에 빈 공간을 확보하는데, 어떠한 페이지를 교체할지 결정하는 것을 Page Replacement라고 한다.\n\n\n\n\n\n\n\n\nPage Replacement Algorithm\n\n\n\n\n  페이지 교체를 할 때에 어떠한 프레임에 있는 페이지를 swap out 할 것인지 결정하는 알고리즘\n    \n      이 알고리즘의 목표는 페이지 부재율을 최소화하는 것\n      주어진 페이지 참조열에 대한 부재율을 계산하여 알고리즘을 평가한다\n    \n  \n\n\n\n\nOptimal Algorithm\n\n\n\n\n  물리 메모리에 존재하는 페이지 중 가장 먼 미래에 참조될 페이지를 쫓아내는 알고리즘\n  미래의 참조를 알아야 하므로 현실적으로 구현할 수 없다\n  하지만 현존하는 알고리즘 중 가장 성능이 좋으므로, 타 알고리즘과의 비교를 위해 사용된다\n  즉, 다른 알고리즘의 성능에 대한 상한선을 제공\n\n\n\n\n\n\n\n\n\n  초기 4회는 물리 메모리가 비어있으므로 불가피하게 Page Fault가 발생\n  이후 1, 2는 물리 메모리에 1, 2페이지가 있으므로 Page Fault가 발생하지 않는다\n  페이지 5는 물리 메모리에 없으므로 가장 먼 미래에 참조되는 페이지 4를 디스크로 swap out\n  반복한다\n\n\n\n\nFIFO (First-In-First-Out)\n\n\n\n\n  물리 메모리에 가장 먼저 올라온 페이지를 우선적으로 swap out한다\n  메모리가 증가하였음에도 Page Fault가 오히려 늘어나는 현상이 발생할 수 있다 (Belady’s Anomaly)\n\n\n\n\n\n\n\n\nLRU (Least Recently Used)\n\n\n\n\n  지역성 이론중, 시간적 지역성에 따른 알고리즘이다\n  최근에 참조된 것이 조만간 다시 참조될 수 있다는 것인데, 역설적으로 말하면 최근에 참조되지 않은 것은 다시 참조될 확률이 적다고 볼수도 있는 것이다\n  즉, 가장 오래 전에 참조됐던 페이지를 swap out 하는 알고리즘이다\n\n\n\n\n\n\n\n\n\n  초기 4회는 물리 메모리가 비어있으므로 불가피하게 Page Fault가 발생\n  이후 1, 2는 물리 메모리에 1, 2페이지가 있으므로 Page Fault가 발생하지 않는다\n  페이지 5는 물리 메모리에 없으므로 가장 오래 전에 참조된 페이지 3을 디스크로 swap out한다\n  반복한다\n\n\n\n\nLFU (Least Frequently Used)\n\n\n  페이지의 참조 횟수가 가장 적은 페이지를 교체하는 알고리즘\n  최저 참조 횟수인 페이지가 여러 개 있는 경우\n    \n      LFU 알고리즘 자체에서는 여러 페이지 중 임의로 선정\n      성능 향상을 위해 가장 오래 전에 참조된 페이지를 지우게 구현할 수도 있다\n    \n  \n  장점\n    \n      LRU처럼 직전 참조 시점만 보는 것이 아니라 장기적인 규모로 보기 때문에 페이지의 인기도를 조금 더 정확히 반영할 수 있다\n    \n  \n  단점\n    \n      참조 시점의 최근성을 반영하지 못한다\n      LRU보다 구현이 복잡하다\n    \n  \n\n\n\n\n다양한 캐싱 환경\n\n\n  캐싱 기법\n    \n      한정된 빠른 공간(=캐시)에 요청된 데이터를 저장해 두었다가 후속 요청시 캐시로부터 직접 서비스하는 방식\n      페이징 시스템 외에도 캐시 메모리, 버퍼 캐시, 웹 캐시 등 다양한 분야에서 사용된다\n    \n  \n  캐시 운영의 시간 제약\n    \n      교체 알고리즘에서 삭제할 항목을 결정하는 일에 지나치게 많은 시간이 걸리는 경우 실제 시스템에서 사용할 수 없다\n      버퍼 캐시나나 웹 캐시의 경우 O(1)에서 O(log N)까지 허용\n      페이징 시스템의 경우\n        \n          Page Fault의 경우에만 OS가 관여한다.\n          페이지가 이미 메모리에 존재하는 경우 참조 시각 등의 정보를 OS가 알 수 없다\n          O(1)인 LRU의 List 조작조차 불가능\n        \n      \n    \n  \n\n\n\n\n페이징 시스템에서 LRU, LFU 가능한가?\n\n\n\n\n\n\n\n\n  프로세스 A가 CPU를 잡고 실행 중인 상태라면, 프로세스 A의 논리 메모리에서 매 순간 명령어를 읽어와서 처리 할 것이다\n  이때 페이지 테이블을 통해서 논리 주소를 물리 주소로 변환 하여 물리 메모리에 있는 내용을 CPU로 읽어와야 한다\n    \n      주소 변환을 했는데 해당하는 페이지가 이미 물리 메모리에 올라와 있다면 물리 메모리를 그대로 읽는다\n      위와 같은 주소 변환 과정은 모두 하드웨어가 담당하며, OS는 일체 관여하지 않는다.\n    \n  \n  변환하려는 논리 주소의 Valid-Invalid Bit의 값이 Invalid 여서 Page Fault가 발생하였다면 Backing Store 접근을 필요로 한다\n  이때 DISK I/O를 수행해야 하므로 trap이 발동하여 interrupt가 발생하고 CPU의 제어권이 프로세스 A에서 OS로 넘어가게 된다\n  OS가 디스크의 Page Fault가 발생한 페이지를 물리 메모리로 swap in하고, 그 과정에서 물리 메모리에 빈 공간이 없다면 물리 메모리의 페이지 하나를 swap out해야 한다\n  위 일련의 과정을 수행하면서 LRU, LFU 알고리즘을 적용할 수 있을까?\n    \n      프로세스가 요청한 페이지가 메모리에 이미 있는 경우에는 CPU가 OS로 넘어가지 않는다\n      Page Fault 가 발생해야 CPU 제어권이 OS로 넘어가므로 디스크에서 메모리로 페이지가 넘어오는 시간을 파악할 수 있다\n      즉, Page Fault가 발생할 때만 페이지에 접근하는 정보를 알 수 있으므로 LRU, LFU 알고리즘은 페이징 시스템에서 사용할 수 없다\n    \n  \n\n\n\n\nClock Algorithm\n\n\n\n\n  LRU의 근사 알고리즘이다\n  여러 명칭으로 불린다\n    \n      Second Chance Algorithm\n      NUR(Not Used Recently)\n      NRU (Not Recently Used)\n    \n  \n  Reference Bit를 사용하여 교체 대상 페이지를 선정한다. (circular list)\n    \n      Reference Bit를 수정하는 작업은 OS가 아닌, 하드웨어가 수행\n      Reference Bit가 0인 것을 찾을 때까지 포인터를 하나씩 앞으로 이동\n    \n  \n  Clock Algorithm 개선\n    \n      Reference Bit와 Modified Bit(Dirty Bit)를 함께 사용한다.\n      Reference Bit가 1이면 최근에 참조된 페이지\n      Modified Bit(Dirty Bit)가 1이면 최근에 변경된 페이지 (I/O를 동반하는 페이지)\n    \n  \n\n\n\n\n\n\n\n\n\n  각 사각형은 물리 메모리에 있는 페이지 프레임을 의미\n  페이지에 대해 어떤 페이지가 참조되어 CPU가 그 페이지를 사용하게 되면, 하드웨어는 그 페이지의 Reference Bit가 1로 세팅한다\n  OS는 포인터를 이동하면서 페이지의 Reference Bit가 이미 1이면, 페이지를 swap out 하지 않고 Reference Bit를 0으로 세팅한 후 다음 페이지의 Reference Bit를 검사\n  OS는 다시 포인터를 이동하다가 Reference Bit가 0인 페이지를 찾으면, 해당 페이지를 swap out\n    \n      Reference Bit는 해당 페이지가 참조될 때 하드웨어가 1로 세팅하므로 시계 바늘이 한 바퀴 돌아오는 동안에 다시 참조되지 않은 경우 그 페이지는 교체되는 것이다\n      A라는 페이지 프레임의 Reference Bit를 0으로 바꾼 후, 다시 한 바퀴 돌아서 A 페이지 프레임의 Reference Bit가 0이면 가장 오랫동안 참조가 일어나지 않은 페이지라고 판단한다\n    \n  \n  개선 클럭 알고리즘은 Reference Bit 외에 Modified Bit를 사용\n    \n      Modified Bit는 어떤 페이지가 쫓겨날 때, 이 페이지의 Modified Bit가 0이면 Backing Store에서 물리적 메모리로 올라온 이후로 수정이 되지 않은 페이지이므로 바로 메모리에서 지워도 된다\n      Modified Bit가 1이면 물리 메모리로 올라온 이후로 수정이 발생한 페이지이므로 swap out 전에 Backing Store에 수정한 내용을 반영하고 메모리에서 지워야 한다\n      Modified Bit가 1이면 디스크로 swap out 되는 페이지의 수정된 내용을 반영하는 오버헤드가 발생하므로, 해당 페이지를 swap out하지 않고 Modified Bit를 0으로 수정한다\n    \n  \n\n\n\n\nPage Frame Allocation\n\n\n\n\n\n\n\nGlobal vs Local Replacement\n\n\n\n\n\n\n\nThrashing\n\n\n\n\n  프로세스의 원활한 수행에 필요한 최소한의 Page Frame수를 할당받지 못하면 Page Fault Rate가 크게 상승하여 CPU 이용률이 떨어지고, 낮은 처리량을 보이는 현상이다.\n  스레싱이 발생하는 시나리오\n    \n      OS는 CPU 이용률이 낮을 경우 메모리에 올라와 있는 프로세스의 수가 적다고 판단하여 메모리에 올라가는 프로세스를 늘린다\n        \n          Ready Queue에 프로세스가 단 하나라도 있으면 CPU는 그 프로세스를 실행하므로 쉬지 않고 일하게 되는데, CPU 이용률이 낮다는 것은 Ready Queue가 비어있다는 것을 의미한다\n          메모리에 올라가 있는 프로세스의 수를 Multi Programming Degree(MPD)라고 부른다\n        \n      \n      MPD가 과도하게 높아지면 각 프로세스에게 할당되는 메모리의 양이 감소한다\n      각 프로세스는 그들이 원활하게 수행되기 위해 필요한 최소한의 Page Frame도 할당 받지 못하므로 Page Fault Rate가 증가한다\n      Page Fault가 발생하면 DISK I/O를 수반하므로 다른 프로세스에게 CPU가 넘어간다\n      다른 프로세스 역시 Page Fault가 발생하고 있어서 또 다른 프로세스에게 CPU가 넘어간다\n      결국 Ready Queue에 있는 모든 프로세스에게 CPU가 한 차례씩 할당 되었는데도 모든 프로세스에 Page Fault가 발생하여 CPU의 이용률이 급격하게 떨어진다\n      OS는 위 현상이 MPD가 낮다고 판단하여 다시 MPD를 높이려고 한다\n      이러한 악순환이 계속 반복되는 상황을 스레싱이라고 부른다\n    \n  \n\n\n\n\n\n\n\n\nWorking-Set\n\n\n\n\n\n\n\n\n\n\n\nPFF (Page-Fault Frequency)\n\n\n\n\n\n\n\n\n  Page Fault Rate를 주기적으로 조사하고 이 값에 근거해서 각 프로세스에 할당할 메모리 양을 동적으로 조절하는 것\n  Page Fault Rate의 상한값과 하한값을 둔다\n    \n      Page Fault Rate의 상한값을 넘으면 페이지 프레임을 더 할당한다\n      Page Fault Rate의 하한값보다 낮으면 할당 페이지 프레임 수를 줄인다\n    \n  \n  빈 페이지 프레임이 없으면 일부 프로세스를 swap out한다\n\n\n\n\nPage Size 결정\n\n\n\n\n\n\n",
      "categories": ["cs","operating-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/operating-system/2022-03-10-virtual-memory/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "운영체제(Operating System) 9강",
      "date": "2022-03-18 00:00:00 +0000",
      "description": "반효경 교수님 - File System\n",
      "content": "\n  Lecture\n  File and File System\n  Directory and Logical Disk\n  Open()    \n      Open() 동작 과정\n    \n  \n  File Protection    \n      Mounting of File System\n    \n  \n  Access Method\n  Allocation of File Data in Disk    \n      Contiguous Allocation\n      Linked Allocation\n      Indexed Allocation\n    \n  \n  UNIX 파일시스템의 구조\n  FAT File System    \n      Free-Space Management\n      Directory Implementation\n      VFS and NFS\n      Page Cache and Buffer Cache\n      Execution of The Program        \n          Memory Mapped I/O 수행\n          read() 수행\n          Memory Mapped I/O vs read()\n        \n      \n    \n  \n\n\n\n\nLecture\n\n\n\n\n  운영체제 - 반효경 교수님\n    \n      File Systems\n      File Systems Implementation 1\n      File Systems Implementation 2\n    \n  \n\n\n\n\nFile and File System\n\n\n\n\n  파일\n    \n      이름이 있는 정보의 묶음\n      일반적으로 비휘발성인 보조 기억 장치(HDD, SSD)에 저장\n      운영체제는 다양한 저장 장치를 파일이라는 동일한 논리적 단위로 볼 수 있게 해 줌\n      연산자(커널 함수, 이느 모두 시스템 콜을 동반한다)\n        \n          create, read, write, reposition(lseek), delete, open, close 등\n          reposition(lseek): 위치를 변경 및 저장\n          open: 파일의 메타데이터를 메모리에 탑재\n        \n      \n    \n  \n  파일의 속성(메타데이터)\n    \n      파일 자체의 내용이 아니라 파일을 관리하기 위한 각종 정보\n        \n          파일의 이름, 유형, 저장된 위치, 파일 사이즈\n          접근 권한(읽기/쓰기/실행), 시간(생성/변경/사용), 소유자 등\n        \n      \n    \n  \n  파일 시스템\n    \n      운영체제에서 파일을 관리하는 부분\n      파일 및 파일의 메타데이터, 디렉토리 정보 등을 관리\n      파일의 저장 방법 결정\n      파일 보호 등\n    \n  \n\n\n\n\nDirectory and Logical Disk\n\n\n\n\n  디렉토리\n    \n      파일의 메타데이터 중 일부를 보관하고 있는 일종의 특별한 파일\n      그 디렉토리에 속한 파일 이름 및 파일의 속성\n      연산자\n        \n          search for a file, create a file, delete a file\n          list a directory, rename a file, traverse the file system\n        \n      \n    \n  \n  파티션 (=논리 디스크)\n    \n      하나의 물리 디스크 안에 여러 파티션을 두는 것이 일반적\n      여러 개의 물리 디스크를 하나의 파티션으로 구성하기도 함\n      물리 디스크를 파티션으로 구성한 뒤 각각의 파티션에 파일 시스템을 깔거나 스와핑(page 관련) 등 다른 용도로 사용할 수 있음\n    \n  \n\n\n\n\nOpen()\n\n\n\n\n\n\n\n\n  open(/a/b/c)\n    \n      디스크로부터 파일 c의 메타데이터를 메모리로 가지고 옴\n      이를 위하여 directory path를 탐색\n        \n          루트 디렉토리 / 를 open하고 그 안에서 파일 위치 a 의 위치를 획득\n          파일 a 를 open한 후 read하여 그 안에서 파일 b 의 위치를 획득\n          파일 b 를 open한 후 read하여 그 안에서 파일 c 의 위치를 획득\n          파일 c 를 open\n        \n      \n      Directory path의 탐색에 너무 많은 시간 소요\n        \n          그래서 open을 read/write와 별도로 둠\n          한 번 open한 파일은 read / write시 directory 탐색이 불필요\n        \n      \n      Open file table\n        \n          현재 open된 파일의 in memory 메타데이터 보관소\n          디스크의 메타데이터보다 몇 가지 정보가 추가됨\n            \n              open한 프로세스의 수\n              file offset: 파일 어느 위치를 접근 중인지 표시 (별도 테이블 필요)\n            \n          \n        \n      \n      File descriptor\n        \n          Open file table에 대한 위치 정보 (프로세스 별)\n        \n      \n    \n  \n\n\n\n\nOpen() 동작 과정\n\n\n\n\n\n\n\n\n  root의 위치는 고정이기 때문에 즉시 알 수 있다. 디스크에 있던 root의 메타데이터가 메모리에 올라감\n  메모리에 있는 root의 주소를 찾고, root에 존재하는 a의 메타데이터에 접근\n  a의 메타데이터를 메모리에 올림 (Open file table)\n  메모리에 있는 a의 주소를 찾고, a에 존재하는 b의 메타데이터에 접근\n  b의 메타데이터를 메모리에 올림 (Open file table)\n  메모리에 올라온 b의 메타데이터를 가르키는 포인터 값(file descriptor)를 open() 함수의 결과로 반환\n  프로세스가 open() 함수의 반환 값을 전달 받음\n  read() 함수가 호출되면, open() 호출시 반환 받은 file descriptor 값을 이용하여 b의 컨텐츠를 읽고, 읽은 컨텐츠를 디스크 버퍼 캐시에 저장\n  디스크 버퍼 캐시에 있는 b의 컨텐츠를 커널 메모리의 버퍼 캐시에 저장\n  커널 메모리 버퍼 캐시에 있는 b의 컨텐츠를 사용자 메모리의 버퍼 캐시에 저장\n\n\n\n\n\n  파일 시스템에서는 메모리때와 다르게 LRU, LFU와 같은 알고리즘을 사용한 버퍼 캐싱이 가능하다\n  메모리 관리는 하드웨어들이 직접 하였기 때문에 운영체제가 관여할 수 없었지만, 파일 시스템의 경우 시스템 콜을 통해 진행이 되기 때문에, 운영체제가 관여할 수 있는 부분이 많다\n\n\n\n\nFile Protection\n\n\n\n\n\n\n\nMounting of File System\n\n\n\n\n\n\n\n\n  각각의 파티션에 별도의 파일 시스템을 설치할 수 있다\n  한 파티션의 파일 시스템에서 다른 파티션의 파일 시스템에 접근하고 싶다면?\n\n\n\n\n\n\n\n\n\n  마운팅을 통해 서로 다른 파티션에 있는 파일 시스템에 접근할 수 있다\n\n\n\n\nAccess Method\n\n\n\n\n\n\n\nAllocation of File Data in Disk\n\n\n\n\n  모든 파일의 크기는 불규칙적이다\n  파일을 동일한 크기로 쪼개어 디스크에 sector(512byte) 단위로 저장한다\n  프로세스를 여러개의 페이지로 나눠 관리하던 메모리 관리를 떠올리면 이해가 쉽다\n  디스크에 파일 데이터를 할당하는 방식은 세가지가 존재한다\n    \n      Contiguous Allocation\n      Linked Allocation\n      Indexed Allocation\n    \n  \n\n\n\n\nContiguous Allocation\n\n\n\n하나의 파일이 디스크 sector에 연속해서 저장되는 방식\n\n\n\n\n\n\n\n\n  장점\n    \n      매우 빠른 I/O\n        \n          디스크의 처리 시간은 디스크 헤드가 디스크 트랙의 특정 sector로 이동하는데 걸리는 시간이 전부\n          파일이 연속적으로 위치하기 때문에 파일의 첫 sector에 한번만 seek/rotation하면 사실상 끝난다\n          빠른 속도로 인해 Realtime 파일 용, 혹은 프로세스의 스와핑용으로 매우 적합(공간 효율성보다 시간 효율성이 중요한 시스템)\n        \n      \n      Direct Access(Random Access)가 가능\n    \n  \n  단점\n    \n      외부 단편화 발생\n      File grow가 어려움\n        \n          파일 생성시 얼마나 큰 hole을 할당할 것인가\n          gorw 가능 vs 낭비(내부 단편화 발생)\n        \n      \n    \n  \n\n\n\n\nLinked Allocation\n\n\n\n하나의 파일이 불연속적인 디스크 sector에 나누어 저장되고, 각 sector가 하나의 노드가 되어 연결리스트 구조로 저장되는 방식\n\n\n\n\n\n\n\n\n  장점\n    \n      외부 단편화 발생 안함\n    \n  \n  단점\n    \n      연결리스트 구조상 반드시 첫 요소부터 차례대로 읽어야 하므로 Random Access 불가\n        \n          Reliability 문제\n            \n              한 sector가 고장나 다음 sector를 가리키는 포인터가 유실되면 많은 부분을 유실함\n            \n          \n          포인터를 위한 공간(4byte)이 필요하므로 공간 효율성을 떨어뜨리게 된다 (512byte/sector - 4byte/pointer = 508byte/remaining sector)\n        \n      \n      변형(Linked Allocation의 개선 버전)\n        \n          File-allocation table (FAT) 파일 시스템\n            \n              포인터를 별도의 위치에 보관하여 신뢰성 문제와 공간 효율성 문제를 해결한 시스템\n            \n          \n        \n      \n    \n  \n\n\n\n\nIndexed Allocation\n\n\n\n파일이 어디에 나눠져 있는지 인덱스를 기록 해 두는 sector(index block) 하나를 만들어 활용하는 방식\n\n\n\n\n\n\n\n\n  장점\n    \n      외부 단편화가 발생하지 않음\n      Random Access 가능\n    \n  \n  단점\n    \n      작은 파일의 경우 공간이 낭비 됨(실제로 많은 파일들이 작다)\n      매우 큰 파일의 경우 하나의 인덱스 블록이 부족할 수 있다\n        \n          Linked Scheme\n          Multi-level Index\n        \n      \n    \n  \n\n\n\n\nUNIX 파일시스템의 구조\n\n\n\n\n\n\n\n\n  Boot block\n    \n      모든 파일 시스템의 약속\n      부팅에 필요한 정보를 담고 있는 블록\n    \n  \n  Super block\n    \n      파일 시스템에 관한 총체적인 정보를 담고 있는 블록\n      빈 블록, 사용 중인 블록, Inode 블록의 위치, Data 블록의 위치 등을 알려 주는 정보 갖고 있다\n    \n  \n  Inode list (index node list)\n    \n      파일 이름을 제외한 파일의 모든 메타데이터를 따로 저장\n      파일 하나 당 Inode가 하나씩 할당되고, Inode는 파일의 메타데이터를 갖고 있다\n      파일의 이름은 디렉토리가 가지고 있으며, 디렉토리는 파일의 이름과 Inode의 인덱스를 갖고 있다.\n        \n          이전 수업에서 디렉토리가 파일의 메타데이터를 모두 가지고 있다고 했는데, 유닉스 파일 시스템의 디렉토리는 파일의 이름과 Inode의 인덱스를 가지고 있다\n        \n      \n      direct block은 파일이 존재하는 인덱스를 저장하는 인덱스 블록이다\n        \n          파일의 크기가 크지 않다면 이 블록을 이용하여 파일에 접근할 수 있다\n        \n      \n      direct block으로 커버할 수 있는 크기보다 저장 용량이 큰 파일은 single indirect를 통해서 하나의 level을 두어서 저장하는 방식을 취하고, 그보다 더 큰 파일은 double indirect, 더 큰 파일은 triple indirect 방식을 취한다\n    \n  \n  Data block\n    \n      파일의 실제 내용을 보관하는 블록\n      이 중 디렉토리 파일은 자신의 디렉토리에 속한 파일들의 이름과 Inode 인덱스를 가지고 있다\n    \n  \n\n\n\n\nFAT File System\n\n\n\n\n\n\n  FAT 파일 시스템은 윈도우즈 계열에서 주로 사용\n  파일의 메타데이터 일부를 FAT에 저장하고, 나머지 정보는 디렉토리가 가지고 있음\n  위 이미지에서 217번이 첫 번째 블록인데, 다음 블록의 위치를 FAT에 별도로 관리\n  FAT 테이블 전체를 메모리에 올려 놓았으므로 Linked Allocation의 단점(Random Access 불가, Reliability 문제, 공간 효율성 문제)을 전부 극복함\n  FAT는 중요한 정보이므로 복제본을 만들어 두어야 함\n\n\n\n\nFree-Space Management\n\n\n\n\n\n\n\nDirectory Implementation\n\n\n\n\n\n\n\n\n  파일 메타데이터의 보관 위치\n    \n      디렉토리 내에 직접 보관\n      디렉토리에는 포인터를 두고 다른 곳에 보관\n        \n          Inode, FAT 등\n        \n      \n    \n  \n  긴 파일명 지원\n    \n      &lt;파일명, 파일 메타데이터&gt;의 리스트에서 각 엔트리는 일반적으로 고정 크기\n      하지만 파일명이 고정된 엔트리 길이보다 긴 경우 마지막 엔트리 내 파일명의 뒷 부분이 위치한 곳에 포인터를 둠\n      파일명의 나머지 부분은 동일한 디렉토리 파일의 일부에 존재\n    \n  \n\n\n\n\nVFS and NFS\n\n\n\n\n\n\n\n\n\n\n\nPage Cache and Buffer Cache\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExecution of The Program\n\n\n\n\n\n\n\n\n  프로그램이 실행되면 실행 파일이 프로세스가 되며, 프로세스만의 독자적인 주소 공간이 만들어 진다.\n  이 공간은 코드, 데이터, 스택으로 구분되며 당장 사용될 부분은 물리 메모리에 올라가고, 당장 사용되지 않는 부분은 스왑 영역으로 내려간다.\n  이때 코드 부분은 이미 파일 시스템에 있기 때문에 스왑 영역에 내리지 않고, 필요 없으면 물리 메모리에서 지운다. 나중에 필요하면 파일 시스템에서 가져오면 된다.\n\n\n\n\nMemory Mapped I/O 수행\n\n\n\n\n\n\n\n\n  프로세스가 일반 데이터 파일을 I/O하고 싶을 수 있음\n  이때 mmap() 호출시 Memory Mapped I/O 방식으로 파일을 I/O 할 수 있고, mmap() 은 시스템 콜이 필요한 함수이므로 운영체제에 CPU의 제어권이 넘어감\n\n\n\n\n\n\n\n\n\n  운영체제는 데이터 파일의 일부를 프로세스 메모리에 매핑한다\n  만약 데이터 파일이 매핑영역에 접근했을 때, 물리 메모리에 페이지가 올라와 있지 않다면 Page Fault가 발생\n  그렇지 않으면 가상 메모리의 매핑영역은 물리 메모리의 페이지 프레임과 일치되므로 프로세스가 데이터 파일에 대해 I/O 를 수행 하고 싶을 때 운영체제의 도움 없이 독자적으로 할 수 있다\n  물리 메모리에 올라간 데이터 파일과 매핑된 페이지 프레임을 swap out 할 때는 스왑 영역으로 옮기는 것이 아니라 수정사항을 파일 시스템에 적용하고 물리 메모리에서 제거\n  현재 프로세스 B가 데이터 파일에 대해 Memory Mapped I/O를 수행하여 물리 메모리에 페이지 프레임을 올려 두었으므로, 프로세스 A도 이 페이지 프레임을 공유하여 사용할 수 있다\n\n\n\n\nread() 수행\n\n\n\n\n\n\n\n\n  프로세스가 일반적인 데이터 파일을 I/O 하기 위해 read() 함수를 호출할 수도 있다\n  read() 함수는 메모리의 버퍼 캐시를 확인해야 하는데, 통합 버퍼 캐시 환경에서는 페이지 캐시가 버퍼 캐시 역할을 동시에 수행한다. 따라서, Memory Mapped I/O로 올라 간 페이지 캐시를 버퍼 캐시로 사용할 수 있다\n\n\n\n\n\n\n\n\n\n  운영체제는 버퍼 캐시에 있던 데이터를 복사하여 프로세스의 주소 공간에 할당한다\n\n\n\n\nMemory Mapped I/O vs read()\n\n\n\n\n  Memory Mapped I/O\n    \n      가상 메모리에 올라온 영역이 파일이므로 시스템 콜 없이 I/O 작업을 할 수 있음\n      페이지 캐시에 있는 내용을 복사할 필요가 없음\n      여러 프로세스가 mmap() 을 사용하여 같은 영역을 공유하여 사용하면 일관성 문제가 발생할 수 있음\n    \n  \n  read()\n    \n      운영체제에 의해 제어 됨\n      페이지 캐시에 있는 내용을 복사해야 함\n      여러 프로세스가 read() 를 사용해도 일관성 문제가 발생하지 않음\n    \n  \n\n\n\n",
      "categories": ["cs","operating-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/operating-system/2022-03-18-file-system/"
    },{
      "image": "/assets/img/cs/cs-logo.jpg",
      "title": "운영체제(Operating System) 10강",
      "date": "2022-03-19 00:00:00 +0000",
      "description": "반효경 교수님 - Disk Management and Scheduling\n",
      "content": "\n  Lecture\n  Disk Management and Scheduling    \n      Disk Structure\n      Disk Management\n      Disk Scheduling        \n          FCFS (First Come First Service)\n          SSTF (Shortest Seek Time First)\n          SCAN (Elevator Algorithm)\n          C-SCAN\n          N-SCAN, LOOK, C-LOOK\n          Disk Scheduling Algorithm의 결정\n        \n      \n      Swap-Space Management\n      RAID (Redundant Array of Independent Disks)\n    \n  \n\n\n\n\nLecture\n\n\n\n\n  운영체제 - 반효경 교수님\n    \n      Disk Management and Scheduling 1\n      Disk Management and Scheduling 2\n    \n  \n\n\n\n\nDisk Management and Scheduling\n\nDisk Structure\n\n\n\n\n\n\n\n\n  Logical Block\n    \n      디스크의 외부에서 보는 디스크의 단위 정보 저장 공간\n      디스크 외부에서는 이를 주소를 가진 1차원 배열로 취급\n      디스크에 데이터가 저장될때, 디스크 I/O가 일어날때 모두 논리 블록 단위로 관리\n      디스크에 저장된 데이터에 접근하기 위해서는 해당 데이터가 저장돼있는 논리 블록의 인덱스 번호를 디스크로 전달해야 함\n      논리 블록은 가상 메모리처럼 논리적인 개념이다\n    \n  \n  Sector\n    \n      디스크의 물리적인 최소 단위\n      논리 블록과 매핑된 디스크의 물리적인 위치 (논리블록 : 섹터 = 1 : 1)\n      디스크의 물리적인 구조는 마그네틱 원판으로 구성돼있으며, 이 원판은 최소 하나 이상이다\n      각 원판은 트랙(Track)으로 구성돼있고, 각 트랙은 섹터로 구성돼있다\n      여러 개의 원판에서 상대적으로 동일한 위치의 트랙 집합을 실린더라고 부른다\n      섹터 0은 최외곽 실린더의 첫 번째 트랙의 첫 번째 섹터이다\n        \n          디스크에 데이터를 읽고 쓰기 위해서는 디스크 암(Disk Arm)이 해당 섹터가 위치한 실린더로 이동 후 원판이 회전하여 디스크 헤드가 저장된 섹터 위치에 도달해야 한다\n        \n      \n    \n  \n\n\n\n\nDisk Management\n\n\n\n\n  Physical Formatting (Low-Level Formatting)\n    \n      디스크를 컨트롤러가 읽고 쓸 수 있도록 여러개의 섹터로 나누는 과정\n      각 섹터는 header + data(보통 512 bytes) + trailer 로 구성\n      header와 trailer는 sector number, ECC(Error-Correcting Code) 등의 정보가 저장되며 컨트롤러가 직접 접근 및 운영\n    \n  \n  Partitioning\n    \n      디스크를 하나 이상의 실린더 그룹으로 나누는 과정\n      OS는 이것을 독립적인 디스크로 취급한다 (물리적인 하드디스크는 하나이지만, C드라이브, D드라이브등으로 나눌 수 있다)\n    \n  \n  Logical Formatting\n    \n      파일 시스템을 만드는 것\n      FAT, Inode, Free Space 등의 구조를 포함\n    \n  \n  Booting\n    \n      ROM에 있는 Small Bootstrap Loader를 실행\n      sector 0(boot block)을 load하여 실행\n      sector 0은 Full Bootstrap Loader Program\n      OS를 디스크에서 load하여 실행\n    \n  \n\n\n\n\nDisk Scheduling\n\n\n\n\n  디스크에 대한 접근 시간(Access Time)은 아래 세 가지 시간의 합\n    \n      탐색 시간(seek time)\n        \n          디스크 헤드를 해당 실린더 위치로 이동하는 데 걸리는 시간\n        \n      \n      회전 지연 시간(rotational latency)\n        \n          디스크가 회전해서 읽고 쓰려는 섹터가 헤드 위치에 도달하기까지 걸리는 시간\n        \n      \n      전송 시간(transfer time)\n        \n          해당 섹터가 헤드 위치에 도달한 후 데이터를 실제로 섹터에 읽고 쓰는 데 소요되는 시간\n        \n      \n    \n  \n  회전 지연 시간과 전송 시간은 상대적으로 수치가 작고 운영체제 입장에서 통제하기 힘든 부분이기에 탐색 시간을 줄이기 위해 헤드의 움직임을 최소화하는 스케쥴링 작업을 함\n  즉, 디스크 스케쥴링의 가장 중요한 목표는 디스크 헤드의 이동 거리를 줄이는 것\n\n\n\n\nFCFS (First Come First Service)\n\n\n\n\n  FCFS은 디스크에 먼저 들어온 요청을 먼저 처리하는 방식 (FIFO와 사실상 같다)\n\n\n\n\n\n\n\n\n\n  현재 디스크 헤드가 53번 실린더에 있을 경우 헤드는 53에서 출발해 98, 183, …과 같이 요청이 들어온 순서대로 이동하게 되므로 총 헤드가 이동한 거리는 640이 된다\n  FCFS는 합리적인 것처럼 보이지만 효율성은 매우 떨어진다\n  최악의 경우 디스크의 한쪽 끝과 반대쪽 끝을 왔다갔다하면 탐색 시간이 매우 길어지므로 접근 시간이 기하급수적으로 커질 수 있다\n\n\n\n\nSSTF (Shortest Seek Time First)\n\n\n\n\n  SSTF 스케쥴링은 헤드의 현재 위치로부터 가장 가까운 위치에 있는 요청을 제일 먼저 처리하는 알고리즘이다.\n\n\n\n\n\n\n\n\n\n  53번 실린더에서 출발하여 가장 가까운 65번, 그 후 65번에서 가장 가까운 67번, …을 반복하여 총 이동 거리는 236이다\n  FCFS보다 약 3배나 성능 개선이 이루어진 것을 볼 수 있다\n  그러나 SSTF는 Starvation(기아) 문제를 초래할 수 있다\n    \n      현재의 헤드 위치 근방으로 무한히 요청이 들어오면, 헤드 위치에서 멀리 있는 요청은 영원히 기다려야 할 수도 있다\n    \n  \n\n\n\n\nSCAN (Elevator Algorithm)\n\n\n\n\n\n\n\n\n  SCAN은 헤드가 디스크 원판의 안쪽 끝과 바깥쪽 끝을 오가며, 그 경로에 존재하는 모든 요청을 처리하는 것\n  즉, 디스크의 어떠한 위치에 요청이 들어오는 가와 상관 없이 헤드는 정해진 방향으로 이동하면서 길목에 있는 요청을 처리하며 지나감\n  문제점: 실린더 위치에 따라 대기 시간이 다름\n    \n      제일 안쪽이나 제일 바깥쪽 위치보다는 가운데 위치가 평균 대기 시간이 짧다\n      예를 들어 0번에서 199번까지 200개의 실린더를 가진 디스크의 경우 0번 실린더나 199번 실린더를 막 지나가고 나서 해당 지점에 요청이 들어왔다면 반대쪽 끝까지 헤드가 갔다 와야 하므로 이동 거리 400만큼 대기해야 하지만, 100번 실린더를 막 지나가고 나서 해당 지점에 요청이 들어왔다면 대기해야 하는 이동 거리가 200에 불과함\n    \n  \n\n\n\n\n\n\n\n\nC-SCAN\n\n\n\n\n\n\n\n\n  C-SCAN은 SCAN처럼 헤드가 한쪽 끝에서 다른 쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리\n  하지만 SCAN과 달리 헤드가 다른 족 끝에 도달해 방향을 바꾼 후에는 요청을 처리하지 않고 곧바로 출발점으로 다시 이동\n  SCAN 알고리즘보다 균일한 대기 시간을 제공\n\n\n\n\n\n\n\n\n\n  헤드가 53번 실린더에서 출발하여 199번 실린더까지 이동하며 중간에 있는 요청을 처리\n  헤드가 199번 실린더에 도달하면 0번 다시 실린더로 이동하는데, 이때는 중간에 있는 요청을 처리하지 않음\n  이후 0번 실린더에서 다시 199번 실린더로 이동하면서 중간에 있는 요청을 처리\n  총 이동 거리는 383\n\n\n\n\nN-SCAN, LOOK, C-LOOK\n\n\n\n\n  N-SCAN 알고리즘\n    \n      SCAN의 변형 알고리즘\n      일단 헤드가 한 방향으로 움직이기 시작하면 그 시점 이후에 도착한 요청은 되돌아올 때 처리\n    \n  \n  LOOK, C-LOOK 알고리즘\n    \n      SCAN이나 C-SCAN은 헤드가 디스크 끝에서 끝으로 이동\n      LOOK과 C-LOOK은 헤드가 이동 중 그 방향에 더 이상 기다리는 요청이 없으면 헤드의 이동 방향을 즉시 반전시킴\n    \n  \n\n\n\n\n\n\n\n\nDisk Scheduling Algorithm의 결정\n\n\n\n\n  SCAN, C-SCAN 및 그 응용 알고리즘은 LOOK, C-LOOK 등이 일반적으로 디스크 입출력이 많은 시스템에서 효율적인 것으로 알려져 있음\n  현대 컴퓨팅 시스템에서는 SCAN 기반의 알고리즘들을 많이 사용하고 있음\n    \n      디스크 헤드의 이동거리를 줄일 수 있는것이 가장 큰 이유\n    \n  \n  File의 할당 방법에 따라 디스크 요청이 영향을 받음\n    \n      연속 할당을 했다면 연속된 실린더 위치에 존재하기 때문에 헤드의 이동거리를 줄일 수 있음\n      불연속 할당을 했다면 헤드의 이동거리가 상대적으로 증가할 수 있음\n    \n  \n  디스크 스케쥴링 알고리즘은 필요할 경우 다른 알고리즘으로 쉽게 교체할 수 있도록 OS와 별도의 모듈로 작성되는 것이 바람직\n    \n      디스크 스케쥴링의 효율을 결정짓는 변인이 많기 때문에, 디스크 스케쥴링 알고리즘을 쉽게 변경할 수 있어야 한다\n    \n  \n\n\n\n\nSwap-Space Management\n\n\n\n\n\n\n\n\n  디스크를 사용하는 이유는 메모리의 제약적인 성질때문이다\n    \n      메모리의 휘발성을 비휘발성인 파일 시스템으로 해결\n      메모리의 단가가 비싸기 때문에 프로그램 실행을 위한 메모리 공간은 항상 부족\n      메모리 공간 부족을 디스크를 활용한 Swap space로 해결\n    \n  \n  Swap-Space\n    \n      가상 메모리 시스템에서 디스크를 메모리의 연장 공간으로 사용\n      파일 시스템 내부에 둘 수도 있으나 별도 파티션을 사용하는 것이 일반적\n        \n          공간 효율성보다는 속도 효율성이 우선\n            \n              공간 효율성이 덜 중요한 이유는, 어차피 시간이 조금 지나 프로세스가 종료되면 사라질 내용들이기 때문\n            \n          \n          일반 파일보다 훨씬 짧은 시간만 존재하고 자주 참조됨\n          따라서 블록의 크기 및 저장 방식이 일반 파일 시스템과 다름\n        \n      \n    \n  \n\n\n\n\nRAID (Redundant Array of Independent Disks)\n\n\n\n\n\n\n\n\n  RAID는 여러 개의 디스크(특히 저렴한)를 묶어서 사용하는 것\n  RAID의 사용 목적\n    \n      디스크 처리 속도 향상\n        \n          여러 디스크에다 블록의 내용들을 분산 저장\n          병렬적으로 읽어올 수 있음 (interleaving 혹은 striping)\n        \n      \n      신뢰성(Reliability) 향상\n        \n          동일 정보를 여러 디스크에 중복 저장\n          하나의 디스크가 고장나도 다른 디스크에서 읽어올 수 있음 (mirroring 혹은 shadowing)\n          단순한 중복 저장이 아니라 일부 디스크에 parity(오류 검출 코드)를 저장하여 공간의 효율성을 높일 수도 있음\n        \n      \n    \n  \n\n\n\n",
      "categories": ["cs","operating-system"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/operating-system/2022-03-19-disk-management/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "자바와 코틀린에 대한 생각 정리",
      "date": "2022-03-27 00:00:00 +0000",
      "description": "미래를 대비하자. 항상 그래왔듯이…\n",
      "content": "\n  Java vs. Kotlin\n\n\n\n\nJava vs. Kotlin\n\n\n\n최근 코틀린에 대해 많은 관심이 생겨 문법도 보고, 이런저런 책도 보고, 코딩도 해보는 시간을 2주가량 가졌는데, 일단 굉장히 주관적인 생각이지만 결론부터 말하자면 코틀린이 자바에 비해 모든 부분에서 우세하지 않나 싶다.\n\n간결함, 확장성, Null Safety, 코루틴 등…\n\n자바로 할 수 있는 모든 것을 코틀린으로 할 수 있으면서도 자바로 하기 힘든 것들을 오히려 코틀린으로 더욱 쉽게 할 수 있는, 그러니까 코틀린은 자바의 슈퍼셋이다.\n\n한마디로 코틀린에 익숙하다면 굳이 자바를 사용해야 하느냐? 라는 의심마저 들 언어라는 생각이 들었다.\n\n\n\n이제 코틀린을 맛만 본 셈이지만 익숙하지 않은걸 한다는게 역시 굉장히 어렵다.\n\n무엇보다 프로그래밍 패러다임의 변화에 따른 사고방식 전환에서 엄청난 어려움을 겪는 것 같다.\n\n예를 들어 최근 카타를 하고있는 코틀린으로 RPG만들기 같은 경우, 플레이어가 물약을 사용하는 메서드가 있는데, 자바였다면 이 메서드가 호출될 때 물약이 없다면 IllegalStateException 같은 예외를 던졌을 것이다.\n\n하지만 함수형 프로그래밍에서는 함수에서 예외가 발생하면 해당 함수가 순수함수가 아니게 되기 때문에, 모나드 연산을 통한 여러 값을 리턴하게 되는 것 같은데, 이 때 물약이 없다면 물약을 먹지 않은 플레이어가 리턴될 것이고, 물약이 있었다면 물약을 먹은 플레이어가 리턴될 것이다.\n\n그렇다면 클라이언트는 해당 플레이어가 물약을 먹었는지 먹지 않았는지를 어떻게 판단해야 하는가?\n\n이러한 고민들로 인해 흐름이 자꾸 끊겨, 사실 코딩이 쭉쭉 이어지지는 않고 있다.\n\n결국 내 함수형 프로그래밍에 대한 이해도가 개세적인 수준이기 때문인 셈이다. 🤣\n\n코틀린도 객체지향적으로 사용하면 별 문제없겠지만, 사실 함수형도 맛깔나게 써볼 수 있는 언어를 공부 해보는데 함수형을 해보지 않는다는것도 말이 안되지 않는가?\n\n아무튼 이 사고전환의 어려움으로 인해 자바와 객체지향에 너무 깊게 심취한 나머지 내 개발 스타일이 갈라파고스화된 느낌이 없지 않아 있다는 자각을 하게 된 계기가 되기도 했다.\n\n\n\n자바는 하위호환성을 굉장히 잘 지켜주는 언어이다.\n\n별도로 JVM 튜닝을 빡세게 한게 아니고서야 당장 자바8로 작성된 프로그램을 자바17로 변경하여 돌려도 별 무리없이 돌아갈거라 장담할 수 있을 정도다.\n\n자바 진영의 하위호환성에 대한 집착은 나도 굉장히 좋게 생각하는 부분이지만(A/B테스트 마냥 올려버린 파이썬2와 3의 선례를 생각하면…), 이렇게 하위호환성에 집착한 나머지 자바는 성장 동력을 잃어버렸다는 생각도 든다.\n\n\n\n코틀린은 이러한 자바와의 상호호환성을 100% 보장해주며, 자바에 더 이상 도입하기 힘든 피쳐들을 도입할 수 있게 해준다.\n\n그러면서도 코틀린은 자바와의 상호호환성에 굉장히 집착한다고도 느꼈다.\n\n아무리 편리한 기능이라도 자바와의 상호호환성을 보장할 수 없다면 도입하지 않는?\n\n이는 아마 코틀린을 창조해낸 JetBrains의 상황 때문인 것 같은데, 이미 JetBrains가 상업용으로 판매하고 있는 소프트웨어들은 자바를 마개조하다시피 해서 사용하고 있는데, 이것이 한계에 부딪혀 코틀린이라는 이름의, 일종의 모던 자바를 만들어낸 셈이다.\n\n즉, 자바와의 상호호환성이 보장되지 않는다면, JetBrains는 자신들의 비즈니스에도 어느정도 타격을 입을 수 밖에 없을 것 같다.\n\n\n\n내가 코틀린에 관심을 가지게 된 계기는, 코틀린에 대해 잘 알지 못하던 시절에도 이미 자바 LTS가 계속해서 릴리즈되며 여러 모던 언어들의 피쳐들을 도입하고 있다는걸 알고는 있었고, 특히 이번 LTS인 자바17에서는 거의 자바8에 준하는 굉장히 큰 변화가 일어났는데, 그중에서도 대부분의 변화들이 코틀린의 피쳐를 차용해와 생긴 부분임을 알았기 때문이다.\n\n자바17을 공부하고 사용하게 되며 자연스럽게 코틀린에도 많은 관심이 가게 됐고, 자바 진영의 이러한 기조와 업계 여러 회사들의 현황, 자바와 코틀린의 상호호환성을 볼 때 근 5년 내, 길어야 10년 내에 코틀린이 국내에서 굉장히 큰 파이를 가져갈 것이라는 확신도 생겼다.\n\n\n\n국내의 고연차 개발자분들(대략 20년차 까지도?)은 사실상 자바 하나로 평생을 먹고살았다 봐도 무방할 정도라고 생각된다.\n\n하지만 우리 세대 개발자들은 어떨까?\n\n최근 100년의 변화가 지난 수천년의 변화보다 더욱 눈부신 인류의 역사에 대비해 생각해볼 때 개발 업계도 이와 크게 다르지 않을 것 같다는 생각이 든다.\n\n미친듯이 급변하는 업계에 발맞춰 살아남기 위해서는 보다 근본적인, 보다 더 로우 레벨의 컴퓨터과학 지식에 시간과 노력을 투자해, 그 어떤 변화가 일어나도 그것들을 쉽게 수용해낼 수 있는 기반을 다져야 하며, 그 와중에도 업계가 어떤 방향으로 향하는지 계속해서 추이를 살펴야만 한다.\n\n\n\n시스템이 발달하며 데이터는 미친듯이 불어나고 있는데 반해, 하드웨어는 더이상 과거처럼 눈부시게 발전하기 어렵다. 무어의 법칙은 이제 옛말이다.\n\n이 막대한 데이터를 처리해내기 위해서는 우리에게 허락된 하드웨어 성능을 최대한 효율적으로 사용해내야 하며, 현 시점 이에 대한 답은 병렬 프로세싱이다.\n\n그리고 이러한 병렬 프로세싱을 잘 활용하기 위해서는 부수효과가 없는 함수형 프로그래밍이 제격이다.\n\n그러니 현 세대 개발자인 나는 시대의 흐름에 맞춰 함수형 프로그래밍에도 시간을 투자해야만 하고, 특히 자바 개발자인 나에게 코틀린은 이 미션을 수행하기 위한 좋은 수단이 된다.\n\n\n\n자연스레 코틀린을 트래킹해야 한다는 생각이 들었다.\n\n\n\n하지만 그러면서도 나는 자바를 자바스럽게 사용하는데에만 1년이 넘게 걸렸고, 아직도 잘 못한다고 생각하기 때문에 새로운 언어를 배운다는게 굉장히 막막하게 느껴진다.\n\n자바를 어떻게 써야 자바스럽게 쓸 수 있는지, 자바의 SDK에는 어떤것들이 존재하는지, 자바의 코드가 어떤 instruction set으로 변환되는지, 자바는 어떤 원리로 돌아가는지, JVM은 대략적으로 어떻게 생겨먹었고 어떻게 돌아가는지 등에 관심을 가져왔고, 아직도 이러한 주제들에 대해 제대로 알지 못한다는 생각을 하곤 한다.\n\n이런 상황에 다른 언어에 눈을 돌린다?\n\n당연히 다른 언어를 공부하며 새롭게 깨달아가는 것도 있겠지만, 아무튼 막막한건 막막한거다.\n\n자바에 쏟아부은 시간과 노력, 그 이상을 코틀린에 또 쏟아부어야 하는 것이기 때문에…\n\n비유하자면, 예전에 getting over it 이라는 이름의 게임이 하나 있었는데, 이것과 굉장히 비슷하다.\n\n어떤 아저씨가 항아리에 하반신이 갇힌 채, 오함마 하나로 벽을 타고 올라가는 게임인데, 어디서 추락하건 한번 추락하면 사실상 처음부터 다시 시작해야 한다.\n\n물론 1회차보다 2회차가 더 쉽기는 하겠다만… 그럼에도 불구하고, 종류를 막론하고 처음부터 다시 시작한다는 것은 굉장히 힘든 일임에 틀림없다.\n\n\n\n언어하나 새로 배우는게 뭐가 어렵냐? 라고 생각할수도 있다.\n\n\n\n결국 이 아젠다에 대한 견해는 사바사일 것 같은데, 어차피 언어의 문법이야 길어야 한두시간정도면 다 배우는 것인데, 나는 고작 이정도 했다고 새로운 언어를 배웠다고 생각하지는 않는다.\n\n내가 생각하는 문제는 그 언어의 철학, 그 이면의 동작원리, 그 언어를 그 언어스럽게 사용하는 것 등인데, 이것들은 결국 굉장히 많은 시간과 노력을 들여야만 체득되는 것이라는 생각을 갖고 있기 때문이다.\n\nC언어만 해도 기능도 별거 없고 문법은 아주 쉽지만, C언어를 잘 활용하기 위한 이런저런 트릭들이 많은걸로 알고 있다.\n\n즉, 새로운 언어 하나를 배운다는 것은 생각보다 많은 시간과 노력이 담보 되어야만 하는, 어렵고 고단한 일이다.\n\n\n\n아무튼 징징대는건 이쯤하고, 미래를 보자면 나는 이걸 해야만 하기는 한다.\n\n위에 말한 게임과 관련된 관용어로 get over it이라는 게 있는데, 불평 그만하고 상황을 받아들이라는 뜻을 가졌다. (이 또한 지나가리~~~)\n\n정확하게 내 상황과 일치하는데, 그나마 코틀린은 자바 개발자에게 아주 좋고 훌륭하고 상대적으로 쉬운 언어이기도 하니 다행이다 싶기도 하다.\n\n\n\n열심히 하자.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-03-27-diary-38/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "개발 포기 !",
      "date": "2022-03-30 00:00:00 +0000",
      "description": "세상만사 쉬운게 하나도 없다\n",
      "content": "\n  뭘 포기하는데?    \n      그래서 ?\n    \n  \n  📕 Reference\n\n\n\n\n뭘 포기하는데?\n\n\n\nJPA에서 DB 테이블과 매핑하기 위해 사용하는 엔티티는 접근제한자가 private이 아닌 기본 생성자가 반드시 필요하다.\n\n그저께 엔티티에 무지성으로(그리고 기계적으로) @NoArgsConstructor를 살포하고 있다가, @Entity를 감지하면 접근제한자가 protected 인 기본 생성자를 자동으로 만들어주는 도구를 만들어 보면 어떨까? 그럼 @NoArgsConstructor 안 써도 되니까 이거 완전 개꿀인 부분 아닌가? 하는 생각이 문득 들었다.\n\n\n\n그리고 그렇다면 이것을 어떻게 만들것인지 곰곰이 생각을 또 해보니 \"이거 그냥 @Entity 감지해서 기본생성자 하나 달아주면 끝이네? 개 쉽네?\" 라고 생각하고 바로 작업에 착수했다.\n\n당시 내가 고려해야 할 사항은 다음과 같이 단순했다.\n\n\n\n\n  컴파일 타임에 매개변수가 없는 기본 생성자를 추가해주면 된다\n    \n      프록시 기반의, 런타임에 바이트 코드를 조작하는 방식들(ASM, Byte Buddy 등)은 사용할 수 없다\n      그럼 annotation processor를 사용하면 되겠다\n    \n  \n\n\n\n\n\n\n\n\n이후 MVP를 만들어 로컬 저장소에 배포해서 돌려보니 이게 웬걸?\n\n이상한 예외가 발생했다.\n\n예외 메시지를 천천히 살펴보니 annotation processor는 새로운 .class파일은 만들수 있지만, 기존에 존재하는 .class파일을 수정 할 수는 없다는 것 같았다.\n\n바로 현실부정에 들어가며 스펙들을 찾아보기 시작했는데…\n\n\n\n\n  During each run of an annotation processing tool, a file with a given pathname may be created only once. If that file already exists before the first attempt to create it, the old contents will be deleted. Any subsequent attempt to create the same file during a run will throw a FilerException, as will attempting to create both a class file and source file for the same type name or same package name. The initial inputs to the tool are considered to be created by the zeroth round; therefore, attempting to create a source or class file corresponding to one of those inputs will result in a FilerException.\n\n  annotation processor를 실행할 때마다 지정된 경로명을 가진 파일은 단 한 번만 생성될 수 있습니다. 파일을 처음 생성하기 전 해당 파일이 이미 존재하는 경우 이전 내용이 삭제됩니다. 이후 실행 중에 동일한 파일을 생성하려고 하면 FilerException이 발생합니다. 이는 동일한 타입 이름 또는 동일한 패키지 이름에 대한 클래스 파일과 소스 파일을 모두 생성하려고 시도하는 것이기 때문입니다. 툴에 대한 초기 입력은 0번째 라운드에서 생성된 것으로 간주됩니다. 따라서 이러한 입력 중 하나에 해당하는 소스 또는 클래스 파일을 만들려고 하면 FilerException이 발생합니다.\n\n\n\n\n진짜 그렇다.\n\n\n\n\n\n\n\n바로 의문이 들었는데, 그럼 롬복(Lombok)은 대체 이걸 어떻게 하는거지?\n\n당장 롬복 깃허브에 들어가 프로젝트를 로컬 머신에 클론하고, 소스코드를 살펴보기 시작했다.\n\n이윽고 어이가 없어져버렸는데, 롬복은 무려 자바 컴파일러를 해킹하고 있었다.\n\n\n\n\n\n\n\n자바 컴파일러가 자바 코드를 구문분석해 이를 트리구조로 만들어 관리하는데, 이를 추상 구문 트리(AST, Abstract Syntax Tree) 라고 부르는 듯 했다. (JCTree가 AST의 루트 노드라는데, 이 녀석 이름 뜻은 Java Code Tree인가? 🤔)\n\n관련 자료들을 좀 둘러보다 보니 eslint같은 정적 코드 분석 도구들이 돌아가는 방식도 이와 비슷한 원리로 추측되었다.\n\n\n\n아무튼 뭐가 문제냐면, 이 AST를 조작하는 API가 정식적인 공개 API가 아니고, 비공개 API 라는 것이다.\n\n한마디로 이것들은 자바팀에서 사용하지 말라고 숨겨놓은 것들인데, 롬복은 이를 리플렉션을 통해 강제로 끄집어내 사용하고 있었다. (tools.jar, com.sun.tools 패키지의…)\n\n그리고 getter, setter등의 노드를 만들어 AST에 append하는 방식으로 돌아가는 듯 했다.\n\n그런데 공개 API는 외부에 직접적으로 노출되는 인터페이스이기 때문에 하위호환성을 위해 변경되지 않는게 원칙이지만, 비공개 API들은 세부 구현이기 때문에 언제든지 변경될 수 있다는게 문제다.\n\n즉, 롬복은(그리고 내가 하려던 짓은) 이 언제든지 변경될 수 있는 비공개 API들을 어거지로 끌어다 사용하고 있기 때문에, 자바의 세부 구현에 직접적으로 영향을 받고 있는 셈이었다.\n\n초창기의 롬복이 굉장히 불안정하고, 호환성이 좋지 않았던 이유가 이와 관련되지 않았을까?\n\n\n\n그래서 ?\n\n\n\n일단 컴파일러와 AST에 대한 내 이해도도 처참한 수준이라, 내게는 구현 난이도부터 매우 높거니와(넘사벽) 어찌어찌 맨땅에 헤딩해가며 구현을 했다 하더라도 자바의 세부 구현이 변경 될 때마다 같이 유지보수를 해야 한다는 생각이 드니, 도저히 이걸 더 진행하지 못하겠다는 생각이 들었다.\n\n나중에 자바가 계속 개선되어 AST를 조작할 수 있는 정식적인 API가 나오게 된다면 그 때 다시 천천히 공부를 해 봐야겠다.\n\n\n\n그리고 사실 롬복이 별거 아닌 줄 알았다.\n\n나는 \"그까이꺼 그냥 annotation processor 몇개 구현하면 되는거 아니야?\" 라는 무식한 생각을 갖고 있었다. (무지에서 나오는 용기…)\n\n근데 코드를 뜯어보고 원리를 파헤쳐보니 정말 자바로 할 수 있는 최고 수준의 프로젝트가 아닌가 ?\n\n\n\n암튼 세상만사 쉬운거 하나 없다.\n\n그래도 이번 삽질에 annotation processor로 어디까지 할 수 있고, 어디까지 할 수 없는지 등 생각보다 많은 걸 배운 것 같기도 하다.\n\n\n\n\n\n\n\n📕 Reference\n\n\n\n\n  📜 javadocs javax.annotation.processing.Processor\n  📜 javadocs javax.annotation.processing.Filer\n  📜 Baeldung - Java Annotation Processing and Creating a Builder\n  📜 Stackoverflow - Can I add a method to a class from a compile time annotation?\n  📜 Reducing Boilerplate Code with Project Lombok\n  📦 projectlombok/lombok\n  📜 Lombok principle and Implementation\n\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-03-30-diary-39/"
    },{
      "image": "/assets/img/spring/spring-security/security-logo.png",
      "title": "antMatchers vs. mvcMatchers",
      "date": "2022-03-31 00:00:00 +0000",
      "description": "CVE-2016-5007\n",
      "content": "\n  CVE-2016-5007    \n      방법 1. URI에 와일드카드를 붙인다\n      방법 2. mvcMatchers를 사용한다\n    \n  \n  📕 Reference\n\n\n\n\nCVE-2016-5007\n\n\n\n\n  Both Spring Security 3.2.x, 4.0.x, 4.1.0 and the Spring Framework 3.2.x, 4.0.x, 4.1.x, 4.2.x rely on URL pattern mappings for authorization and for mapping requests to controllers respectively. Differences in the strictness of the pattern matching mechanisms, for example with regards to space trimming in path segments, can lead Spring Security to not recognize certain paths as not protected that are in fact mapped to Spring MVC controllers that should be protected. The problem is compounded by the fact that the Spring Framework provides richer features with regards to pattern matching as well as by the fact that pattern matching in each Spring Security and the Spring Framework can easily be customized creating additional differences.\n\n\n\n\n업계에서 흔히 RESTful이라고 부르는 API 설계 방식에서는 슬래시(/)를 통해 리소스 구조를 표현한다.\n\n흔히 볼 수 있는 방식인데, 리눅스의 파일 시스템도 이와 같은 방식으로 구분을 하고 있다.\n\n궁금하다면, 터미널에서 pwd를 입력해보자.\n\n아무튼, URI에서 슬래시는 이렇게 특별한 역할을 하고 있기 때문에, 이를 URI 맨 뒤쪽에 넣는다면 혼동이 생길 수 있다.\n\n위와 같은 이유로 스프링 시큐리티에서 기본적으로 사용하는 antMatchers는 URI 맨 뒤에 슬래시가 붙어있다면, 이를 제대로 검증하지 못한다.\n\n이게 무슨 말이냐면, 코드로 보자.\n\n\n\n@EnableWebSecurity\npublic class SecurityConfiguration extends WebSecurityConfigurerAdapter {\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http.httpBasic().disable()\n            .csrf().disable()\n                \n            // 블랙리스트 방식\n            .authorizeRequests()\n            .antMatchers(GET, \"/v1/api/members\").authenticated()\n            .anyRequest().permitAll();\n    }\n}\n\n\n\n\n/v1/api/members로 오는 GET 방식의 요청은 인증된 상태여야만 허용되게끔 설정돼있다.\n\n이 상태에서 다음과 같은 요청을 보내보았다.\n\n\n\n@SpringBootTest\n@AutoConfigureMockMvc\nclass DemoApplicationTests {\n    @Autowired\n    MockMvc mockMvc;\n\n    @Test\n    void contextLoads() throws Exception {\n        mockMvc.perform(get(\"/v1/api/members/\"))\n            .andDo(print());\n    }\n}\n\n\n\n\n보다시피 요청 URI 맨 뒤에 슬래시를 하나 더 붙여버렸다.\n\n실행하면 403이 응답될까? 아닐까?\n\n\n\nMockHttpServletRequest:\n      HTTP Method = GET\n      Request URI = /v1/api/members/\n       Parameters = {}\n          Headers = []\n             Body = null\n    Session Attrs = {}\n\nHandler:\n             Type = me.siro.demo.MemberController\n           Method = me.siro.demo.MemberController#members()\n\nAsync:\n    Async started = false\n     Async result = null\n\nResolved Exception:\n             Type = null\n\nModelAndView:\n        View name = null\n             View = null\n            Model = null\n\nFlashMap:\n       Attributes = null\n\nMockHttpServletResponse:\n           Status = 200\n    Error message = null\n          Headers = [Content-Type:\"application/json\", X-Content-Type-Options:\"nosniff\", X-XSS-Protection:\"1; mode=block\", Cache-Control:\"no-cache, no-store, max-age=0, must-revalidate\", Pragma:\"no-cache\", Expires:\"0\", X-Frame-Options:\"DENY\"]\n     Content type = application/json\n             Body = [{\"name\":\"Liam\"},{\"name\":\"\\tNoah\"},{\"name\":\"\\tOliver\"},{\"name\":\"\\tElijah\"},{\"name\":\"\\tWilliam\"},{\"name\":\"\\tJames\"},{\"name\":\"\\tBenjamin\"},{\"name\":\"\\tLucas\"},{\"name\":\"\\tHenry\"},{\"name\":\"\\tAlexander\"},{\"name\":\"Olivia\"},{\"name\":\"Emma\"},{\"name\":\"Ava\"},{\"name\":\"Charlotte\"},{\"name\":\"Sophia\"},{\"name\":\"Amelia\"},{\"name\":\"Isabella\"},{\"name\":\"Mia\"},{\"name\":\"Evelyn\"},{\"name\":\"Harper\"}]\n    Forwarded URL = null\n   Redirected URL = null\n          Cookies = []\n\n\n\n\n놀랍게도 403이 아닌 200이 응답됐으며, 모든 사용자의 정보가 외부에 노출되어버렸다.\n\n이처럼 모든 엔드포인트를 허용 상태로 두고 몇몇 엔드포인트만 콕 집어서 인증필요 상태로 관리하는 방식을 블랙리스트 방식이라고 부르는데, 이는 스프링 시큐리티에서 권장하는 방식이 아니다.\n\n스프링 시큐리티에서는 모든 엔드포인트를 인증필요 상태로 관리하고, 몇몇 엔드포인트만 콕 집어서 허용 상태로 관리하는 화이트리스트 방식을 권장하고 있다.\n\n즉, 화이트리스트 방식으로 코드를 작성했다면 일단 위와 같은 취약점이 생기지는 않는다.\n\n\n\n@EnableWebSecurity\npublic class SecurityConfiguration extends WebSecurityConfigurerAdapter {\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http.httpBasic().disable()\n            .csrf().disable()\n                \n            // 화이트리스트 방식\n            .authorizeRequests()\n            .antMatchers(POST, \"/v1/api/members\").permitAll()\n            .anyRequest().authenticated();\n    }\n}\n\n\n\n\n하지만, 업무규칙으로 인해 블랙리스트 방식으로 코드를 작성해야만 하는 경우도 있을것이다.\n\n그리고 그런 상황에 위와 같은 정보를 알지 못한다면, 보다시피 보안 취약점이 생길 여지가 분명히 존재한다.\n\n이러한 상황에 대처하기 위해 두가지 방법이 존재한다.\n\n\n\n방법 1. URI에 와일드카드를 붙인다\n\n\n\n@EnableWebSecurity\npublic class SecurityConfiguration extends WebSecurityConfigurerAdapter {\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http.httpBasic().disable()\n            .csrf().disable()\n            .authorizeRequests()\n            .antMatchers(GET, \"/v1/api/members/**\").authenticated()\n//                                            ^^^ - 와일드카드 추가\n            .anyRequest().permitAll();\n    }\n}\n\n\n\n\nURI 맨 뒤에 /**를 추가했다.\n\n이렇게 하면 antMatchers로도 위와 같은 보안 취약점이 발생하지 않는다.\n\n\n\nMockHttpServletRequest:\n      HTTP Method = GET\n      Request URI = /v1/api/members/\n       Parameters = {}\n          Headers = []\n             Body = null\n    Session Attrs = {SPRING_SECURITY_SAVED_REQUEST=DefaultSavedRequest [http://localhost/v1/api/members/]}\n\nHandler:\n             Type = null\n\nAsync:\n    Async started = false\n     Async result = null\n\nResolved Exception:\n             Type = null\n\nModelAndView:\n        View name = null\n             View = null\n            Model = null\n\nFlashMap:\n       Attributes = null\n\nMockHttpServletResponse:\n           Status = 403\n    Error message = Access Denied\n          Headers = [X-Content-Type-Options:\"nosniff\", X-XSS-Protection:\"1; mode=block\", Cache-Control:\"no-cache, no-store, max-age=0, must-revalidate\", Pragma:\"no-cache\", Expires:\"0\", X-Frame-Options:\"DENY\"]\n     Content type = null\n             Body = \n    Forwarded URL = null\n   Redirected URL = null\n          Cookies = []\n\n\n\n\n요청 URI 맨 뒤에 슬래시를 추가하여 요청했음에도 403과 함께 요청이 디나이 된 모습을 볼 수 있다.\n\n\n\n방법 2. mvcMatchers를 사용한다\n\n\n\n@EnableWebSecurity\npublic class SecurityConfiguration extends WebSecurityConfigurerAdapter {\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http.httpBasic().disable()\n            .csrf().disable()\n            .authorizeRequests()\n            .mvcMatchers(GET, \"/v1/api/members\").authenticated()\n//           ^^^^^^^^^^^ - antMatchers 대체\n            .anyRequest().permitAll();\n    }\n}\n\n\n\n\nMockHttpServletRequest:\n      HTTP Method = GET\n      Request URI = /v1/api/members/\n       Parameters = {}\n          Headers = []\n             Body = null\n    Session Attrs = {SPRING_SECURITY_SAVED_REQUEST=DefaultSavedRequest [http://localhost/v1/api/members/]}\n\nHandler:\n             Type = null\n\nAsync:\n    Async started = false\n     Async result = null\n\nResolved Exception:\n             Type = null\n\nModelAndView:\n        View name = null\n             View = null\n            Model = null\n\nFlashMap:\n       Attributes = null\n\nMockHttpServletResponse:\n           Status = 403\n    Error message = Access Denied\n          Headers = [X-Content-Type-Options:\"nosniff\", X-XSS-Protection:\"1; mode=block\", Cache-Control:\"no-cache, no-store, max-age=0, must-revalidate\", Pragma:\"no-cache\", Expires:\"0\", X-Frame-Options:\"DENY\"]\n     Content type = null\n             Body = \n    Forwarded URL = null\n   Redirected URL = null\n          Cookies = []\n\n\n\n\n역시 마찬가지로 요청 URI 맨 뒤에 슬래시를 추가하여 요청했음에도 403과 함께 요청이 디나이 된 모습을 볼 수 있다.\n\n\n\n📕 Reference\n\n\n\n\n  📜 CVE-2016-5007\n  📜 Stackoverflow - Difference between antMatcher and mvcMatcher\n  📜 Spring docs - RequestMatcherConfigurer\n  📜 Spring Boot 2.6 Release Notes\n\n\n\n",
      "categories": ["spring","spring-security"],
      "tags": [],
      
      "collection": "posts",
      "url": "/spring/spring-security/2022-03-31-mvcMatchers/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "클린 코더",
      "date": "2022-05-05 00:00:00 +0000",
      "description": "The Clean Coder\n",
      "content": "\n  성장하기\n  소프트웨어 추정\n  후기\n\n\n\n\n\n  로버트 마인 지음, 정희종 옮김, 에이콘 출판사\n\n  단순 기술자에서 진정한 소프트웨어 장인이 되기까지\n\n\n\n\nThe Clean Coder\n\n\n\n같은 팀 동료분의 추천으로 읽게 되었다.\n\n📕 소프트웨어 장인 과 매우 유사한 책이라고 느꼈다.\n\n전체적으로 프로페셔널로서의 태도, 마음가짐에 대해 단호한 어조로 강조하고 있는 책이다.\n\n\n\n예전에 읽은 소프트웨어 장인에서 많은 감명을 받고 반성의 시간을 가진적이 있었고, 이후 스스로를 프로페셔널 프로그래머라 생각하며 개발에 임해왔다.\n\n이런 입장에서 볼 때 이 책의 내용은 내가 볼때 일부 극단적인 예시도 있긴 했으나, 대체로 크게 공감하며 술술 읽어 나갈 수 있었다.\n\n특히, 엉클밥이라고 불리는 로버트 마틴의 경험담 부분들이 크게 인상 깊었는데, 기간 산정을 잘못하여 프로젝트가 실패하였고 이로 인해 눈물을 쏟았다거나, 스스로의 기술적인 능력만을 과시하여 조직문화를 해쳐 해고당했었다는 이야기들은 내게 큰 교훈을 주었다.\n\n\n\n성장하기\n\n\n\n📦 코드 카타 는 내 개발 커리어 내내 꾸준히 하고 있다.\n\n\n  우리는 직장에서 훈련하기 때문에 실수를 반복하는 것이다.\n\n\n위 문구는 내가 가장 크게 감명을 받은 문구였기 때문이다.\n\n책에서도 카타와 짝 프로그래밍에 대한 이야기가 나오는데 아주 크게 공감하며 읽어나갈 수 있었다.\n\n\n\n또한, 다음과 같은 문구도 나왔었다.\n\n\n  배우기에 가장 좋은 방법은 가르치는 것이다.\n\n\n강의형 스터디를 하고 있는 입장에서 역시 아주 크게 공감하는 대목이었다.\n\n멘토, 멘티관계의 두 사람이 있다면 오히려 더 많은것을 배워가는 사람은 멘토일수도 있다고 생각한다.\n\n사람은 누군가를 가르치며 자신의 지식을 타인에게 설명해줄 수 있을 만큼 잘 정리되어 있는지를 자가진단할 수 있다.\n\n즉, 메타인지에 아주 큰 도움이 된다.\n\n\n\n소프트웨어 추정\n\n\n\n다른 분야에서 약 10년 가까이 일을 해온 나는 누가 내게 어떤 업무가 얼마나 걸릴지 물어보는 상황에 나만의 추정 방식이 있다.\n\n내가 생각할 때 3일이면 끝날 것 같다고 생각된다면, 그 기간에 x2를 하여 대답을 하는 것이다. 즉, 6일이다.\n\n사회초년생 시절에는 별 생각없이 “언제까지 되겠는데?” 라는 생각이 들면 그 생각을 바로 입밖에 내었으나, 이 추정이 많이 실패하고서야 생긴 나만의 방식이다.\n\n그러니까… 어린 시절의 나는 스스로의 능력을 과대평가하고, 다른 동료들에게 능력있어 보이고 싶었던 것 같다.\n\n하지만 위 방식대로 하며 언제나 항상 기한을 지킬 수 있었으며, 오히려 내가 추정했던 시간보다 업무를 더 빨리 마칠때도 아주 많았다.\n\n\n\n이 책에서는 소프트웨어 추정이라는 단어로 정규분포를 활용해 설명을 해주고 있는데, 나는 수학을 잘 하지 못하지만 대략 나만의 기준이 이 책에서 나오는 추정법과 생각보다 비슷하다는 생각을 했다.\n\n약간의 차이라면 나만의 추정 방식은 기한은 절대 어기지 않지만, 오히려 업무가 생각한것보다 훨씬 더 빨리 끝나는 경우는 알기 힘들었다는 점이다.\n\n그러니, 관리자 입장에서 나라는 부하직원은 오히려 일정을 낭비하는 직원일수도 있었겠다.\n\n\n\n후기\n\n\n\n내 꿈은 백발의 개발자인데, 나이가 들어도 내 개발 능력을 토대로 개발자로서 계속 일을하고 싶다.\n\n우리나라의 기업문화는 나이가 찬 직원은 관리직으로 빠지는 경우가 허다하기 때문에 과연 내 꿈이 이뤄질 수 있을지는 잘 모르겠다.\n\n만약, 스스로를 월급쟁이가 아닌 프로페셔널 개발자라고 생각한다면 시간을 내어 읽어보기를 강력하게 추천하는 책이다.\n\n이 책을 추천해준 팀 동료분에게 감사한다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-05-05-diary-40/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "도메인 주도 개발 시작하기",
      "date": "2022-05-20 00:00:00 +0000",
      "description": "DDD 핵심 개념 정리부터 구현까지\n",
      "content": "\n  대상독자\n  후기\n\n\n\n\n\n  최범균 지음, 한빛미디어\n\n\n\n\nDDD 핵심 개념 정리부터 구현까지\n\n\n\n요즘 DDD가 그렇게 핫하다길래 뭔지 궁금해서 자료를 찾던 중 올해 출간된 책이 있어 구매해 읽었다.\n\n결론적으로 적절한 시기에 아주 적절한 책을 골라 읽었다는 만족감이 생겼다.\n\n\n\n대상독자\n\n\n\n저자이신 최범균님께서 아주 적절한 글을 책 초반부에 적어놓으셨다.\n\n\n\n\n\n\n\n\n\n\n\n후기\n\n\n\nDDD 입문서라고는 하지만, 핵심적인 개념들에 대해서는 오히려 아주 상세히 잘 설명되어 있었고, 코드 또한 굉장히 실무적이었다.\n\n최범균님이 평소 글을 많이 쓰시는 분이시라 그런지, 책의 가독성도 굉장히 훌륭하였다.\n\n이 책을 제대로 읽고 에릭 에반스의 DDD를 읽으면 아주 괜찮겠다는 생각도 들었다.\n\nDDD에 대해 관심은 있지만, DDD가 뭔지 잘 모르는 상태라면 굉장히 훌륭한 책이 될 것이라고 장담할 수 있다.\n\n한 가지 단점이라면, 책이 출간된지 얼마 안되어서 그런지 오탈자가 굉장히 많았는데, 몇몇 오탈자들은 내용 자체에 혼선을 일으키는 부분들이여서 한번씩 흐름이 꼬였다.\n\n나도 몇가지 오탈자를 제보하였으며, 이 부분은 시간이 지나면 차차 개선되지 않을까 싶다.\n\n\n\n이 책을 읽고 DDD에 대해 더 관심이 생겨 약간 더 알아보다 약간의 의문이 들었는데, 나는 DDD가 아주 간단하게, 그저 널리고 널린 개발 방법론 중 하나의 개발 방법론이라 생각하고 있었으나, 종국에는 DDD라는 것은 조금 더 본질적인, 그러니까 개발에 대한 개발자의 마인드를 교정하는데 목적이 있는건가? 라는 의구심이 생겼다.\n\n왜냐하면, 대부분의 DDD 관련 아티클들은 애그리거트, CQRS 등의 이야기들만을 상세히 다루며 이러한 정보들을 별 생각 없이 접하다 보면 DDD는 일종의 패턴으로 인식이 된다.\n\nDDD에서 사용되는 용어들은 아주 많으며, 많은 아티클들에서 이 용어들에 대한 설명을 수십, 수백 페이지에 걸쳐 장황하게 설명한다.\n\n그리고 결론적으로, DDD라는 것은 패키지를 어떻게 나누고, 도메인을 어떻게 설계하고, 데이터 입력, 수정, 조회 등은 이렇게 하는 것이다!\n\n이런 식이니 종국엔 DDD가 하나의 레이어드 아키텍처(controller - service - repository)와 유사한, 하나의 개발 패턴으로 인식이 돼버린다.\n\n하지만 DDD에 대한 깊이있는 정보들을 다시 접하면 왜 DDD를 해야 하는지로 시작하고 이에 대한 합당한 주장을 펼친다.\n\n모든 상황에 DDD의 개발 패턴을 따라야 할까? 아니라고 생각한다.\n\n현실적으로 모든 프로젝트에 DDD를 완벽하게 적용하기는 힘들 것이다.\n\n왜냐하면 기존에 작성된 수 많은 레거시 프로젝트들은 도메인 위주가 아닌 데이터 중심적으로 설계됐고 운영되고 있기 때문이다. 또한, 그렇게 운영되어야만 하는 프로젝트들도 반드시 존재 할 것이다.\n\n하지만, 개발자는 단순히 도메인 전문가의 의견을 코드로 번역하는 사람이 아니며, 개발자도 도메인에 대해 도메인 전문가 만큼 깊이있게 이해해야 한다는 주장만큼은 아주 크게 동의할 수 있었다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-05-20-diary-41/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "경력자로서 앞으로 뭐가 중요할까?",
      "date": "2022-06-02 00:00:00 +0000",
      "description": "10X 개발자, 지식의 피라미드\n",
      "content": "\n\n\n최근에 아주 좋은 글을 하나 읽었는데, 어떻게 해야 10배 이상 뛰어난 개발자가 되는지에 대한 글이었다.\n\n\n\n\n  📜 How to Be a 10x Software Engineer\n\n\n\n\n하나하나 내용이 주옥같지만, 내가 가장 영감을 받은 것은 1번 문단이었다.\n\n\n\n\n  \n    사용하는 도구에 대한 연구가 없다\n  \n\n  에이브러햄 링컨은 “나에게 나무를 베는 데 8시간이 주어진다면 도끼를 가는 데 7시간을 쓸 것이다.”라고 말했다. \n주니어 개발자는 무딘 도끼로 8시간 나무를 벨 것이다.\n반면, 시니어 개발자는 작업 시작 전 한 시간 동안 최고의 전기톱을 고를 것이다. \n그리고 그는 5분 만에 모든 나무를 자를 것이다.\n\n  예시: 웹사이트 개발\n\n  나는 최근에 후배 주니어 엔지니어와 누가 개인 웹사이트를 더 빨리 구축할 수 있는지에 대한 내기를 했다.\n후배는 2주 동안 1000줄 이상의 코드를 작성했지만, 그는 2주가 지나도 작업을 마치지 못했다.\n반면, 단 한줄의 코딩조차 하지 않고 하루만에 나만의 웹사이트를 만들어 냈다.\n\n\n\n\n\n내가 보기에 위 일화에서 후배의 문제는, 알고 있는 정보가 너무 적었다는 것이다.\n\n이를 그림으로 그려보면 대략 아래와 같이 될 수 있다고 생각한다.\n\n\n\n\n개발자, 지식의 피라미드\n\n\n\n예를 들어, 내가 전기톱을 아주 잘 다룬다고 가정하자.\n\n하지만 나무에 못을 박아야 하는 상황이 생겼고, 나는 망치라는 도구의 존재를 모른다면?\n\n당연히 전기톱으로 못을 박으려고 들 것이고, 이는 아주 바보같은 짓임에 틀림없다.\n\n하지만, 못을 박는데 최적화된 망치라는 도구의 존재를 내가 알고있지만, 당장 이 망치를 제대로 다루지는 못한다면?\n\n나는 전기톱으로 못을 박기보다는, 망치를 다루는 약간의 연습을 한 후에 망치로 못을 박을 것이다.\n\n\n\n위 지식의 피라미드에서 가장 많은 부분을 차지하는 가장 하위 계층의 내가 모른다는 것조차 모르는 것 부분이 우리가 해결하려는 문제에 대한 가장 완벽한 정답임에도 불구하고 그 존재조차 알지 못하는 많은 언어, 프레임워크, 기술이라고 볼 수 있을 것 같다.\n\n나는 자바를 아주 잘 안다고 자신할 수 없지만, 그럼에도 불구하고 내가 다루는 기술 중 자바를 가장 잘 다룰 수 있다고 생각한다.\n\n내가 잘 다룰 수 있다고 생각하는 자바를 더욱 더 갈고닦는다면 지식의 피라미드에서 내가 안다고 생각하는 것부분이 더욱 넓어질 것이며, 이는 곧 내 기술의 깊이다.\n\n반대로 내가 잘 다루지 못한다고 생각하는 도커, k8s, MQ등의 기술들이 있는데, 나는 이 기술들을 제대로 다뤄본 적은 없으나, 이 기술들이 어떤 목적을 달성하기 위해 탄생했고, 어떤 상황에 쓰여야 하는지 정도는 안다.\n\n그러니까 이는 곧 내 기술의 폭이다.\n\n예를 들어 Spring Application을 모니터링 해야 한다면 내가 선택할 수 있는 선택지들은 어떤것들이 있을까?\n\n리눅스의 iostat, top, htop 명령어 부터 해서, 오픈소스인 Scouter, PinPoint, Spring Actuator + Grafana, Prometheus, 상용 소프트웨어인 제니퍼, 데이터독, 와탭 등이 있을 것이다.\n\n\n\n외에 내가 존재조차 알지 못하는, 예를 들자면 위에서 언급되지 않은 APM 도구들이 내가 모른다는 것조차 모르는 것이라고 볼 수 있겠다.\n\n그리고 내가 존재조차 알지 못하는 그 APM 도구는 내가 해결하려는 문제의 가장 완벽한 솔루션일 수도 있다.\n\n\n\n내가 앞으로 중요시해야 할 것은 무엇일까?\n\n일단 생각하기엔 최대한 IT 트렌드를 파악하고, 다른 현직자들의 경험담을 계속 경청하는 것이다.\n\n그들은 어떠한 문제를 겪었고, 그 문제를 어떻게 해결 했는지 등이다.\n\n기발한 발상으로 문제를 해결했을 수도 있고 내가 알지 못하는 다른 도구를 사용해 문제를 쉽게 해결했을 수도 있다.\n\n또한, 다른 현직자들이 어떤 것들에 관심을 두고 있는지 관심을 기울이며, 계속해서 정보를 공유하는 것이다.\n\n정보가 사소하던 사소하지 않던간에, 그러한 모든 정보들이 내게 도움이 될 거라고 생각한다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-06-02-diary-42/"
    },{
      "image": "/assets/img/common/code1.png",
      "title": "DNS는 무엇이고, 어떻게 동작할까?",
      "date": "2022-06-24 00:00:00 +0000",
      "description": "IP와 도메인을 상호 변환해주는 시스템\n",
      "content": "\n  DNS(Domain Name System)    \n      용어\n      흐름\n      캐싱\n    \n  \n\n\n\n\nDNS(Domain Name System)\n\n\n\nDNS는 Domain Name Server가 아니고 Domain Name System이다.\n\n\n\nDNS는 사람이 쉽게 알아볼 수 있는 문자를 서버의 주소(IP)로 상호 변환해주는 시스템이다.\n\n이 DNS가 없던 옛날에는 구글에 접속하기 위해 google.com을 입력하는것이 아닌, 142.250.196.110같은 IP를 입력해야 했었다고 한다.\n\n참고로 DNS 통신의 well known port는 53이고, TCP/UDP 방식으로 동작한다.\n\n\n\n\n\n📜 IANA - well known ports\n\n\n\n용어\n\n\n\n\n  Local DNS\n    \n      기지국의 DNS 서버이다.\n      컴퓨터가 LAN을 통해 인터넷에 연결되면, 인터넷을 사용할 수 있게 IP를 할당해주는 통신사(KT, SK, LG)들의 DNS 서버를 말한다.\n      이사가면 인터넷 연결을 위해 어디에 전화를 걸게되는지 생각해보자\n    \n  \n\n\n\n\n\n  Root DNS\n    \n      Local DNS의 상위 DNS 서버이며, 최상위 DNS 서버이다.\n      전 세계의 주요 도시에 존재하며, 트리 구조로 하위에 많은 DNS 서버들을 알고 있다.\n      📜 root.server.org 를 참고해보자.\n    \n  \n\n\n\n\n\n  최상위 도메인(Top-Level Domain, TLD)\n    \n      국가 코드 최상위 도메인(Country Code Top-Level Domain, ccTLD)\n      일반 최상위 도메인(Generic Top-Level Domain, gTLD)\n      외 나머지는 📜 인터넷 최상위 도메인 목록을 확인\n    \n  \n\n\n\n\n흐름\n\n\n\n\n\n\n\n위 이미지는 AWS에서 제공하는 DNS에 대한 개요이다.\n\n이미지를 요약하자면 다음과 같다. (접속은 google.com에 접속한다고 가정한다)\n\n\n\n\n  클라이언트가 브라우저의 주소창에 google.com을 입력한다\n  클라이언트 컴퓨터의 hosts 파일에서 google.com의 IP 주소 정보가 있는지 확인한다\n    \n      윈도우: C:\\Windows\\System32\\drivers\\etc\\hosts\n      리눅스: /etc/hosts\n    \n  \n  hosts 파일에 IP 주소 정보가 없다면 PC의 DNS 캐시를 확인한다\n    \n      윈도우: cmd -&gt; ipconfig/displaydns 입력시 확인 가능\n      리눅스: 📜 How to inspect the DNS cache on Windows, Mac OS X, and Linux 참고\n    \n  \n  DNS 캐시에도 IP 주소 정보가 없다면 Local DNS에 google.com의 IP 주소에 대해 질의(Query)한다.\n  Local DNS는 자신의 DNS 캐시에서 IP 주소 정보를 찾고, 없다면 Root DNS에 질의한다.\n  Root DNS는 자신이 google.com의 IP 주소 정보를 갖고있지 않다면, TLD(Top-Level Domain) DNS 서버의 주소를 알려준다\n    \n      여기서 google.com이니 TLD는 .com이 된다. 즉, gTLD\n    \n  \n  Local DNS는 다시 com DNS에 google.com의 IP 주소 정보를 질의한다\n  com DNS에서 google.com의 IP 주소인 142.250.196.110을 응답해준다\n  Local DNS는 클라이언트에 142.250.196.110를 응답해주고, 이 IP 주소를 자신도 캐싱한다\n  클라이언트는 Local DNS에게 받은 14.250.196.110을 캐싱하고, 이후 위 주소로 다시 요청을 이어나간다\n\n\n\n\nURL을 뜯어보면 DNS 관점에서 다음과 같이 나눌 수 있는데, 다음과 같다. (HTTP 관점과는 약간 다름)\n\n\n\n\n\n\n\n위 흐름에서도 알 수 있듯이, Local DNS에서 Root DNS로 질의하면, Root DNS에서 모든걸 알아서 찾아주는 것이 아니고, Root DNS는 Local DNS에 TLD DNS의 정보를 알려주게 된다.\n\n그럼 Local DNS는 TLD DNS에게 다시 물어보며 DNS 트리구조를 타고 내려간다.\n\n모든 노드를 탐색할때까지 이 과정이 반복되기에 이것을 Recursive Query라고 부른다.\n\n\n\n\n\n출처 - 구글 이미지 검색\n\n\n\n캐싱\n\n\n\n위 과정들을 보면 최초에 DNS 캐시를 먼저 조회하고, 마지막에도 찾은 정보를 DNS 캐시에 캐싱한다.\n\n이는 생각해보면 아주 당연한 일인데, google.com의 IP 주소를 찾기 위해 얼마나 복잡하고 많은 질의가 이루어졌는가?\n\n브라우저에 google.com을 입력 할 때마다 위의 과정을 모두 반복하면 이는 매우 비효율적이며, DNS 서버들은 전국, 전세계단위의 요청을 받기 때문에 DNS 서버들에 과부하가 갈 수 밖에 없다.\n\n또한 도메인과 IP는 생각보다 그렇게 자주 변경되지 않기 때문에, 캐싱했을 때의 기대 효율이 높을 수 밖에 없다.\n\n\n",
      "categories": ["backend","server-side"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/server-side/2022-06-24-dns/"
    },{
      "image": "/assets/img/backend/java.png",
      "title": "Java에서의 AOT vs JIT 컴파일",
      "date": "2022-07-16 00:00:00 +0000",
      "description": "어느것이 더 나은가?\n",
      "content": "\n  Java에서 AOT vs JIT 컴파일    \n      Java에서의 컴파일        \n          C1 컴파일러\n          C2 컴파일러\n          Just in Time Compilation (JIT)\n          Ahead of Time Compilation (AOT)\n        \n      \n      JIT vs AOT        \n          AOT 제약 사항: Closed-World Assumption (CWA)\n        \n      \n      GraalVM과 AOT 컴파일은 Java의 미래인가요?\n      결론\n      참고        \n          따로 참고한 것\n        \n      \n    \n  \n\n\n\n\n이 글은 cesarsotovalero의  📜 AOT vs. JIT Compilation in Java를 번역한 글입니다.\n\n제 CS지식이 빈약하고, 영어 실력이 좋지 않아 번역 품질이 많이 떨어지니, 가급적 원 글을 읽어주세요.\n\nJava에서 AOT vs JIT 컴파일\n\n\n\nJIT(Just in Time Compilation) 또는 AOT(Ahead of Time Compilation)를 사용하여 Java 애플리케이션을 컴파일하는 두 가지 방법이 있습니다. JIT는 Java HotspotVM의 기본설정이며 이는 런타임에 Java 바이트 코드를 기계어로 변환하는 데 사용됩니다. AOT는 GraalVM에서 지원되며 빌드타임에 Java 바이트 코드를 기계어로 정적 컴파일링 할 수 있습니다.\n\n이 글에서는 두 가지 컴파일 방식의 차이점에 대해 설명할 것이며, 이 글을 읽고 나면 Java 컴파일러가 하는 일, 기존 컴파일 방식 간의 차이점, AOT 컴파일러를 사용하는 것이 더 적합한 상황에 대해 배울 수 있을것입니다.\n\n\n\n\n\n© JIT vs AOT: 동전의 양면. 사진 출처: Tekniska Högskolan station.\n\nJava에서의 컴파일\n\n\n\n프로그램을 컴파일한다는 것은, Java나 Python과 같은 고수준 프로그래밍 언어의 소스 코드를 📜 기계어로 변환하는 것을 의미합니다. 기계어란 특정 프로세서(즉, CPU. 이 글에서는 하드웨어 혹은 하드웨어 아키텍처라는 용어로도 많이 쓰였음)에서 실행할 수 있도록 만들어진 저수준의 명령어입니다. 그리고 컴파일러는 컴파일을 효율적으로 수행하도록 설계된 프로그램입니다. 컴파일러의 목표는 컴파일된 프로그램의 일관된 실행 파일을 만드는 것이며, 일관된 실행 파일은 소스 코드로 작성된 사양에 맞게 빠르고 안전하게 실행됩니다.\n\n컴파일러는 기계어 생성 과정에서 여러 최적화를 수행합니다. 예를 들어, 대부분의 컴파일러는 컴파일 타임에 constant inlining, loop unrolling, partial evaluation 등을 수행합니다. 이러한 컴파일러의 최적화 작업과 복잡성은 지난 수십 년 동안 크게 증가했습니다.\n\n표준 Java HotspotVM의 컴파일러 최적화 측면에서 두 가지 주요 컴파일러가 있는데, 이들이 바로 C1 컴파일러와 C2 컴파일러입니다.\n\nC1 컴파일러\n\n\n\nC1 컴파일러는 some value numbering, inlining, class analysis를 수행하는 빠르고 가볍게 최적화된 바이트 코드 컴파일러입니다.\n\nC1 컴파일러는 간단한 CFG 지향적인 📜 SSA와 고수준의 📜 중간 표현(IR), 기계 지향적인 저수준의 IR, 선형 스캔 레지스터 할당 및 템플릿 스타일 코드 생성기를 사용합니다.\n\nC2 컴파일러\n\n\n\nC2 컴파일러는 📜 노드의 바다 SSA와 이상적인 IR을 사용하는 고도로 최적화된 바이트 코드 컴파일러이며, IR은 동일한 종류의 기계별 IR로 낮아집니다. C2 컴파일러에는 그래프 색칠 레지스터 할당자도 있습니다. 색상은 로컬, 글로벌, 인수 레지스터와 스택을 포함한 기계의 상태입니다. 또한, C2 컴파일러의 최적화에는 global value numbering, conditional constant type propagation, constant folding, global code motion, algebraic identities, method inlining (aggressive, optimistic, and/or multi-morphic), intrinsic replacement, loop transformations (unswitching, unrolling), array range check elimination 및 기타 등등이 포함됩니다.\n\n\n\n이제 컴파일러의 역할을 어느정도 이해했으므로 컴파일이 수행되는 시점에 대해 이야기 해보겠습니다. Java에는 JIT(Just in Time)와 AOT(Ahead of Time)라는 두 가지 주요한 컴파일 전략이 있습니다. JIT는 프로그램 자체를 실행하는 동안(즉, Java 메서드가 처음으로 호출되기 전) 기계어를 생성하며, AOT는 프로그램이 실행되기 전에 기계어를 생성해냅니다(즉, 애플리케이션의 바이트 코드 검증 및 빌드 단계에서). 다음 섹션에서는 이러한 두 접근 방식의 차이점에 대해 설명합니다.\n\nJust in Time Compilation (JIT)\n\n\n\nJava 프로그램을 컴파일할 때(예: javac 명령줄 도구를 사용하여) 플랫폼(CPU 아키텍처 + OS, 예로 인텔맥은 인텔 CPU + MacOS를 사용하는 플랫폼)에 독립적인 중간 표현(IR, JVM 바이트 코드가 IR의 일종)으로 변환되며, 이 JVM 바이트 코드는 JVM이 읽기에는 아주 쉽지만 반대로 사람이 읽기는 어렵습니다.\n우리 컴퓨터의 기존 프로세서는 JVM 바이트 코드를 직접 실행할 수 없으며, 그렇게 하기 위해 컴파일러는 다시 JVM 바이트 코드를 플랫폼에 종속적인 기계어로 변환해야만 하며, 이것은 프로그램이 본래 컴파일되었던 플랫폼과 동일한 플랫폼에서만 실행할 수 있음을 의미합니다. (즉, 인텔맥에서 컴파일 된 코드는 인텔맥에서만 실행할 수 있음을 의미함)\n\n그리고 이것들은 정확히 바이트 코드 컴파일러가 하는 작업입니다. (여기서 바이트 코드 컴파일러란 바이트 코드를 기계어로 변환하는 JVM 내부의 인터프리터를 의미함. 즉, Java는 기본적으로 정적 컴파일 방식과 동적 컴파일 방식을 함께 사용함.)\n\n\n\n\n\n그림 1. Java 소스 코드는 먼저 바이트 코드로 컴파일된 후 나중에 기계어로 해석되고 실행되며, 다소 무거운 최적화 작업들은 JIT 컴파일 단계에 예정되어 있습니다. 출처\n\n\n\nJVM은 런타임에 현재 어떤 플랫폼에서 프로세스가 실행되고 있는지를 파악하고 바이트 코드를 해석한 후 현재 플랫폼에 최적화된 기계어를 만들어 냅니다. 이 전략은 📜 동적 컴파일의 한 형태인 📜 JIT 컴파일로 알려져 있으며, JVM의 기본 JIT 컴파일러는 일명 Hotspot으로 알려져 있습니다. 그리고, 📦 OpenJDK는 Java로 작성된 이 JVM 바이트 코드 컴파일러의 무료 버전입니다. (즉, OpenJDK는 무료 버전의 HotspotVM이며, HotspotVM은 JIT 컴파일 방식을 사용한다는 의미)\n\n\n\n\n  📜 Understanding How Graal Works - a Java JIT Compiler Written in Java\n\n  HotspotVM의 JIT 컴파일러는 C++로 작성되어 있는데 현 시점 이 코드는 포인터를 직접 다루고 있고, 코드가 오래됐기 때문에 유지보수성, 확장성, 안정성이 매우 떨어집니다. 우리는 이러한 문제를 해결하기 위해 JIT 컴파일러를 Java로 작성하기로 했습니다. C나 C++같은 시스템 언어를 사용하지 않고 JIT 컴파일러를 어떻게 작성할 수 있는지 궁금할 수도 있는데, 따지고 보면 JIT 컴파일러는 오직 JVM 바이트 코드를 입력받아 기계어로 변환 할 수만 있으면 됩니다. 또한, 당신은 JIT 컴파일러에 바이트 배열(byte[])을 입력하면 다시 바이트 배열이 출력되길 원할 수도 있습니다. 이러한 모든 작업들을 Java로 처리하기 위해 많은 복잡한 작업을 해야 하겠지만, 어쨋든 순수하게 Java로 JIT 컴파일러를 작성할 수는 있습니다. 그리고 순수한 Java로 이뤄진 JIT 컴파일러를 작성한다면 이 컴파일러는 더 이상 시스템과 관련이 없으므로 C나 C++과 같은 시스템 언어에 의존하지 않을 수 있게 됩니다.\n\n\n\n\nJIT 컴파일러의 목적은 최적화가 아주 잘 된 고품질의 기계어를 최대한 빠르게 생성해내는 것이며, 런타임에 추가적으로 얻을 수 있는 정보들 덕분에 JIT 컴파일러는 javac 컴파일러보다 훨씬 더 정교한 최적화를 수행 할 수 있게 됩니다. 그리고 이러한 최적화는 애플리케이션의 성능을 더더욱 향상시킵니다.\n\nJIT 컴파일러는 Java 메서드를 미리 수천 번 실행하여 JVM 바이트 코드 컴파일러가 Java 메서드를 “워밍업”할 수 있도록 합니다. 이 워밍업을 통해 컴파일러는 전체 클래스 계층 구조를 미리 관찰할 수 있기 때문에 최적화와 관련된 더 나은 결정을 내릴 수 있게 됩니다. 이 때, JIT 컴파일러는 JVM 바이트 코드 컴파일러가 수집한 분기 및 유형 프로필 정보도 검사할 수 있습니다.\n\n하지만, 이러한 JIT 컴파일러의 발전에도 불구하고 Java 애플리케이션은 기계어를 직접(IR을 거치지 않고) 만들어내는 C 또는 Rust와 같은 언어보다 여전히 훨씬 느립니다. 이러한 바이트 코드 해석 프로세스는 IR을 거치지 않고 기계어를 직접 만들어내는 프로세스보다 애플리케이션을 상당히 느리게 만들 수 밖에 없습니다.\n\nAhead of Time Compilation (AOT)\n\n\n\n📜 AOT 컴파일은 프로그램이 실행되기 전에 소스 코드를 기계어로 변환하는 방식으로 정적 \n컴파일의 한 형태입니다. 이것은 C와 같은 오래된 프로그래밍 언어의 코드가 정적으로 링크되고 컴파일되는 “구형” 방식입니다. 컴파일의 결과로 얻어진 기계어는 특정 플랫폼에 맞게 \n조정되며(단, 플랫폼에 종속됨) 매우 빠른 실행이 가능해집니다.\n\n📦 GraalVM은 JVM 바이트 코드에 고도로 최적화된 AOT 컴파일을 수행할 수 있습니다. GraalVM은 Java로 작성되었으며 JVMCI을 사용하여 HotspotVM과 통합됩니다. GraalVM 프로젝트의 초점은 최신 Java 애플리케이션에 더욱 좋은 성능과 더 나은 확장성을 제공하는 것입니다. 즉, 더 적은 오버헤드로 더 빠르게 실행되며 이는 더 적은 CPU와 메모리 자원의 소비를 의미합니다. 따라서 GraalVM은 JVM과 함께 제공되는 기존 JIT 컴파일러보다 더 나은 대안이 될 수도 있습니다.\n\n\n\nJVMCI는 JVM에서 메타데이터를 읽고 JVM에 기계어를 삽입하는 것과 같은 기능을 위한 JVM에 대한 저수준 인터페이스입니다. Java로 작성된 컴파일러를 동적 컴파일러로 사용할 수 있습니다.\n\n\n\n\n  “GraalVM의 도구로 생성된 네이티브 이미지에는 애플리케이션 클래스, 종속성 클래스, 런타임 라이브러리 클래스 및 JDK에 정적으로 연결된 기계어가 포함됩니다. JVM에서 실행되지 않지만 “Substrate VM”이라는 다른 런타임 시스템의 메모리 관리, 스레드 스케줄링 등과 같은 필수 구성 요소를 포함합니다. Substrate VM은 런타임 구성 요소(예: 디옵티마이저, 가비지 수집기 및 스레드 스케줄링)의 이름입니다. 결과 프로그램은 JVM에 비해 시작 시간이 더 빠르고 런타임 메모리 오버헤드가 더 적습니다.”\n\n\n\n\n다음 그림은 📜 네이티브 이미지 기술을 사용하는 GraalVM 컴파일러의 AOT 컴파일 프로세스를 보여줍니다.\n\nGraalVM은 애플리케이션, 라이브러리, JDK 및 JVM의 모든 클래스를 입력으로 받습니다. 그런 다음 고정된 지점에 도달할 때까지 📜 최첨단 포인트 분석을 사용하여 반복적인 바이트 코드 검색이 수행됩니다. 이 프로세스 동안 모든 안전한 클래스는 정적으로 미리 📜 초기화됩니다(즉, 인스턴스화됨). 초기화된 클래스의 클래스 데이터는 이미지 힙에 로드된 다음 독립 실행 파일(그림 2의 텍스트 섹션)에 저장됩니다. 그 결과 컨테이너에 직접 배송하거나 배포할 수 있는 실행 가능한 네이티브 이미지가 생성됩니다.\n\n\n\n\n\n그림 2. GraalVM의 기본 이미지 생성 프로세스 출처\n\n\n\nGraalVM의 AOT 컴파일은 JDK 및 해당 종속성에서 사용되지 않는 코드 제거, 힙 스냅샷 및 정적 코드 초기화와 같은 최적화를 적극적으로 수행하고, 독립 실행 파일을 생성합니다. 주요 이점은 실행 파일이 올바르게 실행되기 위해 클라이언트 시스템에 JVM을 설치할 필요가 없다는 것이며, 이것은 JVM 바이트 코드로 컴파일되는 프로그래밍 언어를 고성능 프로그램에 사용되는 C, C++, Rust 또는 Go와 같은 언어만큼 빠르게 만듭니다.\n\n\n\nGo의 경우 처음부터 언어차원에서 AOT가 구현되었습니다.\n\nJIT vs AOT\n\n\n\n이제 바이트 코드 컴파일이 작동하는 방식과 두 가지 주요 전략(JIT 및 AOT)을 이해했으므로 어떤 접근 방식을 사용하는 것이 가장 좋은지 궁금할 것입니다. 불행히도 대답은 예상대로 \"그때 그때 다릅니다.\"\n\n이 섹션에서는 각 방식의 장단점을 다룰 것입니다.\n\nJIT 컴파일러는 프로그램을 크로스 플랫폼으로 만들어줍니다(즉, 플랫폼에 독립적이라는 의미). 실제로 📜 “한번만 작성하면 어디에서나 실행 할 수 있다” 라는 슬로건은 90년대 후반에 Java를 대중적인 언어로 만든 기능 중 하나였습니다. JIT 컴파일러는 \n동시 가비지 컬렉터를 사용하여 최대 처리량 조건에서 메모리 회복력을 높여 STW(Stop the World)를 짧게 가져갑니다.\n\n반면에 AOT 컴파일러는 프로그램을 보다 효율적으로 실행하며, 이는 특히 클라우드 애플리케이션에 적합합니다. 네이티브 이미지는 더 빠른 시작 속도를 제공하므로 애플리케이션의 부팅 시간이 단축되고, 이는 클라우드 서비스의 Scale-out이 더욱 간편해지게 만듭니다. 또한, 클라우드에서 실행되는 Docker 컨테이너로 초기화된 마이크로서비스의 경우에 특히 유용합니다. 사용되지 않는 코드의 완전한 제거(클래스, 필드, 메서드, 분기) 덕분에 파일의 크기가 작아지기 때문에 결과적으로 컨테이너의 이미지도 작아집니다. 또한, 메모리 소비가 적기 때문에 동일한 메모리로 더 많은 컨테이너를 실행할 수 있으므로 클라우드 서비스의(AWS, GCP와 같은) 비용도 절감됩니다.\n\n다음 스파이더 그래프는 주요 차이점을 보여줍니다.\n\n\n\n\n\n그림 3. AOT vs JIT. 출처\n\n\n\n요약하면 GraalVM을 사용한 AOT 컴파일은 표준 JIT 컴파일에 비해 다음과 같은 이점을 제공합니다.\n\n\n\n\n  JVM에 필요한 자원의 일부를 사용합니다.\n  애플리케이션이 밀리초 단위로 부팅됩니다.\n  워밍업 없이 최고의 성능을 즉시 제공합니다.\n  더 빠르고 효율적인 배포를 위해 경량 컨테이너 이미지로 패키징할 수 있습니다.\n  공격 표면이 감소됩니다.\n\n\nAOT 제약 사항: Closed-World Assumption (CWA)\n\n\n\nAOT 컴파일의 포인트 분석이 올바르게 작동하려면 모든 바이트 코드를 보아야 할 필요가 있습니다. 이러한 제약은 CWA 한정으로 알려져 있습니다. 즉, GraalVM의 네이티브 이미지 도구가 독립 실행 파일을 빌드할 때 런타임에 호출할 수 있는 응용 프로그램의 모든 바이트 코드와 종속성을 알아야 함을 의미합니다.\n\n따라서 JNI(Java Native Interface), Java Reflection, 동적 프록시 개체(java.lang.reflect.Proxy) 또는 클래스 경로 리소스(Class.getResource)와 같은 동적 언어 기능이 지원되지 않습니다.\n\n\n\n\n  📜 Project Leyden: Beginnings - Oracle\n\n\n\n\n이러한 한계를 극복하기 위해 GraalVM은 일반 JVM에서 실행되는 모든 동적 언어 기능을 추적하는 📜 에이전트를 제공합니다. 실행하는 동안 에이전트는 JVM과 상호작용하며 클래스, 메서드, 필드, 리소스를 조회하거나 프록시 액세스를 요청하는 모든 호출을 가로챕니다. 그런 다음 에이전트 는 지정된 출력 디렉토리에 jni-config.json, reflect-config.json, proxy-config.json 및 resource-config 파일을 생성합니다. 이렇게 생성된 파일들은 가로채는 모든 동적 액세스를 포함하는 JSON 형식의 독립 실행형 구성 파일입니다. 이와 같은 명세 파일들은 네이티브 이미지 도구로 전달되며 네이티브 이미지 빌드 과정에서 사용된 클래스가 제거되지 않습니다.\n\nCWA가 다양한 코드 주입 가능성을 제거하므로 보안에 좋다는 점은 언급할만한 가치가 있습니다(예로 2021년 웹 생태계에 큰 충격을 준 Log4j 취약점은 Java의 동적 클래스 로딩 메커니즘의 악용으로 인해 가능했습니다). 반면에 포인트 분석은 도달 가능한 모든 바이트 코드를 분석해야 하기 때문에 AOT 컴파일을 JIT보다 느리게 만듭니다. 즉, 이는 값비싼 계산 방식입니다.\n\nGraalVM과 AOT 컴파일은 Java의 미래인가요?\n\n\n\n네이티브 클라우드 애플리케이션을 위한 AOT 컴파일의 이점으로 인해 이 기술에 대한 관심이 높아졌고(대표적으로 클라우드 + MSA의 성공적인 사례), 이제 Java 생태계는 이 기술을 적극적으로 채택하고 있습니다. 이 글을 작성하는 시점에서 4가지의 주요 프레임워크는 GraalVM의 이점을 활용하여 애플리케이션을 빌드하고 최적화합니다.\n\n\n\n\n  Quarkus (by RedHat)\n  Micronaut (by The Micronaut Foundation)\n  Helidon (by Oracle)\n  Spring Native (by Spring)\n\n\n\n\nJVM 기반 네이티브 애플리케이션을 구축하는 일반적인 프로세스는 다음과 같습니다.\n\n\n\n\n\n\n\nGraalVM을 사용한 AOT는 Java, Scala, Kotlin과 같은 JVM 기반 언어의 미래인 것 같습니다. 그러나 네이티브 이미지 생성은 애플리케이션의 바이트 코드와 모든 종속성을 분석해야 하기 때문에 종속성 중 하나 이상이 일부 동적인 기능에 의존하고 있는 경우 CWA를 위반할 위험이 있습니다. 커뮤니티는 이러한 위험성을 고려한 새 버전의 라이브러리를 만들고 있지만, 가장 널리 사용되는 Java 라이브러리에 대한 지원은 아직도 충분하지 않습니다.\n\n따라서 이 기술이 대규모로 채택되기까지는 아직 시간이 더 필요합니다.\n\n\n\n기술 채택 지연은 기술 생태계에서 일반적인 현상입니다. Docker 컨테이너와 같은 핵심 기술은 2013년부터 사용 가능했지만 5년 후인 2018년에 이르러서야 대규모로 채택되기 시작했습니다.\n\n결론\n\n\n\nAOT 또는 JIT 접근 방식을 사용하여 JVM 바이트 코드를 기계어로 컴파일하는 것이 가능합니다.\n\n각 방식이 서로 다른 상황에 적합하기 때문에 둘 중 하나가 다른 방식보다 좋다고 말하는 것은 잘못된 것입니다.\n\nGraalVM을 사용하면 AOT 컴파일로 고성능 애플리케이션을 구축할 수 있으므로 시작 시간이 단축되고 성능이 크게 향상됩니다. 이러한 이점은 CWA를 준수하는 대신 얻어집니다.\n\n반대로 개발자는 여전히 Hotspot VM에서 표준 JIT 컴파일러를 사용하여 런타임에 기계어 생성을 지원하는 동적 언어 기능을 사용할 수 있습니다.\n\n참고\n\n\n\n\n  📜 Java is Going to the Moon: Native Images with GraalVM\n  📜 Supporting Binary Compatibility with Static Compilation\n  📜 Initialize Once, Start Fast: Application Initialization at Build Time\n  📜 Deep Dive Into the New Java JIT Compiler – Graal\n  📜 JEP 295: Ahead-of-Time Compilation\n  📜 Ahead of Time Compilation (AoT)\n\n\n따로 참고한 것\n\n\n\n\n  📜 Understanding How Graal Works - a Java JIT Compiler Written in Java\n  📜 .NET 환경의 컴파일 과정 - CLR, CIL, JIT, AOT\n  📜 Scalable pointer analysis of data structures using semantic models\n  📜 Intermediate Representation\n  📜 Static Single Assignment Form\n  📜 HotSpot Glossary of Terms\n  📜 Sea of Nodes\n  📜 https://en.wikipedia.org/wiki/Closed-world_assumption\n  📜 Closed World Assumption (CWA; 닫힌 세계 가정)\n\n\n\n",
      "categories": ["backend","java"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/java/2022-07-16-aot-vs-jit-in-java/"
    },{
      "image": "/assets/img/cs/git.png",
      "title": "Git의 구조 - Objects",
      "date": "2022-07-21 00:00:00 +0000",
      "description": "Git은 어떤 원리로 동작하는가?\n",
      "content": "\n  Git의 구조 - Objects    \n      Blob (Binary Large Object)\n      Tree\n      Commit\n    \n  \n  정리\n\n\nGit의 구조 - Objects\n\n\n\ngit을 이루고 있는 가장 기본적인 단위는 commit, tree, blob이다.\n\ncommit은 몇가지 재료를 합성해 만들어지고, 이 commit의 재료들이 바로 tree와 blob이다.\n\n위의 세 가지 오브젝트들은 사용자가 .git 디렉토리를 직접적으로 조작(예: rm -rf .git)하지만 않는다면 절대 수정되거나 삭제되지 않으며, 유일하다.\n\n또한, commit을 포함한 모든 오브젝트들은 0-9a-z로 이뤄진 40자리의 해시코드(SHA1)를 식별자로 갖는다.\n\n그리고 40자리중 맨 앞의 2자리는 오브젝트가 저장된 디렉토리의 이름이 되고 뒤의 38자리는 오브젝트 파일의 이름이 된다.\n\n다음과 같은 디렉토리가 있다.\n\n.\n└── src\n    └── a.txt\n\n\nBlob (Binary Large Object)\n\n\n\nblob은 파일과 매핑된 오브젝트이다.\n\n위 . 디렉토리의 최하위에는 a.txt라는 이름의 텍스트 파일이 존재하는데 git은 이 파일의 이름과 내용등을 취합하여 blob 타입의 오브젝트로 만들어 저장한다.\n\nTree\n\n\n\ntree는 디렉토리와 매핑된 오브젝트이다.\n\n위 . 디렉토리의 하위에는 src라는 이름의 디렉토리가 하나 존재한다.\n\ngit은 이러한 디렉토리들을 tree 타입의 오브젝트로 만드는데, 이때 tree의 재료는 src 디렉토리의 하위에 있는 a.txt의 blob 오브젝트를 포함한다.\n\nCommit\n\n\n\ncommit은 위 계층 구조에서 . 디렉토리의 tree 오브젝트와 커미터의 정보를 포함한 오브젝트이다.\n\ncommit은 tree와 blob, 커미터 정보의 집합으로 이루어져 있다.\n\n정리\n\n\n\ngit log를 입력해 출력된 commit 히스토리는 다음과 같다.\n\n\n\n조금 더 보기전에 먼저 방금 생성한 commit을 눈으로 직접 확인해보기 위해 .git/objects로 들어가 tree 명령어를 입력하면 다음과 같이 출력된다.\n\n\n\n위에서 모든 오브젝트는 40자리의 SHA1 해시코드로 생성되며, 가장 앞 2자리는 디렉토리명, 나머지 38자리는 파일명이 된다고 하였다.\n\n실제로 그러하다.\n\n방금 생성한 commit은 baf09e6으로 시작하는 해시코드를 가지며, .git/objects/ba/f09e6... 이 존재함을 확인 할 수 있다.\n\nfile 명령어를 통해 commit의 파일 정보를 출력하면 다음과 같이 출력된다.\n\n\n\nzlib 방식으로 압축된 파일임을 알 수 있는데, 이를 해석할 수 있는 저수준 명령어를 git이 지원한다.\n\ngit cat-file -p baf09e6 를 입력하면 다음과 같은 데이터가 출력된다.\n\n\n\nbaf09e6 commit에 2092b97로 시작하는 tree 타입의 오브젝트가 포함되어 있음을 알 수 있다.\n\n위의 설명을 대입시켜보면 위의 tree 오브젝트는 src 디렉토리일것이다.\n\n이어서 쭉쭉 파고들어가보자.\n\n\n\nsrc 디렉토리는 a.txt 파일을 포함하고 있으므로, 해당 파일에 매핑된 blob 타입의 오브젝트가 존재함을 알 수 있다.\n\n이어서 blob 타입의 오브젝트도 풀어보면 a.txt 파일의 데이터가 출력되게 된다.\n\n결과를 비교해보면…\n\n\n\n\n\n1개의 commit - create src/a.txt(ba4f09e)\n\n2개의 tree - . 디렉토리(2092b97), src 디렉토리(924b0f9)\n\n1개의 blob - a.txt(b5e4569)\n\n총 4개의 git 오브젝트가 생성되었음을 알 수 있으며…\n\n\n\n.git/objects에도 마찬가지로 4개의 오브젝트가 실제로 존재함을 확인 할 수 있다.\n",
      "categories": ["cs","software-design"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/software-design/2022-07-21-git-objects/"
    },{
      "image": "/assets/img/cs/git.png",
      "title": "Git - HEAD & Branch & Tag",
      "date": "2022-08-14 00:00:00 +0000",
      "description": "작업한게 날아갔어요\n",
      "content": "\n  Git의 구조 - HEAD &amp; Branch &amp; Tag    \n      HEAD\n      Branch\n      Tag\n    \n  \n\n\nGit의 구조 - HEAD &amp; Branch &amp; Tag\n\n\n\ngit은 이 글을 쓰는 시점(2022년 8월), 세계에서 가장 많이 쓰이는 VCS(Version Control System)중 하나이며, 실무에서는 원활한 협업을 위해 아주 많이 쓰이고 있다.\n\n그리고 원활한 협업을 위해 보통 branching을 통해서 작업을 하게 되는데, git에 대한 이해가 부족하다면 굉장히 곤혹스러운 상황들이 많이 생길 수 있다. 그런 상황을 미연에 방지하기 위해, 혹은 이미 한번이상 겪어봤다면 이후에는 곤혹스럽지 않기 위해 git에 대한 깊은 이해가 필요하다.\n\nHEAD\n\n\n\n우선 HEAD에 대해 알아야 한다.\n\nHEAD는 아주 단순하다. HEAD는 현재 우리가 바라보고 있는 commit을 의미한다.\n\n그냥 단순히 git checkout 명령어를 통해 특정 commit, branch, tag등으로 이동하면 HEAD가 옮겨진다고 이해하면 되겠다.\n\n다음과 같은 git history가 존재한다.\n\n\n\n여기서 cd ./git 명령을 통해 이동하면 HEAD라는 파일이 존재하는데, 해당 파일의 내용을 출력해보면 main branch를 가리키고 있음을 알 수 있다.\n\n\n\n이후 git checkout de70330을 입력하여 HEAD를 옮긴 후 다시 HEAD 파일의 내용을 출력해보면 어떻게 될까?\n\n\n\n이전에는 refs/heads/main을 가리키고 있었지만, 이제는 그냥 특정 commit을 가리키게 바뀌었음을 알 수 있다.\n\nBranch\n\n\n\nbranch도 정말 별거 없다.\n\ngit은 단순히 단방향 연결리스트(Singly Linked List)구조로 만들어져있는 commit의 나열일 뿐이며, branch는 특정 commit을 기록하고 있는 파일일 뿐이다. 최초의 commit을 제외한 모든 commit은 부모 commit이 존재하며, 모든 commit의 부모 commit은 일반적으로 1개이고, merge commit에 한해 최대 2개까지만 존재할 수 있다. (두 부모 commit을 병합(merge)하여 만들어내는 commit이기 때문)\n\n즉, 모든 commit이 가질 수 있는 최대 부모의 개수는 2개이다.\n\n또한, 모든 commit은 오직 자신의 부모만 알 수 있으며, 자식의 존재는 알지 못한다. 즉, 자식 commit으로 탐색을 해나갈 수 없기 때문에 특정 commit을 참조하는 포인터에서 history를 출력하면 실제로는 .git 디렉토리에 모두 저장돼있지만 화면에서는 자식 commit들을 볼 수 없는것이다. 그리고 우리는 이것을 작업이 날아갔다고 인식하게 된다. (실제로는 그렇지 않다. 명심하자!)\n\n\n\n위 git history 이미지를 보면 HEAD가 main branch를 가리키고 있고(HEAD -&gt; main), main branch가 aa28560 commit을 가리키고 있음을 알 수 있다.\n\ngit reset명령어등을 통해 이 branch가 가리키고 있는 commit을 변경할 수 있다.\n\n그리고 git log명령어를 입력하면 branch가 가리키고 있는 commit의 시조(??) commit까지의 그래프를 보여주는것이다.\n\n모든 branch의 정보는 [project]/.git/refs/heads에 파일로 존재하며, 현재 데모 프로젝트에는 main밖에 없으므로 main 파일하나만 존재함을 볼 수 있다.\n\n\n\nTag\n\n\n\n같이 협업을 하다가 동료와 커뮤니케이션이 잘 되지 않아 merge가 잘못 된 경우 이를 해결하기 위해서나, 본인이 commit을 잘못하여 reset등의 작업을 하는 경우가 종종있는데, 이때 실수하여 작업이 날아가는 경우가 존재한다.\n\n하지만 걱정마시라, 이전 포스팅에서 git의 가장 기본적인 요소가 되는 object들인 commit, tree, blob에 대해 작성했었는데, 이전 글에서는 다음과 같이 이야기했었다.\n\n\n  위의 세 가지 오브젝트들은 사용자가 .git 디렉토리를 직접적으로 조작(예: rm -rf .git)하지만 않는다면 절대 수정되거나 삭제되지 않으며, 유일하다.\n\n\n즉, 이미 한번이라도 commit된 것은 .git 디렉토리를 직접적으로, 그리고 잘못된 방향으로 조작한게 아니고서야 절대 날아가지 않는다.\n\n단지, 우리의 눈에 보이지만 않고 있을 뿐이다.\n\n한마디로 commit의 해시코드만 알고있다면 언제라도 작업을 복구할 수 있음을 의미한다. 하지만, commit의 해시코드는 40자리의 랜덤한 문자열이므로 사람이 기억하는것이 불가능에 가깝다.\n\n따라서 작업을 추적하기 위해 git reflog를 통해 commit log를 보여주기도 하지만, 더 간편한 방법이 있다. 바로, commit에 사람이 기억하기 쉬운 이름을 박아버리는 것이다.\n\n이는 DNS와 완벽에 가까우리만큼 같은 개념인데, IP주소(ex 192.168.0.1 etc)를 사람이 기억하기 힘들기 때문에 www.naver.com과 같은 도메인 네임을 IP에 매핑하는것이다. tag와 같지 않은가?\n\ntag는 git tag [tagname] 명령어를 통해 생성할 수 있다. 이 명령어를 입력하면 현재 HEAD가 바라보고 있는 commit을 바라보는 tag를 생성해낸다.\n\n나는 aa28560 commit에 git tag save-point명령어를 통해 tag를 생성했다.\n\n\n\n이후 [project]/.git/refs/tags에 진입해보면 save-point라는 파일이 생성돼있고, 내용을 확인해보면 aa28560 commit을 가리키고 있음을 확인할 수 있다.\n\n\n\n이제 tag를 생성했으니 git reset --hard de70330를 입력하여 branch의 참조를 이전 commit으로 돌린 후 git log를 입력하면 aa28560가 삭제된것처럼 보인다.\n\n\n\n하지만 aa28560 commit에 tag를 남겨두었으니, git reset --hard save-point를 입력하게 된다면 삭제된것처럼 보이는 commit을 언제든지 다시 복구(사실은 그냥 다시 보이게 한것에 불과하다)할 수 있다.\n\n혹은 해시코드를 알고 있으니 git reset --hard aa28560를 입력해도 똑같은 결과가 나타난다.\n\n\n\n\n\n\nGit은 리눅스를 개발한 리누스 토발즈가 개발한 것인데(그것도 단 몇일만에…), 이러한 구조를 보면서 운영체제 책에서 보았던 inode-dentry가 살짝 연상됐다. 아마 리누스 토발즈가 리눅스를 개발하며 활용했던 설계를 Git에 일부 차용한게 아닐까? 라는 생각이 들었다.\n",
      "categories": ["cs","software-design"],
      "tags": [],
      
      "collection": "posts",
      "url": "/cs/software-design/2022-08-14-git-brach-tag/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "인프콘 2022 - 인프런 아키텍처의 과거와 현재, 그리고 미래",
      "date": "2022-08-27 00:00:00 +0000",
      "description": "부제: 적정 소프트웨어 아키텍처 (현실과 이상 사이 어딘가?)\n",
      "content": "\n  인프런 아키텍처의 과거와 현재, 그리고 미래    \n      시즌 1\n      시즌2\n      시즌3\n      시즌4\n      나의 Q&amp;A\n    \n  \n\n\n인프런 아키텍처의 과거와 현재, 그리고 미래\n\n부제: 적정 소프트웨어 아키텍처 (현실과 이상 사이 어딘가?)\n\n시즌 1\n\n\n  자금과 동료가 없음(극초창기 스타트업) → 대표 혼자 모든걸 개발\n  직접 개발은 최소화하고 외부 자원을 적극활용(SaaS)\n  JQuery, PHP, WordPress, MySQL로 회원수 10만까지 버텼으나 한계가 느껴짐\n\n\n시즌2\n\n\n  개발자를 채용하여 SaaS를 걷어내고 모든 서비스를 다시 개발함 (BE1, FE1, DevOps1, 대표1)\n  BE = Java, FE = TS, DevOps = Go 등으로 기술 스택이 다양해지면 어느 분야 개발자가 단 한명이라도 빠질 경우 전체 개발 진행이 안되는 아주 큰 리스크가 존재함\n  따라서 모든 직군의 기술 스택을 JS로 통일하였음\n  3.5(0.5명은 대표님)명의 개발자가 5개월동안 전체 시스템을 워드프레스 → JS로 전환에 성공\n  JS로 변경 후 문제\n    \n      코드만 봐서는 함수가 어떤 값을 반환하는지 알 수 없음\n      console.log와 디버그 모드를 활용해 코드를 파악해야만 함\n      테스트 코드를 작성하기가 불가능에 가까움\n      IDE의 도움을 받기가 힘듬(인터프리터 언어의 한계?)\n      BE와 FE가 싱글 레포에서 모두 관리되었음\n        \n          FE를 수정해도 BE까지 영향이 감\n          BE를 수정해도 FE까지 영향이 감\n          Bundling, Reload 속도가 참을 수 없을정도로 느려짐\n        \n      \n      신규 입사자들이 기존의 코드를 이해하기가 점점 어려워짐\n    \n  \n\n\n시즌3\n\n\n  개발자들이 코드 수정에 자신감이 생기도록 개선해야함\n    \n      테스트 코드, 정적분석 등을 도입\n    \n  \n  신규 입사자들의 진입장벽이 낮아지도록 메이저한 라이브러리, 패턴등을 사용하기로 함\n    \n      언어를 TS로 변경\n      FE = React, Next.js를 도입\n      BE = Nest.js &amp; TypeORM 도입\n      Layered Architecture와 DI 도입\n      FE, BE를 분리하여 서로 독립적으로 개발 할 수 있게끔 하기로 함\n    \n  \n  어떻게 할 것인가?\n    \n      빅뱅\n        \n          서비스 개선을 중단하고 전체를 다시 만들어서 한번에 교체 → 약 1년 예상\n        \n      \n      점진적 개선\n        \n          서비스 개선과 시스템 개편을 병행 → 약 2년 예상\n          서비스 성장속도가 가팔랐음(매년 약 200~300%)\n          회사의 압축 성장을 가속화 해야 하기 때문에 서비스를 중단 하기가 어려웠음\n        \n      \n      교살자 패턴으로 서비스를 개선하기로 함. 즉, 점진적 개선 (달리는 마차의 바퀴를 갈아끼운다)\n    \n  \n  FE, BE 모노 레포를 신규로 생성하고 기존 코드를 점진적으로 이관 시키려 함\n    \n      통합 IAM 시스템을 분리 개발 → API Gateway 도입\n    \n  \n  모든 계획을 짜고 코드 이관 작업을 시작\n    \n      3일동안 매일 2시간씩 서버가 죽는 장애가 발생\n      한 기능의 작은 장애가 전체 시스템의 장애로 전파되기 시작함\n    \n  \n\n\n시즌4\n\n\n  개발팀 구성\n    \n      BE 8\n      FE 11\n      DevOps 4\n      CTO 1\n    \n  \n  장애\n    \n      어드민에서 ROW 50,000 정도의 엑셀을 다운받았더니 전체 시스템이 다운되는 경우도 발생\n      독립적으로 운영되는 서비스들을 분리하기로 결정하고 실행\n        \n          서버의 메모리, CPU를 많이 점유하는 작업으로 인한 장애는 격리됨\n        \n      \n      하지만 단일 RDB 구조로 인한 장애는?\n        \n          분산 DB까지 도입하면 시스템 복잡도가 너무 크게 늘어남\n          트랜잭션 관리가 매우 어려워짐\n          기존 쿼리들도 모두 개선해야함\n          지금 못하니까 시즌5에 하도록 하자\n        \n      \n    \n  \n  집중\n    \n      시스템 복잡도를 극한으로 최소화\n      (구)인프런 레거시 개편\n      레거시 개편하며 발생하는 장애 트러블 슈팅\n      다양한 신규 요구 사항 커버\n      기술 스택을 컴팩트하게 가져가 관리 포인트를 최대한 줄이자 (안 그래도 해야할게 많다)\n      MongoDB Atlas로 검색엔진, Data Lake, 실시간 데이터 등을 모두 처리 (최소 2~3년만 DB 장애 안나게 버티면서 다른거에 집중해보자)\n    \n  \n  서비스 구조\n    \n      (구)인프런\n      (신)인프런\n      통합 IAM\n      AWS SNS를 도입 → 멀티 구독\n      AWS SQS로 최종적인 일관성을 보장\n      Spring Boot를 도입하고 Back Pressure를 이용해 서버가 다운 되지 않게 대용량 데이터를 핸들링\n        \n          🔔 Back Pressure ?: 클라이언트가 서버에 자신이 감당할 수 있는 만큼만 요청해서 처리할 수 있게 해주는 기술을 말한다. 한국어로는 배압 또는 배압 조절로 번역되고 있으며 자바 진영에서 이러한 기술의 구현을 위한 스펙이 리액티브 스트림이다. 그리고, 이 스펙의 구현 중 하나가 그 유명한 리액터이고 스프링에서는 리액터를 사용해 웹 플럭스를 구현했다.\n        \n      \n      서버 → AWS SNS로 이벤트 발행이 실패하면?\n        \n          이벤트 저장소를 중간에 두면 쉽게 해결할수는 있다\n          단, 시스템 복잡도가 너무 높아짐\n          이번 시즌에는 이벤트 발행이 실패하면 로그를 확인해 수동으로 재 발행 하기로 결정\n        \n      \n      현재는 시스템 복잡도를 최소화하고 (구)인프런을 모두 걷어내는데에 집중하고 있음\n        \n          완벽한 시스템을 최초에 단번에 만들어 낼 수는 없다\n          시스템을 수시로 모니터링하며 점진적으로 고쳐 나간다\n        \n      \n    \n  \n\n\n나의 Q&amp;A\n\n우리 회사는 현재 시리즈 B에서 누적 330억 규모의 투자를 받아 다음 라운드를 준비하고 있고, 파이썬 2.7로 된 레거시를 자바로 마이그레이션 하는 작업을 진행하고 있다. 하지만 서비스 개선 작업시 기존 레거시에 대부분의 리소스를 점유당하고 있다. 복잡하게 얽힌 의존성과 매우 나쁜 가독성으로인함이다. 상황이 이러하니 이 세션내내 내가 현재 재직중인 회사의 상황과 굉장히 비슷해서 매우 몰입하며 들었고, 대부분의 내용도 공감됐다.\n\n세션이 종료된 후 나는 세션 발표자인 이동욱(인프런 CTO)님께 다음과 같은 질문을 드렸고, 다음과 같은 답변을 들었다.\n\nQuestion: 우리 회사도 파이썬으로 된 레거시 시스템을 자바로 옮기고 있는데, 파이썬이라는 언어 자체가 잘못된 함수 호출을 막을 수가 없다. 또한 코드만 봐서는 함수에 어떤 값이 입력되고 어떤 값이 리턴되는지 알 수가 없기 때문에 코드를 파악하기 위해 print 함수와 디버그 모드를 활용해야만 한다. 무엇보다 테스트 코드를 작성하기가 너무 어렵다. 내가 생각하기엔 JS도 이와 크게 다르지 않을 것 같은데 어떻게 코드를 이관하고 있는지?\n\nAnswer: JS역시 비슷하다. 테스트 코드를 완벽하게 작성하기가 불가능에 가깝다. 따라서 우리는 각 엔드 포인트마다 성공하는 케이스에 대해서만 테스트 코드를 작성하고 장애를 맞아가면서 강제로 코드를 옮겼다. 아마 파이썬도 크게 다르지 않을 것이라고 생각한다.\n\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-08-27-diary-43/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "두번째 직장 온보딩 회고",
      "date": "2022-09-10 00:00:00 +0000",
      "description": "부제: 소프트 스킬의 중요성\n",
      "content": "\n원래 개발과 상관없는 일을 8년 정도 했고, 어머니 수술을 계기로 개발을 독학으로 5개월가량 공부했다.\n그리고 첫 회사에서 1년 6개월 정도의 경력을 마무리하고 8월 16일부로 개발자로서 두 번째 직장에 출근을 시작했다.\n\n이번 주로 온보딩이 마무리되어 회고를 작성한다.\n\n현재 재직 중인 회사는 시리즈 B, 누적 투자 규모 약 300억원의 스타트업이며, 다음 라운드를 준비하고 있다. \n그리고 내가 이 회사에 입사하게 된 계기는 다음과 같다.\n\n\n  팀 차원에서 기술 부채 청산을 생존의 관점으로 생각하고 있다\n    \n      파이썬 2.7로 된 레거시를 자바 or 코틀린으로 갈아엎을 수 있는, 돈을 주고도 경험 해보지 못 할 값진 경험을 해볼 수 있다\n    \n  \n  회사가 시장에서 경쟁력이 있다고 판단했다\n    \n      새로운 투자를 받은 시기가 자이언트 스텝 이후였다\n      주관적으로 BM이 아주 좋다고 생각했다\n    \n  \n  기존에 다니던 회사보다 규모가 더욱 컸다\n    \n      더 큰 규모의 IT 기업에서 일해보고 싶었다\n      규모가 더 큰 만큼, 대기업에서 오신 시니어 개발자분들도 다수 계셨다\n      도메인도 물론 중요하지만, 기술적인 역량은 도메인에 독립적이다\n        \n          도메인 지식은 해당 분야에서 경력을 쌓으면 쌓을수록 자연스럽게 증대될 수 있다\n          기술적인 역량은 퇴근 후 개인의 노력이 가장 중요하지만, 경험이 풍부한 시니어들이 많으면 더욱 빠르게 증대될 수 있다\n          기술적인 역량은 부족한데, 도메인 지식만 풍부하면 다른 도메인으로 이직했을 때 아무것도 못하는 사람이 될 수 있다\n        \n      \n    \n  \n\n\n그런고로 나는 자바와 코틀린밖에 할 줄 모르지만… 최근에 파이썬(그것도 2.7이다)을 새로 학습해서 기존 시스템을 개선하는 데 심혈을 기울이는 중이다.\n\n기존 레거시가 파이썬 2.7에 자체 개발된 프레임워크(😒)라는 보기 드문 레거시라 신규 비즈니스 요구 사항을 충족시키는데 매우 많은 리소스가 점유 되고 있다. \n즉, 그린 필드였다면 5~10분이면 끝났을 작업도 이러한 브라운 필드에서는 몇 일씩 걸리는 작업이 될 수도 있는 것이다. \n아무튼, 스트레스를 꽤 많이 받을거라 예상하면서 들어왔지만, 오히려 생각보다 즐겁게 일하고 있다. \n왜 그런지 생각을 해봤는데, 일이라기보다는 전부 다 내 경험치로 보이는 상태에 더 가까운 것 같다. \n온보딩 기간이라 비중 있는 업무는 안할줄 알았지만, 생각보다 비중 있는 업무들을 맡고 있고 오히려 매우 만족스럽다. \n최근에는 퇴근 후에 하던 개인 공부 시간을 모조리 회사 레거시 개선에 쏟고 있다. \n그냥 회사에서도 일하고 집에서도 일하는데, 이게 일이라고 느껴지지는 않는다. \n이런 게 워라블인가 싶기도 하다. 🧐\n\n온보딩 기간 동안 느낀 점으로는 그동안 해온 CS 공부, 코드 카타 등이 이 정도의 브라운 필드에서도 비즈니스 요구 사항을 별 문제없이 충족시킬 수 있을 만큼 \n내 하드 스킬을 확실하게 끌어 올려줬다고 생각하는 부분이 있고, 이렇게 애자일한 팀에서 일하는데 내 소프트 스킬이 생각보다 미흡하다고 느껴지는 부분도 있다. \n내 생각을 글로 풀어 쓰는 건 자주 해와서 익숙하고 편한데, 내 생각을 실시간으로 여러 사람에게 전달하는 건 생각보다 몹시 어렵다. \n컴퓨터만 붙들고 산 방구석 아싸의 한계에 봉착했다는 생각도 든다.\n\n현재는 회사 차원에서 기술 부채 청산에 많은 리소스를 투자하고 있기 때문에, \n내 작업의 상당수는 기존 레거시를 개선해서 우리 회사 임직원들의 업무 효율을 개선하는 쪽에 치중되어있다. \n이러한 작업을 하면서 역시 크게 느낀 부분은, 개발자라고 요구 사항만 넙죽넙죽 받아서 코딩만 하면 되는 게 아니라는 것이다. \n원래도 이러한 생각을 갖고 있기는 했는데, 이렇게 내 생각을 직접적으로 업무에 적용하고 그 여파를 느끼며 일해보는 건 또 처음이라 꽤 신선하다.\n\nIT 회사들은 아주 크게 보면 사업 -&gt; 기획 &lt;- 제품(디자인, 개발 등) 정도의 구조로 이뤄져 있다고 생각한다. \n사업은 회사가 돈을 벌어서 성장해나갈 수 있게 시장을 개척하는 사람들이다. \n그리고 이 사람들의 생각을 실제 제품으로 구현해 시장에서 임팩트를 내기 위해서는 디자이너, 개발자들이 필요한데, 문제는 이 사람들은 사업을 모르고, 사업하는 사람들은 디자인과 개발을 모른다. \n그러니 중간에서 이들을 조율해줄 수 있는 사람들이 필요한데, 이 사람들이 바로 기획이다. \n즉, 기획은 사업의 말을 제품 그룹이 잘 알아먹을 수 있게, 혹은 반대로 번역해주는 사람들에 가깝다. \n주로 요구 사항을 정리하는데 많은 시간을 쏟는 이유도 이와 일맥상통한다고 생각한다.\n\n문제는, 현재 우리가 하는 작업들의 주 목적은 우리 제품 그룹의 업무 효율을 개선하는 데 있기 때문에 중간에 기획이 없다. \n그래서 타 부서 동료들의 요구 사항이 우리에게 다이렉트로 넘어온다는 점이다. \n우리 개발자들은 타 부서 동료들이 어떻게 일하고 있는지 대체로 잘 모르며, 마찬가지로 타 부서의 동료들 또한 우리 개발자들이 어떻게 일하는지 잘 모른다. \n그러니 타 부서 동료들의 요구 사항이 딴에는 쉽다고 생각되어도 막상 개발로 넘어오면 굉장히 난해한 요구 사항이 될 수도 있는 것이다.\n\n어떻게 해결해야 할까? 답은 생각보다 간단하다. 개발자들이 직접 타 부서 동료들과 마주하고 그들이 어떻게 일하고 있는지 관심을 기울이면 된다. \n그럼 그들의 요구 사항이 더욱 명확하게 와닿기도 하고, 그들의 요구 사항보다 더욱 좋은 해결방안이 떠오르기도 한다. \n혹은 해당 요구 사항이 굳이 개발하지 않아도 되는지도 알 수 있으며(개발 자체가 비용이기 때문에, 때로는 아예 개발하지 않는 것이 더 좋은 경우도 분명 존재한다.), 혹은 해당 요구 사항이 굉장히 중요한 급 건인지도 알 수 있다. \n나 같은 경우엔 직접 요구 사항을 전해온 동료의 자리로 가 어떻게 일하고 있고, 무엇 때문에 불편한지 보여달라고 요구한다.\n\n최근에는 기억나는 작업 중 하나로는 어떤 업무를 자동화해달라는 요구를 받았는데, 티켓을 전달 받은 것이 아니고 해당 실무자분이 내 자리로 직접 와서 요구해 오셨다. \n그래서 대체 어떻길래 직접 찾아와가면서 요구를하시는지 궁금해 어떻게 일하고 계시는지 보여주실 수 있냐고 여쭤봤는데, 그 자리에서 바로 보여주시더라. \n구글 시트에서 고객의 휴대폰 번호를 복사해 우리 어드민에 붙여 넣은 다음 일부 상태를 변경하는 작업이었다. \n문제는 이걸 하루에 수백 번씩 반복하고 있다는 것이었고… 당연히 최대한 빠르게 처리해야 할 일이라는 생각이 들었다.\n\n이제 남은 문제는 어떻게 처리할 것인지였는데, 나는 우선 도메인 자체가 비효율적이기 때문에 이런 상황이 된 게 아닌가? 라는 의문을 가졌다. \n우리 모두의 업무 프로세스와 코드는 결국 도메인을 따라가기 때문에, 도메인이 명확하다면 업무 효율 개선에 큰 도움이 된다. \n하지만 나는 입사한 지 이제 2주 차였기 때문에 도메인에 대해 무지했고, 당장 이분들의 루틴한 업무를 개선해드리기 위해 도메인 파악을 먼저 하기에는 시간이 부족했다. \n아무리 봐도 나한테 하루에 수백 번씩 그 짓거리를 하라고 하면 나 같아도 지칠 것 같았다.\n그러니 일단 땜질을 해서라도 빠르게 자동화부터 하고 보자는 생각이 들었고, 시스템 구조를 살펴봤는데, 또 SaaS가 너무 많이 붙어있어 모든 시스템을 자동화하기에는 공수가 굉장히 많이 들어갈 것으로 판단됐다.\n\n그래서 실무진분들과 미팅을 잡아, 이러한 상황을 설명해 드리고 생각할 시간이 약간 필요하다고 말씀을 드렸는데, 이분들이 “그러면 고객 휴대폰 번호만 보내드리면 쉽게 될수도 있나요?” 라고 역제안을 해오시는 것이다.\n내 입장에서는 그렇게 되면 그냥 어드민에 휴대폰 번호를 수신해서 상태 업데이트만 하면 끝나게 되기 때문에 매우 간단해지는 부분이었고. \n근데 나는 그게 어떻게 가능한지를 잘 몰라서 또 여쭤봤는데, 마케터분들이 쓰시는 브레이즈(Braze)라는 툴이 그걸 가능하게 해줬나 보다.\n\n이 대목에서 나한테 어떤 부분이 부족한지를 또 느꼈었는데, 나는 아무래도 개발자다 보니 평소에 “필요하면 직접 만들지.” 라는 마인드를 갖고 있는데, 그러다 보니 오히려 여러 가지 유용한 툴들을 잘 알지 못한다고 느꼈다.\n오히려 개발을 모르시는 분들이기 때문에 유용한 노코드 툴들을 폭넓게 알고 활용하실 수 있는 건가? 싶기도 했고. \n내가 저런 유용한 도구들을 잘 알고 있고 이것들을 잘 활용할 수도 있고, 소통하는 데도 쓸 수 있다면 생산성이 많이 늘어날 수도 있겠다는 생각이 들었다.\n\n이번 주 수요일에는 리팩토링 데이라 하여 CTO님과 다른 동료 개발자 한 분, 나까지 총 세 명이서 10인실을 종일 사용했다. \n알림톡 시스템을 어떻게 개선할지 계속해서 논의했고, 서로 키보드를 번갈아 잡아가며 코딩했다. \n식사는 배달을 시켜 먹었고, 그 날은 외부의 어떠한 인터럽트도 들어오지 않았다. 우리는 하루를 온전하게 리팩토링에 투자할 수 있었다.\n굉장히 재미있고 유익한 시간이었다고 생각한다. 이러한 경험을 더 많이 할 수 있으면 좋겠다는 생각도 들었다.\n\n아무튼, 한 달 정도밖에 출근하지 않았지만, 현재로서는 이 회사가 굉장히 마음에 든다. \n요즘 좀 엉뚱한 생각을 하는데, 또라이 보존의 법칙이라고 직장을 좀 다니신 분들은 아실 것이다. \n근데 우리 회사에는 내가 볼 때 아무리 봐도 모난 사람이 딱히 없는 것 같은데, 이쯤 되니까 내가 또라이인 게 아닐까? 싶기도 하고…\n\n다음 달에는 회사 사무실이 역삼역 GFC로 이전한다. \n현재 사무실의 크기가 좁다는 생각은 안 드는데, 사무실 대비 인원이 많아지다 보니 사무실이 비좁게 느껴지기는 한다. \n특히 회의실… 그래서 회사 이전이 많이 기대된다.\n여기서 질 좋은 많은 경험을 하고, 사업적으로나 개발적으로나 내 역량이 크게 좋아질 수 있기를 기원한다. \n물론 그만큼 내 시간과 노력도 많이 투자되어야 할 것이다.\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-09-10-diary-44/"
    },{
      "image": "/assets/img/backend/python.png",
      "title": "파이썬 내장 함수 round()는 왜 생각과 다르게 동작하는가?",
      "date": "2022-09-21 00:00:00 +0000",
      "description": "사사오입? 오사오입?\n",
      "content": "\n  사사오입? 오사오입?\n  참고\n\n\n사사오입? 오사오입?\n\n파이썬 내장함수 학습 테스트 도중 알게 된 내용이다. 보통 round 함수는 반올림으로 사용 되는데, 파이썬에서는 생각과 다르게 동작하는 부분이 있었다.\n\n파이썬 인터프리터에 round(1.5)라는 코드를 넘기면 예상대로 반올림 된 값인 2가 반환된다.\n\n\n\n하지만 round(2.5)를 넘기면 3이 아닌 2가 반환된다.\n\n\n\n왜 이러한 현상이 발생하는지 문서를 찾아봤다.\n\n\n  📜 Built-in Functions - Python 3.10.7 documentation\n\n  Return number rounded to ndigits precision after the decimal point. If ndigits is omitted or is None, it returns the nearest integer to its input.\nFor the built-in types supporting round(), values are rounded to the closest multiple of 10 to the power minus ndigits; if two multiples are equally close, rounding is done toward the even choice (so, for example, both round(0.5) and round(-0.5) are 0, and round(1.5) is 2).\n\n\n대상 값이 정확히 중간값이면 짝수가 나오는 방향으로 반올림한다는 내용이다.\n즉, 2.5는 2와 3의 중간값이며 올림 할 경우 홀수인 3이 나오기 때문에, 2.5에서 내림하여 짝수인 2가 나오는 방향으로 연산이 된다는 것이다.\n\n이러한 방식을 오사오입이라고 부르는 듯하다. \n그리고 1~4면 버리고 5~9면 올리는, 흔히 우리가 생각하는 반올림을 옛날 용어로 사사오입이라고 불러왔으며, 이 용어를 대신해 사용되기 시작한 용어가 반올림이라고 한다.\n\n주변 아는 사람들 대여섯 명에게 round(2.5)를 실행하면 어떤 값이 반환될 것 같느냐고 질문했을 때, 모든 사람이 3이 반환 될 것이라고 대답했다. 물론 나도 그러했고… \n그럼 파이썬은 왜 이렇게 사람들의 직관에 반하는 이러한 연산 방식을 표준 내장 함수에 적용했을까?\n\n\n\n그러니까 통계학에서는 변량이 홀수보다 짝수가 많아야 오차가 더 작기 때문에 오사오입이 합리적인데, 파이썬이 수학과 통계 분야에서 많이 사용되기 때문인 듯 하다.\n\n그렇다면 대부분의 일반인들은 왜 수학과 통계 분야에서 사용되는 합리적인(?) 오사오입 방식이 아닌 사사오입 방식을 배우고 사용해왔는가?\n\n\n\n맞는지는 잘 모르겠고, 내 주변 사람들에게 물어본 바, 단 한명의 예외도 없이 1~4는 버리고 5~9는 올린다고 답하는 것을 보면 그냥 이 방식이 사람한테 직관적이기 때문인 게 아닐까 싶기도 하다.\n\n참고\n\n  📜 Built-in Functions - Python 3.10.7 documentation\n  📜 반올림하는 두 가지 방법 (Round-off(사사오입), Round-to-nearest-even(오사오입))\n\n",
      "categories": ["backend","python"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/python/2022-09-21-function-round/"
    },{
      "image": "/assets/img/backend/python.png",
      "title": "파이썬 종속성 충돌 문제 원인 및 해결",
      "date": "2022-09-24 00:00:00 +0000",
      "description": "pip install -r requirements.txt 문제\n",
      "content": "\n  원인\n  해결\n\n\n원인\n\n다음과 같은 모듈간 의존 구조가 있다.\n개발중인 프로젝트가 모듈 A를 의존하는데, 모듈 A는  모듈 B(v1.1)을 의존한다. (module A → module B(v1.1))\n그리고 프로젝트가 별도로 모듈 B(v1.0)을 직접적으로 의존하는 상태이다. (PROJECT → module(v1.0))\n\n그렇다면 프로젝트는 v1.0과 v1.1의 두 모듈 B중 어떤 모듈을 사용해야 할까?\n이러한 상황을 dependency conflict 라고 부른다.\n\n\n\n실제로 이러한 상황이 발생하면 pip에서는 다음과 같은 에러 메시지를 출력한다.\n\nThe conflict is caused by:\n    The user requested google-auth==2.6.0\n    google-api-core 2.2.2 depends on google-auth&lt;3.0dev and &gt;=1.25.0\n    google-api-python-client 2.2.0 depends on google-auth&lt;2dev and &gt;=1.16.0\n\n\n해석을 해보면, 유저가 google-auth 2.6.0을 사용하겠다고 requirements.txt에 명시해뒀으나, google-api-core와 google-api-python-client가 google-auth 2.6.0이 아닌 다른 버전을 또 의존하고 있고, \n이러한 다른 버전들을 가져오려고 하고 있기 때문에 google-auth==2.6.0 라는 구문과 충돌이 나는 것이다.\n\n해결\n\npip는 다음과 같은 해결 방식을 제시한다.\n\nTo fix this you could try to:\n1. loosen the range of package versions you've specified\n  (종속성 버전을 특정하지 말고 느슨하게 한다)\n2. remove package versions to allow pip attempt to solve the dependency conflict\n  (pip가 종속성 충돌을 해결할 수 있도록 패키지 버전을 제거한다)\n\n\n\n\nrequirements.txt 에서 google-auth==2.6.0 을 제거한다면 모듈 A가 2.6.0이 아닌 google-auth를 가져오려 해도 충돌날 일이 없다.\n\n혹은, == 연산자로 종속성 버전을 특정하지 말고 &gt;, &gt;=, &lt;, &lt;= 등의 연산자로 느슨하게 잡는다.\n\n최근에 자바 진영에서 많이 사용되는 Gradle은 이러한 문제를 해결하기 위해 의존 구조에 가시성을 부여하는 방식을 도입했다.\ncompile 함수를 통해 모듈을 가져오면 하위 모듈을 모두 가져오는 셈인데(compile 함수는 최신 버전의 Gradle에서 deprecated 되었으며, 이러한 동작을 원한다면 api 함수 사용을 권장한다), 최근 Gradle에서 강력하게 권장하는 함수는 implementation 으로 모듈 A를 가져오면, 실제로 모듈 B도 함께 가져와지지만 프로젝트는 모듈 B의 존재를 모르게 된다.\n파이썬 진영에서는 이러한 방식을 사용하고 있는지 검색을 해봤으나, 이에 대해 찾지 못했다. 아마 pip의 가이드를 통해 추측하기로는 아직 가시성을 활용하는 방식이 지원되지 않고 있는게 아닐까?\n",
      "categories": ["backend","python"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/python/2022-09-24-pip-dependency-conflict/"
    },{
      "image": "https://user-images.githubusercontent.com/71188307/192101873-987a0da6-bdfd-42ee-9655-f1b2fb37bb95.png",
      "title": "클린 코드, 기술 부채, 성공적인 프로젝트",
      "date": "2022-09-24 00:00:00 +0000",
      "description": "클린 코드는 왜 중요한가?\n",
      "content": "프로젝트를 일정하게 예측 가능한 속도로 개발하기 위해서는 유지 보수성이 뛰어난 코드가 필수적인데, 클린 코드는 프로젝트의 유지 보수성을 향상시켜주고 이는 기술 부채를 감소시키는 선순환을 일으켜 프로젝트가 성공적으로 진행 될 수 있게 도와준다.\n\n차를 운전한다고 가정해보자. \n차에 아무런 문제가 없고, 목적지까지의 도로가 아주 깨끗하게 관리되어 있으며, 다른 차들도 거의 없어 교통정체조차 일어나지 않는다면 목적지에 도착하는 시점을 꽤 정확하게 예측할 수 있을 것이다. \n하지만 목적지까지 운전하는 도중 자연재해로 도로가 파손되어 먼 길을 돌아가야 한다거나, 차에 문제가 생겨 중간에 정비소에 들러야 한다면 도착 시점을 특정하기가 매우 어려울 것이다.\n\n소프트웨어 개발도 이와 비슷하다. \n일정하게 예측 가능한 속도로 개발하기 위해서는 기존의 코드를 최대한 짧은 시간 안에 최대한 정확하게 파악할 수 있어야 한다. \n그래서 소프트웨어 개발에서 코드의 가독성은 매우 중요한 요소 중 하나이다. \n코드를 파악하기도, 기존의 코드를 수정하기도 매우 어렵다면 새로운 요구사항이 들어올 때마다 그동안 차곡차곡 쌓아왔던 기술 부채를 해결하기 위한 추가적인 작업을 거쳐야 할 것이고, 이러면 요구사항에 대한 중요한 개발 작업은 매끄럽게 진행될 수 없을 것이다.\n\n기술 부채는 개발자의 올바르지 않았던 결정이나, trade-off를 고려한 적당한 타협의 결과로 생긴 소프트웨어의 결함을 의미한다.\n대부분의 부채는 이자를 유발하는데, 코드는 지금 바꾸는 것보다 미래에 변경하는 것이 대부분 더 어려우므로 부채라는 단어가 딱 어울린다. \n기술 부채가 발생했다는 것은 내일은 코드를 수정하기가 더 어렵고 내일모레는 더더욱 어려워질 것이라는 의미이다.\n\n개발팀이 제시간에 클라이언트가 원하는 것을 제공할 수 없어 기존의 코드를 개선하기 위해 멈춘다는 것은 기술 부채에 대한 이자를 지불한다는 뜻이다. \n기술 부채는 지금 당장 정신 사납게 시끄러운 경고음을 내는 그런 문제는 아니다. 기술 부채는 프로젝트에 전역적으로 흩어져 있는 잠재적인 문제이며, 이것들은 언젠가 깨어나 프로젝트 진행에 제동을 거는 돌발 변수가 될 것이다.\n현재 본인이나 동료가 마주친 문제는 과거에 잘못 작성 된 코드로 인해 발생한 문제일 수도 있다. \n그러니 코드를 작성할 때, 현재 마주친 문제를 적절하게 해결하기 위해 충분한 시간을 투자하지 않고 또 다시 지름길로 가기로 결정한다면 그 코드를 유지 보수하게 될 미래의 본인이나 동료가 어떠한 어려움을 겪게 될지 한 번쯤은 충분한 시간을 들여 고민을 해 보자.\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-09-24-diary-45/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "IntelliJ failed to start with code 3",
      "date": "2022-10-12 00:00:00 +0000",
      "description": "window &amp; fleet\n",
      "content": "\n  🚨 문제\n  🚧 원인\n  ✅ 해결\n\n\n\n\n🚨 문제\n\n\n\n오늘부터 JetBrains 의 Fleet이 공개 테스트에 돌입했다.\nFleet은 에디터 모드와 스마트 모드로 나뉘는데, 처음 켜질때는 에디터 모드로 켜져 매우 빠르게 실행되고, 스마트 모드를 키게되면 IDE가 된다.\n아는 동생이 윈도우 환경에서 Fleet을 설치한 후 스마트 모드를 키자 IntelliJ failed to start with code 3 라는 에러가 발생하며 켜지지 않았다.\n\n🚧 원인\n\n로그를 뽑아보니 다음과 같은 내용이 출력됐다.\n\nfleet.controller.ManagedProcessAbnormalExitException: Process [cmd, /C, fleet_backend.bat, FleetStarter, 127.0.0.1, 56803, f1trui9nu21hj7qr2inf, 9vm2eafrfakbegbp59ea] finished with exit code 3. Check log for details.\nintellij backend\n3\nat fleet.controller/fleet.controller.ProcessHolder.start$lambda-2(FleetController.kt:103)\nat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(Unknown Source)\nat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(Unknown Source)\nat java.base/java.util.concurrent.CompletableFuture.postComplete(Unknown Source)\nat java.base/java.util.concurrent.CompletableFuture.postFire(Unknown Source)\nat java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(Unknown Source)\nat java.base/java.util.concurrent.CompletableFuture$Completion.exec(Unknown Source)\nat java.base/java.util.concurrent.ForkJoinTask.doExec(Unknown Source)\nat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(Unknown Source)\nat java.base/java.util.concurrent.ForkJoinPool.scan(Unknown Source)\nat java.base/java.util.concurrent.ForkJoinPool.runWorker(Unknown Source)\nat java.base/java.util.concurrent.ForkJoinWorkerThread.run(Unknown Source)\n\n\n로그를 보아하니 스마트 모드가 백그라운드에 인텔리제이를 켜서 써먹는 것 같은데, cmd로 인텔리제이를 킬때 제대로 켜지지 않은걸로 보인다.\n\n✅ 해결\n\nFleet을 설치하기 위해 별도로 설치한 JetBrains ToolBox를 관리자 권한으로 실행하니 해결됐다.\n",
      "categories": ["debugging"],
      "tags": [],
      
      "collection": "posts",
      "url": "/debugging/2022-10-12-debugging-17/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "대기업들이 시장에 MSA라는 독을 풀었다",
      "date": "2022-10-19 00:00:00 +0000",
      "description": "대부분의 기업들에게 MSA는 신기루와 같다. MSA에서 모듈형 모놀리식 아키텍처로의 전환 이유.\n",
      "content": "요즘 여러 채용 공고를 보면 기업 규모도 작은데 맹목적으로 MSA, 쿠버네티스 등의 키워드를 남발하는 경향이 있습니다. \nMSA는 몇몇 대기업에게는 매우 유용한 방법론일 수 있지만, 스타트업이나 중소기업들이 그저 대기업을 흉내내기 위해 쉽게 따라하는 것은 절대적으로 지양해야 합니다.\n\n저는 현재 시리즈 B 규모의 스타트업에 근무하고 있으며, MSA를 모듈형 모놀리식 아키텍처로 전환하는 작업을 진행하고 있습니다. \n제가 입사 후 가장 큰 문제로 제기했던 것은 서버 비용인데, 당시 MSA로 인해 서버비가 매달 약 4,000만원 가량 발생하고 있었으며, 많은 마이크로서비스가 통폐합된 현재는 한달에 약 2,000만원 가량의 서버 비용이 발생하고 있는 상황입니다. \n자금 흐름이 중요한 스타트업에 이 정도의 서버 비용이 얼마나 큰 부담이 될지는 대부분 아시리라 생각합니다. 그리고 아직도 비용을 절감할 포인트는 굉장히 많이 남아있는 상황입니다.\n\n서버비 외의 다른 문제들도 많은데, 간단한 테스트를 위해 로컬 환경에 항상 다수의 마이크로서비스를 실행해야만 하는 큰 번거로움이 있으며, 각 마이크로서비스 간 의존성으로 인한 시스템 복잡도도 굉장한 수준입니다. 서비스가 많은 만큼 배포도 굉장히 복잡합니다. \n서버에서 많은 서비스들이 실행되고 있으나 트래픽이 많지 않아 서버의 컴퓨팅 리소스를 100% 효율적으로 사용하지 못하고 낭비하고 있기도 하며, 에러가 발생하면 각 마이크로서비스를 넘나들며 디버깅을 해야만 하는 일이 생기기도 합니다.\n\n관리 포인트가 이렇게 많아지니 근무중인 개발자가 적은 스타트업에서는 개발자들에게 굉장한 부담을 주고 있기도 합니다.\n\n나열된 이 모든 낭비되는 비용들은 이전 라운드에 근무하던 CTO가 합당한 근거 없이 무리하게 MSA를 도입한 바람에 발생한 문제들입니다.\n시리즈 B에 진입하며 새로 입사하신(저를 포함한) 모든 개발자분들은 MSA가 문제라는데에 모두 공감하셨고 MSA를 모듈형 모놀리식 아키텍처로 전환하는데 동의하게 됐습니다.\n\n이 잘못된 단 한번의 결정으로 인해 회사는 회복하기 힘든 굉장한 손해를 입었으며, 근 1년간 이 손해를 메꾸기 위한 작업들이 진행중이고, 이 작업은 아직도 끝이 보이지 않습니다.\n마지막으로, 무리하게 MSA를 도입했던 CTO는 이에 대한 책임은 하나도 지지 않고 퇴사하며 자신의 커리어에 MSA 전환 경험 한 줄을 적어갔습니다.\n\nMSA로의 전환에 성공하고 MSA를 찬양하는 기업들에는 공통점이 있습니다. \nDB가 SPOF(Single Point of Failure)가 되었다는 점입니다. \n이러한 기업들은 트래픽과 데이터가 상상할 수 없을 정도로 많기 때문에 DB 장애가 자주 발생하고, 이 장애가 모든 서비스로 전파되어 MSA 전환을 생존 과제로 여겼으며, 결국 성공했습니다. \n그래서 MSA로 전환에 성공한 기업들의 성공 이야기에는 DB를 분리하는 작업이 핵심적으로 언급됩니다.\n\n웹 애플리케이션 서버는 DB가 ACID를 보장해주기 때문에 대량의 외부 요청이 입력되어도 스케일아웃을 통해 CPU와 I/O 부하를 아주 쉽게 분산시킬 수 있습니다.\n하지만 DB는 컴퓨터 부품 중 가장 느린 하드 디스크와 직접적으로 상호작용하며 읽기와 쓰기 작업을 수행하기 때문에 작업 속도가 굉장히 느리며, 데이터의 정합성을 보장해줘야하는 막중한 책임을 갖기 때문에 스케일아웃을 통한 부하 분산이 너무 어렵습니다. \n예를 들어, 스케일아웃을 해 A와 B라는 두 개의 DB가 존재한다면, A라는 DB에 데이터를 쓰는 즉시 A와 B 두 DB의 데이터가 상이해집니다. \n이러한 문제를 해결하기 위해 A와 B 두 DB의 데이터를 항상 동기화해줘야하는 기술적인 과제가 발생하며, 이 과제는 해결하기가 굉장히 어렵습니다. \n이렇게 DB를 스케일아웃하면 읽기와 쓰기 시 각 DB 간 데이터의 정합성을 맞추기가 어려워지므로 DB에서 스케일아웃은 효율적이지 않습니다.\n이러한 이유로 DB에서는 스케일업을 통한 해결을 주로 시도합니다. \n메모리는 전기 신호를 통해 모든 작업을 빛의 속도로 처리할 수 있지만, HDD는 디스크 암이 대상 섹터가 위치한 실린더로 이동하고 디스크 헤드가 섹터의 위치에 도달해야 데이터를 읽거나 쓸 수 있기 때문에 빛의 속도에 비해 너무 느리게 동작합니다. \n이런 디스크 I/O 시간은 웹 애플리케이션의 API 지연 시간에 추가되며, 디스크 I/O로 인한 지연은 대체로 ms~s 이상의 아주 큰 시간입니다. \nSSD를 사용하면 메모리만큼은 아니더라도 그에 준하게 빨라질 수 있지만 대용량 스토리지를 전부 SSD로 대체하는 것은 비용이 많이 들기 때문에 아직도 많은 기업에서는 HDD를 사용하고 있습니다. \n이렇게 느린 디스크 I/O를 최소화하기 위해 메모리를 증설하고 메모리에 데이터를 적극적으로 캐싱해 디스크 I/O를 최소화합니다.\n\n추가로 DB의 성능이 충분하지 않을 경우, 테이블을 컴팩트하게, 정규화 이론에 따라 재설계하고, 인덱스를 설계하고 쿼리를 튜닝하는 등의 작업도 시도 할 수 있습니다. (이러한 작업들이 아주 잘 된다면 대체로 DB로 인한 성능 문제를 겪지 않을 겁니다.) \n예를 들어, 1억 개의 레코드가 있는 테이블에서 8바이트 크기의 컬럼 하나를 제거하는것만으로 스토리지 용량이 약 1GB 절약될 수 있습니다. \n또한, 레플리케이션과 테이블 파티셔닝을 효율적으로 적용하여 읽기 요청을 여러 슬레이브 노드에 분산시키면 각 슬레이브 노드가 특정 테이블에만 액세스할 수도 있으므로 OS 캐시도 효과적으로 활용될 수 있습니다. \n조금 더 자세히 설명하자면, 한 슬레이브 노드가 A 테이블을 스캔하고 A 테이블의 데이터를 메모리에 캐싱한 상태에서 B 테이블에 대한 액세스 요청이 들어올 경우 B 테이블의 데이터도 메모리에 캐싱하려 할 수 있습니다. \n이때, 메모리 부족으로 페이지 스왑이 발생한다면 메모리에서 A 테이블의 데이터를 비우고 B 테이블의 데이터를 캐싱하게 됩니다. \n이렇게 되면 다음 읽기시 페이지 폴트가 발생할 확률이 높아지고 결국 여러 이유로 인해 디스크 I/O가 빈번하게 발생하게 됩니다. \n그러나 해당 슬레이브 노드가 계속해서 A 테이블만 액세스한다면, 처음 액세스 이후로는 이미 필요한 데이터가 메모리에 캐싱되어 있을 확률이 높기 때문에 디스크 I/O가 최소화됩니다.\n\n하지만 위의 모든 작업을 수행해도 여전히 DB 장애가 발생한다면, 그 기업은 아주 높은 확률로 이미 많은 사용자와 트래픽, 데이터를 다루는 큰 기업일 것입니다. 당연히 개발자도 많을겁니다. \n이런 상황에서야 비로소 MSA로의 전환을 고려할 수 있는 최소한의 요건을 충족한다고 볼 수 있습니다. \n또한, MSA 전환으로 인해 레디스, 몽고DB, 엘라스틱서치 등과 같이 각 서비스에 특화된 효율적인 DB를 사용할 수 있게 될수도 있습니다. \n시간이 지난 후에 분리된 DB가 다시 커진다면 이러한 작업을 반복해 여러 개의 마이크로서비스로 다시 분리할 수 있을 겁니다. \n(전 세계적으로 유명한 MAANG 기업들의 사례를 상기해보면 그들의 마이크로서비스는 전 세계에 네트워크처럼 퍼져있습니다.)\n\n이제 도커와 쿠버네티스에 대해 생각해보겠습니다. \n도커는 대표적인 컨테이너 기술로, 프로세스를 컨테이너로 감싸고 독립적인 환경에서 동작하는 것처럼 격리해 한정된 컴퓨팅 리소스를 사용할 수 있도록 제한해줍니다.\n원래 도커가 탄생하게 된 계기는 이식성이었습니다. 내 로컬에서는 되는데 배포만 하면 안되네? 라는 문제가 있었던 것이죠. 근데 이 문제는 JVM 기반의 언어들에 대해서는 해당사항이 없습니다.\n그렇다면 도커를 사용함으로써 얻을 수 있는 다른 효과는 프로세스들이 한정된 컴퓨팅 리소스를 사용하도록 강제하는 것인데요, 그러나 이러한 효과를 충분히 누리기 위해서는 서버에 여러 개의 프로세스가 떠 있어야 한다는 요구사항이 있어야 합니다. \n그리고 이러한 요구사항이 생길만한 대표적인 사례는 MSA라고 볼 수 있습니다. 하나의 서버에서 여러 개의 프로세스를 운영해야 하는 경우입니다. \n하지만, 모놀리식 아키텍처로 개발하고 서버에 단일 프로세스를 유지하는 것이 컴퓨팅 리소스를 최대한 활용하는 효율적인 방법일 수 있습니다. \n왜냐하면, 서버에 필요 이상으로 많은 프로세스가 실행된다면 CPU 스케쥴링과 컨텍스트 스위칭으로 인한 오버헤드가 극대화될 수 있기 때문입니다. \n게다가 단일 프로세스였다면 메모리 내 함수 호출로 끝났을 작업들이 IPC를 통해 이뤄져야 하므로 이 또한 추가적인 오버헤드를 유발합니다. \n이러한 이유들로 컨테이너 기술은 데이터가 많지 않고 서비스가 작은 대부분의 기업에서는 필요하지 않을겁니다. \n(도커가 로컬 개발 환경 구축에 유용하다는 주장에는 이견의 여지가 없다고 생각합니다.)\n\n쿠버네티스는 왜 사용할까요? \n예를 들어, 하나의 프로세스를 두 개로 분리하여 서버에 A와 B라는 두 개의 프로세스를 컨테이너로 띄웠다고 가정해봅시다. \nA 프로세스에 트래픽이 집중되어 자신에게 주어진 컴퓨팅 리소스가 부족해진다면, 서버 관리자는 B 프로세스에서 일부 리소스를 뺏어와 A 프로세스에 할당해야 합니다. \n이러한 작업을 수동으로 수행하는 것은 번거로울 뿐만 아니라 복잡합니다. \n이런 이유로 쿠버네티스라는 기술이 등장했습니다. \n쿠버네티스는 컨테이너 오케스트레이션을 제공하여 자동으로 리소스 관리와 프로세스 간의 상호 작용을 관리합니다. \n이를 통해 프로세스 간 리소스 조정이 자동화되어 효율적으로 운영됩니다. \n그러나 쿠버네티스 역시 컨테이너를 사용하지 않으면 필요가 없는 기술입니다. \n결과적으로 MSA로의 전환이 전혀 필요하지 않은 대부분의 기업에서는 도커와 쿠버네티스는 유의미한 효과를 가져다주기 힘들겁니다.\n나중에 회사가 커졌을 때, 정말 필요할 때 학습하고 도입해도 늦지 않습니다.\n\nMSA를 도입하는 결정을 내리기 전에 기업의 현재 상황과 요구사항을 신중하게 고려하고, MSA가 정말로 필요한지 신중하게 검토해야 합니다. \n데이터베이스와 서버의 성능 개선을 통해 문제를 해결할 수 있는지, 기업의 규모와 트래픽이 반드시 MSA로 전환해야 하는 수준인지 등을 고려해야 합니다. \n필요한 경우에는 MSA를 도입하되, 그 결정은 신중하게 내려야 합니다.\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-10-19-diary-46/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "회사에서는 제발 바로바로 질문을 하세요",
      "date": "2022-11-19 00:00:00 +0000",
      "description": "질문을 하지 않으면 평생 바보가 되지만, 질문을 하면 5분 동안만 바보가 되면 됩니다\n",
      "content": "온라인 커뮤니티를 보다 보면 질문자의 무성의한 질문에 굉장히 공격적인 태도를 보이는 사람들이 많은 것을 흔하게 볼 수 있다.\n이는 온라인 커뮤니티의 특성에서 기인했다고도 볼 수 있는데, 서로 아무런 접점이 없는 온라인 커뮤니티에서는 서로에게 지식을 공유해 생산성을 올릴 이유도 필요도 없기 때문이다.\n그들은 커뮤니티에 중복된 자료가 생기지 않게 관리해야 하며, 같은 목적을 가지고 함께 시간을 사용하고 있는 관계도 아니다. 단지 각자의 시간이 귀중한 사람들일 뿐이다.\n위의 내용이 잘 이해되지 않는다면 스택 오버플로에 접속해 구경도 해보고, 질문 글도 작성해보면 이해할 수 있게 될 것이다.\n\n따라서 온라인 커뮤니티에서 질문할 때는 자신의 상황이 어떻고, 어떤 문제가 있었고, 어떠한 것들을 시도해봤고, 어떤 도움이 필요한지를 상세하게 기술할 필요가 있다.\n그래야 답변자가 질문자의 상황을 제대로 이해하고 올바른 답변을 줄 확률이 높아진다.\n이렇게 성의있는 질문을 올렸음에도 여전히 공격적인 태도를 보이는 답변자들이 있다면 그 답변자들이 이상한 것이다.\n또한, 사실 질문이 매우 무성의했더라도 거기에 대고 핑프니 뭐니 해가며 댓글을 작성할 필요조차 없기도 하다.\n도와주기 위해 관련 링크를 첨부해 댓글을 작성하나, 질문자를 비난하기 위해 댓글을 작성하나 드는 시간은 비슷하지만, 전자는 질문자가 도움을 받을 확률이 조금이라도 존재하는 데 반해, 후자는 생산성조차 바닥을 치는 무의미한 행위이기 때문이다.\n따라서 차라리 질문자를 비난하고 싶더라도 댓글을 달지 않고 조용히 뒤로 가기를 눌러 관심을 주지 않는 게 오히려 커뮤니티의 문화 형성에도 도움이 될 것이다. 가장 무서운것은 무관심이다.\n\n문제는 위의 문화를 회사에 들고와서 행동하는 사람들이 꽤 존재한다는 것이다.\n회사에서는 아무리 사소한 것이라도 동료에게 편하게 질문할 수 있는 환경이 굉장히 중요하며, 이러한 문화가 잘 정착되어있는 팀이라면 그 팀의 생산성은 굉장히 좋을 것이 분명하다.\n떠오르는 이유를 몇 가지 적어보자면,\n\n\n  회사에서 발생한 문제는 함께 일하고 있는 동료들이 상세하게 알고 있을 확률이 매우 높다.\n  인터넷에 존재하는 솔루션은 대부분 범용적인 상황에 대한 것이며, 회사의 상황에 맞게 재해석해야 하는 과정이 필요할 확률이 높다.\n  회사의 동료들은 같은 목적을 가지고 함께 시간을 사용하고 있으므로 서로의 생산성을 끌어 올리는 것이 가장 중요하다.\n  동료가 어떤 것을 모르는지를 알아야 문서를 보강하던, 온보딩을 보강하던 어떠한 대책이라도 세울 수 있어진다.\n  몰입을 깨준다. 몰입의 장점도 분명히 많지만, 단점도 많다. 예시를 하나 들자면, 한 문제에 꽂혀 시야가 매우 좁아질 수 있다. 시야를 넓게 가지면 쉽게 해결될 문제가 많다.\n\n\n질문자를 쉽게 비난해 질문하기를 꺼리는 문화가 팀에 정착된다면 위의 장점들을 모두 누리지 못하고 사일로 현상이 심해지며, 한번 생긴 이러한 심리적인 장벽은 다시 허물기 위해 매우 많은 시간과 노력이 필요하다.\n계속해서 강조하지만, 회사에서 일할 때는 생산성이 가장 중요하다. 이러한 이유로 알아서 찾아보고 될 때까지 해보다가 안 되면 그때 질문하라는 마인드를 가진 사람들과는 함께 일하기가 꺼려진다.\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2022-11-19-diary-47/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "2022년 회고",
      "date": "2023-01-28 00:00:00 +0000",
      "description": "덕업일치를 이루니 워라블이 아주 잘 맞더라\n",
      "content": "이제 사회생활 11년 차다.\n\n개발자로서는 이제 경력이 만 2년이니 3년 차다.\n\n그동안의 행적을 정리하고 앞으로의 목표를 정하며 2022년 회고를 한번 작성해본다.\n\n정말 천직을 찾았구나!\n\n집이 정말 가난해서 중학생 때 군대에 가지 않고 돈을 벌겠다고 생각했고, 방법을 알아보던 중 산업기능요원, 그러니까 병역특례 혹은 병특이라고 알려진 제도를 알게 됐다.\n이 제도를 이용하기 위해 준비했고, 산업기능요원으로서 20살에 사회생활을 시작할 수 있게 되었다. 직장에선 쉴 틈 없이 일해 돈을 벌고, 퇴근 후엔 취미를 즐겼다.\n나에게 직장은 단순히 생활을 영위하기 위해 돈을 벌러 가는 곳이었을 뿐이다. 이 시기의 나는 워라밸을 추구했었다.\n\n20대 중후반에는 내 평생의 꿈 중 하나를 성취할 수 있었다.\n어릴 때부터 이사를 워낙 많이 다녔기에 이사를 하는 게 정말 지긋지긋해서 내 집을 갖는 게 평생의 소원 중 하나가 되었는데, 다행히 사회생활을 일찍 시작한 만큼 돈을 차곡차곡 모아서 대출을 끼고 내 집을 마련할 수 있었다.\n언젠가 등본을 뗐는데, 장표가 많이 나오길래 뭔가 하여 보니 모두 이사기록이었고, 내가 이사를 한 횟수가 20번 가까이 되었던 기억이 난다… 😩\n\n2020년에 갑자기 어머니가 장의 1/3가량을 절제하는 큰 수술을 하게 되셨다. 다니던 직장을 그만두고 서울로 올라왔다.\n당시는 코로나가 한참 난리였던 시기여서 보호자 신분으로 어머니와 함께 병원에 들어간 후 2개월 가까이 밖으로 잘 나오질 못했다.\n\n그리고 이 사건은 내가 개발자로 직종 전환을 하게 된 가장 큰 계기가 되었다.\n\n병원에서 갑자기 큰 수술을 하게 되어 누워계신 어머니와, 아픈 많은 사람을 보면서 정말 많은 생각이 들었다.\n병실의 밤은 마치 온 세상에 죽음이 깔린 느낌이었으며, 이런 상황에 쳐해지니 돈만 보고 살아온 그동안의 10년 가까운 내 세월이 덧없게 느껴졌다.\n막말로 나도 출퇴근하다 갑자기 교통사고를 당해 죽으면 내 수중에 돈이 얼마가 있던 아무런 의미가 없지 않겠는가?\n\n병원에서 퇴원한 후 나는 다시 직장을 구해야 했는데, 이때 내 관심사는 단 하나였다.\n“내가 즐겁게 할 수 있는 일을 내 직업으로 가져야겠다.”\n나는 평생을 취미생활이 직업이 되면 그조차 재미가 없어지고 말 것이라고 생각을 해온 사람이었는데, 이 시기의 나는 이 생각을 뒤집고 재미있는 일을 하고 싶었다.\n근데 진심으로 내가 뭘 좋아하는지 나조차도 알 수가 없어서 어떤 직업을 골라야 할지 알 수 없었다.\n그래서 한참을 궁리한 끝에 여러 가지 검사들을 해봤다. 심리검사, 적성검사, 직무검사 등을… 내 스스로를 모르겠다면 검사를 받으면 된다고 생각했다.\n모든 검사 결과의 교집합에 추천 직업으로 개발자라는 직종이 있었고, 나는 그 즉시 C언어 책을 하나 사 들고 공부를 시작했다.\n사실 모든 과정이 굉장히 미심쩍었는데, 막상 코딩을 시작해보니 정말 재미있어서 금방 결정할 수 있었다.\n\n공부는 어떻게?\n\n학원은 다 사짜였다. 딱 봐도 제대로 아는 게 없어 보이는 사람들이 강의하고 있는 곳이 많았다.\n나는 사회생활을 오래 한 만큼 사기꾼(?) 같아 보이는 사람들을 보는 즉시 알 수 있었다.\n\n그래서 그냥 독학했다. 책, 인터넷 강의의 도움을 많이 받았다. 개발 관련 자료들은 인터넷에 무료로 모두 풀려있었고, 이를 제대로 이해할 수 있는 기본기만 갖출 수 있으면 되었다.\n책이나 강의를 보면서 내가 보고 들은 한 문장에 내가 제대로 이해하지 못하는 단어가 단 하나라도 있으면 그 단어부터 다시 찾아보러 갔다.\n내가 생각하기에 공부할 때 가장 중요한 것은 메타인지다. 자기 객관화, 내가 알고 있는 게 제대로 알고 있는 게 맞는 것인지 등을 객관적인 시선으로 바라볼 수 있어야 한다.\n그리고 사실 공부고 자시고 할 것도 없는 게 그냥 엄청 재미있어서 이것저것 닥치는 대로 다 보고 닥치는 대로 다 코딩했다.\n\n돌이켜보면 이때 한 공부량을 고등학생 때 했으면 최소 서성한 라인 정도는 그냥 갔지 않았을까 싶긴 하다. 물론 나는 수능이란걸 봐본적이 없는 녀석이기 때문에 헛된 망상에 가까울 것이다. (ㅋㅋ)\n아무튼 이때 제일 어려운 건 영어였고, 영어로 된 문서들은 번역기의 도움을 받아 가면서 봤다.\n영어를 더럽게 못 하니 굉장히 지루하고 어렵고 힘든 일이었는데 그래도 피하지 않으려고 했다.\n당장 힘들어도 영어에 익숙해지는 게 장기적으로 좋다고 생각했다. 이 생각과 행동원칙은 아직도 계속 유효하다.\n\n첫직장 회고\n\n21년 2월 1일에 개발자로서 첫 회사에 취업하게 되었다.\n회사는 굉장히 안정적이고 보수적이었다.\n사실 개발팀은 그렇게 보수적이라고 느끼진 않았는데, C 레벨의 성향이 보수적이었고, 이게 회사의 운영방침이 되었다.\n워라밸은 칼같이 지켜졌고, 업무는 한가했다. 그래서 자기 계발에 많은 시간을 할애할 수 있었다.\n\n이때 내가 가장 크게 성장을 했다고 생각하는 것은 내가 한가한 시간에 계속 진행한 코드 카타다.\n코딩을 훈련처럼 하는 것인데, 간단한 주제와 무지막지하게 빡빡한 코딩 규약을 정하고 이에 맞게 코딩을 진행한다.\n그리고 코딩을 마치면 작성한 모든 코드를 폐기하고 처음부터 다시 작성한다. 단, 이전에 진행했던 방식과는 차별화된 방식을 생각하고 적용해야 했다.\n위의 순서를 계속 반복한다.\n\n나는 이 훈련을 몇 달 동안 반복하면서 간단한 CRUD를 할 수 있는 게시판 API와 테스트 코드를 10분 이내에 모조리 구현할 수 있을 정도로 자바 코딩에 능숙해질 수 있었고, 실패에 대한 두려움을 없앨 수 있었다.\n실패에 대한 두려움이란 이런 거다. 내가 아무것도 없는 빈 프로젝트에서 어떤 것을 개발해야 한다고 상상해보자. 나는 아무런 부담감 없이, 거리낌 없이 개발을 즉시 진행할 수 있을까?\n나는 더 아름다운 코드를 작성하고 싶은 욕심에 코딩을 시작조차 못 하는 상황을 많이 겪어왔고, 훈련 끝에 이 욕심을 버릴 수 있게 되었다. 아름다운 코드는 테스트 코드와 리팩토링으로 추구할 수 있다는 것을 알 수 있게 되었다.\n그리고 테스트 코드를 작성할 수 있는 코드란 것은 이미 그 자체로 훌륭한 설계가 뒷받침된 것임도 알 수 있게 되었다.\n\n그리고 비전공자인 만큼(사실 전공이랄게 없다. 고졸이니까.) KOCW와 책을 통해 운영체제, 네트워크, 데이터베이스, 자료구조 등의 컴퓨터 과학 기본기에 계속 시간을 투자했다. 겸사겸사 이때 정보처리기사도 취득했다.\n정보처리기사의 경우 막 개편된 시점이었는데 이때 합격률이 3%였다. 목적이 자격증을 취득하는데 있지 않았고, 그냥 기사 자격증(조건이 4년제 졸업인 자격증이므로)의 필기과목을 다 씹어먹으면 전공자 뒤꽁무니에라도 비벼볼 수준은 되지 않을까? 였다. \n그리고 이 정도 되면 자격증은 그냥 따라오는거라고 생각했고, 이 생각은 유효했다. 정보처리기사 필기 과목을 빡세게 공부한 후 적어도 내가 뭘 모르는지 정도는 아는 상태가 됐다고 생각한다. 막히면 어떤 키워드로 검색해봐야 하는지 알게 됐다.\n이 시기의 나는 회사에서는 회사 업무에 충실하고(이때 리팩토링, 디자인패턴을 실무에서 많이 연습해볼 수 있었다), 퇴근 후에는 CS와 코드 카타를 병행하는 삶의 나날이었다. 재미가 없었다면 계속할 수 없었을 거다.\n\n첫번째 이직\n\n그동안 쌓아온 개발 실력과 업무 능력을 팀장님께 인정받아 연봉이 천만원 이상 올랐다.\n우리 회사에서 굉장히 이례적인 일이었고 이때 회사에 여러 가지 말이 많았던 걸로 안다.\n\n근데 결국 작년 중순에 현 직장으로 이직했다. 이유는 아주 단순했다.\n다니고 있던 회사는 성장에 대한 열망이 없다고 느꼈기 때문이다.\n돈은 물론 중요하고 다다익선이지만, 나한테 이제 돈은 사실 내가 먹고 싶은 거 먹고, 사고 싶은 거 부담 없이 살 수 있을 정도만 받으면 더 욕심을 부릴만한 가치가 없는 그런 것이였다.\n\n나는 오늘의 나보다 내일의 내가 조금이라도 더 나아질 거라 믿고, 성장에서 오는 재미에 중독되어있었다.\n이제 직장은 나한테 자아실현, 지적성장의 장이었다.\n\n근데 내가 아무리 성장을 해도 회사의 성장이 정체되면 나의 성장도 둔화될 수밖에 없다.\n내가 다니던 회사는 안정적이었고, 보수적이었다. 대부분의 임직원이 공무원처럼 일하는 곳이었다. 업무는 치열하지 않았고, 워라밸은 철저하게 지켜졌다.\n\n즉, 도전의 기회가 없었다.\n\n이게 나쁘다는 게 아니다.\n\n단지 나한테 잘 맞지 않았을 뿐.\n도전이 없다면 실패도 없고, 실패가 없다면 성장도 없다.\n개개인이 성장하지 못하는데, 회사가 성장할 수 있을까?\n\n지금 다니는 회사에 오게 된 계기는 사실 별것 없었다.\n오픈 카톡방에 HR 직군에 종사하시는 어떤 분이 주기적으로 채용 홍보를 했는데, 마침 이직 생각을 하고 있었어서 그냥 별생각 없이 지원서를 넣어봤었다.\n어떻게 어떻게 프로세스가 진행되고 첫 면접을 보게 됐는데, 애초에 아무 생각 없이 지원했기에 첫 면접도 사실 준비를 아예 하지 않았다. 면접도 그날 퇴근 후 회사 근처 카페에 가서 대충 노트북 열고 봤다.\n애초에 그냥 면접이나 한번 봐보자는 생각이었기 때문에…\n그리고 이때 첫 면접관으로 들어오신 분이 쿠팡을 다니시던 시니어 개발자분이셨다. 현재는 함께 일하고 계신 동료 개발자중 한분이시다.\n\n나는 사실 여태 시니어 개발자라는 존재에 대해 아무런 의미를 두지 않고 살아왔다.\n내가 나를 잘 통제해내면 내가 잘하는 건 상수지만, 다른 사람이 나에게 어떤 도움을 준다거나 하는 것은 내가 통제할 수 없는 변수기 때문에 애초에 남의 도움이란 없는 거다 라는 게 내 가치관이었고 그렇게 살아왔기 때문이다.\n그러니까, 어차피 성장은 결국 내가 노력해야 이뤄지는 것이라 생각해왔고, 시니어 개발자가 주변에 있건 없건 결국 나만 잘하면 성장은 지속할 수 있는 것이라고 생각했다.\n\n이런 생각을 갖고 있었는데 첫 면접에서의 임팩트가 대단히 컸다.\n그러니까, 주변에 시니어 개발자가 있건 없건 사실 아무런 의미가 없다는 마인드였는데, 이 시기를 기점으로 훌륭한 시니어 개발자가 주변에 있다면 그것은 아주 좋은것이라고 생각이 바뀐 셈이다.\n\n첫 면접을 마치고 최종면접이 남았는데 CTO님과 첫 면접에서 만난 개발자분이 들어온다고 하셨다.\n나도 이 최종 면접은 준비를 꽤 많이 했다. 첫 면접에서의 임팩트가 강렬했고, 첫 면접에 나오셨던 분도 CTO님과 면접을 보고 쿠팡을 나와 여기로 오게 되셨다고 하여서 회사와 개발팀에 관심이 많이 생겼기 때문이다.\n결국 최종면접도 굉장히 느낌이 좋았다. 다행히 사측도 생각이 비슷했는지 가부가 금방 나왔고 나도 입사하기로 결정하였다.\n\n근황\n\n현재 회사에 근무한 지 이제 5개월이 지났는데, 정말 많은 도전을 하고 있다.\n내가 작업한 것 하나하나가 내 눈에 보이고 내가 체감할 수 있을 정도의 임팩트를 만들어내고 있다.\n하루하루가 즐겁다 보니 요즘은 아예 워라블을 추구하고 있다.\n\n워라블이 무엇이냐? Work Life Blending, 즉 일과 삶의 경계가 없어지는 거다. 이렇게 말하면 그냥 일만 하는 것처럼 느껴질 수도 있겠다 싶긴 한데 전혀 그렇지 않다.\n왜냐하면 그냥 개발 자체가 재미있기 때문이다.\n\n오히려 근무 시간에도 쉬거나 놀고 싶으면 즉시 일에서 손을 떼고 카페에 가서 쉬다 온다거나 산책한다거나 한다. 회사에서도 아무런 터치를 하지 않는다.\n어디 놀러 가서도 개발이 하고 싶으면 그냥 그 자리에서 노트북을 열고 개발한다. 밤이든 주말이든 새벽이든 개발이 하고 싶으면 그냥 개발하고, 놀고 싶다면 놀고, 쉬고 싶다면 쉰다.\n원래는 내가 관심 있는 분야에 관한 공부를 하거나 코드 카타를 하고 깃허브에 코드를 올렸는데, 이제는 회사 코드를 개선하고 Pull Request를 연다. 훈련은 충분히 해왔고, 이제 훈련의 성과를 실무에서 보일 차례다.\n\n일과 삶이 분리된 생활, 즉 워라밸을 추구할 때는 일하는 시간이 그저 시간을 낭비하는 것이라고 생각했었다. 회사는 출근하자마자 퇴근이 하고 싶어지는 곳이었다. 햄스터가 매일매일 쳇바퀴를 돌듯이, 직장은 나에게 이와 같았다.\n\n하지만 지금은 전혀 그렇지 않다. 덕업일치가 이뤄지고 나니 워라블을 추구하는 삶이 지금 나한테는 아주 잘 맞는 것 같다.\n\n올해의 목표\n\n우선 회사의 기술 부채를 청산하는 작업을 올해 안에 마무리는 못 하겠지만 그래도 끝이 보일 정도까지는 진행하고 싶다.\n회사가 시리즈 B까지 쉴 틈 없이 달려온 만큼 그동안 쌓아온 기술 부채가 굉장하긴 하다.\n기술 부채가 어느 정도냐면, 내가 입사 후 2개월 동안 손댄 것만으로 월 서버비가 2천만원이 넘게 줄었다.\n내가 뭐 대단한걸 한 게 아니다. 그냥 깨진 유리창 위에 쌓여있는 쓰레기들을 좀 치웠을 뿐이다.\n단지 그 쓰레기가 워낙 많아 쓰레기를 좀 치운 것만으로도 굉장한 임팩트를 냈을 뿐이고.\n그리고 사실 이 기술 부채를 개선하는 건 내 기술적인 역량으로나 멘탈적인 측면으로나 전혀 힘들고 고된 일이 아니었다.\n오히려 내가 오를 산이 있음이 좋고, 산을 올랐을 때 느낄 성취감이 기대마저 된다. 역경과 고난이 큰 만큼 성취감도 비례해서 커지는법 아니겠는가?\n\n두번째로는 개발팀을 정상으로 되돌리는것이다.\n현재 CTO님 입사 시기를 기준으로 이전에 계시던 개발자분들과 이후에 입사하신 개발자분들간의 괴리감이 상당히 크게 느껴지는데, 심적으로 나를 괴롭히는것은 타성에 젖어온 기존 개발팀의 개발문화다.\n깨진 유리창 하나를 고쳐도 다른데서 여러개의 유리창이 또 깨진다면 그만큼 지치는게 없다.\n빠르게 개발을 해야하는것과 코드 퀄리티를 지키는것. 이 사이의 밸런스를 잡는다는게 물론 굉장히 어려운 일임은 너무 잘 알고 있다. 하지만 여지껏 빠르게 개발을 하는데만 치중해왔기 때문에 이제는 더 이상 빠르게 개발을 할 수 없는 상태다. 일정조차 예측할 수 없다. 코드를 이해할 수 없으니까.\n그리고 빠르게 개발을 하는 데에만 집중해왔기 때문에 이에 대한 타성에 젖어있다.\n요즘은 “빠르게 개발하려면 퀄리티 포기하는 게 너무 당연한 거 아니냐? 시간을 더 주던가!” 라는 느낌마저 들 정도긴 하다.\n어느정도 이해되는 입장이긴 한데, 기본적으로 개발자는 자신의 코드에 프라이드가 있어야 한다고 생각한다.\n당연하게 여기는 것과 어쩔 수 없이 선택하는 것은 아예 다른 차원의 얘기라고 생각한다.\n본인이 유리창을 계속 깨왔고 계속 깨고 있으면서 막상 개발해야 할 때가 오면 “유리창이 너무 많이 깨져있어 개발이 오래 걸릴 것 같습니다. 개발이 언제 끝날지 알 수 없습니다.”라고 하는 것은 굉장히 무책임한 행동과 발언들이라고 생각한다.\n\n개발자는 기본적으로 회사에서 개발 업무를 하지만, 그 근본은 비즈니스다. 그리고 비즈니스는 항상 Cost vs Benefit이다. 개발자의 인건비, 서버비, 사무실 임대료 등 그냥 자연스레 흐르는 시간의 흐름만으로도 회사는 막대한 비용을 지불하고 있다. 한 팀에 연봉 3천만원을 받는 직원이 5명만 있어도 하루에 약 52만 원 정도의 지출이 발생한다. 어떤 기능 하나를 개발하기 위해 5일이 걸렸다면 회사는 약 260만원+@의 비용을 지불한 셈이다.\n그러니까, 때로는 기능을 개발하지 않는 게 더 이득일 수도 있다는 소리이다. 왜? 이렇게 막대한 비용을 들여 기능을 개발했는데 막상 돈은 벌지 못하는데도 불구하고 오히려 해당 기능을 유지보수하기 위해 인력이 투입되는 경우도 많기 때문이다.\n\n개발자라고 마냥 개발만 하지 말고 비즈니스를 알아야 한다. 정말 개발할만한 가치가 있는 것인지, 이것을 개발하면 최소 내 인건비라도 건질 수 있는 일인 것인지, 그럼에도 불구하고 개발해야 한다면 최대한 빠른 기간 안에 정말 필요한 스펙만을 정의해 개발에 들어가야 한다. 일정이 부족하다고 느낀다면 왜 일정이 부족한 것인지 동료들을 설득할 수 있어야 한다. 이러한 고민 없이 그냥 “일정이 촉박해요. 불가능해요.” 혹은 “일정이 부족하니까 돌아가게 만이라도 개발해야지” 같은 태도가 즉시 나온다면 그것은 일을 제대로 잘못하고 있는 것이다. 경력이 쌓일수록 이러한 자세와 스킬이 더더욱 중요해진다고 생각한다.\n\n큰 목표는 이정도들이고, 요즘은 테스트코드를 작성하고 코드리뷰를 잘 할 수 있게끔 시스템을 구축하고 개발 문화를 정착시키고 있다.\nVCS 플랫폼을 깃허브로 통째로 이전해왔고, 각종 자동화를 추가하고 있다. 그리고 깨져있던 모든 테스트를 고치고 코드 스타일을 통일시켰다. \n이제 PR을 열면 PR의 제목이 형식에 맞는지, 신규 개발로 인해 테스트가 깨지진 않았는지, 코드 스타일이 안맞지는 않는지, 앱이 제대로 실행이 되기는 하는건지 등을 모두 자동으로 체크한다.\n\n그리고 방치되어있던 젠킨스를 청소하고 버전을 LTS로 올리고 각종 job을 작성하고 젠킨스 유저들의 권한을 재정립했다.\n\n마지막으로, 모든 데이터베이스의 쿼리 통계를 기록하도록 변경하고, 슬로우 쿼리를 모니터링하며 쿼리 튜닝을 꾸준히 진행하고 있다.\n\n그동안 해왔던대로, 누군가가 또 다시 별 생각없이 유리창을 깨지 않게끔, 그게 깨서는 안되는 유리창임을 인지할 수 있게끔 계속 감시하고 목소리를 내고 있다. \n그래서 최종적으로 코드 레벨과 서비스 품질이 더이상 떨어지지 않게끔, 더 좋아질 수 있게끔 노력하고 있다. \n이렇게 돌이켜보니 현재 나라는 놈은 아마 현재 우리 개발팀에서 꽤 피곤한녀석으로 느껴지고 있지 않을까 싶기는 하다.\n정말 그렇다면 마음 아픈 일이겠지만, 내가 인상 깊게 봤던 어떤 드라마에서 나온 대사를 되새겨본다.\n\n\n  내가 매일 보는 동료들이, 내 옆의 완전 보통 사람들이 이러는 게, 난 이게 더 안 돼요 이게. 받아들이는 게.\n저 사람들이 죄다 처음부터 저랬겠어요? 하다 보니까, 되니까 그러는 거예요. 눈감아주고 침묵하니까.\n누구 하나만 눈을 제대로 부릅뜨고 짖어주면 바꿀 수 있어요.\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2023-01-28-diary-48/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "좋은 코드, 나쁜 코드",
      "date": "2023-03-16 00:00:00 +0000",
      "description": "프로그래머의 코드 품질 개선법\n",
      "content": "\n  Chapter 1. 코드 품질    \n      코드 품질의 핵심 요소\n      코드는 읽기 쉬워야 한다\n      코드는 예측 가능해야 한다\n      코드를 오용하기 어렵게 만들라\n      코드를 모듈화하라\n      코드를 재사용 가능하고 일반화할 수 있게 작성하라\n      테스트가 용이한 코드를 작성하고, 제대로 테스트하라\n      고품질 코드 작성은 일정을 지연시키는가 ?\n    \n  \n  Chapter 2. 추상화 계층    \n      인터페이스를 통해 패키지의 의존성을 관리하는 예\n      클래스 레벨에서 추상화를 구현\n      함수는 한 가지 일만 해야 한다\n    \n  \n  Chapter 3. 다른 개발자와 코드 계약    \n      자신에게 분명하다고 해서 다른 사람에게도 분명한 것은 아니다\n      다른 개발자는 무의식중에 여러분의 코드를 망가뜨릴 수 있다\n      시간이 지나면 자신의 코드를 기억하지 못한다\n      코드 계약\n    \n  \n  Chapter 4. 오류    \n      복구 가능한 오류\n      실패는 빠르고, 요란할수록 좋다\n      오류 처리는 고수준에서 한다\n      오류를 먹지 마라\n    \n  \n  Chapter 5. 가독성 높은 코드를 작성하라    \n      서술적이지 않은 이름은 코드를 읽기 어렵게 만든다\n      적절한 주석문을 사용하는게 좋다\n      코드 라인이 짧고 간결하다고 좋은 코드는 아니다\n      일관된 코딩 스타일을 고수해라\n      언어의 새로운 기능을 적절하게 활용해라\n    \n  \n  Chapter 6. 예측 가능한 코드를 작성하라\n  Chapter 7. 코드를 오용하기 어렵게 만들라\n  Chapter 8. 코드를 모듈화하라\n  Chapter 9. 코드를 재사용하고 일반화할 수 있도록 해라\n  Chapter 10. 단위 테스트의 원칙    \n      블랙박스 테스트\n      테스트 더블\n      좋은 단위 테스트는 어떻게 작성 할 수 있는가?\n    \n  \n  Chapter 11. 단위 테스트의 실제    \n      기능뿐만 아니라 동작을 시험하라\n      테스트만을 위해 퍼블릭으로 만들지 말라\n      퍼블릭 API를 통해 테스트하라\n      코드를 더 작은 단위로 분할하라\n    \n  \n\n\nChapter 1. 코드 품질\n\n코드 품질의 핵심 요소\n\n엔지니어들이 코드를 작성할 때 내리는 일상적인 결정은 그것만 보면 작고 때로는 보잘것없어 보일 수도 있지만, 좋은 소프트웨어인지 그렇지 않은지는 그 모든 작은 결정들이 모여서 이루어진다\n\n코드는 읽기 쉬워야 한다\n\n코드의 가독성이 떨어진다면 다른 개발자가 그 코드를 이해하는데 많은 시간을 들여야 한다. 또한 코드의 기능에 대해 잘못 이해하거나 몇 가지 중요한 세부 사항을 놓칠 가능성 역시 크다\n\n코드는 예측 가능해야 한다\n\n함수 이름이 A를 읽는다 라면 그 함수는 정말 A를 읽는 일만 해야 한다\n\n코드를 오용하기 어렵게 만들라\n\nTV 제조업체들은 HDMI 소켓에 전원 코드를 꽂지 못하도록 HDMI 소켓과 전원 코드의 모양이 서로 다르도록 만든다\n\n근데 언어 자체가 타입을 강제하지 못한다면 이 문제는 어떻게 해결할 것인가 ? 🤔\n\n코드를 모듈화하라\n\n코드가 잘 모듈화되어 있다면 코드를 재사용하기 쉬워지고, 코드의 유연성이 극대화된다. 이는 곧 요구사항의 변경에 민첩하게 대응할 수 있다는 말과 같다.\n\n코드를 재사용 가능하고 일반화할 수 있게 작성하라\n\n\n  재사용성(reusablility): 어떤 문제를 해결하기 위한 무언가가 여러 가지 다른 상황에서도 사용될 수 있음을 의미한다. 핸드 드릴은 벽, 바닥 판 및 천장에 구멍을 뚫는데 사용할 수 있기 때문에 재사용 가능한 도구다. 문제는 동일하지만(드릴로 구멍을 뚫어야 한다), 상황은 다르다(벽을 뚫는 것과 바닥을 뚫는 것과 천장을 뚫는 것)\n  일반화성(generalizability): 개념적으로는 유사하지만 서로 미묘하게 다른 문제들을 해결할 수 있음을 의미한다. 핸드 드릴은 구멍을 뚫는 데 사용될 뿐만 아니라 나사를 박을 때도 사용될 수 있어서 일반화성을 갖는다.\n\n\n테스트가 용이한 코드를 작성하고, 제대로 테스트하라\n\n테스트 코드가 필요한 이유는 다음과 같다\n\n  버그나 제대로 동작하지 않는 기능을 갖는 코드가 코드베이스에 병합되지 않도록 방지\n  버그나 제대로 동작하지 않는 기능을 갖는 코드가 배포되지 않도록 막고 서비스 환경에서 실행되지 않도록 보장\n\n\n고품질 코드 작성은 일정을 지연시키는가 ?\n\n단기적으로는 고품질의 코드를 작성하기 위해 시간이 더 걸릴수 있다. 하지만 고품질 코드를 계속 작성해나간다면 중장기적으로는 개발 시간을 단축시켜준다.\n\nChapter 2. 추상화 계층\n\n인터페이스를 통해 패키지의 의존성을 관리하는 예\n\n\n\n클래스 레벨에서 추상화를 구현\n\n\n\n함수는 한 가지 일만 해야 한다\n\n함수가 한 가지 일만 하기 어렵다면 더 큰 개념으로 추상화하고 함수로 구현한다. 상위 개념의 추상화는 하위 개념의 여러 추상화로 이루어진다.\n예를 들어 라면을 끓인다의 하위 개념은 물을 끓인다와 라면을 넣는다이다. 그리고 이 두 개념은 역시 또 다시 하위 개념으로 나뉠 수 있다.\n\nChapter 3. 다른 개발자와 코드 계약\n\n\n\n자신에게 분명하다고 해서 다른 사람에게도 분명한 것은 아니다\n\n다른 개발자가 작성한 코드와 상호작용하거나, 코드를 변경하거나, 의존하고 있는 코드를 변경할 수 있다는 것을 기억해야 한다. 코드를 작성할 당시에 너무도 분명해 보였던 것들이 그들에게는 분명하지 않을 것이다.\n\n다른 개발자는 무의식중에 여러분의 코드를 망가뜨릴 수 있다\n\n작성한 코드는 다른 코드로부터 전혀 영향을 받지 않은 채 독립적으로 있는 것이 아니라, 끊임없이 변화하는 코드 위에 놓여 있고, 여러분의 코드를 기반으로 계속해서 변화하는 코드 역시 끊임없이 작성된다. \n코드 베이스가 작동되지 않거나 오용되는 결과를 막기 위해서 코드 컴파일이 중지되거나 테스트가 실패하도록 만든다.\n\n시간이 지나면 자신의 코드를 기억하지 못한다\n\n배경지식이 거의 없거나 전혀 없는 사람에게도 자신의 코드가 이해하기 쉬워야 하고 잘 작동하던 코드에 버그가 발생하는 것이 어려워야 한다.\n\n코드 계약\n\n서로 다른 코드 간의 상호작용을 마치 계약처럼 생각한다. 어떤 코드를 호출하는 코드는 특정 요건을 충족해야 하며 호출되는 코드는 원하는 값을 반환하거나 일부 상태를 수정한다.\n\n\n  선결 조건: 코드를 호출하기 전에 사실이어야 하는 것\n  사후 조건: 코드가 호출된 후에 사실이어야 하는 것\n  불변 사항: 코드가 호출되기 전과 후에 시스템 상태를 비교해서 변경되지 않아야 하는 사항\n\n\nChapter 4. 오류\n\n복구 가능한 오류\n\n많은 소프트웨어 오류는 치명적이지 않으며, 오류가 발생하더라도 사용자는 알아채지 못하도록 적절하게 처리한다면 작동을 계속할 수 있는 합리적인 방법이 있다. \n한 가지 예로 사용자가 잘못된 입력을 제공하는 경우가 있다. \n예를 들어 사용자가 유효하지 않은 전화번호를 입력할 때 저장되지 않은 이전의 작업들을 잃어버리면서 전체 시스템이 작동을 멈춘다면 훌륭한 사용자 경험은 아니다. 대신 사용자에게 전화번호가 유효하지 않다는 오류 메시지를 제공하고 올바른 번호를 입력하도록 재요청하는 것이 더 낫다.\n\n실패는 빠르고, 요란할수록 좋다\n\n복구할 수 없는 오류도 존재한다. 예를 들자면 개발자가 코드를 명확하게 잘못 작성한 경우를 들 수 있다. \n이러한 경우는 절대적으로 코드를 수정하여 다시 배포를 해야만 하는데, 이러한 오류로 인한 피해를 최소화 하기 위해서는 최대한 빠르게 코드가 수정되고 배포가 진행되어야만 한다. \n빠르게 실패하고 최대한 요란하게 실패할수록 이러한 문제들이 빨리 발견될 수 있다.\n\n\n  빠르게 실패\n    \n      빠르게 실패할수록 실패 위치가 원인에서 가까워진다. 느리게 실패한다면 실질적으로 문제가 되는 코드보다 수백라인 이후, 아예 다른 코드 파일에서 실패가 발생할 수 있다. 이러면 근본 원인을 찾는게 더 어려워진다.\n    \n  \n  요란하게 실패\n    \n      극단적인 예이지만, 실패하는 순간 애플리케이션이 작동을 멈춰버린다면 그 누구라도 뭔가 문제가 생겼다는 것을 인지할 수 있을 것이다.\n    \n  \n\n\n오류 처리는 고수준에서 한다\n\n예를 들어 사용자가 웹 페이지에서 전화번호를 입력했다고 가정하면, 웹 페이지는 서버로 전화번호를 보낼 것이고, 서버는 전화번호의 유효성 검사를 진행할 것이다. \n이때 전화번호가 유효하지 않다면 서버는 어떤 결과를 응답해주어야 할까? 서버에서 이러한 잘못된 입력을 자체적으로 처리하기는 불가능하다.\n서버에서 할 수 있는 최선은 입력된 전화번호가 유효하지 않다는 응답을 보내주고, 웹 페이지에서 전화번호를 다시 입력하라는 UI를 노출시키는게 합리적일것이다.\n이렇게 저수준에서는 고수준으로 예외를 던지고, 고수준에서 예외처리를 진행하는게 좋다.\n\n오류를 먹지 마라\n\n다음과 같은 코드가 있다. 무엇이 문제인가?\n\ntry {\n    doSomething();\n} catch(Exception e) {\n    // do nothing\n}\n\n\n\n  최상위 예외인 Exception을 통해 예외를 받으므로 저수준에서 정확히 어떤 예외가 발생하는지 명확하지 않다.\n  예외를 잡았으나, 아무런 처리도 하지 않고 있다\n\n\n이런 코드가 있다면 로그가 없기 때문에 예외가 발생했을 때 어떤 문제가 발생했는지 인지하는것조차 어려우며, 어떻게 어떻게 문제를 인지하더라도 이후 어떤 처리들이 진행될지 명확하지 않다.\n\n위의 코드를 개선하면 다음과 같을 수 있다.\n\ntry {\n    doSomething();\n} catch(IllegalArgumentException e) {\n    log.error(e.getMessage());\n    handle();\n} catch(IOException e) {\n    log.error(e.getMessage());\n    handle();\n}\n\n\nChapter 5. 가독성 높은 코드를 작성하라\n\n서술적이지 않은 이름은 코드를 읽기 어렵게 만든다\n\n변수나 함수등의 이름을 지을 때 서술적인 이름을 짓기 위한 노력을 충분히 기울이지 않는다면 코드가 어떻게 보일지 보여주는 다소 극단적인 예다. \n다음 코드를 30초정도 살펴보고 이 코드가 무슨일을 하고 있는지 맞춰보자.\n\nclass T {\n    Set&lt;String pns = new Set();\n    Int s = 0;\n    \n    ...\n    \n    Boolean f(String n) {\n        return pns.contains(n);\n    }\n    \n    Int getS() {\n        return s;\n    }\n    \n    Int? s(List&lt;T&gt; ts, String n) {\n        for ( T t in ts) {\n            if (t.f(n)) {\n                return t.getS();\n            }\n        }\n        return null;\n    }\n}\n\n\n적절한 주석문을 사용하는게 좋다\n\nfun generateId(firstName: String, lastName: String): String {\n    // \"{이름}.{성}\"의 형태로 ID를 생성한다\n    return \"${firstName}.${lastName}\"\n}\n\n\n위의 주석문이 유의미한가? 이미 함수 시그니처와 함수의 세부 구현으로 모든게 명확하게 설명되고 있다고 생각되지 않는가? \n주석이 없다면 코드가 잘 이해되지 않는지 주석을 지우고 다시 보자.\n\nfun generateId(firstName: String, lastName: String): String {\n    return \"${firstName}.${lastName}\"\n}\n\n\n반대로 주석이 유용한 경우도 확실히 존재한다.\n\n아래의 코드는 어떤 객체의 유효시간을 의미한다.\n\nprivate static final long EXPIRY_TIME_IN_MS = 691200000;\n\n\n변수명을 통해 단위가 ms임을 명시하긴 하였으나 691,200,200이 정확히 앞으로 얼마의 시간동안 유효한지가 직관적으로 떠오르지 않는다. 일단 가독성을 좋게 하기 위해 다음과 같은 절차들을 밟을 수 있다.\n\nprivate static final long EXPIRY_TIME_IN_MS = 691_200_000;\n\n\n우선 3자리 단위로 끊어볼 수 있다. 하지만 여전히 얼마의 시간인지는 명확하지 않다.\n\nprivate static final long EXPIRY_TIME_IN_MS = 1_000 * 60 * 60 * 24 * 8;\n\n\n위와 같이 단위를 구분지어 표현할수도 있다. 이 경우엔 상당히 명확해진다. 1,000ms는 1초이며, 60초는 1분, 60분은 1시간, 24시간은 하루이므로 위의 691,200,00ms 라는 값이 총 8일을 의미함을 알 수 있다.\n\n그래도 여전히 개발자가 코드를 보며 계산을 하기는 해야 한다. 다음과 같다면 어떨까?\n\nprivate static final long EXPIRY_TIME_IN_MS = 1_000 * 60 * 60 * 24 * 8; // 8 days\n\n\n이외에도 해당 코드가 작성되어야만 했던 맥락이 담긴 문서등은 주석으로 작성할 가치가 충분하다. \n이렇게 가독성 높은 코드와 함께 적절히 사용된 주석은 분명 유의미한 가치가 있다. \n하지만 근본적으로 주석문만으로 가독성 높은 코드를 대체할수는 없다.\n\n코드 라인이 짧고 간결하다고 좋은 코드는 아니다\n\n다음의 간결한 코드가 정확히 어떤것을 하고 있는지 파악해보자.\n\nboolean isIdValid(UInt16 id) {\n    return countSetBits(id &amp; 0x7FFF) % 2 == ((id &amp; 0x8000) &gt;&gt; 15);\n}\n\n\n코드라인이 한줄밖에 되지 않는 간결한 함수다. 파악이 되는가?\n대부분의 개발자가 위 함수가 어떤것을 하고 있는지 제대로 파악하지 못할거라 생각한다. \n대부분의 코드는 작성되는 시간보다 이후 읽히는 시간이 압도적으로 많기 때문에, 가독성을 위해 코드 라인이 길어지는게 오히려 더 좋은 경우가 많다. (단, 컴퓨팅 리소스가 한정된 상황에서 개발을 진행하고 있다면 이 조언이 맞지 않을 수 있다. (예: 임베디드 프로그래밍 등))\n\n일관된 코딩 스타일을 고수해라\n\nclass GroupChat {\n\n    ...\n    \n    void end() {\n        connectionManager.terminateAll();\n    }\n}\n\n\n위의 코드가 실패했다. 이유가 무엇일까?\n위 코드를 보는 대부분의 자바개발자는 connectionManager 가 GroupChat의 인스턴스 변수일것으로 예상했을 것이다. \n하지만 실제로 connectionManager는 클래스였으며, terminateAll()은 connectionManager의 static 함수였다.\n\nclass connectionManager {\n\n    ...\n    \n    static terminateAll() {\n        ...\n    }\n}\n\n\n이와 같이 절대 다수의 개발자들이 준수하고 있는 특정 생태계의 스타일 가이드를 따르는것은 매우 중요하다. \n다른 개발자들이 동의하고 따르고 있는 스타일 가이드를 지키지 않고 혼자 다른 스타일의 코드를 작성한다면 다른 개발자들에게 혼동을 줄 여지가 매우 높다.\n모든 사람들이 하늘에 떠있는 해를 바라보며 해라고 부르는데, 혼자 달이라고 부른다면 다른 사람들과의 의사소통에 많은 문제가 생기지 않을까?\n\n언어의 새로운 기능을 적절하게 활용해라\n\n다음 코드는 문자열 리스트를 입력받아 빈 문자를 걸러내는 작업을 수행하는 전통적인 자바 함수이다.\n\nList&lt;String&gt; getNoneEmptyStrings(List&lt;String&gt; strings) {\n    List&lt;String&gt; nonEmptyStrings = new ArrayList(strings.size());\n    for (String str : strings) {\n        if (!str.isBlank()) {\n            nonEmptyStrings.add(str);\n        }\n    }\n    return nonEmptyStrings;\n}\n\n\n자바8부터 도입된 람다와 스트림 API를 사용한다면 다음과 같이 간결하고 직관적이게 표현할 수 있다.\n\nList&lt;String&gt; getNoneEmptyStrings(List&lt;String&gt; strings) {\n    return strings.stream()\n           .filter(str -&gt; !str.isBlank())\n           .collect(Collectors.toList());\n}\n\n\n새로운 기능들은 코드를 더 유지보수하기 쉽게 개발하는데 큰 도움을 줄 수 있다.\n\nChapter 6. 예측 가능한 코드를 작성하라\n\n다른 개발자가 작성하는 코드는 종종 우리가 작성하는 코드에 의존한다. \n다른 개발자가 우리 코드의 기능을 잘못 해석하거나 처리해야 하는 특수한 경우를 발견하지 못하면, 우리가 작성한 코드에 기반한 그 코드에서 버그가 발생할 가능성이 크다. \n코드를 호출하는 쪽에서 예상한대로 동작하기 위한 좋은 방법 중 하나는 중요한 세부 사항이 코드 계약의 명백한 부분에 포함되도록 하는 것이다.\n\n우리가 사용하는 코드에 대해 허술하게 가정을 하면 예상을 벗어나는 또 다른 결과를 볼 수 있다.\n예를 들어 열거형에 추가되는 새 값을 예상하지 못한 경우다.\n의존해서 사용 중인 코드가 가정을 벗어날 경우, 코드 컴파일을 중지하거나 테스트가 실패하도록 하는 것이 중요하다.\n\n테스트만으로는 예측을 벗어나는 코드의 문제를 해결할 수 없다. \n다른 개발자가 코드를 잘못 해석하면 테스트해야 할 시나리오도 잘못 이해할 수 있다.\n\nChapter 7. 코드를 오용하기 어렵게 만들라\n\n코드가 오용되기 쉽게 작성되고 나면 어느 시점에선가는 오용될 가능성이 크고 이것은 버그로 이어질 수 있다.\n\n코드가 오용되는 몇 가지 일반적인 사례는 다음과 같다.\n\n  호출하는 쪽에서 잘못된 입력을 제공\n  다른 코드에서 일어나는 부수 효과\n  함수 호출 시점이 잘못되거나 올바른 순서로 호출되지 않은 경우\n  원래의 코드에 연관된 코드를 수정할 때 원래의 코드가 내포한 가정과 어긋나게 수정하는 경우\n\n\n오용이 어렵거나 불가능하도록 코드를 설계하고 구조화하는 것이 종종 가능하다. \n이를 통해 버그 발생 가능성이 크게 줄어들고 중장기적으로 개발자의 시간을 많이 절약할 수 있다.\n\nChapter 8. 코드를 모듈화하라\n\n코드가 모듈화되어 있으면 변경된 요구 사항을 적용하기 위한 코드를 작성하기가 쉽다. \n모듈화의 주요 목표 중 하나는 요구 사항의 변경이 해당 요구 사항과 직접 관련된 코드에만 영향을 미치도록 하는 것이다.\n코드를 모듈식으로 만드는 것은 간결한 추상화 계층을 만드는 것과 깊은 관련이 있다.\n\n다음의 기술을 사용하여 코드를 모듈화 할 수 있다.\n\n  의존성 주입\n  구체적인 클래스가 아닌 인터페이스에 의존\n  클래스 상속 대신 인터페이스 및 구성의 활용\n  클래스는 자신의 기능만 처리\n  관련된 데이터의 캡슐화\n  반환 유형 및 예외 처리 시 구현 세부 정보 유출 방지\n\n\nChapter 9. 코드를 재사용하고 일반화할 수 있도록 해라\n\n\n  동일한 하위 문제가 자주 발생하므로 코드를 재사용하면 미래의 자신과 팀 동료의 시간과 노력을 절약할 수 있다.\n  다른 개발자가 여러분이 해결하려는 문제와는 다른 상위 수준의 문제를 해결하더라도 특정 하위 문제에 대해서는 여러분이 작성한 해결책을 재사용할 수 있도록 근본적인 하위 문제를 식별하고 코드를 구성하도록 노력해야 한다.\n  간결한 추상화 계층을 만들고 코드를 모듈식으로 만들면 코드를 재사용하고 일반화하기가 훨씬 쉽고 안전해진다.\n  가정을 하게 되면 코드는 종종 더 취약해지고 재사용하기 어렵다는 측면에서 비용이 발생한다.\n  가정을 하는 경우의 이점이 비용보다 큰지 확인하라.\n  가정을 해야 할 경우 그 가정이 코드의 적절한 계층에 대해 이루어지는 것인지 확인하고 가능하다면 가정을 강제적으로 적용하라.\n  전역 상태를 사용하면 특히 비용이 많이 발생하는 가정을 하는 것이 되고 재사용하기에 전혀 안전하지 않은 코드가 된다. 대부분의 경우 전역 상태를 피하는 것이 가장 바람직하다.\n\n\nChapter 10. 단위 테스트의 원칙\n\n블랙박스 테스트\n\n\n  \n    \n      테스트\n      설명\n    \n  \n  \n    \n      동치 분할 테스트(Equivalence Partitioning Test)\n      프로그램의 입력 데이터를 여러 분류로 나누어 검사\n    \n    \n      경계값 분석  (Boundary Value Analysis)\n      입력값의 경계값을 중심으로 예외 발생 검사\n    \n    \n      원인-결과 그래프 기법(Cause-effect Graphing)\n      입력데이터 간의 관계, 출력에 미치는 영향의 분석 그래프 이용\n    \n    \n      오류 예측검사 (Fault Based Testing)\n      테스터의 감각이나 경험, 지식을 통해 에러케이스를 예측\n    \n    \n      비교 검사 (Comparison Testing)\n      테스트 대상과 비교 대상 프로그램에 같은 입력값을 넣어 데이터를 비교\n    \n  \n\n\n테스트 더블\n\n\n  TestDouble - 마틴 파울러\n\n  제라드 메스자로스는 다양한 Xunit 프레임워크를 사용하는 패턴을 모아 놓은 책을 만드는 중입니다. \n그가 부딪힌 문제 중 하나는 시스템의 일부를 테스트하기 위해 대체하는데 사용되는 스텁(stubs), 목(mock), 페이크(fake), 더미(dummy) 등의 다양한 이름들입니다. \n이를 해결하기 위해 그는 자신만의 용어를 만들었으며, 이는 더욱 널리 알리면 좋을 것이라 생각됩니다.\n\n  그가 사용하는 일반적인 용어는 ‘테스트 더블’(stunt double을 생각하면 됩니다)입니다. \n‘테스트 더블’은 테스트 목적으로 제작 객체를 대체하는 일반적인 용어입니다. 제라드가 나열한 여러 종류의 더블은 다음과 같습니다. \n더미 객체는 전달되지만 실제로 사용되지는 않습니다. 보통 매개변수 목록을 채우기 위해 사용됩니다.\n\n  페이크 객체는 실제 구현을 가지고 있지만, 일반적으로 프로덕션에 적합하지 않은 지름길을 사용합니다.(InMemoryTestDatabase가 좋은 예임)\n스텁은 테스트 중에 호출된 호출에 대한 canned answer(일정한 대답)을 제공하며, 테스트에 프로그래밍된 것 이외의 것에는 대응하지 않습니다.\n스파이는 호출된 방식에 따라 일부 정보를 기록하는 스텁입니다. 이 중 하나는 얼마나 많은 메시지가 전송되었는지를 기록하는 이메일 서비스일 수 있습니다.\n목(mock)은 호출되기를 기대하는 명세를 형성하는 기대치로 미리 프로그래밍됩니다. 기대하지 않은 호출을 받으면 예외를 던질 수 있으며, 확인 중에 확인하여 예상했던 모든 호출을 받았는지 확인할 수 있습니다.\n\n\n이를 코드로 보면 다음과 같을 수 있다. (sut는 system under test의 약자로, 테스트중인 시스템을 의미한다.)\n\n@ExtendWith(MockitoExtension.class)\nclass ExampleServiceTests {\n    @Test\n    void withMock(@Mock ExampleRepository exampleRepository) {\n        // given\n        when(exampleRepository.findAll()).thenReturn(List.of(\"Hello World\"));\n        \n        var sut = new Example(exampleRepository);\n\n        // when\n        var result = sut.findAll();\n\n        // then\n        assertThat(result)\n                .hasSize(1)\n                .containsExactly(\"Hello World\");\n    }\n\n    @Test\n    void withStub() {\n        // given\n        ExampleRepository stub = new ExampleRepository() {\n            @Override\n            public void save(String value) {\n                // do nothing\n            }\n\n            @Override\n            public List&lt;String&gt; findAll() {\n                return List.of(\"Hello World\");\n            }\n        }; \n        \n        var sut = new ExampleService(stub);\n        \n        // when\n        var result = sut.findAll();\n\n        // then\n        assertThat(result)\n                .hasSize(1)\n                .containsExactly(\"Hello World\");\n    }\n\n    @Test\n    void withFake() {\n        // given\n        var sut = new ExampleService(new FakeExampleRepository());\n        sut.save(\"Hello World\");\n\n        // when\n        var result = sut.findAll();\n\n        // then\n        assertThat(result)\n                .hasSize(1)\n                .containsExactly(\"Hello World\");\n    }\n}\n\npublic class ExampleService {\n    private final ExampleRepository exampleRepository;\n\n    public ExampleService(ExampleRepository exampleRepository) {\n        this.exampleRepository = exampleRepository;\n    }\n\n    public void save(String value) {\n        this.exampleRepository.save(value);\n    }\n\n    public List&lt;String&gt; findAll() {\n        return this.exampleRepository.findAll();\n    }\n}\n\npublic interface ExampleRepository {\n    void save(String value);\n\n    List&lt;String&gt; findAll();\n}\n\npublic class FakeExampleRepository implements ExampleRepository {\n    private final List&lt;String&gt; db = new ArrayList&lt;&gt;();\n\n    @Override\n    public void save(String value) {\n        this.db.add(value);\n    }\n\n    @Override\n    public List&lt;String&gt; findAll() {\n        return new ArrayList&lt;&gt;(this.db);\n    }\n}\n\n\n좋은 단위 테스트는 어떻게 작성 할 수 있는가?\n\n액면 그대로의 단위 테스트는 매우 간단해 보일지 모른다. \n실제 코드가 작동하는지 확인하기 위해 테스트 코드를 작성하기만 하면된다. \n안타깝게도 이는 기만적인것이며, 수 년 동안 많은 개발자가 쉽게 단위 테스트를 잘못된 방식으로 작성해왔다.\n\n단위 테스트에서 문제가 발생하면 유지 관리가 매우 어렵고, 버그가 테스트 코드에서 발견되지 못하고 배포한 뒤에 발생 할 수도 있다. \n그러므로 어떻게해야 좋은 단위 테스트가 되는지 생각해 보는것이 중요하다. \n이를 위해 좋은 단위 테스트가 가져야 할 5가지 주요 기능을 정의한다.\n\n  훼손의 정확한 감지: 코드가 훼손되면 테스트가 실패한다. 그리고 테스트는 코드가 실제로 훼손 된 경우에만 실패해야 한다.\n  세부 구현 사항에 독립적: 세부 구현 사항을 변경하더라도 테스트 코드는 변경하지 않는것이 이상적이다.\n  잘 설명되는 실패: 코드가 잘못되면 테스트는 실패의 원인과 문제점을 명확하게 설명해야한다.\n  이해 할 수 있는 테스트 코드: 다른 개발자들이 테스트 코드가 정확히 무엇을 테스트하기 위한 것이고 테스트가 어떻게 수행 되는지 이해할 수 있어야 한다.\n  쉽고 빠르게 실행: 개발자는 일상 작업 중에 단위 테스트를 자주 실행한다. 단위 테스트가 느리거나 실행이 어려우면 개발 시간이 낭비된다.\n\n\nChapter 11. 단위 테스트의 실제\n\n\n  코드의 모든 동작을 효과적으고 신뢰성 있게 테스트하기\n  이해하기 쉽고 실패가 잘 설명되는 테스트 코드의 작성\n  의존성 주입을 사용하여 테스트가 용이한 코드의 작성\n\n\n기능뿐만 아니라 동작을 시험하라\n\n코드를 테스트하는 것은 할 일 목록을 만들어 작업하는 것과 약간 비슷하다. \n그러나 다른 할 일 목록과 마찬가지로 성공적인 결과는 실제로 목록에 있는 것들이 얼마나 올바른지 달려 있다.\n\n테스트만을 위해 퍼블릭으로 만들지 말라\n\n프라이빗 함수는 구현 세부 사항이며 클래스 외부 코드가 인지하거나 직접 사용하는 것이 아니다.\n구현 세부 사항과 밀접하게 연관된 테스트가 될 수 있고 궁극적으로 우리가 신경써야 하는 코드의 동작을 테스트하지 않을 수 있다.\n\n퍼블릭 API를 통해 테스트하라\n\n비교적 간단한 클래스의 경우 퍼블릭 API만을 사용하여 모든 동작을 테스트하기가 매우 쉽다. \n그러나 클래스가 더 복잡하거나 많은 논리를 포장하면 퍼블릭 API를 통해 모든 동작을 테스트하는 것이 까다로울 수 있다.\n이 경우는 코드를 더 작은 단위로 분할하는 것이 유익하다.\n\n코드를 더 작은 단위로 분할하라\n\n\n\n\n  각 함수를 테스트하는 것에 집중하다 보면 테스트가 충분히 되지 못하기 쉽다. 보통은 모든 중요한 행동을 파악하고 각각의 테스트 케이스를 작성하는 것이 더 효과적이다.\n  결과적으로 중요한 동작을 테스트 해야 한다. 프라이빗 함수를 테스트하는 것은 거의 대부분 결과적으로 중요한 사항을 테스트하는 것이 아니다.\n  한 번에 한 가지씩만 테스트하면 테스트 실패의 이유를 더 잘 알 수 있고 테스트 코드를 이해하기가 더 쉽다.\n  테스트 설정 공유는 양날의 검이 될 수 있다. 코드 반복이나 비용이 큰 설정을 피할 수 있지만 부적절하게 사용할 경우 효과적이지 못하거나 신뢰할 수 없는 결과를 초래할 수 있다.\n  의존성 주입을 사용하면 코드의 테스트 용이성이 상당히 향상될 수 있다.\n  단위 테스트는 개발자들이 가장 자주 다루는 테스트 수준이지만 이것만이 유일한 테스트는 아니다. 높은 품질의 소프트웨어를 작성하고 유지하려면 여러가지 테스트 기술을 함께 사용해야 할 때가 많다.\n\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2023-03-16-diary-49/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "모 기업 대표님의 파이낸셜 모델링에 대한 이야기를 듣고...",
      "date": "2023-03-17 00:00:00 +0000",
      "description": "생각 정리\n",
      "content": "\n  방문 기업의 상황\n  직원들은 바보가 아니다\n  제품 주도 성장\n  항상 Burn Rate와 ROI에 대해 고민할 것\n  단기적인 지표만을 위한 업무를 하지 말 것\n  기본적으로, 개인이 스스로 동기를 부여할 줄 알아야 한다.\n\n\nCTO님, 개발팀 인원 세명과 함께 모 기업에 방문했다. 이후 설탕 가득한 꽈배기를 집어먹으며 나누었던 이야기를 토대로 개인적으로 생각했던 내용들을 정리 및 기록한다. \n각 회사의 상황과 맥락이 다르니 다른 잘나가는(?) 회사의 방식이 무조건 옳다고 보기는 어렵다. 하지만 많은 내용이 공감되었다.\n\n방문 기업의 상황\n\n  처음 몇달간 아예 제품을 개발하지 않고 기획과 VoC에만 집중했다.\n  어느정도 동기부여가 되어있는 소수 정예로 팀을 구성했다\n  팀에 회사의 지표를 투명하게 공개했다\n    \n      내부 앱을 개발해 앱을 열면 회사의 런웨이가 얼마나 남았는지, ARR이 얼마나 늘었는지 등이 모두 한눈에 파악된다\n    \n  \n  가장 근간이 되는 제품의 퀄리티에 가장 많이 투자했다\n    \n      결과적으로 매출 원가가 약 20%내외로 아주 낮아 수익률이 굉장히 좋다\n      매출 원가가 낮아져 수익률이 증대되니 런웨이가 계속해서 늘어난다\n      회사에 돈이 많아지니 여유가 생겨 더 많은 시도를 해볼 수 있어졌다\n    \n  \n  수익을 직원들에게 공유한다\n    \n      소수정예인 만큼 직원 한명 한명이 너무 소중하다\n      연봉, 복지등을 최대한 지원한다\n        \n          ARR이 10% 증가했다면 전 직원들의 연봉을 10% 인상하고, 20%가 올랐다면 20% 인상한다\n        \n      \n      자진 퇴사율이 0%에 가깝고, 직원들의 사기가 매우 높다\n      직원들이 강한 동기와 회사의 제품이 내 제품이라는 오너십을 가진채 업무에 임한다\n        \n          회식에서 메뉴 하나를 고를때조차도 이 메뉴하나 시키면 ARR 얼마다 라는식으로 생각하게 된다\n          회사의 ARR이 증대되면 본인들의 처우가 그대로 좋아지니 야근, 주말근무도 자발적이고 적극적으로 진행한다\n        \n      \n    \n  \n  선순환이 일어난다\n\n\n직원들은 바보가 아니다\n회사의 상황을 투명하게 공개하고 모두의 동의를 이끌어내야한다. 헤게모니를 쥔다고 표현할 수 있겠다. \n특정 집단의 동의를 이끌어내 집단의 대변자가 된다면 그것은 강력한 힘이 된다. \n독일 국민들은 하나된 독일, 강한 독일을 원했고 히틀러는 독일 국민들의 이러한 염원과 지지를 얻어냈다.\n\n이러한 동의 없이 리드급 이상에서 모든 업무가 결정되고 진행된다면 리드급 미만의 직원들은 함께 일하고 있다는 느낌을 받기 어렵다.\n그리고 이런 현상이 일어나기 시작하면 직원들의 사기와 동기는 점점 떨어질 것이다.\n\n엔젤 언저리일때 기업의 대표가 70% 이상의 지분을 들고 있어야 하는 이유를 다음과 같이 직원들에게 설명해보자.\n\n  IPO까지 가기 위해 최소 5번 이상의 라운드를 거쳐야 한다\n  매 라운드마다 투자자들에게 10% 내외의 지분을 주어야 한다\n  IPO 직전까지 갔을 때 대표에게 남은 지분이 없다면 모럴헤저드가 일어나 IPO가 수월하게 진행되지 않을 수 있다\n  IPO가 되지 않는다면 결국 경영진, 직원, 투자자들 모두에게 좋을 게 없다\n  모두가 윈윈하려면 사공이 많아 더이상의 진척이 이뤄지지 않는 상황을 막기 위해 대표가 지분을 많이 들고 있어야 한다\n\n\n직원들이 이러한 맥락을 듣는다면 대표가 많은 지분을 들고 있다고 부정적으로 생각하는 사람이 과연 있을까?\n\n제품 주도 성장\n가장 전통적인 마케팅은 세일즈맨이 직접 발로뛰며 영업을 하는것이었으나, 이제는 한계가 보이기 시작하고 있다. 영업과 운영에 인력이 많이 투입될수록 판관비로 인한 매출 원가가 높아져 결국 회사의 수익률이 떨어지게 된다.\n\n\n\n이제는 그냥 제품의 퀄리티가 너무 좋아 고객들이 자발적으로 지갑을 열기 시작하는것이 가장 이상적인 형태가 될 것이다.\n\n예를 들어보자면, 직접 가게에 전화를 하거나 직접 가게로 가 테이크 아웃을 하면 배달비와 수수료가 더 저렴해지거나 아예 없어질수도 있음에도 불구하고 많은 고객들이 배달앱을 통해 주문을하고 배달료와 수수료를 지불한다. \n왜? 편하기 때문이다. 배달앱을 통해 배달주문을 하는것이 번거로웠다면 사람들은 요금을 지불하고 배달앱을 사용했을까?\n\n요즘 돌풍을 일으키고 있는 Chat-GPT를 보면 많은 사람들이 자발적으로 매월 20달러를 결제하고 Chat-GPT Plus로 업그레이드를 하고 있다. \n왜? 이 서비스에 돈을 지불할 가치가 충분하다고 느꼈기 때문이다. \n그리고 Chat-GPT를 사용해본 사람들은 주변 사람들에게 이를 권한다. 즉, 고객들의 입소문을 통해 영업과 마케팅이 진행된다.\n\n제품의 품질을 기반으로 유입과 리텐션이 일어나면 원가가 최적화된다.\n\n항상 Burn Rate와 ROI에 대해 고민할 것\n\n  성공하는 스타트업은 “번 레이트(Burn Rate)”에 예민하다.\n\n\n개발자는 기본적으로 회사에서 개발 업무를 하지만, 그 근본은 비즈니스다. \n그리고 비즈니스는 항상 Cost vs Benefit이다. 개발자의 인건비, 서버비, 사무실 임대료 등 그냥 시간이 흐르는 것만으로도 회사는 막대한 비용을 지불하고 있다.\n\n한 팀에 연봉 3천만원을 받는 직원이 5명 있으면, 아무것도 하지 않고 하루가 지나는 것 만으로 회사는 하루에 약 52만 원 정도의 지출을 하는 셈이다. \n이런 상황에서 어떠한 기능 하나를 개발하기 위해 5일이 걸렸다면 회사는 약 260만원+@의 비용을 지불한 셈이다. \n이렇게 막대한 비용을 들여 기능을 개발했는데 막상 돈은 벌리지 않고, 오히려 해당 기능을 유지보수하기 위해  소중한 인력과 시간이 투입되기 시작하면 손실은 배가되기 시작한다.\n\n그러니까, 때로는 기능을 개발하지 않는 게 더 이득일 때도 있다.\n\nROI를 아주 쉽게 풀어 얘기하면 어떤 업무를 진행했을 때 이 업무의 결과가 과연 우리의 인건비라도 건져줄 수 있는지를 따져보는 것이다.\n\n새로운 수익 아이템을 찾는 것도 물론 매우 중요하지만, 회사의 근간이 되는 제품의 PMF를 먼저 찾고, 그것을 기반으로 수익을 창출하는 것이 스타트업에게는 더 중요하다. \n즉, 스타트업에는 아주 잘 만들어진 제품 하나가 가장 중요하다.\n\n기본이 없는 상태에서 계속 새로운 시도를 해 돈이 부족해지기 시작하면 여유가 없어지고, 여유가 없어지면 올바른 판단을 내리기 어려워진다.\n\n\n  13명의 직원, 1조 원의 가치\n\n\n단기적인 지표만을 위한 업무를 하지 말 것\n기준금리가 낮아 시장에 돈이 많이 풀려있었던 최근까지의 시장의 룰은 규모의 경제였다. \n막대한 자금을 집행해 매출을 크게 일으키면 더 많은 투자를 받는다. \n그리고 다시 모든 자금을 사업에 재 투자하여 더 큰 매출을 일으키고, 다시 더 큰 투자를 받는다. \n이를 반복하며 회사의 몸집을 키우고 BEP를 넘긴다. \n성공하면 IPO를 진행한다.\n\n유니콘이라 불리던 몇몇 기업들은 이러한 방식을 통해 막차를 타는데 성공했다. 하지만 기준금리가 급격하게 오르며 시장의 룰이 바뀌었고, 이제는 투자를 받기 위해서는 실질적인 영업이익을 내고 있는지가 중요해졌다. 그리고 역시 유니콘이라 불리던 몇몇 회사들은 막차를 놓친 상황이기도 하다.\n\n하지만 역설적으로 시장의 룰이 바뀌었으므로 변경 된 룰에 적응해내는 기업들은 더 큰 기회를 얻을 수 있는 상황이다. 이제는 개인과 기업 모두 옥석가리기에 들어갔다.\n\n이러한 상황에 굳이 지표를 보고 일을 한다면, 회사의 모든 구성원이 최종적으로 집중해야 할 지표는 이제는 매출이 아닌 영업이익이다.\n예를 들자면 마케팅팀이 매출을 KPI로 정하고 업무를 진행한다고 가정해보자. \n매출은 비용+이익이므로 비용에 해당하는 마케팅비를 크게 집행하면 매출이 당연히 증대된다. \n하지만 근본적으로 영업이익이 늘어날까? 마케팅비를 줄이면 그 즉시 매출이 떨어질 것이다. \n이러면 마케팅팀은 KPI를 쉽게 달성할 수 있을것이나, 회사 차원에서 보면 이는 유의미한 이득이 되기 어렵다.\n\n즉, 목표와 이니셔티브가 건강한지 고민해봐야 한다.\n\n기본적으로, 개인이 스스로 동기를 부여할 줄 알아야 한다.\n\n경영진이 직원들에게 동기부여를 제공하는 것도 한계가 있기 때문에, 임직원들은 개개인이 확실한 목표를 가지고 자발적인 동기부여를 발휘해야 한다. \n“회사가 더 많은 연봉을 주면 더 열심히 일하겠다”가 아니라 “내가 성장하고 성과를 달성했기 때문에 회사는 나에게 더 투자해야 한다”는 마음가짐이 필요하다.\n\n회사가 나를 연봉 3천만원에 고용했다면, 회사는 내가 1년 동안 3천만원 이상의 이익을 가져다 줄 것을 바랄 것이다. \n그렇지 않다면, 회사는 나를 고용할 이유가 없다. \n연봉이 오르면, 회사의 기대치도 높아진다. \n대부분의 초년생과 일부 경력직들은 이러한 맥락을 이해하지 못한 채, 회사에 입사하여 높은 연봉만을 원한다. \n이런 태도로 스타트업에 입사한다면, 상황이 악화되고, 조직 구조가 조금이라도 변화할 때 구조조정의 대상이 될 가능성이 높아진다.\n\n단순히 돈을 받기 위해 회사를 다니고, 상급자로부터 받은 업무만 처리하는 업무 방식은 스타트업에 적합하지 않다. \n이런 방식은 공무원, 공기업, 은행, 대기업과 같은 보수적인 조직에 어울린다. \n스타트업에 있을 때는 나이, 직급, 직책, 경력, 실력 등에 연연하지 않고 적극적으로 아이디어를 제시하고 주도해야 한다. \n프로페셔널이 되어야 한다. 나의 마음가짐, 실력, 성과가 인정되면 연봉, 스톡옵션, 대우가 따라올 것이다. \n단지 경력만 쌓아서 처우가 좋아지길 원한다면, 호봉제를 실시하는 회사로 가는 것이 좋다. \n이런 맥락을 모르고 스타트업에 입사한다면 처우에 대한 기대는 포기하는 것이 좋다.\n\n스타트업의 가장 큰 장단점 중 하나는 규모가 작고 조직 구조가 명확하지 않다는 것이다(속된말로 체계가 없다). \n역설적으로 이런 특성 덕분에 원하는 일을 자유롭게 할 수 있으며, 수행한 일의 영향이 명확하게 보이고, 그에 대한 피드백이 즉시 이루어진다는 장점도 있다. \n능동적이고 주도적으로 일하는 사람들에게는 이러한 환경이 적합할 수 있다.\n\n솔직히 말하면, 스타트업의 연봉과 복지 등은 대기업에 비해 상대적으로 떨어지는 부분이 많다는 것이 사실이다. \n그러나 급격하게 성장하는 기업에서만 얻을 수 있는 경험, 시장에 대한 통찰력과 민첩함, 그리고 더 나은 미래를 위한 노력이라는 가치를 얻을 수 있다. \n그리고 만약 정말 성공한다면, 스톡옵션을 통해 상당한 차익을 얻을 수도 있다(비록 낮은 확률이지만!). \n이것이 바로 내가 생각하는 스타트업의 가장 큰 장점들이다.\n\n스타트업에서 일하는 동안에는 시장 상황에 주목하면서, 각자가 스타트업에서 얻고자 하는 것이 무엇인지 명확한 목적과 명확한 목표를 세워야 한다. \n그리고 그 목표를 달성하기 위해 강력한 동기부여를 갖춘 채 끊임없이 노력해야 한다.\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2023-03-17-diary-50/"
    },{
      "image": "/assets/img/backend/mysql.png",
      "title": "MySQL 5.7 테이블 리팩토링중 varchar 길이 제한 문제 해결",
      "date": "2023-04-25 00:00:00 +0000",
      "description": "Column length too big for column ‘content’ (max = 16383); use BLOB or TEXT instead\n",
      "content": "\n  현재 상황과 정규화의 중요성\n  TF 상황\n  테이블 정규화\n\n\n현재 상황과 정규화의 중요성\n\n현재 운영 중인 TF에 참여하면서 백오피스(혹은 콘솔 또는 어드민)을 개선하고 있는 애플리케이션에 대해 데이터베이스 읽기에 대한 요구사항이 대부분입니다.\n우리 회사의 레거시 시스템도 데이터베이스에서 시작하며(MySQL 5.7을 사용하고 있습니다), 현재 우리의 데이터베이스에는 큰 문제가 있습니다.\n그 문제는 대부분의 테이블이 제1 정규화도 제대로 되어있지 않다는 것입니다.\n예를 들어 고객, 주문, 결제, 결제내역이라는 도메인이 있다고 가정해봅시다. 이 모든 도메인을 하나의 테이블 A에 몰아넣고, type이라는 열을 추가하고 0(고객), 1(주문), 2(결제), 3(결제내역)과 같이 정의합니다. 그리고 하나의 열에 여러 개의 데이터가 파이프문자(|)로 구분되어 저장됩니다.\n이런 상황에서는 인덱스를 제대로 활용할 수 없어 대부분의 쿼리가 비효율적일 수밖에 없게 됩니다. 특히, 고객 데이터를 조회하기 위해서는 다음과 같은 쿼리를 작성해야 합니다.\n\nSELECT *\nFROM A\nWHERE type = 0;\n\n\n이런 상황에서는 type 열에 인덱스를 걸어도 의미가 없습니다. 왜냐하면 type 열에는 0, 1, 2, 3 이렇게 4개의 값만 들어가기 때문에, 인덱스를 걸어 정렬을 해두어도 type이 0인 모든 데이터를 조회하려면 결국 테이블의 25%를 반드시 읽어야 하기 때문입니다. 이러면 옵티마이저는 테이블 풀스캔이나 인덱스 풀스캔을 선택할 수밖에 없게 됩니다.\n\nAPI의 지연시간을 최소화하기 위해서는 테이블에 액세스했을 때 가져오는 데이터가 최소화되어야 합니다. 그러나 원하는 데이터를 조회하기 위해서는 모든 데이터가 짬뽕되어 있는 특정 테이블을 반드시 조회해야 하고, 액세스 조건이 테이블 풀스캔 또는 인덱스 풀스캔으로 시작되어버리면 가져오는 데이터를 최소화시킬 수 없게 됩니다.\n\n예를 들어, 가입일이 2020-12-31 이후인 고객의 목록을 조회하고 싶다면 다음과 같은 쿼리를 작성해야 합니다.\n\nSELECT *\nFROM A\nWHERE type = 0\n  AND created_at &gt; '2020-12-31';\n\n\n위 쿼리는 액세스 조건인 type = 0이 테이블 풀스캔이나 인덱스 풀스캔으로 시작되어버리기 때문에, 결국 테이블의 25%를 읽어야 합니다. (상황에 따라 옵티마이저가 created_at을 액세스 조건으로 변경할 수도 있습니다.) 이후 created_at 조건이 평가되며, 가입일이 2020-12-31 이후인 데이터를 분류하게 됩니다.\n\n반면, 테이블이 고객, 주문, 결제, 결제내역으로 나뉘어 있었다면(정규화 되어 있었다면), 위 쿼리는 다음과 같이 작성되었을 것이며 성능이 훨씬 더 좋았을 것입니다.\n\nSELECT *\nFROM 고객\nWHERE created_at &gt; '2020-12-31';\n\n\n이러한 방식의 테이블 설계는 현재 우리 회사에서 다음과 같은 문제들을 일으키고 있습니다.\n\n\n  인덱스를 활용한 고성능 쿼리 작성이 어렵습니다. (API의 지연 시간이 느려지는 가장 큰 이유 중 하나)\n  정규화가 되어 있지 않기 때문에 각 테이블의 행렬이 비대해집니다. (코드가 더러워지는 가장 큰 이유 중 하나)\n  \n    \n      \n        \n          확장이 어렵습니다. 예를 들면 고객이 여러 개의 권한을 가질 필요가 있을 때, 고객과 권한이 하나의 테이블로 구성되어 있다면 새로운 권한을 추가하는 것이 불가능합니다. (이런 문제로 파이프문자(\n          )로 여러 개의 데이터가 들어있거나, JSON 열을 추가한 히스토리가 있음)\n        \n      \n    \n  \n\n\nTF 상황\n\n현재 운영 중인 TF에서는 위의 상황으로 인해 단순한 데이터베이스 읽기 요구사항들이 굉장히 어려움을 겪고 있습니다. 단순한 목록을 출력하는 데에도 5초 이상의 시간이 소요되는 경우가 많습니다.\n\n기존 테이블 구조를 변경하지 않고도 쿼리 튜닝으로 해결할 수 있는 부분들은 해결하고 있지만, 도저히 해결할 수 없는 경우도 발생하고 있습니다.\n\n회사 내에는 message라는 이름의 테이블이 있는데, 이 테이블에는 이메일, SMS, 알림톡 등 각종 타입의 코멘트들이 혼재되어 있습니다. 즉, 문자열로 이루어진 콘텐츠가 대부분 혼재되어 있는 행의 수가 4천만 건 이상인 테이블입니다.\n\n특정 데이터를 조회하여 목록에 같이 보여주어야 하는데, 어떻게 해도 만족스러운 성능을 얻을 수 없었습니다.\n\n테이블 정규화\n\n문제가 너무 커지기 때문에 정말로 손대고 싶지 않았지만, 결국 message 테이블에서 관리자들이 작성한 코멘트들을 분리해 별도의 테이블로 정규화하기로 결정했습니다.\n\n새로운 테이블의 DDL은 다음과 같습니다. (이름들이 마음에 들지는 않지만, 기존 시스템과 위화감이 없도록 최대한 그대로 가져갔습니다.)\n\nCREATE TABLE recommendation_admin_memo (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    recommendation_id VARCHAR(36) NOT NULL,\n    writer_id VARCHAR(36) NOT NULL,\n    content VARCHAR(8000) NOT NULL,\n    created_at DATETIME DEFAULT CURRENT_TIMESTAMP NOT NULL,\n    CONSTRAINT recommendation_admin_memo_ibfk_1 FOREIGN KEY (recommendation_id) REFERENCES recommendation (sid),\n    CONSTRAINT recommendation_admin_memo_ibfk_2 FOREIGN KEY (writer_id) REFERENCES account (sid)\n) COMMENT '관리자들이 정보를 공유하기 위해 수업신청서에 작성한 메모';\n\nCREATE INDEX idx_created_at ON recommendation_admin_memo (created_at);\nCREATE INDEX recommendation_id ON recommendation_admin_memo (recommendation_id);\nCREATE INDEX writer ON recommendation_admin_memo (writer_id);\n\n\n그리고 데이터 이관을 위해 다음 쿼리를 실행했습니다.\n\nINSERT INTO recommendation_admin_memo (recommendation_id, writer_id, content, created_at)\nSELECT m.requested_system_sid, m.sender_account_sid, m.content, m.sent_at\nFROM message m\nJOIN account a ON a.sid = m.sender_account_sid\nJOIN recommendation r ON r.sid = m.requested_system_sid\nWHERE m.message_type = 2;\n\n\ncontent의 길이가 너무 길어 varchar(500)에 넣지 못한다는 에러가 발생했습니다.\n\n대체 메모가 얼마나 길길래 500자를 넘어서는지 궁금하여 아래의 쿼리를 실행해보았습니다.\n\nSELECT MAX(LENGTH(m.content))\nFROM message m\nJOIN account a ON a.sid = m.sender_account_sid\nJOIN recommendation r ON r.sid = m.requested_system_sid\nWHERE m.message_type = 2;\n\n\n\n\n많이 놀랐으나 어쨋든 데이터 이관은 해야하니 DDL의 varchar(500)을 varchar(18000)으로 변경하려 하니 이번엔 다음과 같은 에러가 발생했습니다.\n\n[42000][1074] Column length too big for column 'content' (max = 16383); use BLOB or TEXT instead\n\n\nvarchar의 최대 길이는 65,536 정도라고 알고 있었는데, 이러한 결과가 나와서 결국 MySQL 5.7의 공식 문서를 찾아봤습니다.\n\n\n  String Functions and Operators\n  The CHAR and VARCHAR Types\n\n\n문서를 대충 요약하자면, varchar 타입은 65,535 바이트까지 허용되며, length 함수는 문자열의 바이트를 반환한다는 내용입니다.\n\n우리 테이블의 collation은 utf8mb4로 설정되어 있으므로 문자 한개당 4 바이트로 계산됩니다. 에러 메시지의 max값인 16,383이라는 수치에 4를 곱하면 65,532 바이트가 나오죠.\n하지만 16,383을 초과하는 16,384라는 수치에 4를 곱하면 65,536 바이트이기 때문에 varchar 타입이 허용하는 65,535 바이트를 넘어가게 됩니다.\n이쯤에서 varchar 뒤 소괄호에 넣는 값은 단순히 문자열의 길이(문자의 수)를 의미함을 알 수 있었습니다. 즉, varchar(16383)이라는 의미는 16383개의 문자를 넣을 수 있다는 의미죠.\n\n이제 위 length 함수를 사용한 쿼리의 결과인 17,995는 17,995 바이트를 의미함을 알 수 있습니다. 여기서 단순히 4로 나눠 나온 값인 약 4500을 varchar에 적용해 varchar(4500)으로 설정하려고 할 수 있는데요, 맹점이 하나 있습니다.\nlength 함수는 한글, 이모지등의 멀티바이트 문자에 대해서는 정확한 바이트 계산이 되지 않는다는 겁니다. (공식문서) \n관리자들이 작성한 메모는 대부분이 한글이기 때문에, varchar(4500)으로 해도 역시 똑같은 에러가 발생하며 insert 쿼리가 실패하게 됩니다.\n\n관리자들이 작성한 메모들중 가장 긴 메모의 진짜 길이를 알기 위해서는 다음과 같은 쿼리를 작성해야 했습니다.\n\nSELECT MAX(CHARACTER_LENGTH(m.content))\nFROM message m\nJOIN account a ON a.sid = m.sender_account_sid\nJOIN recommendation r ON r.sid = m.requested_system_sid\nWHERE m.message_type = 2;\n\n\n\n\n함수가 length에서 character_length로 바뀌었습니다. 이 함수가 문자의 수를 알려주는 함수입니다.\n이제 content의 타입을 varchar(500)에서 varchar(7691) 이상으로 변경하고 insert 쿼리를 실행해보니 성공적으로 데이터 이관이 완료되었음을 확인할 수 있었습니다.\n\n최종적으로 실행된 DDL은 다음과 같습니다.\n\nCREATE TABLE recommendation_admin_memo (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    recommendation_id VARCHAR(36) NOT NULL,\n    writer_id VARCHAR(36) NOT NULL,\n    content VARCHAR(8000) NOT NULL,\n    created_at DATETIME DEFAULT CURRENT_TIMESTAMP NOT NULL,\n    CONSTRAINT recommendation_admin_memo_ibfk_1 FOREIGN KEY (recommendation_id) REFERENCES recommendation (sid),\n    CONSTRAINT recommendation_admin_memo_ibfk_2 FOREIGN KEY (writer_id) REFERENCES account (sid)\n) COMMENT '관리자들이 정보를 공유하기 위해 수업신청서에 작성한 메모';\n\nCREATE INDEX idx_created_at ON recommendation_admin_memo (created_at);\nCREATE INDEX recommendation_id ON recommendation_admin_memo (recommendation_id);\nCREATE INDEX writer ON recommendation_admin_memo (writer_id);\n\n\n최초에 생각했던 varchar(500)과는 큰 차이가 있는 수치이지만, 기존의 비정상적으로 긴 관리자 메모들을 제거하자니 혹시 모를 꺼림칙함이 있었습니다. 또한, text 타입을 사용하자니 문제가 발생했습니다.\ntext 타입은 기본적으로 char(16383)과 같기 때문에(중간과 큰 크기의 text는 더 큽니다) 실제 문자가 10개라면 이후를 모두 패딩처리하여 저장하므로 메모리가 과도하게 낭비될 수 있는 문제가 있고, 인덱싱이 제한되는 등의 문제가 발생할 수 있습니다.\n그리고 데이터가 과하게 커지게 되면 off-page라고 하는 외부 공간에 저장할수도 있는 위험이 생기게 됩니다.\n\n결국 다른 선택지를 고를 수 없어, 난생 처음으로 varchar에 이렇게 큰 수치의 값을 적용해보는 것을 선택하게 되었습니다. 처음에는 정말로 이렇게 해도 되는 건지 의심스러웠지만, 결국 수행하게 되었습니다.\n\n또한, varchar 숫자의 의미와 length 함수의 맹점에 대해서 더 알아보고, 잘못 알고 있던 정보를 업데이트하게 된 계기가 되었습니다.\n",
      "categories": ["backend","database"],
      "tags": [],
      
      "collection": "posts",
      "url": "/backend/database/2023-04-25-db-4/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "C 레벨의 경이로운 결정과 어이없고 화나는 장애",
      "date": "2023-09-14 00:00:00 +0000",
      "description": "속풀이\n",
      "content": "\n  C 레벨의 경이로운 결정\n  어이없고 화나는 장애\n\n\nC 레벨의 경이로운 결정\n\n우리 회사에 와서 느낀 가장 큰 문제는 시리즈 B에 도달하기까지 6년의 시간동안 회사는 엄청난 기술부채를 축적했다는 것이다.\n\n그래서, 일년동안 기술부채 청산에 대해 노래를 부르고 다니고, 여기저기 많은 설득을 시도했었다.\n일개 팀원이지만 리드 미팅까지 쳐들어가서 우리 회사는 기술부채를 청산하는 게 가장 시급하다는 주장을 펼치기도 했었다.\n\n그러고 있던 와중 최근에 C 레벨에서 믿기 힘든 결정이 내려졌다. 이게 정말 될지는 몰랐는데, 이제부터는 비즈니스를 모두 접고 내실을 다지는 데 총력을 다한다고 한다. 🥺\n\n그동안은 우리 플랫폼 개발팀의 개발자들은 기술부채를 청산하는 데 주력하고 다른 팀의 개발자들은 비즈니스를 진행했는데, 이렇다 보니 많은 혼란이 있었다. \n우리는 하위호환성 문제로 구조를 시원시원하게 갈아엎지 못하고 찔끔찔끔 개선작업을 진행했으며, 다른 팀은 더러운 시스템에 새로운 비즈니스를 진행하면서 기술부채를 계속 늘려갔다. 시스템이 더러우니 아주 당연한 결과다. 그들의 잘못은 절대 없다.\n이제는 수십 명의 개발자를 모두 개발부채 청산에 몰빵한다고 한다. 우리도 이제 기술부채 청산에 온전히 몰두할 수 있는 환경이 조성됐다.\n\n기술부채 청산이 가장 시급하다고 노래를 부르고 다닌 이유는 다름 아니다.\n이제는 개발자들조차 우리 코드를 이해하는 게 불가능에 가까워졌기 때문이다. 개발 일정을 전혀 예상할 수 없으며, 시도때도없이 발생하는 버그들 탓에 원인을 분석하고, 데이터베이스에 쿼리를 수동으로 입력하느라 우리가 해야 할 일을 아예 못하고 있다. \n새로운 개발을 진행하고 나면 다음 개발은 배 이상 느려진다.\n기회는 준비된 자가 잡을 수 있는 법인데, 우리는 준비가 전혀 되지 않은 상태였다. \n이 상태로 미래는 꿈조차 꾸기 어렵다고 생각했다.\n\n그럼에도 불구하고, 사업이란 굉장히 현실적인 문제들이 많이 얽혀있기 때문에 나는 C 레벨에서 이런 결정이 내려질 거라고는 정말 상상도 하지 못했다.\nC 레벨이 이런 결정을 내린다는 것은 그들이 투자자와 주주들의 비판과 비난을 온몸으로 감내해가며 방패막이가 되어주겠다는 결정이라고 생각했기 때문이다.\n나는 C 레벨이 이런 결정을 내린 상황에 대해 굉장히 열렬한 지지를 보낸다. \n아주 옳은 결정이고, 어떻게 보면 생존을 위한 어쩔 수 없는 선택이라고 볼 수도 있겠지만, 엄청난 고난이 예상되는 결정이기 때문에 엄청나게 어려운 선택이었음을 아주 잘 알고 있고, 그 용기가 존경스럽기마저 하다.\n\n어이없고 화나는 장애\n\n데이터베이스가 워낙에 막장이다 보니, 주로 데이터 무결성이 보장되지 않음으로 인한 장애들이 하루에도 수십번씩 발생한다.\n\n고객의 주소와 좌표를 핵심으로 다루는 테이블이 있는데, 주소는 있지만, 좌표가 없는 사례가 아주 많았다.\n그래서 8월 초에 애플리케이션 코드에서 주소는 있는데 좌표가 없다면 좌표를 계산해 데이터베이스에 채워넣는 코드를 작성했었다.\n아주 단순한 코드였고, 메인이 되는 쿼리도 대략 다음과 같이 아주 간단했다.\n\nupdate address set lat = ?, lng = ? where address_guid = ?\n\n\n이게 한 달여가 지난 후인 최근에 굉장히 어이없는 장애를 일으켰는데, 약 34만여 개의 고객 좌표가 엉뚱한 좌표로 변경된 것이다.\n아무리 봐도 딱히 문제가 될게 없어 보여 원인을 알아내는데 약 2시간 정도가 걸렸는데, 알고 보니 이유는 아주 간단했다.\n\naddress_guid가 고유한 값이 아니었던 것이다.\naddress_guid 컬럼에 ＂home＂이라는 문자열이 저장된 데이터가 30만 개 이상 존재했고, 그동안은 위 쿼리의 where 절에 guid가 바인딩 되어 문제가 없다가 어느 날 ＂home＂이 바인딩 되며 30만 개 이상의 데이터가 모두 변경된 것이다.\n\n한참동안 코드를 보며 원인을 찾던 중 설마? 하며 address_guid를 기준으로 group by 쿼리를 입력해본 후 나는 뒤통수를 세게 맞은 느낌과 함께 곧바로 좌절할 수밖에 없었다.\n\n30만개의 데이터를 복구하는데 약 7시간이 소요되었는데, 이 시간 동안 회사의 핵심 시스템이 중단될 수밖에 없었다.\n\n그동안 코드의 함수명이 get~인데, 동작이 이상해 구현을 모조리 까 뒤집어 보니, 실제로 데이터베이스에 update 쿼리를 보낸다거나 하는 식의 함정 카드가 많아 코드의 모든 이름을 믿지 못하고 모든 코드를 DFS하는 상황에 와 있었는데, 이제는 테이블의 스키마조차 믿기 힘든 상황이 되었다.\n\n정말 쉽지 않다.\n",
      "categories": ["diary"],
      "tags": [],
      
      "collection": "posts",
      "url": "/diary/2023-09-14-diary-51/"
    },{
      "image": "/assets/img/debugging/debugging.jpg",
      "title": "전자지급결제서비스",
      "date": "2023-09-17 00:00:00 +0000",
      "description": "전자지급결제서비스를 이해해봅시다\n",
      "content": "\n  지급결제\n  지급결제서비스\n  부가가치통신망 (VAN, Value Added Network)    \n      신용카드 결제 과정        \n          인증\n          승인\n          카드전표매입\n        \n      \n    \n  \n  전자지급결제대행(PG, Payment Gateway)\n  재미있는 자료\n\n\n지급결제\n우리가 쿠팡과 같은 온라인 이커머스 플랫폼에서 \b상품을 구매하는 과정을 떠올려보면, 항상 마지막에는 결제가 일어납니다.\n이 일련의 결제 과정을 지급결제라고 부르고, 지급결제는 내부적으로 굉장히 복잡한 과정을 거치게 되는데요.\n우리가 개발자로서 결제 시스템을 개발하기 위해 결제가 어떤 방식으로 이뤄지는지 잘 알아야 할 필요가 있습니다.\n\n지급결제는 크게 지급, 청산, 결제라는 3가지 과정을 거치는데 이 3가지의 과정은 각각 다음과 같은 의미를 갖습니다.\n\n\n  지급\n    \n      지급인이 채무의 변제를 위해 수취인에게 은행권이나 예금등의 화폐적인 청구권을 이전하는 행위\n      결제까지의 모든 과정이 끝나면 지급이 완료됨\n    \n  \n  청산\n    \n      지급지시의 전송, 확인 혹은 지급지시 간 차감을 통한 포지션을 산정하는 행위를 통해 최종적으로 수취하거나 지급해야 할 차액이 얼마인지를 산정하는 과정\n      우리가 일상생활에서 흔히 사용하는 정산 이라는 용어로 이해해도 큰 문제가 없는 과정\n    \n  \n  결제\n    \n      청산 과정이 끝난 후 마지막으로 한국은행의 거액 결제망인 한은금융망을 통해 지급이 완료되는 단계\n      한국은행에 개설된 지급은행의 당좌예금계좌에서 수취은행의 당좌예금예좌로 화폐가 실제로 이동하면서 경제주체간 채권, 채무의 해소가 완결 됨\n    \n  \n\n\n용어가 생소하고 어려울 수 있는데요, 지금부터 쉬운 예시를 통해 한번 이해해 봅시다.\n채권과 채무라는 용어부터 짚고 넘어갈게요. 우리가 미용실에서 머리를 자르면 미용실은 우리에 대한 채권이 생기고 우리는 미용실에 채무를 지게 됩니다.\n채권과 채무는 어려운게 아니고 각각 돈을 받을 수 있는 권리와 돈을 지불해야 할 의무를 뜻합니다.\n그리고 이것들은 법적으로 보장되게 됩니다.\n\n온라인 결제 시장, 그러니까 위의 예시인 쿠팡을 들어보면 우리가 쿠팡에서 물건을 장바구니에 담고 결제창에 진입해 결제를 하게 되면 쿠팡은 우리에 대한 채권이 생기고 우리는 쿠팡에 대한 채무가 생기게 되는 것이죠.\n이 채무관계를 청산하는 일련의 과정, 그러니까 우리의 계좌에서 돈이 빠져나가고 쿠팡의 계좌에 돈이 입금되는 과정이라고 볼 수 있겠죠? 이 과정을 바로 지급결제라고 부르게 됩니다.\n\n이제 다음 그림을 한번 봅시다.\n\n\n\n지급인은 우리가 되겠고, 수취인은 쿠팡이 되겠죠? 내부적으로는 위와 같은 과정을 통해 화폐의 이동이 이뤄집니다.\n여기서 당좌예금계좌는 수표나 어음 등을 발행할 수 있는 특수한 계좌를 의미하는데, 기업마다 하나씩 가지고 있는 대표 계좌라고 생각하시면 됩니다.\n개인적으로 개발자로서 굳이 깊게 팔만한 내용은 아니라고 생각되는데, 만약 파봤는데 너무 복잡하다면 우리가 일상생활에서 흔히 볼 수 있는 마이너스 통장과 유사한 개념이라고 이해하고 넘어가도 개발하는데 큰 문제는 없을거에요.\n\n지급결제서비스\n\n\n잘 안보인다면 화면을 확대해주세요\n\n지급결제서비스는 위와 같은 흐름으로 이뤄집니다. 그리고 가장 마지막의 금융기관 항목에서 바로 처음 언급한 지급결제가 실질적으로 이뤄지는 것이죠.\n모든 흐름을 완벽하게 알면 너무 좋겠지만 가성비가 떨어지니 차치하고, 여기서 오프라인 결제와 온라인 결제로 나뉘는데 개발자들은 당연히 온라인 결제를 개발하게 될 테니 개발자들이 가장 많이 접하게 되는 부분은 바로 전자지급결제대행, 즉 PG사가 되겠습니다. 그리고 추가로 부가가치통신망, 즉 VAN사를 함께 알아두면 좋겠습니다.\n\n그리고, 이제부터 사장님들과 가맹점은 같은 의미로 사용되는 점을 알아주세요.\n\n부가가치통신망 (VAN, Value Added Network)\n\nVAN사가 없던 옛날에는 각 카드사별로 카드단말기가 상이했기 때문에, 사장님들이 각 카드사에 별도로 가맹하여 직접 가맹점이 되어야 했습니다.\n그래서 옛날에는 각 가게마다 가게 정문에 국민카드\b 결제 됩니다 라는 문구와 함께 국민카드 스티커가 붙어있다던가 하는 경우가 많았습니다.\n상황이 이렇다 보니 사장님들은 여러 카드사의 단말기를 모두 관리해야 하는 문제가 있었죠.\n그리고, 사장님들이 직접 카드전표 제출까지 해야 하다 보니 카드사로부터 상품대금을 정산받는 것도 오래 걸렸다고 합니다. (10년 가까이 자영업을 하고 있는 친동생 피셜입니다)\n\n\n  카드전표매입\n\n  채권자(여기서는 사장님)가 카드사에 채무이행을 하라는 의미로 카드전표(카드영수증, 채권)를 카드사(채무자)에 제출하는데, 카드사에서는 카드전표를 받는다 하여 이 업무를 카드전표매입이라 부릅니다. 카드사는 자신들의 돈으로 우선 사장님에게 화폐를 지불하고, 이후 금융기관에 지급요청을하여 사장님에게서 물건을 사간 고객의 계좌에서 돈을 인출해옵니다.\n\n\nVAN사는 이런 문제를 해결하기 위해 등장했습니다. 그림으로 보면 다음과 같을 것 같아요.\n\n\n\nVAN사는 다음과 같은 일을 합니다.\n\n  카드사를 대신해 가맹점을 모집합니다\n  가맹점에 통합단말기를 설치해줍니다\n  통합단말기를 통해 가맹점과 카드사간의 카드승인중계를 해줍니다\n  카드전표매입을 해줍니다\n\n\n또 어려운 용어들이 튀어나오는데, 실생활 예시를 통해 이해해봅시다.\n\n신용카드 결제 과정\n\n인증\n아래에 후술할 승인이 이뤄지기 위해서는 인증이라는 과정을 거칩니다.\n뭐 별다를게 없고 카드가 유효한지, 한도가 남아있는지 등을 판단하는 것이죠.\n\n승인\n우리가 점심시간에 분식집에 가서 점심을 먹고 카드를 카드단말기에 대 결제를 하고 나오면 휴대폰으로 카드결제가 되었다는 알림이 옵니다.\n이를 승인이 완료됐다고 표현하는데요, 실제로 이 시점에서는 화폐가 단 하나도 이동하지 않았습니다. 채무관계가 발생했고, 채권만 여기저기 오간 상황이죠.\n\n카드전표매입\n손님은 이미 결제를 하고 떠났지만 분식집 사장님은 아직 돈을 한푼도 받지 못한 상황입니다. 단지 채권만 가진 상태이죠.\n사장님은 카드사 가맹점으로서 이제 카드전표를 카드사에 보내고 카드사에서 카드전표에 대한 검토가 완료되고 나서야 돈을 정산받을 수 있습니다.\n옛날에는 사장님들이 이 작업을 수기로 하나하나 하셨다고 해요.\n\n카드사에서는 카드전표를 매입한 후에 카드가 도난된게 아닌지, 이중결제가 되었는지 등의 유효성 검증을 마친 후에 아무런 문제가 없다면 거래를 확정시키고 대금을 사장님들에게 정산해주게 됩니다.\n\n이렇게 복잡한 과정을 거치는 이유는 결국 리스크 관리 차원이 가장 크다고 볼 수 있겠습니다. 이러한 복잡한 절차를 사이에 둠으로써 잘못된 자금 운용이 발생할 리스크를 줄이는것이죠.\n\n하지만 이런 상황은 손님, 사장님들과 카드사 모두에게 좋지 않습니다.\n\n어떤 점이 안 좋을까요?\n\n  손님\n    \n      국민카드만 가지고 있다면 국민카드를 취급하는 가게를 찾아야 합니다\n      위의 상황이 싫다면 각 카드사별로 카드를 여러개 소지하고 다녀야 합니다\n    \n  \n  사장님\n    \n      가맹중인 카드사가 다섯군데라면 다섯개의 카드단말기를 관리해야 합니다\n      가맹중인 카드사가 다섯군데라면 카드전표를 정리해서 다섯군데의 카드사에 카드전표를 제출해야 합니다\n      상품을 팔았지만 상품대금을 정산받는게 늦어집니다 (일련의 과정이 복잡하므로)\n    \n  \n  카드사\n    \n      업무가 많고 복잡해집니다\n      일련의 과정이 복잡해지기 때문에 비용이 커지고, 더 많은 가맹점을 유치하기가 어려워집니다\n      결제가 쉽지 않기 때문에 유입이 적어집니다\n    \n  \n\n\nVAN사는 사장님들과 카드사 사이에서 이러한 문제들을 해결해주고, 카드사에게 직접 수수료를 받습니다.\n이제 손님과 사장님들, 카드사, VAN사가\u001f모두 윈윈하게 되는 것이죠.\n\n어떤 점이 좋아졌을까요?\n\n  손님\n    \n      기존에는 국민카드를 들고 있다면 국민카드 결제가 가능한 가게만 찾아다녀야 했는데, 이제는 아무데나 가도 국민카드로 결제가 됩니다\n      더 이상 여러개의 카드를 들고 다닐 필요가 없습니다\n    \n  \n  사장님\n    \n      이젠 통합단말기(주로 POS기) 하나만 관리하면 됩니다\n      통합단말기에서 카드전표제출 버튼을 한번만 누르면 모든 카드전표제출이 완료됩니다\n      상품대금을 정산받는게 빨라집니다 (23년 기준 빠르면 하루, 늦으면 3일이내)\n    \n  \n  카드사\n    \n      VAN사에서 모든 카드전표를 정리해주니 업무가 확 줄어듭니다\n      업무가 확 줄어드니 정산이 빨리빨리 이뤄지고, 자금 흐름이 빨라집니다\n      VAN사에서 가맹점 유치까지 해줍니다\n      고객 입장에서는 결제하기가 편해지니 유입이 많아지고 카드 결제가 더 많이 일어나게 되어 수수료를 많이 받을 수 있게 됩니다\n      위의 과정을 인력을 채용해 처리하는것보다 VAN사에 약간의 수수료를 지불하고 끝내는것이 더 경제적입니다\n    \n  \n\n\nVAN사는 카드사로부터 수수료를 받으니 역시 좋겠죠?\n\n\n  POS기\n\n  흔히 카드단말기라 하면 그냥 카드를 대는곳만 있는 장치를 떠올릴 수 있는데, POS기는 이 카드단말기에 모니터가 달린 제품을 의미합니다.\n즉, POS기도 카드단말기의 범주에 들어가는 것이죠. 단, POS기는 카드단말기의 역할을 모두 포함하면서, 사용자 친화적인 UI/UX로 사용자의 실수를 줄여주기에\n사장님들이 POS기를 선호하시는 경향이 있습니다.\n\n\n전자지급결제대행(PG, Payment Gateway)\n\n흔히 PG사라고 부릅니다. 영문명에 Gateway(관문)라는 이름이 들어가죠? 이 용어가 PG사의 핵심을 나타내는 용어라고 할 수 있습니다.\n\n위의 내용들을 통해 카드결제가 이뤄지는 흐름을 어느정도 이해했을겁니다.\n위에서는 언급을 하지 않았지만, 사실 카드사는 카드결제를 많이 일으키는 가맹점에는 수수료를 깎아주고 카드결제가 많지 않은 영세한 사장님들에게는 높은 수수료를 받는데요, 이렇다 보니 영세한 사장님들은 높은 카드 수수료의 부담이 있었던 거죠.\n\n이 문제를 해결하기 위해 탄생하는 개념이 바로 PG사입니다. 한 마디로 설명하자면 PG사는 모든 카드 가맹점들의 대표 가맹점이라고 할 수 있습니다.\n카드사가 수수료를 깎아주는 메커니즘을 이용하면 PG사가 많은 가맹점을 유치할수록 가맹점들이 부담해야 할 수수료가 적어지기 때문에, 영세한 가맹점들은 PG사 밑으로 들어가 “우리 대신 대표로 결제해주세요” 를 시전하게 되는 것이죠.\n\b그리고 이렇게 되면 VAN사와 카드사 입장에서는 모든 결제가 이 대표 가맹점(PG사)에 의해 이뤄진것처럼 보여지기 때문에 PG사에 대한 카드사의 수수료가 대폭 깎여나가게 됩니다.\n서버 개발로 비유하면 리버스 프록시(Reverse Proxy)와 아주 유사한 개념이라고 볼 수 있겠습니다.\n\n하지만 PG사는 결국 가맹점이라는 포지션에서 벗어나지 않기 때문에 PG사 역시 VAN사 혹은 카드사와 직접 가맹하게 되며, PG사는 카드사에게 직접 수수료를 받아내는 VAN사와 다르게 오히려 카드사에 수수료를 지불하는 입장이 됩니다. 그래서 하위 가맹점들에게 소정의 수수료를 받게 되죠.\n그런데 이게 사장님들 입장에서는 VAN사랑 거래할때와 다르게PG사랑 거래하니 추가적인 수수료가 생기네? 가 되기 때문에 (그럼에도 불구하고 더 쌉니다!), PG사는 VAN사와 다르게 고객들에게 여러 편의기능들을 더 제공해주게 됩니다. (물론 다른 이유들도 있습니다!)\n\n아무튼 우리 개발자들이 주로 PG사를 접하게 되는 이유도 이 맥락에서 나오는데, 대부분의 PG사가 바로 온라인 결제(전자지급결제서비스)를 지원해주기 때문입니다.\n개발자들 입장에서는 원래라면 각 결제 수단, 결제 채널 등을 모두 고려하여 코드를 작성해야 했을 일이 PG사 하나만 연동하면 모두 끝나게 되는 것이니 제품 개발 기간이 획기적으로 줄어들고, 유지보수도 편리해지게 됩니다.\n\n하지만 위에서 언급한 PG사의 특수성으로 인해 사장님들 입장에서는 VAN사가 아닌 PG사를 거치게 되면 PG사에 수수료를 추가로 지불해야 하기 때문에 업장의 상황에 따라서 오히려 PG사를 거치는것이 손해가 될수도 있게 됩니다. \n이미 카드결제를 많이 일으키고 있어서 카드사로부터 수수료 할인을 많이 받는 입장이라면 굳이 PG사를 거칠 이유가 없는 것이죠. \n오히려 이런 경우에는 본인들이 PG사를 차리는 경우도 있게 됩니다. 왜냐하면, 하위 가맹점들로부터 추가적인 수수료를 더 받을 수 있으니까요. 대표적으로 빅테크들이 자회사로 운용하는 PG사들이 있을 수 있겠죠?\n\n즉, 업장이나 회사의 규모, 거래매출 상황 등에 따라 VAN사와 거래할 것인지 PG사와 거래할 것인지를 잘 따져봐야 할 필요가 있는데요.\nPG사가 태어나게 된 계기가 계기이다 보니 시장의 대부분을 차지하는 영세한 업장의 입장에서는 사실 PG사를 이용하는게 이익일 때가 많겠죠?\n\n재미있는 자료\n\n  페이(Pay)와 신용카드의 동상이몽. 전면전이냐, 공존이냐? (feat. Visa의 전략)\n\n",
      "categories": ["financial"],
      "tags": [],
      
      "collection": "posts",
      "url": "/financial/2023-09-17-financial-1/"
    },{
      
      "title": "<u>BackEnd</u>",
      "date": "2024-03-24 17:42:53 +0000",
      "description": "backend full stack for java\n",
      "content": "\n  Test\n  Java\n  Python\n  Groovy\n  Gradle\n  Database\n  Server Side\n\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "featured_categories",
      "url": "/backend/"
    },{
      
      "title": "<u>Computer Science</u>",
      "date": "2024-03-24 17:42:53 +0000",
      "description": "organize computer science subjects\n",
      "content": "\n  운영체제\n  데이터베이스 구축\n  프로그래밍 활용\n  정보시스템 구축\n  자료구조 &amp; 알고리즘\n\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "featured_categories",
      "url": "/cs/"
    },{
      
      "title": "<u>Debugging</u>",
      "date": "2024-03-24 17:42:53 +0000",
      "description": "development issues and debugging experiences\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "featured_categories",
      "url": "/debugging/"
    },{
      
      "title": "<u>Diary</u>",
      "date": "2024-03-24 17:42:53 +0000",
      "description": "records special events in my daily life\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "featured_categories",
      "url": "/diary/"
    },{
      
      "title": "<u>Financial</u>",
      "date": "2024-03-24 17:42:53 +0000",
      "description": "Understanding the financial domain\n",
      "content": "\n",
      "categories": [],
      "tags": [],
      
      "collection": "featured_categories",
      "url": "/financial/"
    },{
      
      "title": "<u>FrontEnd</u>",
      "date": "2024-03-24 17:42:53 +0000",
      "description": "frontend …\n",
      "content": "\n  Javascript\n  Vue.js\n\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "featured_categories",
      "url": "/frontend/"
    },{
      
      "title": "<u>IDE</u>",
      "date": "2024-03-24 17:42:53 +0000",
      "description": "integrated development environment\n",
      "content": "\n  IntelliJ\n\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "featured_categories",
      "url": "/ide/"
    },{
      
      "title": "<u>Spring</u>",
      "date": "2024-03-24 17:42:53 +0000",
      "description": "spring framework\n",
      "content": "\n  Spring Boot\n  Spring MVC\n  Spring Security\n  Spring Data Jpa\n  Spring Batch\n  Spring WebFlux\n  Spring Cloud\n\n\n",
      "categories": [],
      "tags": [],
      
      "collection": "featured_categories",
      "url": "/spring/"
    }
  ]
}

